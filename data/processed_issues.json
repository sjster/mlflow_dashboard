{"html_url":{"0":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5447","1":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5444","2":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5443","3":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5440","4":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5438","5":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5434","6":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5423","7":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5421","8":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5410","9":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5408","10":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5405","11":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5397","12":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5394","13":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5392","14":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5388","15":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5383","16":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5381","17":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5380","18":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5378","19":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5376","20":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5372","21":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5371","22":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5365","23":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5364","24":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5361","25":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5354","26":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5351","27":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5350","28":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5349","29":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5341","30":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5340","31":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5339","32":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5338","33":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5337","34":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5335","35":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5334","36":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5332","37":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5331","38":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5330","39":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5327","40":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5309","41":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5301","42":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5297","43":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5296","44":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5295","45":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5290","46":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5286","47":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5276","48":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5274","49":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5269","50":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5266","51":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5265","52":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5262","53":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5259","54":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5257","55":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5251","56":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5250","57":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5247","58":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5241","59":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5237","60":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5233","61":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5231","62":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5227","63":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5224","64":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5223","65":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5218","66":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5216","67":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5214","68":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5213","69":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5209","70":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5208","71":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5207","72":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5204","73":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5203","74":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5201","75":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5199","76":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5195","77":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5193","78":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5192","79":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5187","80":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5184","81":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5181","82":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5179","83":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5178","84":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5173","85":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5171","86":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5170","87":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5169","88":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5168","89":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5157","90":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5154","91":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5152","92":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5150","93":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5148","94":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5146","95":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5145","96":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5144","97":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5142","98":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5138","99":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5133","100":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5131","101":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5129","102":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5128","103":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5116","104":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5115","105":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5110","106":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5109","107":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5100","108":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5098","109":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5094","110":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5093","111":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5090","112":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5086","113":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5084","114":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5083","115":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5077","116":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5076","117":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5074","118":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5068","119":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5067","120":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5062","121":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5061","122":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5059","123":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5054","124":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5050","125":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5038","126":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5035","127":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5034","128":"https:\/\/github.com\/mlflow\/mlflow\/issues\/5020","129":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5013","130":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5004","131":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4996","132":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4994","133":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4993","134":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4992","135":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4987","136":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4983","137":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4982","138":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4981","139":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4974","140":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4973","141":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4972","142":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4961","143":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4960","144":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4957","145":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4953","146":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4951","147":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4949","148":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4943","149":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4920","150":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4916","151":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4915","152":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4911","153":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4910","154":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4909","155":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4901","156":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4900","157":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4897","158":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4896","159":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4895","160":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4892","161":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4889","162":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4888","163":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4886","164":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4882","165":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4881","166":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4878","167":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4876","168":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4874","169":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4873","170":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4868","171":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4867","172":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4865","173":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4860","174":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4854","175":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4852","176":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4842","177":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4833","178":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4832","179":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4831","180":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4830","181":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4828","182":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4824","183":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4821","184":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4818","185":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4815","186":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4814","187":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4812","188":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4811","189":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4808","190":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4807","191":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4806","192":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4805","193":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4804","194":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4803","195":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4802","196":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4799","197":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4794","198":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4793","199":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4791","200":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4782","201":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4781","202":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4763","203":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4761","204":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4760","205":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4758","206":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4755","207":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4754","208":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4752","209":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4750","210":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4747","211":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4745","212":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4733","213":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4720","214":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4713","215":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4704","216":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4696","217":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4693","218":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4689","219":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4687","220":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4685","221":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4680","222":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4676","223":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4671","224":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4665","225":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4661","226":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4659","227":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4657","228":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4656","229":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4655","230":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4654","231":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4647","232":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4645","233":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4643","234":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4642","235":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4636","236":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4630","237":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4626","238":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4624","239":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4623","240":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4617","241":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4616","242":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4614","243":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4607","244":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4606","245":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4596","246":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4595","247":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4594","248":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4591","249":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4587","250":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4582","251":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4579","252":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4578","253":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4569","254":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4567","255":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4563","256":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4553","257":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4552","258":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4543","259":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4536","260":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4532","261":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4531","262":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4530","263":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4525","264":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4522","265":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4514","266":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4510","267":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4505","268":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4504","269":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4502","270":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4499","271":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4498","272":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4496","273":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4495","274":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4492","275":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4487","276":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4484","277":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4472","278":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4470","279":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4463","280":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4462","281":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4457","282":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4456","283":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4454","284":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4451","285":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4450","286":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4448","287":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4443","288":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4442","289":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4441","290":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4430","291":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4429","292":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4425","293":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4419","294":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4415","295":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4414","296":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4412","297":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4411","298":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4408","299":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4407","300":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4401","301":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4400","302":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4396","303":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4391","304":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4390","305":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4387","306":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4367","307":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4365","308":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4362","309":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4361","310":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4358","311":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4353","312":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4347","313":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4345","314":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4340","315":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4337","316":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4331","317":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4330","318":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4328","319":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4327","320":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4326","321":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4317","322":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4315","323":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4312","324":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4308","325":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4305","326":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4300","327":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4299","328":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4294","329":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4288","330":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4283","331":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4277","332":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4273","333":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4272","334":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4267","335":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4258","336":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4257","337":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4248","338":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4246","339":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4245","340":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4239","341":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4235","342":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4232","343":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4224","344":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4219","345":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4215","346":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4214","347":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4212","348":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4210","349":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4204","350":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4202","351":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4201","352":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4199","353":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4196","354":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4192","355":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4190","356":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4189","357":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4186","358":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4185","359":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4182","360":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4177","361":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4176","362":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4175","363":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4168","364":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4166","365":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4165","366":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4158","367":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4154","368":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4148","369":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4146","370":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4145","371":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4137","372":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4135","373":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4131","374":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4129","375":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4128","376":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4125","377":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4124","378":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4123","379":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4122","380":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4121","381":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4120","382":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4115","383":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4107","384":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4106","385":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4104","386":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4098","387":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4095","388":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4092","389":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4081","390":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4080","391":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4078","392":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4077","393":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4076","394":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4074","395":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4073","396":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4072","397":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4071","398":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4066","399":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4065","400":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4061","401":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4058","402":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4056","403":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4055","404":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4053","405":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4048","406":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4045","407":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4039","408":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4037","409":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4035","410":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4034","411":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4033","412":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4032","413":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4031","414":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4027","415":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4026","416":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4025","417":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4022","418":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4019","419":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4015","420":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4005","421":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4000","422":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3999","423":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3996","424":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3988","425":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3985","426":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3974","427":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3973","428":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3971","429":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3969","430":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3967","431":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3966","432":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3965","433":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3963","434":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3962","435":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3961","436":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3960","437":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3959","438":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3956","439":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3954","440":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3952","441":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3951","442":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3950","443":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3945","444":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3940","445":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3934","446":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3932","447":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3931","448":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3925","449":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3924","450":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3915","451":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3908","452":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3897","453":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3888","454":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3879","455":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3873","456":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3868","457":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3865","458":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3862","459":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3857","460":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3856","461":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3849","462":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3848","463":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3843","464":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3842","465":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3840","466":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3839","467":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3831","468":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3827","469":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3823","470":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3817","471":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3812","472":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3811","473":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3806","474":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3804","475":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3803","476":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3792","477":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3790","478":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3785","479":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3783","480":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3777","481":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3770","482":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3769","483":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3766","484":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3763","485":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3762","486":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3757","487":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3755","488":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3748","489":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3746","490":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3744","491":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3743","492":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3742","493":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3741","494":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3738","495":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3733","496":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3732","497":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3727","498":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3726","499":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3724","500":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3719","501":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3715","502":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3712","503":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3711","504":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3695","505":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3694","506":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3693","507":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3692","508":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3691","509":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3690","510":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3689","511":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3688","512":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3686","513":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3684","514":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3683","515":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3674","516":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3673","517":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3672","518":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3661","519":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3657","520":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3656","521":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3652","522":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3637","523":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3633","524":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3631","525":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3626","526":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3625","527":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3624","528":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3618","529":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3615","530":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3614","531":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3613","532":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3595","533":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3593","534":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3587","535":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3583","536":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3581","537":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3580","538":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3579","539":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3578","540":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3577","541":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3572","542":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3570","543":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3569","544":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3565","545":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3564","546":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3553","547":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3548","548":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3547","549":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3546","550":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3545","551":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3536","552":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3532","553":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3529","554":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3524","555":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3519","556":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3515","557":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3514","558":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3511","559":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3500","560":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3499","561":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3490","562":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3487","563":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3485","564":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3484","565":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3483","566":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3482","567":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3481","568":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3480","569":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3478","570":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3476","571":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3475","572":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3473","573":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3469","574":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3463","575":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3461","576":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3460","577":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3458","578":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3457","579":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3450","580":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3448","581":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3440","582":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3432","583":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3431","584":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3430","585":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3429","586":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3427","587":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3426","588":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3425","589":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3418","590":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3415","591":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3414","592":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3413","593":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3412","594":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3397","595":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3395","596":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3393","597":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3392","598":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3390","599":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3389","600":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3384","601":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3383","602":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3381","603":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3379","604":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3378","605":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3375","606":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3374","607":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3367","608":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3362","609":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3361","610":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3354","611":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3343","612":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3337","613":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3334","614":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3332","615":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3325","616":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3319","617":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3318","618":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3311","619":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3310","620":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3309","621":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3307","622":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3303","623":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3299","624":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3298","625":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3297","626":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3296","627":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3293","628":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3292","629":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3291","630":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3290","631":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3284","632":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3283","633":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3277","634":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3274","635":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3268","636":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3262","637":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3258","638":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3246","639":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3239","640":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3237","641":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3230","642":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3229","643":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3226","644":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3222","645":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3221","646":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3208","647":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3206","648":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3202","649":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3201","650":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3199","651":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3195","652":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3186","653":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3176","654":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3175","655":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3160","656":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3159","657":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3156","658":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3153","659":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3150","660":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3144","661":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3136","662":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3132","663":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3125","664":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3123","665":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3122","666":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3101","667":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3100","668":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3099","669":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3097","670":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3081","671":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3077","672":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3071","673":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3069","674":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3065","675":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3063","676":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3057","677":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3044","678":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3042","679":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3039","680":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3032","681":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3031","682":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3024","683":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3021","684":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3018","685":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3015","686":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3013","687":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3012","688":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3010","689":"https:\/\/github.com\/mlflow\/mlflow\/issues\/3008","690":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2995","691":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2993","692":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2990","693":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2989","694":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2984","695":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2979","696":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2978","697":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2973","698":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2972","699":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2967","700":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2964","701":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2956","702":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2948","703":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2945","704":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2944","705":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2934","706":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2932","707":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2931","708":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2924","709":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2922","710":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2918","711":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2910","712":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2907","713":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2901","714":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2890","715":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2886","716":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2883","717":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2878","718":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2877","719":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2870","720":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2854","721":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2851","722":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2850","723":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2848","724":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2847","725":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2839","726":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2838","727":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2837","728":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2836","729":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2834","730":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2830","731":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2828","732":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2826","733":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2825","734":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2824","735":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2823","736":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2822","737":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2820","738":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2816","739":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2815","740":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2813","741":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2804","742":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2796","743":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2795","744":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2793","745":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2791","746":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2783","747":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2772","748":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2770","749":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2768","750":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2767","751":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2753","752":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2751","753":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2748","754":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2740","755":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2736","756":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2735","757":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2730","758":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2729","759":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2727","760":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2720","761":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2719","762":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2714","763":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2704","764":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2702","765":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2701","766":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2697","767":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2696","768":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2690","769":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2681","770":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2678","771":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2677","772":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2672","773":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2671","774":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2669","775":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2659","776":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2658","777":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2651","778":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2648","779":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2645","780":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2637","781":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2628","782":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2623","783":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2621","784":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2617","785":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2605","786":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2601","787":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2577","788":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2573","789":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2557","790":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2555","791":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2545","792":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2544","793":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2543","794":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2542","795":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2541","796":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2535","797":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2518","798":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2512","799":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2501","800":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2497","801":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2496","802":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2491","803":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2475","804":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2469","805":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2464","806":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2458","807":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2455","808":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2453","809":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2451","810":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2450","811":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2446","812":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2445","813":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2444","814":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2443","815":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2440","816":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2436","817":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2432","818":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2426","819":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2425","820":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2424","821":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2419","822":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2414","823":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2403","824":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2396","825":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2390","826":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2385","827":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2384","828":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2382","829":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2381","830":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2380","831":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2379","832":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2361","833":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2360","834":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2351","835":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2347","836":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2335","837":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2329","838":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2311","839":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2310","840":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2304","841":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2300","842":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2296","843":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2294","844":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2273","845":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2268","846":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2264","847":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2263","848":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2260","849":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2252","850":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2248","851":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2247","852":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2241","853":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2240","854":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2239","855":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2236","856":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2214","857":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2209","858":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2208","859":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2199","860":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2189","861":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2185","862":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2184","863":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2183","864":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2178","865":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2172","866":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2171","867":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2169","868":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2168","869":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2166","870":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2164","871":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2153","872":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2152","873":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2151","874":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2150","875":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2141","876":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2140","877":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2139","878":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2133","879":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2127","880":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2126","881":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2123","882":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2115","883":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2113","884":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2112","885":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2108","886":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2106","887":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2092","888":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2091","889":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2082","890":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2071","891":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2049","892":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2029","893":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2023","894":"https:\/\/github.com\/mlflow\/mlflow\/issues\/2016","895":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1997","896":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1991","897":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1984","898":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1979","899":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1976","900":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1964","901":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1963","902":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1962","903":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1951","904":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1945","905":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1944","906":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1942","907":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1937","908":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1930","909":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1921","910":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1920","911":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1912","912":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1909","913":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1899","914":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1896","915":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1875","916":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1870","917":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1867","918":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1856","919":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1850","920":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1849","921":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1842","922":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1837","923":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1829","924":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1828","925":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1827","926":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1826","927":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1825","928":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1815","929":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1812","930":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1811","931":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1810","932":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1808","933":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1806","934":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1792","935":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1781","936":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1768","937":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1762","938":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1756","939":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1752","940":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1747","941":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1735","942":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1731","943":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1723","944":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1721","945":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1711","946":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1698","947":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1691","948":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1670","949":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1662","950":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1655","951":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1651","952":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1645","953":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1627","954":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1563","955":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1556","956":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1555","957":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1554","958":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1531","959":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1506","960":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1475","961":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1465","962":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1464","963":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1457","964":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1422","965":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1414","966":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1412","967":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1402","968":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1284","969":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1252","970":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1139","971":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1128","972":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1090","973":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1061","974":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1030","975":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1028","976":"https:\/\/github.com\/mlflow\/mlflow\/issues\/1009","977":"https:\/\/github.com\/mlflow\/mlflow\/pull\/946","978":"https:\/\/github.com\/mlflow\/mlflow\/issues\/925","979":"https:\/\/github.com\/mlflow\/mlflow\/pull\/919","980":"https:\/\/github.com\/mlflow\/mlflow\/issues\/867","981":"https:\/\/github.com\/mlflow\/mlflow\/issues\/866","982":"https:\/\/github.com\/mlflow\/mlflow\/issues\/841","983":"https:\/\/github.com\/mlflow\/mlflow\/issues\/835","984":"https:\/\/github.com\/mlflow\/mlflow\/issues\/834","985":"https:\/\/github.com\/mlflow\/mlflow\/issues\/826","986":"https:\/\/github.com\/mlflow\/mlflow\/issues\/724","987":"https:\/\/github.com\/mlflow\/mlflow\/issues\/569","988":"https:\/\/github.com\/mlflow\/mlflow\/issues\/556","989":"https:\/\/github.com\/mlflow\/mlflow\/issues\/550","990":"https:\/\/github.com\/mlflow\/mlflow\/issues\/482","991":"https:\/\/github.com\/mlflow\/mlflow\/pull\/457","992":"https:\/\/github.com\/mlflow\/mlflow\/issues\/425","993":"https:\/\/github.com\/mlflow\/mlflow\/issues\/421","994":"https:\/\/github.com\/mlflow\/mlflow\/issues\/315","995":"https:\/\/github.com\/mlflow\/mlflow\/issues\/301","996":"https:\/\/github.com\/mlflow\/mlflow\/issues\/269","997":"https:\/\/github.com\/mlflow\/mlflow\/issues\/238","998":"https:\/\/github.com\/mlflow\/mlflow\/issues\/160","999":"https:\/\/github.com\/mlflow\/mlflow\/issues\/105"},"id":{"0":1158285227,"1":1157909633,"2":1157855347,"3":1157371354,"4":1155252484,"5":1154107413,"6":1152588150,"7":1151404707,"8":1150136673,"9":1149825598,"10":1147503263,"11":1145166171,"12":1144033473,"13":1142897742,"14":1141583729,"15":1139285427,"16":1138571630,"17":1138248024,"18":1137855297,"19":1137183207,"20":1133230534,"21":1132744593,"22":1129273287,"23":1128321921,"24":1128071877,"25":1126041737,"26":1125407749,"27":1125236856,"28":1124686556,"29":1121895746,"30":1121877219,"31":1121336299,"32":1121243942,"33":1121055907,"34":1120926253,"35":1120373446,"36":1118683314,"37":1117933615,"38":1117297569,"39":1116034963,"40":1114167000,"41":1112400135,"42":1110670818,"43":1110163405,"44":1109835190,"45":1106810734,"46":1106772100,"47":1105410003,"48":1104817257,"49":1103486711,"50":1102177107,"51":1101756357,"52":1101430020,"53":1100930896,"54":1100235885,"55":1099187621,"56":1098867620,"57":1098301242,"58":1097283926,"59":1096720464,"60":1096128259,"61":1095943305,"62":1095155733,"63":1094903000,"64":1094769623,"65":1094246783,"66":1093104391,"67":1092581035,"68":1092404613,"69":1091085188,"70":1090735322,"71":1090476488,"72":1089527168,"73":1089282048,"74":1088770850,"75":1088547474,"76":1087405915,"77":1086731308,"78":1086415003,"79":1085515508,"80":1084632761,"81":1084226138,"82":1082624048,"83":1082413226,"84":1081465747,"85":1081258821,"86":1081206120,"87":1081069373,"88":1080902898,"89":1077664014,"90":1076147894,"91":1073950375,"92":1073648486,"93":1073316192,"94":1071935121,"95":1071916050,"96":1070859714,"97":1070383315,"98":1069671703,"99":1068793065,"100":1067770230,"101":1067151304,"102":1067117920,"103":1065391967,"104":1065333749,"105":1064756099,"106":1064504920,"107":1062318004,"108":1062125631,"109":1061344393,"110":1060486113,"111":1059718959,"112":1058137841,"113":1057810567,"114":1057342059,"115":1055866608,"116":1055656685,"117":1054854157,"118":1053761667,"119":1053745603,"120":1052534526,"121":1052374133,"122":1051711692,"123":1051470691,"124":1050475569,"125":1049441114,"126":1048739218,"127":1048732550,"128":1047216340,"129":1046080851,"130":1044446966,"131":1043729499,"132":1043245731,"133":1043055416,"134":1042977336,"135":1042608485,"136":1041249806,"137":1041227237,"138":1041046145,"139":1040545003,"140":1040437881,"141":1040388072,"142":1039175700,"143":1039129980,"144":1038695034,"145":1037771560,"146":1037215649,"147":1036686793,"148":1035146204,"149":1032421314,"150":1032118445,"151":1032078312,"152":1031135455,"153":1031076315,"154":1030628145,"155":1026658570,"156":1026320637,"157":1025745261,"158":1025454963,"159":1025128006,"160":1024638296,"161":1023753413,"162":1023705809,"163":1023432828,"164":1021952096,"165":1021935073,"166":1021121968,"167":1020193814,"168":1019232118,"169":1018444357,"170":1015993369,"171":1015440460,"172":1015083506,"173":1013059718,"174":1010697711,"175":1009516422,"176":1005192228,"177":1001447679,"178":1000806656,"179":1000162896,"180":1000042914,"181":999796967,"182":999157213,"183":998883534,"184":998779114,"185":998622920,"186":998318598,"187":997783072,"188":997778736,"189":997447596,"190":997430279,"191":997405248,"192":997237217,"193":997096463,"194":997083674,"195":996878743,"196":995838513,"197":995208690,"198":994536467,"199":993757209,"200":989748340,"201":989680806,"202":986772407,"203":985257249,"204":983500376,"205":983475341,"206":982703190,"207":982502073,"208":981704340,"209":981074407,"210":980395496,"211":980116866,"212":978077806,"213":975855357,"214":974494506,"215":971995643,"216":969368300,"217":968289075,"218":967104028,"219":966675972,"220":966106221,"221":964833837,"222":964539015,"223":963652777,"224":962164245,"225":961868154,"226":961470464,"227":960629670,"228":960510320,"229":960311422,"230":960170894,"231":959616863,"232":959423501,"233":959073987,"234":958897851,"235":958145843,"236":957317083,"237":955887749,"238":955550299,"239":955307859,"240":954622286,"241":954413063,"242":953683471,"243":952947820,"244":952809964,"245":951889938,"246":951827362,"247":951817897,"248":951094661,"249":950084616,"250":949424256,"251":947869083,"252":947661831,"253":946636563,"254":945660912,"255":944993838,"256":942991766,"257":942947690,"258":939963861,"259":938534525,"260":937319867,"261":937221231,"262":936715071,"263":935729674,"264":935203217,"265":933647631,"266":933014671,"267":929952109,"268":929327495,"269":928933501,"270":928609095,"271":928526860,"272":928173686,"273":927878197,"274":926451620,"275":925918191,"276":925407532,"277":924361204,"278":923791871,"279":922233944,"280":922102058,"281":921507760,"282":921201521,"283":920944043,"284":919745552,"285":919588497,"286":917551612,"287":916725171,"288":916657376,"289":916299601,"290":913397067,"291":913376032,"292":910691497,"293":909641705,"294":909118314,"295":908062100,"296":906656886,"297":906436418,"298":905965097,"299":905348529,"300":903927965,"301":903430706,"302":902616283,"303":901029797,"304":900609595,"305":899631043,"306":893194774,"307":893112854,"308":892284748,"309":891327881,"310":890926866,"311":890814942,"312":889867116,"313":888201552,"314":882627823,"315":879568761,"316":879019523,"317":878787537,"318":878645578,"319":878618818,"320":878424538,"321":877720722,"322":877061431,"323":876033678,"324":875035514,"325":872677331,"326":870357436,"327":870078773,"328":868866449,"329":866458370,"330":865454193,"331":864155570,"332":863345133,"333":863300715,"334":862596411,"335":860774294,"336":860725292,"337":857692330,"338":857177374,"339":857096561,"340":855744654,"341":854831722,"342":853891052,"343":849494153,"344":846492961,"345":844650196,"346":844444139,"347":843827409,"348":843391996,"349":841654667,"350":840494386,"351":840006925,"352":839945260,"353":838069841,"354":837822715,"355":837145393,"356":837123901,"357":835590289,"358":834010009,"359":833302621,"360":831936002,"361":831486481,"362":831105313,"363":826694308,"364":826158768,"365":825284030,"366":821304972,"367":819404390,"368":817764569,"369":817653101,"370":817019542,"371":815291099,"372":814462836,"373":813836665,"374":812758749,"375":812756792,"376":812477986,"377":812389235,"378":812176928,"379":812172646,"380":812162488,"381":812105286,"382":811496030,"383":810473182,"384":810084621,"385":808341832,"386":807055908,"387":806740438,"388":806443004,"389":804384346,"390":804062954,"391":803814984,"392":803699793,"393":803669365,"394":803199220,"395":802939644,"396":802786662,"397":802572068,"398":801355552,"399":801240460,"400":801099950,"401":800884489,"402":800566182,"403":800411814,"404":799956139,"405":799635328,"406":799438776,"407":798473880,"408":798264288,"409":796664838,"410":796363515,"411":796161869,"412":796108618,"413":796010448,"414":795208074,"415":794953499,"416":794895720,"417":794516963,"418":793021431,"419":792298315,"420":791000927,"421":789350188,"422":789342876,"423":788217433,"424":786868652,"425":786526859,"426":784591403,"427":784585701,"428":784501473,"429":784469291,"430":783958253,"431":783603556,"432":783333781,"433":782623937,"434":782385355,"435":782302955,"436":782152142,"437":782020122,"438":781813843,"439":781371505,"440":781048134,"441":780970103,"442":780627177,"443":779482519,"444":777992530,"445":777543397,"446":777476934,"447":777271638,"448":776552161,"449":776549213,"450":775153855,"451":774552371,"452":773278435,"453":772594944,"454":771438742,"455":771272208,"456":770678181,"457":770510676,"458":769941282,"459":769207812,"460":768960766,"461":767585606,"462":767431520,"463":767151833,"464":767134699,"465":766846438,"466":766817589,"467":766154248,"468":765883142,"469":763102150,"470":762411719,"471":761235170,"472":761145598,"473":760762775,"474":760435346,"475":760322754,"476":758835445,"477":758681387,"478":757938301,"479":757695934,"480":756293797,"481":755750865,"482":755748671,"483":755511048,"484":755294675,"485":755284144,"486":754628185,"487":753971641,"488":753137708,"489":752943392,"490":752198743,"491":752196160,"492":752055314,"493":752050957,"494":751493139,"495":749750667,"496":749740178,"497":748477172,"498":747983207,"499":746984101,"500":746257784,"501":745838028,"502":745433410,"503":745096753,"504":743316394,"505":743310606,"506":743260553,"507":742968499,"508":742955119,"509":742802955,"510":742748939,"511":742731520,"512":742602547,"513":742446672,"514":742356847,"515":741026517,"516":740955066,"517":740742994,"518":739793374,"519":739056082,"520":739055904,"521":738698857,"522":736025474,"523":735847179,"524":735684837,"525":735343514,"526":735321262,"527":735181360,"528":734631729,"529":734052134,"530":734042954,"531":733829761,"532":728979869,"533":728858075,"534":728176818,"535":727989150,"536":727742401,"537":727736404,"538":727656339,"539":727648167,"540":727639122,"541":726868371,"542":726532431,"543":726441555,"544":726371416,"545":726365790,"546":725209625,"547":724546445,"548":724487863,"549":724387921,"550":724297633,"551":722446643,"552":721737511,"553":721258949,"554":720915310,"555":719844411,"556":719342655,"557":719342142,"558":718476922,"559":716537582,"560":716142477,"561":714134030,"562":713538921,"563":712943207,"564":712905671,"565":712664810,"566":712560360,"567":712497228,"568":712487550,"569":712368939,"570":712065674,"571":712065618,"572":711672400,"573":711051365,"574":709073117,"575":708817643,"576":708815134,"577":708524132,"578":708450662,"579":706752071,"580":706233014,"581":704858070,"582":703916666,"583":703912967,"584":703895678,"585":703577316,"586":702698694,"587":702623245,"588":701631648,"589":701034874,"590":699599567,"591":699567687,"592":699387493,"593":699375679,"594":695171306,"595":695121230,"596":694306497,"597":694152349,"598":693409991,"599":693406980,"600":692044234,"601":692027692,"602":691756061,"603":691425307,"604":690978243,"605":690120683,"606":690106651,"607":689315495,"608":688565598,"609":688470666,"610":688225159,"611":687220159,"612":686345125,"613":686220969,"614":686146864,"615":685127736,"616":684941506,"617":684735373,"618":684057035,"619":684041826,"620":684013924,"621":683910847,"622":683225058,"623":682550288,"624":682337354,"625":682226104,"626":682005198,"627":680842791,"628":680841565,"629":680831874,"630":680551195,"631":679709404,"632":679707482,"633":679385177,"634":679077672,"635":678676391,"636":678061545,"637":676854134,"638":675820001,"639":674911263,"640":674570176,"641":673229449,"642":673113574,"643":672694262,"644":672389786,"645":672383169,"646":669982737,"647":669759024,"648":669195707,"649":669191812,"650":669122064,"651":668221443,"652":667428687,"653":666197998,"654":666018042,"655":664202757,"656":664195832,"657":663864872,"658":663645541,"659":663569958,"660":662767302,"661":661815449,"662":661106151,"663":659381920,"664":659331704,"665":659205736,"666":656987489,"667":656894326,"668":656761504,"669":656359252,"670":654176422,"671":653823881,"672":653040411,"673":652850814,"674":652787140,"675":652524427,"676":651787044,"677":650655077,"678":650502785,"679":650034584,"680":649066044,"681":648909570,"682":647994614,"683":647640147,"684":647557135,"685":647487895,"686":646996753,"687":646800325,"688":646207064,"689":645728363,"690":644405207,"691":644346399,"692":643532277,"693":643174485,"694":642747918,"695":642529381,"696":642472172,"697":641934549,"698":641871490,"699":641616572,"700":641473159,"701":640700612,"702":640082855,"703":639777309,"704":639375059,"705":638884237,"706":638267502,"707":637956286,"708":637376675,"709":636847196,"710":635459441,"711":634692583,"712":632666641,"713":630636637,"714":626585949,"715":626249674,"716":625055531,"717":623704450,"718":623604297,"719":622885675,"720":620515963,"721":620289821,"722":620281513,"723":619962907,"724":619915709,"725":619259953,"726":619065192,"727":619003888,"728":619001539,"729":618981674,"730":618588765,"731":618525858,"732":618052693,"733":618031355,"734":617971575,"735":617812720,"736":617399265,"737":617116674,"738":616608449,"739":616456542,"740":616338251,"741":615003656,"742":614161800,"743":614159300,"744":613830567,"745":613404280,"746":611807016,"747":610320070,"748":609723556,"749":609312235,"750":609162927,"751":607145931,"752":607112035,"753":606005350,"754":604397553,"755":603380430,"756":603038641,"757":602436983,"758":602393683,"759":602204704,"760":601369476,"761":601362054,"762":601209826,"763":599949102,"764":599537748,"765":599336867,"766":599114381,"767":599103983,"768":598432725,"769":596580856,"770":595964977,"771":595657109,"772":594323790,"773":594196692,"774":594091767,"775":592575984,"776":592513822,"777":590596110,"778":589834211,"779":589282571,"780":587803635,"781":586980553,"782":586358804,"783":585823239,"784":585381454,"785":584140148,"786":583670803,"787":579955181,"788":579562413,"789":577201712,"790":576766527,"791":575858935,"792":575828962,"793":575788153,"794":575720863,"795":575587374,"796":574513842,"797":573562956,"798":573343121,"799":572170497,"800":571847302,"801":571620922,"802":571208245,"803":570609030,"804":570085045,"805":569593119,"806":569228082,"807":568545572,"808":568341564,"809":568029846,"810":568005461,"811":567843031,"812":567705108,"813":567691424,"814":567657793,"815":567408664,"816":566777384,"817":565387025,"818":564414012,"819":564407737,"820":564190776,"821":563271980,"822":562687037,"823":561893195,"824":560818386,"825":560377780,"826":559402111,"827":559341115,"828":559300905,"829":559089983,"830":558963576,"831":558955034,"832":557457030,"833":557444993,"834":556242257,"835":555717549,"836":553446389,"837":552715998,"838":550163797,"839":549972658,"840":549633529,"841":549086527,"842":548518457,"843":548509800,"844":546684686,"845":545957881,"846":545727936,"847":545250269,"848":545084838,"849":543911441,"850":542943564,"851":542938823,"852":542557818,"853":542190578,"854":541676125,"855":540444204,"856":539095024,"857":538376464,"858":538373129,"859":537334861,"860":536448169,"861":535810780,"862":535715312,"863":535421175,"864":534865331,"865":533613695,"866":533350936,"867":532975695,"868":532958737,"869":532840326,"870":532588861,"871":530512176,"872":530443270,"873":530294948,"874":529541799,"875":528689703,"876":528563364,"877":528414719,"878":527687058,"879":526482156,"880":526324739,"881":525894718,"882":524858254,"883":524548098,"884":524463555,"885":524119333,"886":523829649,"887":522532118,"888":522080628,"889":521564800,"890":520413712,"891":518639312,"892":515313601,"893":514688299,"894":514085620,"895":512825990,"896":512408041,"897":511891949,"898":511278106,"899":510908420,"900":509907642,"901":509805341,"902":509544054,"903":509018434,"904":508076564,"905":507725624,"906":507477799,"907":506635728,"908":506307260,"909":505115838,"910":505081933,"911":504289118,"912":503364358,"913":501767339,"914":501574832,"915":497750868,"916":497346660,"917":496650463,"918":495221232,"919":494704576,"920":494646803,"921":493106903,"922":492569457,"923":491639454,"924":491349506,"925":491081407,"926":491071925,"927":491043305,"928":489689950,"929":489199494,"930":489119608,"931":489073650,"932":488954458,"933":488318354,"934":486523464,"935":485261373,"936":483231665,"937":482642360,"938":481991414,"939":481722051,"940":481428819,"941":480437671,"942":479868070,"943":479406571,"944":479299967,"945":478337265,"946":476708053,"947":476106086,"948":473367056,"949":472398095,"950":471949569,"951":471552125,"952":471055438,"953":469959486,"954":466207742,"955":465359075,"956":465307105,"957":465302024,"958":462314517,"959":460669248,"960":458091258,"961":457106136,"962":456963121,"963":456504041,"964":453677009,"965":453110626,"966":452999107,"967":452450600,"968":444985697,"969":443098217,"970":435031672,"971":433396265,"972":428541539,"973":427149411,"974":424173089,"975":424150477,"976":421944087,"977":416867517,"978":414594096,"979":414008645,"980":406403860,"981":406401567,"982":402815616,"983":402367300,"984":402366615,"985":401484960,"986":382887716,"987":365004545,"988":364088612,"989":363632386,"990":359804676,"991":358690585,"992":356683327,"993":356141795,"994":351504495,"995":350541893,"996":348804741,"997":347510467,"998":341648665,"999":337117936},"number":{"0":5447,"1":5444,"2":5443,"3":5440,"4":5438,"5":5434,"6":5423,"7":5421,"8":5410,"9":5408,"10":5405,"11":5397,"12":5394,"13":5392,"14":5388,"15":5383,"16":5381,"17":5380,"18":5378,"19":5376,"20":5372,"21":5371,"22":5365,"23":5364,"24":5361,"25":5354,"26":5351,"27":5350,"28":5349,"29":5341,"30":5340,"31":5339,"32":5338,"33":5337,"34":5335,"35":5334,"36":5332,"37":5331,"38":5330,"39":5327,"40":5309,"41":5301,"42":5297,"43":5296,"44":5295,"45":5290,"46":5286,"47":5276,"48":5274,"49":5269,"50":5266,"51":5265,"52":5262,"53":5259,"54":5257,"55":5251,"56":5250,"57":5247,"58":5241,"59":5237,"60":5233,"61":5231,"62":5227,"63":5224,"64":5223,"65":5218,"66":5216,"67":5214,"68":5213,"69":5209,"70":5208,"71":5207,"72":5204,"73":5203,"74":5201,"75":5199,"76":5195,"77":5193,"78":5192,"79":5187,"80":5184,"81":5181,"82":5179,"83":5178,"84":5173,"85":5171,"86":5170,"87":5169,"88":5168,"89":5157,"90":5154,"91":5152,"92":5150,"93":5148,"94":5146,"95":5145,"96":5144,"97":5142,"98":5138,"99":5133,"100":5131,"101":5129,"102":5128,"103":5116,"104":5115,"105":5110,"106":5109,"107":5100,"108":5098,"109":5094,"110":5093,"111":5090,"112":5086,"113":5084,"114":5083,"115":5077,"116":5076,"117":5074,"118":5068,"119":5067,"120":5062,"121":5061,"122":5059,"123":5054,"124":5050,"125":5038,"126":5035,"127":5034,"128":5020,"129":5013,"130":5004,"131":4996,"132":4994,"133":4993,"134":4992,"135":4987,"136":4983,"137":4982,"138":4981,"139":4974,"140":4973,"141":4972,"142":4961,"143":4960,"144":4957,"145":4953,"146":4951,"147":4949,"148":4943,"149":4920,"150":4916,"151":4915,"152":4911,"153":4910,"154":4909,"155":4901,"156":4900,"157":4897,"158":4896,"159":4895,"160":4892,"161":4889,"162":4888,"163":4886,"164":4882,"165":4881,"166":4878,"167":4876,"168":4874,"169":4873,"170":4868,"171":4867,"172":4865,"173":4860,"174":4854,"175":4852,"176":4842,"177":4833,"178":4832,"179":4831,"180":4830,"181":4828,"182":4824,"183":4821,"184":4818,"185":4815,"186":4814,"187":4812,"188":4811,"189":4808,"190":4807,"191":4806,"192":4805,"193":4804,"194":4803,"195":4802,"196":4799,"197":4794,"198":4793,"199":4791,"200":4782,"201":4781,"202":4763,"203":4761,"204":4760,"205":4758,"206":4755,"207":4754,"208":4752,"209":4750,"210":4747,"211":4745,"212":4733,"213":4720,"214":4713,"215":4704,"216":4696,"217":4693,"218":4689,"219":4687,"220":4685,"221":4680,"222":4676,"223":4671,"224":4665,"225":4661,"226":4659,"227":4657,"228":4656,"229":4655,"230":4654,"231":4647,"232":4645,"233":4643,"234":4642,"235":4636,"236":4630,"237":4626,"238":4624,"239":4623,"240":4617,"241":4616,"242":4614,"243":4607,"244":4606,"245":4596,"246":4595,"247":4594,"248":4591,"249":4587,"250":4582,"251":4579,"252":4578,"253":4569,"254":4567,"255":4563,"256":4553,"257":4552,"258":4543,"259":4536,"260":4532,"261":4531,"262":4530,"263":4525,"264":4522,"265":4514,"266":4510,"267":4505,"268":4504,"269":4502,"270":4499,"271":4498,"272":4496,"273":4495,"274":4492,"275":4487,"276":4484,"277":4472,"278":4470,"279":4463,"280":4462,"281":4457,"282":4456,"283":4454,"284":4451,"285":4450,"286":4448,"287":4443,"288":4442,"289":4441,"290":4430,"291":4429,"292":4425,"293":4419,"294":4415,"295":4414,"296":4412,"297":4411,"298":4408,"299":4407,"300":4401,"301":4400,"302":4396,"303":4391,"304":4390,"305":4387,"306":4367,"307":4365,"308":4362,"309":4361,"310":4358,"311":4353,"312":4347,"313":4345,"314":4340,"315":4337,"316":4331,"317":4330,"318":4328,"319":4327,"320":4326,"321":4317,"322":4315,"323":4312,"324":4308,"325":4305,"326":4300,"327":4299,"328":4294,"329":4288,"330":4283,"331":4277,"332":4273,"333":4272,"334":4267,"335":4258,"336":4257,"337":4248,"338":4246,"339":4245,"340":4239,"341":4235,"342":4232,"343":4224,"344":4219,"345":4215,"346":4214,"347":4212,"348":4210,"349":4204,"350":4202,"351":4201,"352":4199,"353":4196,"354":4192,"355":4190,"356":4189,"357":4186,"358":4185,"359":4182,"360":4177,"361":4176,"362":4175,"363":4168,"364":4166,"365":4165,"366":4158,"367":4154,"368":4148,"369":4146,"370":4145,"371":4137,"372":4135,"373":4131,"374":4129,"375":4128,"376":4125,"377":4124,"378":4123,"379":4122,"380":4121,"381":4120,"382":4115,"383":4107,"384":4106,"385":4104,"386":4098,"387":4095,"388":4092,"389":4081,"390":4080,"391":4078,"392":4077,"393":4076,"394":4074,"395":4073,"396":4072,"397":4071,"398":4066,"399":4065,"400":4061,"401":4058,"402":4056,"403":4055,"404":4053,"405":4048,"406":4045,"407":4039,"408":4037,"409":4035,"410":4034,"411":4033,"412":4032,"413":4031,"414":4027,"415":4026,"416":4025,"417":4022,"418":4019,"419":4015,"420":4005,"421":4000,"422":3999,"423":3996,"424":3988,"425":3985,"426":3974,"427":3973,"428":3971,"429":3969,"430":3967,"431":3966,"432":3965,"433":3963,"434":3962,"435":3961,"436":3960,"437":3959,"438":3956,"439":3954,"440":3952,"441":3951,"442":3950,"443":3945,"444":3940,"445":3934,"446":3932,"447":3931,"448":3925,"449":3924,"450":3915,"451":3908,"452":3897,"453":3888,"454":3879,"455":3873,"456":3868,"457":3865,"458":3862,"459":3857,"460":3856,"461":3849,"462":3848,"463":3843,"464":3842,"465":3840,"466":3839,"467":3831,"468":3827,"469":3823,"470":3817,"471":3812,"472":3811,"473":3806,"474":3804,"475":3803,"476":3792,"477":3790,"478":3785,"479":3783,"480":3777,"481":3770,"482":3769,"483":3766,"484":3763,"485":3762,"486":3757,"487":3755,"488":3748,"489":3746,"490":3744,"491":3743,"492":3742,"493":3741,"494":3738,"495":3733,"496":3732,"497":3727,"498":3726,"499":3724,"500":3719,"501":3715,"502":3712,"503":3711,"504":3695,"505":3694,"506":3693,"507":3692,"508":3691,"509":3690,"510":3689,"511":3688,"512":3686,"513":3684,"514":3683,"515":3674,"516":3673,"517":3672,"518":3661,"519":3657,"520":3656,"521":3652,"522":3637,"523":3633,"524":3631,"525":3626,"526":3625,"527":3624,"528":3618,"529":3615,"530":3614,"531":3613,"532":3595,"533":3593,"534":3587,"535":3583,"536":3581,"537":3580,"538":3579,"539":3578,"540":3577,"541":3572,"542":3570,"543":3569,"544":3565,"545":3564,"546":3553,"547":3548,"548":3547,"549":3546,"550":3545,"551":3536,"552":3532,"553":3529,"554":3524,"555":3519,"556":3515,"557":3514,"558":3511,"559":3500,"560":3499,"561":3490,"562":3487,"563":3485,"564":3484,"565":3483,"566":3482,"567":3481,"568":3480,"569":3478,"570":3476,"571":3475,"572":3473,"573":3469,"574":3463,"575":3461,"576":3460,"577":3458,"578":3457,"579":3450,"580":3448,"581":3440,"582":3432,"583":3431,"584":3430,"585":3429,"586":3427,"587":3426,"588":3425,"589":3418,"590":3415,"591":3414,"592":3413,"593":3412,"594":3397,"595":3395,"596":3393,"597":3392,"598":3390,"599":3389,"600":3384,"601":3383,"602":3381,"603":3379,"604":3378,"605":3375,"606":3374,"607":3367,"608":3362,"609":3361,"610":3354,"611":3343,"612":3337,"613":3334,"614":3332,"615":3325,"616":3319,"617":3318,"618":3311,"619":3310,"620":3309,"621":3307,"622":3303,"623":3299,"624":3298,"625":3297,"626":3296,"627":3293,"628":3292,"629":3291,"630":3290,"631":3284,"632":3283,"633":3277,"634":3274,"635":3268,"636":3262,"637":3258,"638":3246,"639":3239,"640":3237,"641":3230,"642":3229,"643":3226,"644":3222,"645":3221,"646":3208,"647":3206,"648":3202,"649":3201,"650":3199,"651":3195,"652":3186,"653":3176,"654":3175,"655":3160,"656":3159,"657":3156,"658":3153,"659":3150,"660":3144,"661":3136,"662":3132,"663":3125,"664":3123,"665":3122,"666":3101,"667":3100,"668":3099,"669":3097,"670":3081,"671":3077,"672":3071,"673":3069,"674":3065,"675":3063,"676":3057,"677":3044,"678":3042,"679":3039,"680":3032,"681":3031,"682":3024,"683":3021,"684":3018,"685":3015,"686":3013,"687":3012,"688":3010,"689":3008,"690":2995,"691":2993,"692":2990,"693":2989,"694":2984,"695":2979,"696":2978,"697":2973,"698":2972,"699":2967,"700":2964,"701":2956,"702":2948,"703":2945,"704":2944,"705":2934,"706":2932,"707":2931,"708":2924,"709":2922,"710":2918,"711":2910,"712":2907,"713":2901,"714":2890,"715":2886,"716":2883,"717":2878,"718":2877,"719":2870,"720":2854,"721":2851,"722":2850,"723":2848,"724":2847,"725":2839,"726":2838,"727":2837,"728":2836,"729":2834,"730":2830,"731":2828,"732":2826,"733":2825,"734":2824,"735":2823,"736":2822,"737":2820,"738":2816,"739":2815,"740":2813,"741":2804,"742":2796,"743":2795,"744":2793,"745":2791,"746":2783,"747":2772,"748":2770,"749":2768,"750":2767,"751":2753,"752":2751,"753":2748,"754":2740,"755":2736,"756":2735,"757":2730,"758":2729,"759":2727,"760":2720,"761":2719,"762":2714,"763":2704,"764":2702,"765":2701,"766":2697,"767":2696,"768":2690,"769":2681,"770":2678,"771":2677,"772":2672,"773":2671,"774":2669,"775":2659,"776":2658,"777":2651,"778":2648,"779":2645,"780":2637,"781":2628,"782":2623,"783":2621,"784":2617,"785":2605,"786":2601,"787":2577,"788":2573,"789":2557,"790":2555,"791":2545,"792":2544,"793":2543,"794":2542,"795":2541,"796":2535,"797":2518,"798":2512,"799":2501,"800":2497,"801":2496,"802":2491,"803":2475,"804":2469,"805":2464,"806":2458,"807":2455,"808":2453,"809":2451,"810":2450,"811":2446,"812":2445,"813":2444,"814":2443,"815":2440,"816":2436,"817":2432,"818":2426,"819":2425,"820":2424,"821":2419,"822":2414,"823":2403,"824":2396,"825":2390,"826":2385,"827":2384,"828":2382,"829":2381,"830":2380,"831":2379,"832":2361,"833":2360,"834":2351,"835":2347,"836":2335,"837":2329,"838":2311,"839":2310,"840":2304,"841":2300,"842":2296,"843":2294,"844":2273,"845":2268,"846":2264,"847":2263,"848":2260,"849":2252,"850":2248,"851":2247,"852":2241,"853":2240,"854":2239,"855":2236,"856":2214,"857":2209,"858":2208,"859":2199,"860":2189,"861":2185,"862":2184,"863":2183,"864":2178,"865":2172,"866":2171,"867":2169,"868":2168,"869":2166,"870":2164,"871":2153,"872":2152,"873":2151,"874":2150,"875":2141,"876":2140,"877":2139,"878":2133,"879":2127,"880":2126,"881":2123,"882":2115,"883":2113,"884":2112,"885":2108,"886":2106,"887":2092,"888":2091,"889":2082,"890":2071,"891":2049,"892":2029,"893":2023,"894":2016,"895":1997,"896":1991,"897":1984,"898":1979,"899":1976,"900":1964,"901":1963,"902":1962,"903":1951,"904":1945,"905":1944,"906":1942,"907":1937,"908":1930,"909":1921,"910":1920,"911":1912,"912":1909,"913":1899,"914":1896,"915":1875,"916":1870,"917":1867,"918":1856,"919":1850,"920":1849,"921":1842,"922":1837,"923":1829,"924":1828,"925":1827,"926":1826,"927":1825,"928":1815,"929":1812,"930":1811,"931":1810,"932":1808,"933":1806,"934":1792,"935":1781,"936":1768,"937":1762,"938":1756,"939":1752,"940":1747,"941":1735,"942":1731,"943":1723,"944":1721,"945":1711,"946":1698,"947":1691,"948":1670,"949":1662,"950":1655,"951":1651,"952":1645,"953":1627,"954":1563,"955":1556,"956":1555,"957":1554,"958":1531,"959":1506,"960":1475,"961":1465,"962":1464,"963":1457,"964":1422,"965":1414,"966":1412,"967":1402,"968":1284,"969":1252,"970":1139,"971":1128,"972":1090,"973":1061,"974":1030,"975":1028,"976":1009,"977":946,"978":925,"979":919,"980":867,"981":866,"982":841,"983":835,"984":834,"985":826,"986":724,"987":569,"988":556,"989":550,"990":482,"991":457,"992":425,"993":421,"994":315,"995":301,"996":269,"997":238,"998":160,"999":105},"title":{"0":"Improve infer model type method for default evaluator.","1":"[WIP] Remove mlflow.keras.autolog()","2":"Create index on `run_uuid` columns for PostgreSQL to improve SQL operations","3":"[BUG] Security Vulnerability","4":"Add ENV variables to control GCS upload\/download chunk size and timeouts","5":"Prototype restoring model dependencies for `pyfunc.load_model` and `pyfunc.spark_udf`","6":"Discussion: How should I save my object detection.pt weights in mlflow?","7":"chore: Use pickle by default when saving Scikit-learn models","8":"[Feature Request] HTML support image in Artifacts","9":"[BUG] fastai pyfunc implementation doesn't support multiclass classification or models returning probabilities","10":"[Custom Metrics] Artifact type detection and logging","11":"[Feature Request] show multiple plots in Tracking UI","12":"[do-not-merge] Pseudo code for SparkML model logging with disabled DBFS root","13":"Mlflow & vertex AI integration","14":"Tracking experiments on both file and db backed tracking servers.","15":"[FR] Allow user to download metrics data as csv","16":"[FR] Add a timeout argument in model serve (scoring server)","17":"Add virtualenv support for MLflow Models","18":"Introducing abstract endpoint methods","19":"ModelInfo should contain registered model version[FR]","20":"[BUG] mlflow.sklearn.log_model raises TypeError: expected string or bytes-like object","21":"Inject MLProject environment variables to the Docker image when running on Kubernetes","22":"[BUG] Extra run results (past 100), loaded with the \"Load more\" button, disappear as soon as you sort runs by a column.","23":"[BUG] The scatter plot is empty when this is downloaded.","24":"Not able to tag experiment to USER in cloud jupyter notebook for running transformer models","25":"[BUG] Impossible to see run names in Experiments Comparision mode","26":"[BUG] Unable to load when there is more than 1 model","27":"WIP: JSON Schema Validation, Part 1","28":"[FR] Implement a way to filter experiments by tags","29":"MLflow does not return an error when sorting on non-existing metrics","30":"[FR] Make the AzureML entry script accept more data types","31":"[BUG] tensorflow autolog doesn't capture batch size correct for tf Dataset input","32":"[FR] Parallelize ModelsArtifactRepository.download_artifacts() file access","33":"[FR] Use custom `predict_proba` with default evaluators","34":"[BUG] pyspark required when using mlflow.evaluate","35":"xgb.predict() and  mlflow.predict() time difference for model prediction on same machine[BUG]","36":"[BUG] Memory usage 400MB (very high) - can it be reduced?","37":"[FR] Improve logarithm labels within metric plots with standard scientific notation","38":"[BUG] MLFlow + Wasabi + Prophet not working","39":"[FR] Allow `stage` as version value in `set_model_version_tag`","40":"Enable plugin approach to enable default experiments framework","41":"Running MLprojects using old commit [BUG]","42":"[BUG] --serve-artifacts URIs on separate server","43":"add signed url return value when getting GCS download uri","44":"[BUG] Filtering registered models by tag results in INVALID_PARAMETER_VALUE error","45":"Remove deprecated `mlflow.pyfunc.load_pyfunc`","46":"Remove deprecated numpy type aliases","47":"[WIP] Better confusion matrix visualization","48":"[BUG] Error on create_registered_model from MlflowClient","49":"[FR] Log an array of metrics in one call.","50":"Incorrect error message when user is not using Databricks CLI","51":"[BUG]Mlflow fails to create conda environments which is caused by pip dependency failure","52":"[BUG] mlflow destructor fails when using TensorFlow MirroredStrategy","53":"[BUG] Keras pyfunc uses keras.Model.predict instead of calling as function resulting in large slowdown","54":"[FR] Support of nested model output signature","55":"[BUG] - Error on load_model registered from MlFlow CLI","56":"Mark \"Changing param values is not allowed\" as User initiated failure exception type","57":"Unable to log a TensorFlow SavedModel","58":"Allow users to download all run artifacts from a model uri","59":"Bump protobuf-java from 3.6.0 to 3.16.1 in \/mlflow\/java","60":"[FR] Make autogenerated model prediction code snippet adaptable","61":"[FR] the use of GCS Signed URL for mlflow model service","62":"something went wrong [BUG]","63":"[BUG] Empty Experiment Name is Allowed","64":"[FR] Lightning ecosystem CI","65":"[FR] Adding versioning of MLproject file specification","66":"[FR] Support spark `transformers` tracking with mlflow","67":"OSX Rscript not found","68":"Issue with creating Experiments","69":"[FR] Support an option to use sqlalchemy.pool.NullPool to avoid overwhelming DB in parallel runs","70":"[FR] Validate request JSON with JSON schema or similar","71":"[FR] Support for nullable numeric types for models with pandas-based signature","72":"[BUG] Changing the Tracking's URI doesn't change the Artifact's URI","73":"[FR] Display of parameters in comparison plot.","74":"Adding new Example Sklearn Heart Attack Predictor","75":"`mlflow_transition_model_version_stage` (R) fails with HTTP `500` [BUG]","76":"[BUG] mlflow ui not launching in iframe","77":"[BUG]","78":"mlflow.exceptions.MlflowException ","79":"Fix issue #2804 - Set run name in MLProject execution","80":"[BUG] Metric visualization in UI becomes broken. Rectangular\/Constant curve instead of real curve.","81":"[FR] [R] Add support for {sparklyr} models","82":"[Question] Query regarding multi-threading, threadlock, concurrent futures inside mlflow?","83":"[BUG] ModuleNotFoundError: No module named 'custom_transformer'","84":"[FR] Add `mlflow.set_run_name` function","85":"[BUG] Using MlflowClient.get_latest_version with an older server instance causes 404","86":"[FR] Better and configurable logging in docker container.","87":"[BUG] tensorflow.autolog or keras.autolog submitting empty runs","88":"[Question] Repository structure of model flavours","89":"Create custom_class.py","90":"Add version-pinned MLflow skinny client as dependency for MLflow core","91":"[BUG] infer_signature fails when categorical Pandas series contains a null","92":"[BUG] Cannot set MFLOW_TRACKING_URI environment variable","93":"[SETUP-BUG] asyncpg driver does not work with mlflow for a postgres backend db","94":"[SETUP-BUG]","95":"Control the creation of Conda env when starting a mlflow project","96":"[FR] Model Input Validation Outside of Pyfunc or MLFlow Deployment","97":"How to remove experiment and related artifacts in minio and entries in mysql.","98":"[SETUP-BUG]; [R]; [mlflow]","99":"[BUG] ModuleNotFoundError: No module named 'autosklearn' -- but it's in the artifact's dependencies","100":"[BUG] COMMIT and ROLLBACK queries that never end while running MLFlow Server on Postgres backend store.","101":"[BUG] Too many scrollbars in experiment view","102":"[FR] Folow best practices for REST API","103":"[BUG] Could not find a registered artifact location for c: on Windows (Spark model via databricks-connect)","104":"i want to add user authentication in Mlflow.","105":"[BUG] MLflow UI fails to list experiments in local sqllite store","106":"[FR] Support downloading object versions in S3ArtifactRepository","107":"How to setup SQLite and Azure Blob Storage (in ADLS Gen2) respectively as backend and artifact stores ","108":"how to disable annoying HTTP output when using mlflow","109":"[BUG]","110":"[BUG] Issue with setting up MySQL on Server","111":"Add script to list failed cross version tests","112":"[BUG] Cannot use HDFS as artifact root","113":"[FR] Support tensor input types in deployment plugin predict CLI","114":"[BUG] 'log_artifact' and 'log_model' methods does not support files bigger than 5GB on s3","115":"[SETUP-BUG] getwd() error in python versions ","116":"[FR] Enable >250 characters for `mlflow.log_params`","117":"[SETUP-BUG] Node modules installation failed","118":"Remove duplicate calls to _validate_param_name and _validate_tag_name","119":"[FR] _validate_param_name and _validate_tag_name methods are called twice in sqlalchemy_store and file_store","120":"[FR] Keras Tuner or other automl support?","121":"How to pass multiple values for a single parameter in the mlflow run command ?","122":"[BUG] can't load model when use HDFS as artifact store","123":"[BUG] Timestamp created in R Log Model API is an invalid timestamp","124":"Reduce fluent API search runs batch size from 10k to 1k","125":"How to serving multi-step project","126":"[FR] add tflite mlflow flavor","127":"[BUG] Internal Server Error while launching the MLFlow UI","128":"[FR] Better support from MLFlow within PyTorch Lightning","129":"feat(fix): Logger callback for spaCy trainer","130":"gRPC grammar generation for MLflow models #4911","131":"[SETUP-BUG] What's the best way to run `mlflow sagemaker build-and-push-container`?","132":"[BUG] unable to run  prophet example","133":"autologged model signature uses estimator.predict instead of predictor column ?","134":"[DOC-FIX] Add mention of character limit in `mlflow.log_param`","135":"[SETUP-BUG] Issue in pip dependency resolution of test-requirements.txt","136":"[BUG] R: mlflow_rest fails with boolean arguments","137":"[FR] Add custom plots (images) to run","138":"Unable to generate artifacts for pmml models","139":"[BUG] Mlflow try to create new SparkContext","140":"[BUG] get_metric_history raises exception instead of returning empty list when metric has not been logged before","141":"Drop support for old ML package versions","142":"Return project for fetch_and_validate_project().","143":"[BUG] when i am trying to load lightgbm pmml model and log it I am getting error: ","144":"[BUG] MLFlow logger prevents airflow log handler from writing remote logs","145":"[DOC-FIX] spacy tracking using MLflow","146":"[FR] Dotenv file support","147":"[FR] model serving for image inference","148":"[BUG] Model names containing apostrophes cannot be opened","149":"[BUG] Bug when I try to download an artifact from the mlflow UI","150":"[FR] Interoperability of spark model.","151":"Log model signature and input example in tensorflow autologging","152":"[FR] gRPC grammar generation for MLflow models","153":"[SETUP-BUG]","154":"[BUG] Using HDFS as artifact store. Using dfs.nameservices with Upper Cases broke pyarrow connection","155":"[DOC-FIX] Link to Tracking server storage has a wrong anchor","156":"[FR] Show image artifacts at highest possible width","157":"[BUG] `mlflow models serve` fails with HTTP 500 instead of 400 on bad input","158":"feat: add header 'Orientation' that defines the pandas return orientation","159":"[FR] Adding mlflow.autolog support for User defined ML package.","160":"[BUG] \/health endpoint on mlflow model serve","161":"[FR] MLFLow model serving responds with json in records format (instead of split)","162":"[BUG] Frontend doesn't show correct `Run Command`","163":"[BUG] mlflow fails to create conda environments with hash-pinned pip packages","164":"[FR] Don't show default experiment in home page","165":"[FR] Support mlflow runs on existing Databricks cluster","166":"[BUG] `psycopg2-binary` is not listed in package dependencies","167":"[SETUP-BUG] Node modules installation failed","168":"[BUG] mlflow pyfunc is not predicting the model trained on tensorflow 1.15.4 ","169":"Deploy HF models in kubernetes","170":"[BUG] fatal error: 'jpeglib.h' file not found while running npm install","171":"INVALID_PARAMETER_VALUE: Model registry functionality is unavailable; got unsupported URI '.\/mlruns' for model registry data storage. Supported URI schemes are: ['postgresql', 'mysql', 'sqlite', 'mssql']. See https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#storage for how to run an MLflow server against one of the supported backend storage locations.","172":"Large JSON artifact takes a long time to load and not kept in memory","173":"[BUG] Params: TypeError: x has type <type>, but expected one of: bytes, unicode","174":"[BUG]","175":"[FR] improving load model function","176":"[FR] Implement Paddle Distributed Training Visualization based on MLFlow","177":"[BUG] examples\/docker no longer runs","178":"[BUG]prophet model","179":"BUG-FIX: Fix spark artifacts not copied to DFS when using a remote artifact store","180":"[BUG] RESOURCE_DOES_NOT_EXIST when mlflow call start_run()","181":"[FR] Record model signatures and input examples for all autologging integrations","182":"[BUG] Pytest fails on fresh installation due to missing of mleap.","183":"[FR] Sort runs table on multiple columns","184":"[FR] Improve keras model support in mlflow.tensorflow module","185":"[BUG] R API not able to find the sqlite tracking server URI. failing with Unsupported scheme error","186":"[BUG] Unable to load pretrained model","187":"Multi-class classification metrics are used for autologging of binary data","188":"Pytorch serving doesn't work for multiple inputs, multiple outputs model","189":"[BUG] unable to re-create tables after the sqlite db is dropped and re-created","190":"[FR] show tags in compare model versions view","191":"[FR] better visibility of metrics across registered model versions","192":"[FR] Direct links to HTML Artitfacts","193":"[FR] Context manager for autologging","194":"Please allow ability to save pipeline objects i.e. grid.best_estimator_ objects ","195":"[BUG] mlflow models build-docker fails to create environment","196":"[FR] Support for specifying environment variables to sagemaker.deploy_transform_job","197":"Added local_destination_path argument in load_model() calls","198":"[DOC-FIX] MLflow tracking documentation for scenario 3 and 4 are confusing","199":"[FR] update PyTorch Lightning MLFlowLogger","200":"[BUG] Tensorflow `load_model()` drops reference to variables in graph","201":"[BUG] MLflow unable to spawn multiple process with different run names while using MLproject and raytune.","202":"mlflow + pytorch lightning not able to log custom models","203":"[FR] Track source code and diff between runs","204":"[FR] Add run ID to runs table in experiment page UI","205":"[FR] Display actual timestamp for \"Start Time\" column in runs table of experiment page UI","206":"[FR] GitHub and GitHub Enterprise advanced integration","207":"how to use mlflow set model publish strategies?","208":"[BUG]  DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get\/find descriptors from generated code or query the descriptor_pool.","209":"[FR] Display max\/min value of a metric in the experiments UI","210":"Does Java API support MLflow run models?","211":"[FR] Use mamba for creating environments","212":"Replace the `import` workflow with a pytest script to decrease the number of workflows","213":"[FR] A lightweight search API","214":"[FR] Setting default set of columns to be displayed in MLflow ui","215":"[FR]","216":"mlflow.pytorch.autolog does not work with Multi GPU [BUG]","217":"[BUG] mlflow crashes randomly during training","218":"Curl command returning a single output for multiple text input ","219":"[SETUP-BUG]","220":"[FR] Autologging for detectron2","221":"[BUG] MlflowTracking UI can't retrieve model from S3-compatible storage (Hitachi Container Platform - Vantara)","222":"[FR] mlflow gc working for gcs artifact store","223":"[BUG] higher load time when loading model from mlflow compared to loading model directly from S3 bucket","224":"Remove the artifacts","225":"[BUG] Could not find the artifact from the model of mlflow models serve in windows10","226":"[BUG]","227":"[FR] Support logging plots from plotnine from Python client","228":"Bug Fix self-hosted bitbucket Issue #4642","229":"[BUG] Issue with mlflow.tensorflow.load_model not returning model object causing inference to fail.","230":"[BUG] Artifacts are there but not shown in UI","231":"[DOC-FIX] Standardize the official spelling: PyFunc or Pyfunc?","232":"[FR] \"Freeze\" experiments in ui to static html site","233":"[FR] Migrating Experiments from a Different MLFlow Server","234":"[BUG] Hyperlink not working for self-hosted Bitbucket","235":"ML Flow - Pytorch lightning Multi GPU Pickling error","236":"[BUG] Check that 'source' argument to MlflowClient.create_model_version() actually exists","237":"ERROR mlflow.cli: Could not find main among entry points [] or interpret main as a runnable script Supported script file extensions: ['.py', '.sh'] ===","238":"[DOC-FIX] Adding custom flavors","239":"[BUG] Pytorch-ligthning Logger Bug","240":"[FR] mlflow CLI: mlflow models build-docker always sets gunicorn listening address to localhost, impossible to deploy to Kubernetes","241":"PyTest results are not visible, since the whole log is overflown with deprecation warnings","242":"[FR] Setting the MLFLOW_TRACKING_URI from the MLproject file","243":"[BUG] h2o model inference error","244":"Bug-Fix Issue #2501 Running a MLflow project with docker_env fails to create the docker container","245":"[FR] Push Docker Image to Private Image \/ Container Registry in Kubernetes Backend","246":"[FR] Experiments folder structure","247":"[FR] Server version number (REST API \/ Python API \/ UI)","248":"How do I log an existing MLFlow model?","249":"[FR] adjustable width experiments sidebar in tracking server UI","250":"import tensorflow.keras for autolog instead of keras [BUG]","251":"[DOC-FIX] Projects page is missing information and contains confusing example","252":"[FR] Support for optional columns and sequential data types in MLflow Signature","253":"[FR] Add autolog support for daskml estimators","254":"mlflow deployment python flavors issue","255":"[FR] Proper visualization of runs nested more than one level deep","256":"Permissions on experiments depending of the user","257":"[BUG] GPU based inference does not work on Sagemaker","258":"Set GCS upload timeout higher, allow overrides.","259":"How do I stop the local deployment of a MLflow model?","260":"[FR] MFlow log_model should accept functions for loader_module","261":"Log docker build errors","262":"[BUG] RuntimeError: Could not parse python long as longdouble: -64 (Invalid argument)","263":"Tutorial on Packaging Training Code in a Conda Environment is outdated [DOC-FIX]","264":"[BUG] SageMaker deployment fails when running inside scheduled Databricks Job","265":"Fixed model_path for R in Windows","266":"Add support for azure-identity to authenticate with Azure storage accounts","267":"Remote target (TensorFlow Lite & Micro)","268":"[DOC-FIX] mlflow.azureml.deploy doesnt work with model_uri :models:\/<model_name>\/<stage> format","269":"can't find artifacts when running local mlflow","270":"[DOC-FIX] update download_artifacts() example in mlflow documentation","271":"[DOC-FIX] missing source information for mlflow.register_model()","272":"[BUG] mlflow.tensorflow.log_model causes signature issues when loading keras model","273":"Unable to use cloud SQL(postgre) backend for mlflow version > 1.11.0 [BUG]","274":"Creating Custom functions for R","275":"Linux Docker - Artifacts\/model not getting save in mlruns [BUG]","276":"[FR] Serve REST API endpoint under static prefix","277":"Pass Gunicorn args through to docker container","278":"[FR] Track hardware metrics","279":"Cannot pass  kwargs to mlflow.keras.log_model method.","280":"Add support for model signature and input example to mlflow_log_model() in R","281":"[DOC-FIX] Java API Dcumentation should be used in the examples","282":"[FR] Native Java or REST support for downloading mlflow artifacts from Databricks","283":"[BUG] MLFlow Server is slow on AWS ECS on instances with EBS","284":"[BUG] download_artifacts fails with OSError: [Errno 30] Read-only file system: '\/ml'","285":"MLflow UI not showing full path of the artifact","286":"Save custom model with mlflow","287":"Adds support for spacy.load() kwargs to be passed to mlflow.spacy.load_model()","288":"[FR] Add support to pass keyword arguments to m","289":"[EN] Add namespace or increase the number of characters visible","290":"[FR] Model service from the UI","291":"[FR] Feature for best model logging, not last","292":"Making SQLite as default scheme for backend store fix bug #4415","293":"install_mlflow() in R yields: Error installing package(s): \"mlflow==1.17.1\"","294":"\"Something went wrong\" error on selection of a run","295":"deploy pytorch models in databricks ","296":"wait_for(function() mlflow_rest(\"experiments\", \"list\", client = client)","297":"[BUG] mlflow run seems to ignore --no-conda flag","298":"[FR] Make log_param() return the passed parameter value (expression for functional use)","299":"Feature requirements\/queries","300":"Mask sensitive information in log","301":"[BUG] \"No Artifacts Recorded Use the log artifact APIs to store file outputs from MLflow runs.\" ","302":"[FR] Allow a registered model to be both Staging and Production","303":"[FR] Stop runs through the UI or MLflow API","304":"Parameters format in mlflow.run","305":"mlflow.projects.run not working inside docker container (backend=kubernetes)","306":"[BUG] Wrong return type in NumpyEncoder.try_encode() method in utils.proto_json.utils module","307":"Databricks Issue: mlflow dependency not working with external package sources","308":"Run MLFlow job on Kubernetes with conda_env instead of docker_env","309":"Support 'boolean' result type for spark_udf","310":"[BUG] Python dependencies are not versioned","311":"[BUG] Deadlock issue raised from backend store DB","312":"the model can't serve and how to slove?","313":"[BUG] log_artifact() not working on remote server: AttributeError: 'NoneType' object has no attribute 'time'","314":"pytorch model serve gives ResolvePackageNotFound","315":"can't log model on PC with Windows 10 [BUG]","316":"[FR] Build docker image automatically","317":"[BUG] Incompatibility between MLflow and Dash ?","318":"[FR] Allow customisation of active model stages above Staging, Production","319":"Can't log artifacts on remote server - probably '--default-artifact-root' issue [BUG]","320":"Sagemaker container build returns pip not found and failed [BUG]","321":"WIP: Kubernetes CRD support","322":"Mlflow models UI not loading.[BUG]","323":"FR-2770: add flavor support for Gensim models","324":"[FR] Support for JFrog Artifactory (and nuget) as Backend Store","325":"Worker Timeout error on running mlflow ui[BUG]","326":"Implementing oauth2 workflow","327":"[FR] SqlAlchemyStore.log_batch should really write in batches","328":"allow mvn to configure proxy","329":"[FR] Paginate experiments in the UI","330":"[FR] Support for tensorboardX autologging in MLflow","331":"[FR] Result aggregation in mlflow compare UI","332":"[FR] Building images with JIB - https:\/\/github.com\/GoogleContainerTools\/jib","333":"[FR] MLflow Model Serving -- Add CORS headers to enable calls from javascript web applications","334":"[FR] Compare many metrics between multiple steps \/ multiple runs","335":"[FR] Create a public ROADMAP file","336":"[BUG] Artifacts UI broken for certain model types after MLflow 1.13.0","337":"[FR] Continue runs","338":"[FR] Use other package manager than conda for MLFlow Projects","339":"[FR] Add Transformers Pretrained Model Flavor","340":"[BUG] Run ends on notebook end","341":"[BUG] mlflow.autolog() for PyTorch Lightning logs `_step` metrics for epochs instead of steps","342":"[FR] Support Azure Stack Hub storage blob as MLflow Server artifact store","343":"Updated skinny readme","344":"[FR] trigger deployment of models via MLFLOW UI","345":"[SETUP-BUG] Pinned requirement of alembic version getting old","346":"Azure Databricks managed mlflow - metadata and artifact store","347":"CNCF SIG-Runtime Discussion\/Presentation?","348":"[FR] Add in the tracking API a decorator to log all function arguments as MLFlow params","349":"XGBoost support","350":"[DOC-FIX] Document the maximum value and legal characters for log_param, log_metric and set_tag","351":"[BUG] UI register model button missing, Upgraded to v. 1.14.1 from 1.9 ","352":"[DOC-FIX] Document legal characters for experiment names, run names and artifacts","353":"[SETUP-BUG] MLFLOW database session expires for AWS RDS Serverless database","354":"[BUG] Incorect path used in list_artifacts with a FTP artifact store on a windows host combined with a MLflow server on a linux host","355":"[FR] gRPC inference server for pyfunc flavor ","356":"Absolute path for waitress-serve.exe","357":"[FR] Friendly contour color for color blindness or color weakness","358":"[FR] Add delete_artifact method to mlflow API","359":"[WIP] support tidymodels workflow flavor","360":"[FR] mlflow.pytorch.autlog() not working for params","361":" Run id not found exception when using set tracking uri","362":"[mlflow ui] FileNotFoundError: [WinError 2] The system cannot find the file specified","363":"[SETUP-BUG]","364":"[FR] Support of TF-serving structure when using mlflow.tensorflow.log_model","365":"[DOC-FIX] No clear difference between mlflow.azureml.build_image and mlflow.azureml.deploy API methods","366":"[FR] Model Serving: Support \"signature_name\" in tf serving input format in models inference API","367":"[FR] Allow argument for 'local_dst_path' when loading Pyfunc Models","368":"fixing bug when importing package","369":"[BUG] Error for mlflow models build-docker","370":"Is it possible to use \"mlflow.log_artifact(my_artifact)\" on an object \"my_artifact\" which is located on HDFS?","371":"[FR] Support Kubeflow in MLFlow projects","372":"[FR] Support `or` in search clause","373":"[BUG] Spark UDF throws IllegalArgumentException","374":"[BUG] 'mlflow' is not recognized as an internal or external command, operable program or batch file on windows.","375":"[SETUP-BUG]","376":"[FR] When mouseover a curve on graph, should see entire name, just not start and then `...`","377":"[FR]Be able to add a run to an existing graph plot","378":"How to start simulataneous runs in the same experiment without some of them tripping over experiment creation?","379":"[FR]Make it possible to open 'Compare' in new window","380":"[DOC-FIX] Make it easier to find the exact way to search for runName, source name etc.","381":"[FR] Add mlflow version to bottom of main page \"powered by mlflow 1.2.3\"","382":"[DOC-FIX] artifact_path argument to log_artifact() needs clearer explanation","383":"[FR] Harmonize Dockerization in projects and models ","384":"Enable JSON xgboost serialization format [FR]","385":"mlflow models serve fails with 'FileNotFoundError: [Errno 2] No such file or directory: \/tmp\/tmpv459n53j\/MLmodel\/MLmodel'","386":"How to prevent deprecated type aliases in numpy?","387":"[FR] Use run_id passed to mlflow.projects.run for backends \"kubernetes\" (and \"databricks\")","388":"mlflow serve not working, getting \"AttributeError: module 'types' has no attribute 'ClassType'\"","389":"INTERNAL_SERVER_ERROR on ui after logging pytorch model","390":"[BUG] Concurrent deployment calls cause [Errno 2] No such file or directory","391":"[FR] Increase max logged parameter size (currently 500 bytes)","392":"[FR] No way to configure artifact store path when tracking on SQLAlchemy","393":"[FR] Allow definition of aws keys without env vars","394":"Development UI - No module named 'mlflow_test_plugin.sqlalchemy_store'","395":"[FR] Add a refresh button on MLflow UI","396":"Add synchronous flag to mlflow run cli.","397":"[FR] Use model-specific Shap explainers in mlflow.shap.log_explanations","398":"[BUG] Missing \"forge\" parameter in install_mlflow() ","399":"Add mlflow_run convenience decorator to fluent API","400":"[BUG] Cannot load multiple python_function models with the same script file name","401":"Add pagination in the search_model_versions server API","402":"[FR] Experiments organization","403":"[BUG] infer_signature fails when dataframe contains ExtensionDtype","404":"MLFlow Tracking - Auto-logging doesn't capture parameters by default on TF 1.15.0","405":"[BUG] `np.object` raises `DeprecationWarning` in numpy 1.20.0","406":"Numpy 1.20.0 compatibility: Using object and int instead of deprecated np aliases","407":"[FR] Model server: automatic reloading of updated models","408":"[BUG] Returned json types are inconsistent with documentation and MLflow on Azure Databricks (creation_timestamp: INT64, last_updated_timestamp: INT64)","409":"[BUG]  Unable to create the docker image for the model.","410":"How to make mlflow tracking useable on shared file systems?","411":"[BUG] Pytorch-lightning: autologging model unexpected error in pickling","412":"[BUG]","413":"[BUG] Not corrected source path model in OS ","414":"[FR] Streaming\/pre-signing artifacts","415":"Resource Management and Job Schedule","416":"[BUG] mlflow.pyfunc.log_model doesn't work correctly when artifact storage is HDFS and artifact size is greater than 2gb","417":"Enter docker run arguments in MLproject docker environment","418":"[BUG] Unable to see the list of the model versions in a model UI which has a lot model versions(>=10000)","419":"[FR] SHAP Explainer Integration","420":"[BUG] TypeError: cannot pickle 'weakref' object","421":"[BUG] Tensorflow model that has feature column cannot be predicted on","422":"JAVA API Update Parameters, Metrics and Artifacts","423":"[BUG] Boolean columns are not validated.","424":"[DOC-FIX] Document MLproject feature for R","425":"Add sampling strategy parameter for mlflow.shap.log_explanation","426":"#3973 Mount AWS credentials in \/root\/.aws instead of \/.aws","427":"[BUG] local docker backend incorrectly mounts .aws credentials path","428":"#3969 Implement .dockerignore parsing to ignore files when creating temporary work dir","429":"[BUG] MLFlow needs to read .dockerignore and .gitignore or have its own .ignore file","430":"Record branch name for local run","431":"[FR] autolog support for xgboost.dask and lightgbm.dask","432":"[FR] Basic Authentication for Scoring Server (flask)","433":"[BUG] MLproject run via Docker is very slow","434":"[BUG] KubernetesSubmittedRun.get_status() does not have the correct Kubernetes cluster URI host name","435":"[FR] Kubernetes CRD support","436":"Extend java client to support list-registeredmodels API","437":"Mlflow file - read from config","438":"[FR] Http Artifact Repository","439":"[BUG] models not showing in UI","440":"Something went wrong If this error persists, please report an issue here in Model section","441":"mlflow models serve fails with 'Something went wrong'","442":"[FR] Experiment Tracking Decorator to remove boilerplate","443":"Issue 3842 python db connection factory","444":"[BUG] UI is slow with the new Models column","445":"[FR] Configure Different Backends for Experiment Tracking and Model Registry","446":"[BUG] Status not correct when not using with statement","447":"[FR] Increase parameter length","448":"[BUG] H2O with R, Mlflow model failed to load after logging it using R log_model API","449":"How to increase response time of running model?","450":"[BUG] base image in Dockerfile uses python3.8 that pyspark does not support.","451":"[FR] MLFlow tracking clickable hyperlinks","452":"Expose additional SpaCy functionality when using pyfunc to load model","453":"[BUG] Deleting tests\/test_cli.py causes failures in tests\/tracking\/test_tracking.py ","454":"[Repro] Deleting tests\/test_cli.py causes failures in tests\/tracking\/test_tracking.py","455":"[BUG] Pytorch Lightning Autologging fails with older Cloudpickle version","456":"[FR] decrease model predict response data io","457":"decrease model predict reponse data io","458":"[FR] Add link to children in parent of multi-step","459":"Update mlflow.fastai Python API to fastaiV2","460":"ERROR mlflow.cli: Could not find main among entry points [] or interpret main as a runnable script.","461":"[FR] Add Pandas category dtype to mlflow.types.schema","462":"[FR] Enable multi-step pipelines with a kubernetes backend","463":"[FR] Add image artifact to \"Comparing 2 Runs\" UI","464":"[FR] Programmatically specify a backend store connection string","465":"[BUG] Model signatures with space-separated fields crashes UI","466":"[BUG] Unable to deploy to a SageMaker Endpoint","467":"[FR] Provide a way to ship MLFlow logs to remote servers such as logstash","468":"[BUG] Unable to load pytorch model that is saved using mlflow.log_model to s3 artifact store","469":"[FR] Add hooks from the pre-commit framework to the development workflow","470":"[FR] support build-docker functionality in MLflow R package","471":"Unable to terminate mlflow models serve process started from python with subprocess.Popen","472":"[FR] Add input validation to `mlflow.search_runs`","473":"mlflow ui doesn't work on a jupyterhub environment","474":"[BUG] Python logging & MLFlow Plugins Documentation","475":"Theme-ing support for MLFlow UI [FR]","476":"[BUG] Python-related interop issues on Windows","477":"Support logging text for R","478":"[BUG] No index on foreign keys, in postgres store","479":"[FR] Publishing Docker Container to Registry","480":"[FR] Add synchronized option to mlflow run cli","481":"[DOC-FIX] transition-request API not in REST API docs","482":"[FR] Registry UI should display comment in pending transition requests","483":"fix some of the Windows-related interop issues and partially enable MLflow R CI workflow on Windows","484":"[FR] Smart selection of parameters in comparison ui","485":"[FR] Aggregate runs into groups","486":"[BUG] Run Name logged as a parameter while running a script as MLproject (mlflow run .)","487":"[BUG] Yaml file '\/Path\/to\/mymodel\/meta.yaml' does not exist.","488":"Add `get_iris` to avoid installing sctkit-learn in the cross version tests","489":"[BUG] log_artifact timeout when using Azure Blob Storage","490":"[FR] Log parameters that can be None","491":"[FR] New parameter types for MLflow Projects","492":"The 'kubernetes' backend should allow users to use existing docker images ","493":"[FR] The 'kubernetes' backend should allow users to use existing docker images","494":"[BUG] UI breaks if project name contains a \"\/\"","495":"[FR] Adding NextPageToken support to ListExperiments API","496":"[FR] Add experiment date into export to csv ","497":" FATAL:  remaining connection slots are reserved for non-replication superuser and rds_superuser connections","498":"should paramiko be listed in requirements.txt as dependency? ","499":"Adding Sklearn Gridsearch Example","500":"[BUG] unable to change artifact-uri for existing experiment","501":"[FR]Improve sortability of parameters.","502":"How to deploy a pytorch model","503":"[BUG] [Windows] mlflow.start_run assigns new run_id-s by multiprocessing","504":"[FR] Source file detection should be aware of notebooks.","505":"[FR]Delete child runs together with partent runs","506":"[FR] Show all digits of Metrics","507":"[FR] Persist state of \"Columns Selection\".","508":"[FR] Persist state of \"Hide Experiment List\".","509":"[BUG] mlflow.pytorch.log_model yields mlflow.exceptions.RestException: INVALID_PARAMETER_VALUE: Tag value ... had length 5031, which exceeded length limit of 5000","510":"[FR] Let tracking server just store files in locale filesystem.","511":"[FR] Mark runs with Note","512":"[FR] Allow users to define custom stages for the model registry","513":"[BUG] Numpy datetime type not supported in model signatures","514":"Served Scikit-learn mlflow pyfunc model not consumable for arbitrary number of rows in the input via the served endpoint","515":"[SETUP-BUG] ERR_CONTENT_LENGTH_MISMATCH when accessing UI over GCP IAP Tunnel","516":"[BUG] MlflowClient.list_run_infos() loads run details from store even though they are not needed","517":"[FR] Global parameters for projects","518":"fix bug gc  - No such file or directory #3595","519":"Create experiment set in MLFLOW_EXPERIMENT_NAME","520":"[FR] Setting MLFLOW_EXPERIMENT_NAME creates experiment","521":"is it possible to create and deploy the model using mlflow=1.10.0 with system environment in windows(python environment..without conda) ?","522":"[BUG] AttributeError: module 'mlflow.sklearn' has no attribute 'autolog'","523":"mlflow serve command with --no-conda not working in windows python environment","524":"\"Running the MLflow server using a source installation of the Python MLflow package\"","525":"[BUG] UI not displaying all available existing models when registering a model from a run","526":"[FR] don't require conda for R installation","527":"[FR] Add MlflowException on the top level","528":"mlflow.azureml.build_image option to register model first","529":"[FR] Log files to Experiments and not just runs","530":"\"Something went wrong message\" present at ui screen. ","531":"[FR] Model Cards (Documentation)","532":"[BUG] mlflow gc - No such file or directory","533":"stumped by bad request after building Docker image ","534":"[BUG] MLflow deployment on AzureML fails because of a previous version of Numpy.","535":"mlflow UI not working in iframe[BUG]--cross origin issue","536":"Add singularity container to project","537":"[FR] make flavor a viable filter on search_model_versions and search_registered_models","538":"[FR] SkinnyClient: setup.py needs to be made configurable alongside deployment infrastructure to release both packages","539":"[FR] SkinnyClient: MLflow skinny should not require numpy or pandas","540":"[FR] SkinnyClient: flavors should lazy load pandas and numpy","541":"[BUG] Unable to Register Custom Python Model Creme","542":"[BUG] Unable to invoke models tracked by MLFlow that requires high-dimensional inputs\/outputs","543":"Use existing Environment Variable for S3 Upload File in Sagemaker Artifact Upload","544":"[FR] Add Maven Proxy Configuration on model build and publish method","545":"[FR] Add Environment Variable for S3 Upload File ExtraArgs ","546":"Manage role and permission user of the tracking server ","547":"[FR] Add  3dim array input possibility for the REST API","548":"[BUG] Artifact not being saved when using spark log_model in Databricks","549":"[BUG] Cloudpickle in pyfunc fails to serialize gpytorch model","550":"setup the authenticaion to tracking server via Python","551":"[BUG]mlflow project throws INVALID_PARAMETER_VALUE exception for float parameter","552":"Updated CONTRIBUTING with grammatical, punctuation","553":"Corrections to README.md: Grammatical, punctuation corrections","554":"[FR] When going back to experiment view from comparison views, keep previously compared runs selected","555":"[FR]Disabling download artefacts","556":"[FR]Is mlflow support distributed XGBoost model? ","557":"[BUG]cannot autolog the parameters of distributed version of xgboost","558":"[BUG] MLflow CLI takes a long time to display help and version","559":"[BUG] metric history api: steps are not ascending if more than 100 steps","560":"How to serve model manually without using mlfow model serve command","561":"Databricks: Cannot register sklearn model because of Metadata issue when using workspace experiment","562":"mlflow silently fails to load results [BUG]","563":"[FR] Update proto files to proto3","564":"Added the option to use AAD for auth for store","565":"[FR] Azure Active Directory for Artifact Store with Azure blob storage","566":"[SETUP-BUG] prepare-commit-msg hook not working on Windows","567":"[SETUP-BUG] Install from source test requirements Torch error","568":"[SETUP-BUG] Install from source dev requirements error","569":"[BUG] log_artifact timeout","570":"Using NFS as remote artifact store with Windows client","571":"[BUG] Metrics don't display for version 1.8 or later on port!=5000","572":"[Do not merge] Add option to protect registered production models from modification","573":"[FR] Add a set_artifact_uri function ","574":"Using NFS server with mlflow.log_artifact() .No proper documntation on mlflow.org","575":"fix instructions on installing mlflow-spark (issue #3460)","576":"[DOC-FIX] Incorrect example how to add mlflow-spark to SparkSession","577":"Clarify that MLflow requires Python >= 3.5 in README & quickstart","578":"[BUG] Webservice for deploying model via DBFS and other python IDEs","579":"I am using machine A to set up tracking server on machine B, but mlflow.set_tracking_uri() gives following error.","580":"[BUG] MLflow not picking up environment variables and not mounting volumes when run with --backend kubernetes","581":"[BUG] MlflowClient and logging PyTorch model artifacts","582":"[FR] Allow viewing full-size images without rescaling or cropping in Artefacts view","583":"[FR] MLflow should pass parameters to underlying stores as kwargs in MlflowClient to simplify plugin forward\/backward compatibility","584":"[BUG] MLflow Projects Run fails for windows Absolute paths","585":"[BUG] Default experiment is not created when root directory already exists","586":"[FR] Avoid save h5 model artifact when running mlflow.keras.autolog()","587":"[FR] Kibana-style one-click filtering ","588":"Best practice to include private libraries\/dependencies for Mlflow model","589":"[FR] Support for `tidymodels` flavours for R","590":"[FR] Allow plugin support for tracking_uris that are only the schema mlflow.set_tracking_uri(\"plugin_schema\")","591":"[BUG] Loading Pyfunc Class missing custom instance methods","592":"[BUG] any json request to MLFLow server containing \":\/\/\" fails with the current pandas version","593":"[BUG] mlflow run with --backend kubernetes fails when local docker image with same IMAGE ID exists","594":"[BUG] start_time is treated as a decimal instead of an integer when logging to mssql","595":"[DOC-FIX] Migrate to NumPy documentation style","596":"[BUG] Error in wait_for(function() mlflow_rest(\"experiments\", \"list\", client = client), : Operation failed after waiting for 10 seconds","597":"[FR] Add model explainability with SHAP","598":"[FR] Stack trace on run failure","599":"Integration with Ray Tune?","600":"[BUG] Accidentally clicking on large previewable artifacts causes the web UI to hang","601":"[BUG] MLflow Projects: there is no --docker-args option in MLflow UI","602":"[BUG] MLflow Projects: can't copy environment variables to docker container environment","603":"Fix ArtifactView styles","604":"Adding end time and run duration to Compare Runs view","605":"Initial support for pip projects","606":"MLflow overwrites Alembic version data for other applications [BUG]","607":"[BUG] Autologging metrics for object detection in Tensorflow 2.x","608":"Exception using infer_signature from mlflow.models.signature","609":"[BUG] Database initialization fails if primary keys enforced","610":"[BUG] MLflow scoring server should return 4xx HTTP status code for bad request data","611":"pass custom environment variables to sagemaker docker","612":"[FR] pass custom environment variables to sagemaker docker","613":"[BUG] http.client.RemoteDisconnected for get_metric_history","614":"[BUG] Error with `mlflow models serve no--conda` under Windows 10","615":"[Model Registry Search] Tags support for filter_string and order_by in searchRegisteredModels","616":"mlflow installation issue on Windows 10 [BUG]","617":"[FR] sklearn serve model fails with custom function in FunctionTransformer","618":"[FR] Search runs by \"nested\" property","619":"Providing S3 path instead of just bucket name for artifact store","620":"[FR] Allow SQLAlchemy pool customization in Tracking Server","621":"Added support for high dimensional onnx models","622":"[FR] Support serving Keras\/TensorFlow models with TensorFlow Serving","623":"[FR] Support update experiment or delete experiment permanently","624":"[FR] Support creating conda environments from spec files","625":"[FR] Enhancements to the Runs search bar","626":"[Model Registry Search] Tags support for filter_string and order_by in searchRegisteredModels","627":"[BUG] Resize columns when experiments list is minimized","628":"Add more file extensions to show content on frontend side","629":"[FR] Order by tag from the UI","630":"[BUG] MLFlow on Mac OS with Python3 and no Conda","631":"[FR] _build_image return values for integrate with other services in python","632":"[FR] build image from customize base image for performance and varitieties of usage","633":"[DOC-FIX] switch from Rd to markdown documentation","634":"More specific git uri regex","635":"[BUG] If default experiment 0 is deleted and mlflow restarted, observe psycopg2.errors.UniqueViolation:  Key (experiment_id)=(0) already exists.","636":"Fix MflowClient can't get tracking store registered by UI","637":"[BUG] mlflow logs pytorch model instead of weights only -> prevents serving modularized code","638":"[FR] Serialization format for TensorFlow 2.x (Keras) model should be SavedModel per TF 2.0 doc","639":"[DOC-FIX] List of artifact viewer supported file types","640":"[FR] Log metrics with confidence intervals and include them in plots","641":"[FR] Enhance Pytorch autologging support to extend to other higher-level frameworks (e.g. Pytorch lightning, etc)","642":"[BUG] ONNX predict fails for high-dimensional models","643":"[BUG] Unable to log using mlflow.tensorflow.log_model()","644":"[FR] A mechanism to view the logs of an ongoing run on the MLFlow UI","645":"Adding support to download http files from MLflow Projects","646":"Docker Size Reduction","647":"mlflow not found in r-mlflow-1.10.0 conda environment | mlflow rith R ","648":"[FR] Need hooks for start and end run events in RunContextProvider","649":"Added more actions to RunContextProvider","650":"Unable to log pytorch models","651":"[DOC-FIX] Add code snippets where necessary to MLflow Python fluent API module","652":"[FR] load_model Support for Windows Absolute Path","653":"fix mlflow version when creating conda env","654":"[FR] Block registered models from being updated","655":"[FR] Prevent run being deleted if a model from the run is registered","656":"[FR] Support tensor inputs to MLflow inference APIs","657":"[BUG] Import error with mlflow.onnx with version 1.10.0 but not in later versions","658":"Problems encountered in multistep running under docker","659":"Add to_dictionary() method for mlflow.entities.model_registry.registe\u2026","660":"[FR] artifact location when moving mlruns folder","661":"Fix empty creator field in model version if basic authentication is set up","662":"[FR] Draft & publish MLflow Python version support policy.","663":"[BUG] Representation Error for mlflow.pyfunc.PythonModel SubClass","664":"[FR] Allow users to specify a cache directory for loading models","665":"[FR] Allow specifying --backend-store-uri as an environment variable","666":"[FR] Reorder Runs table columns, including parameters and metrics","667":"[BUG] Multiple Runs created for one Run when using MLFlow Server","668":"[FR] Support for pre\/post-processing for R models","669":"[FR] Save logs to artifact store when running in Kuberentes","670":"[DOC-FIX] List of URIs needed to be allowlist for mlflow on (azure) databricks","671":"[BUG]Operation failed after waiting for 10 seconds","672":"[FR] set proxy on build docker image","673":"[BUG]Issue with R API log artifacts","674":"[FR] Support serving Pytorch models via TorchServe","675":"[BUG] run id issue when running in kubernetes ","676":"Check to make sure user doesn't delete last experiment","677":"[FR] UI should show the version and point to according documentation","678":"[FR] Increase height of artifact viewer (or make the height flexible)","679":"[FR] Hydra Support","680":"[BUG] Error when using mlflow.keras.log_model(model, 'best_model')","681":"Accessing model context for pyfunc packaged model in mlflow >= 1.9","682":"Speed up logging of multiple metrics","683":"[FR] Add pip native support","684":"[FR] Sort\/Filter Registered Models in GUI","685":"[FR] Event based notifications for model registry changes","686":"Issues deploying to AWS SageMaker with aws-cli v2","687":"MLFlow with custom cookie \/ header support","688":"[FR] logging metrics via log_batch using SqlAlchemyStore takes very long","689":"[FR] allow kwarg passing to MLmodel for pyfunc loader_module paradigm","690":"Add ability to build Docker image for experiment run from Dockerfile","691":"[BUG] R API use SQLAlchemy database URI as Backend Stores Make Error","692":"Don't shell-escape PyPI library version lower-bounds when running projects on Databricks","693":"[BUG] Postgressql and local aren't synchronized, artifacts saved to wrong folder","694":"[FR] Specify what conda environment to activate while running a project","695":"[BUG] mlflow version is not fixed in default conda env","696":"question \/ [FR] - how to download model from UI?","697":"[FR] Add delete_metric() functionality so that when a run is restarted from an intermediate epoch checkpoint, data after this point can be purged","698":"[FR] Open API 2.0 specs for model webservices","699":"If main.py exists but MLProject does not, use main.py as default entry point [FR]","700":"Added check on AzureML SDK dev version","701":"[BUG] Incorrect sort order for exponential notation metrics\/params","702":"[FR] REST API Swagger File","703":"[BUG] Wrong source identified with jupyter lab","704":"[FR] Add a button to execute a script on mlflow UI","705":"Add Local and Kubernetes execution backends","706":"[BUG] Running mlflow sagemaker run-local with custom docker image","707":"[FR] Check and truncate string length","708":"[FR] Improve stability of MLflow APIs for saving\/loading pytorch models","709":"[FR] Ability to search for missing values\/NAs using search_runs","710":"[FR] Save optimizer state_dict with mlflow.pytorch.save_model() with a dictionary ","711":"[FR] Upload a run from one source (e.g. the local `mlrun` directory) into another tracking server","712":"How to read metrics stored in mlflow?","713":"[FR] Use all the width of screen to display feature importance artifacts","714":"[FR] Adding snowflake support for backend store uri","715":"[BUG] Windows 10 - CondaHTTPError: HTTP 000 CONNECTION FAILED","716":"[BUG] mlflow Docker creates all folders as root","717":"Gensim flavor","718":"[FR] - option to specify conda \/ docker environments per entry point","719":"[FR] Add Scikit-Learn API support XGBoost auto-logging","720":"[FR] Support resolution \/ execution of projects stored in WASBS, S3, GCS, etc","721":"[HELP WANTED][BUG] Can't find Docker for multistep projects","722":"[FR] Improve support for simultaneous Conda and Docker environment","723":"add support for StructType return in spark_udf","724":"Start a mlflow model serve by config file","725":"[BUG] MlflowClient.download_artifacts throws OSError if run does not have artifacts","726":"[FR] Better visualization of nested params","727":"[DOC-FIX] Librairies needed per storage option are not clear","728":"[FR] Compare run configurations and metrics in one page","729":"[DOC-FIX] Make clear that the client is the one logging artifacts to the artifact store","730":"[BUG] Predict N-dimensional data with pyfunc from MLmodel","731":"[FR] Adding custom API endpoints to mlflow prediction based services","732":"Add option to specify run name in mlflow project execution","733":"Git uri regex ignores paths starting with single symbol and : in orde\u2026","734":"[BUG] Git url regex matches any windows path in projects.run()","735":"[FR] Remove barriers for running MLflow servers behind a reverse proxy","736":"fix problem with POST request to Databricks","737":"[BUG]: parameter passing integers when expecting floats to mLflow run throws an Exception","738":"[BUG] MlflowClient use a relative path to download_artifacts without using the absolute path in tracking_uri","739":"[FR] Support for built-in SageMaker algorithms","740":"Getting INTERNAL_SERVER_ERROR on mlflow ui each time I log my model through pytorch.","741":"[BUG] Run name not set when using start_run inside a MLproject execution","742":"Add clear_run() to end run without sending termination","743":"Improve documentation of end_run() for distributed settings","744":"[BUG] AWS_DEFAULT_REGION environment variable is not propagated to docker container","745":"Using HDFS as artifact store","746":"[BUG] Tests on Windows: Artifact path urlparse does not work with absolute Windows paths. ","747":"Cannot serve Spacy model \"Exception: No suitable flavor backend was found for the model.\"","748":"[FR] Support for gensim models","749":"[FR] Plot metrics across multiple runs in an experiment","750":"Changed HashRouter to BrowserRouter in app.js","751":"Absolute path at server startup","752":"[FR] API for querying JSON to support custom plots via Vega-Lite","753":"[FR] Dynamic sorting at model comparison page","754":"[FR] Support Tensorflow ModelServer for serving","755":"[FR] Support SageMaker multi-model endpoints","756":"[BUG] Setting experiment id from python fails when running script from CLI","757":"[FR] Make mlflow tracking backend scale beyond thousand of runs","758":"[BUG] Artifact URI doesn't change on existing experiments","759":"[FR] View custom tags in comparison view ","760":"[FR] Introduce shadow curves to line smoothness metrics plot","761":"[BUG] Plotting ~ 35 metric curves causes significant browser lag","762":"[FR] Add documentation clarifying that the `code_paths` arguments of `log_model` calls should refer to self-contained modules for best results","763":"[FR] Support explicit AWS credentials and multiple MLFLOW connections to s3","764":"[BUG] ","765":"[BUG]","766":"[BUG] Remote Tracking server with Docker env throws 'ConnectionError'","767":"[FR] Comparing different artifacts in comparison view ","768":"[BUG] Could not create run under non-active experiment with ID 0. After the default experiment been deleted.","769":"GC CLI S3 Support: implement delete_artifacts in S3ArtifactRepository","770":"Kerberos Option in Client [FR]","771":"[BUG] uploading artifacts to FTP server doesn't work","772":"[FR] Add symlink support for logging artifacts","773":"[BUG] Wrong path for artifacts when using http server","774":"ConnectionRefusedError: [Errno 61] Connection refused","775":"run mlflow without bash","776":"[FR] Allow displaying multiple metrics\/parameters along Y axis in scatter plot, distinguished by color","777":"cannot reuse deleted experiment names","778":"[FR] Add Neuraxle pipelines for easier pipelining","779":"[FR] More info about the registered model versions (description, last activity, source run)","780":"The Java tracking client doesn't support file URIs","781":"[BUG] log-param REST call doesn't return reason for failure","782":"[FR] Use the docker-py API for building docker images ","783":"Setting HTTP proxy before building docker images using the \"mlflow models build-docker\" command","784":"[FR] Add ability to visualize CSVs in data grid ","785":"[FR] Project with a Docker environment on a login-protected registry","786":"UI: Display all columns in the experiment view","787":"Question - Is there a way to set the artifact-uri of an existing run?","788":"[BUG] SageMaker deploy fails due to invalid link to model","789":"[FR] Publish separate mlflow-client package that doesn't contain server-only dependencies","790":"BUG-Fix mlflow projects with Docker_Env now works on Windows","791":"[FR] compressing models stored by log_model (for example mlflow.sklearn.log_model API)","792":"[BUG] log_model for PyTorch brakes with mixed Modules","793":"[BUG] Issue starting tracking server backed by Postgres\/S3","794":"[BUG] mlflow gc command fails with postgres backend store","795":"hyperparam: save best parameters from optimisation to parent run","796":"[BUG] Large images not showing correctly in artifacts section","797":"[FR] Show experiment tags in mlflow ui","798":"[FR] Enable upload and download of artifacts via MLflow server","799":"[BUG] Running a MLflow project with docker_env fails to create the docker container. ","800":"[BUG] mlflow sagemaker deploy fails to create endpoint","801":"Optimize docker image size by creating docker image based on the model flavor","802":"[BUG] Deploy to SageMaker - (IllegalLocationConstraintException) when calling the CreateBucket operation","803":"[BUG] Columns disappear after sort in UI","804":"[FR] MLflow Model Deployment in SQL Server","805":"[FR] Allow existing experiment name upon create_experiment","806":"[FR] MLServe Support AWS multiple accounts for S3","807":"[BUG] MLflow doesn't delete conda environment created with pip dependency failure","808":"Add action type to parameter","809":"[FR] How to log metric of array","810":"Enable running MLflow projects from notebooks","811":"[BUG] mlflow.start_run() - nested=true is ignored when parent is specified","812":"[FR] Plugins loader should be lazy","813":"[BUG] \"mlflow db upgrade\" fails on PostgreSQL instance due to invalid keyword CONSTRAINT","814":"[BUG] mlflow.spark Model predictions cannot reliably be matched to the input data","815":"[FR] UI plugins (make UI configurable)","816":"[FR] Ability to select epoch (aka \"best step\") from which to display metrics on UI","817":"Show only differing parameter for runs","818":"[FR] Reduce Docker Image Size for Predict","819":"[FR] Make the number of features to plot configurable for XGBoost & LightGBM autologging","820":"[FR] Enhance mlflow run command to accept runs URI for reproducibility.","821":"[FR] Automatic step increment by default when logging metrics","822":"[FR] Double nesting - better UI visualization","823":"[FR] Consider using HiPlot for our parallel coordinates plot","824":"Tensorflow object detection api fixes #1964 ","825":"[BUG] Keras support in tensorflow 2.0","826":"[BUG] Disable conda environment when serving pyfunc on Aws Sagemaker","827":"[FR] Is it possible to load a trained model from a within a Java application . ","828":"[FR] Tool to migrate file backend to SQL","829":"[BUG] Cannot create Mllfow tracking Server Database on Linux - Ubuntu 16.04 Error: (1071, 'Specified key was too long; max key length is 767 bytes')","830":"[FR] Support searching the GUI with an run_id","831":"[FR] Avoid git call if it is known that the project is not in a git repository","832":"allow kwargs in `pyfunc` models","833":"[FR] Allow additional keyword args for Pyfunc model","834":"[BUG] SQL Server connection doesn't write data","835":"[FR] Allow deleting child runs when parent runs are deleted","836":"[BUG] Tensorflow inference doesn't work with Spark UDFs","837":"[BUG] Artifact location as hdfs - tracking UI doesn't show the artifacts","838":"mlflow sagemaker build-and-push-container broken on windows","839":"[FR] Able to delete a run on its run page, with more intuitive display","840":"[FR] Display version in rest api","841":"[FR] Customizing the tracking server's logging format","842":"mlflow run . errors attempting to conda activate during multistep_workflow example[BUG]","843":"Allow MLFLOW_NO_CONDA","844":"[FR] Parallel Coordinates Plot  - Select\/Deselect all parameters\/metrics","845":"Extend doc on R and MLprojects","846":"[FR] Log conda environment creation failure log","847":"[FR] Saving torchscript models","848":"[FR] Model Monitoring after Deployment","849":"[BUG]Issue with subprocess.Popen in backend.py","850":"[DOC-FIX] Document errors for all methods","851":" [BUG] get_experiment returns Default experiment for non-existent experiment ID using MySQL backend-store","852":"Add hdfs support for path parameters","853":"[BUG] Can't run mlflow on HTTPS","854":"Add yarn backend for MLflow project (#75)","855":"[FR] Support for None type in mlflow params or optional arguments","856":"Inject private git webserver in mlflow (#45)","857":"Added backendConfig tag for mlflow project","858":"[BUG] Model Registry does not show username in the UI for Model Versions","859":"[FR] Optionally include a data tranformation.","860":"Added support for base images and elimination of Java in build_docker","861":"Create dockerimage.yml","862":"[FR] Add 'delete' and 'add to comparison' buttons in the run view page","863":"[FR] Allow configuring the number of runs loaded at a time in the experiment view","864":"Unknown custom activation function in mlflow keras[BUG]","865":"[When an artifact is overriden using log_artifact the UI still displays the first version]","866":"add get-git-user","867":"[FR] Maintain a history of registered model stage and version ","868":"Azure ML authentication with service principal ID","869":"Optionally provide a custom image tag","870":"[BUG] preview of text files in MLflow UI","871":"[HELP WANTED] ConnectionReset Error [BUG]","872":"[FR] Add functionality to permanent delete of run","873":"[Example request] examples on saving a spark submit job into a mlflow and serving the saved spark model with the ability to specify the spark configurations when serving the model ","874":"[BUG] NoCredentialsError: Unable to locate credentials On MLFLOW with remote tracking server","875":"[BUG]","876":"[FR]  Add pipeline type runs","877":"[BUG] UI - Dashboards as HTML Artifact - `allow-same-origin` Iframe attrib","878":"[FR]Show summary of of parameters ","879":"Cap train_loss at null_train_loss","880":"[BUG] mlfow server failed to start in k8s","881":"[DOC-FIX]","882":"[FR] Track multiple git repo's in MLFLOW tracking","883":"[SETUP-BUG] mlflow db upgrade fails on first deploy","884":"[FR] I can compare runs of different experiments. Can you generalize it ?","885":"[BUG] Tensorflow gevents collides with MLflow gunicorn when using Docker","886":"[FR] Display execution progress logs on UI","887":"[FR] save_model() support for remote paths","888":"Add filtering capabilities for \"compare runs\" screen","889":"[FR] A run can store artifacts in the \"user\" HDFS folder instead of the experiment one.","890":"Consolidate artifact and backend URI naming","891":"[BUG] OUT-OF-SATE DB SCHEMA (PostgreDB)","892":"[FR] run duration comparison","893":"[FR] parameter information in Active Run object","894":"[BUG] .dockerignore is... ignored","895":"[BUG] h2o.log_model() does not work properly (wrong file type, no upload to S3) + a workaround","896":"[FR] Default modifiable temp folder for log_artifact() \/ log_model() plus 'keep_local_copy' param","897":"[FR] Keep nested runs in UI filtering","898":"[BUG] failed artifact logging to s3 breaks run view in UI","899":"[FR] Allow more than 250 characters for parameter values","900":"[BUG] mlflow.tensorflow.autolog() does not work with tensorflow object detection api.","901":"[FR] Custom docker images for models","902":"Automated CrossValidator tracking [FR]","903":"[BUG] Error running `mlflow ui` when installed from conda-forge","904":"[FR] Allow passing in bool parameters in MLproject entrypoint","905":"[FR] Add templating to create new projects","906":"[FR] Create conda and pip dependencies based on users' installation in `get_default_conda_env()`","907":"keras.backend has no attribute _BACKEND at line 293 keras.py","908":"[FR] Support MMLSpark Serving for Spark models","909":"[FR] Decouple run from data, allow metric logging by dataset","910":"[BUG] Cannot Build a Docker Image with a private network","911":"[FR] Flag commit hash as \"dirty\" in UI if git repo has local changes","912":"[FR] Make MLFlow PyTorch log_model and save_model supports PyTorch models with custom inputs.","913":"Add support for specifying dependent libraries in Databricks backend specification","914":"[FR] Stronger Nesting of Runs","915":"[WIP] Add get_credentials_context to ArtifactRepository","916":"[BUG] Submitting a long param value triggers 5xx code instead of 4xx (bad request)","917":"[FR] When using HTTPS tracking server, keep connection alive to reduce latency when submitting many metrics","918":"Tracking Server start\/stop\/restart\/pause\/list","919":"Support multi-column TensorFlow outputs","920":"[FR] Automatic reload","921":"[BUG] Mlflow CLI run use existing databrick cluster","922":"[FR] Download artifact(s) as tar.gz via a URL","923":"Navigation on the experiment table with Tags","924":"adding argument to pass existing client to mlflow_set_experiment()","925":"Save Global Configuration for Parallel Coordinates Plot","926":"Model comparison with Pivot Tables ","927":"Authentication Mechanism & OAuth Support","928":"How to store artifacts on a server running MLflow instead of the mlruns directory in local server","929":"Upgrade react scripts to v3","930":"[BUG] Race condition in create_experiment with PostgresSql Backend","931":"[FR] Log and programmatically query precision\/recall curves","932":"Allows specifying docker run command through the MLproject file","933":"[FR] UI Metric: Adding an additional plot.","934":"[Feature Request] add golang client","935":"[FR] Allow custom fields in MLModel","936":"how to update model when served the old model[FR]","937":"[BUG] mlflow run MLproject failed but same python command worked","938":"[FR] Add mypy \/ typing checks","939":"[FR] Parallel Coordinate Plot Enhancements","940":"[WIP] Run MLFlow Projects on Azure","941":"[FR] Method for identifying best-performing model","942":"[FR] Implement autolog for tensorboardX support for pytorch","943":"[FR] Managed artifacts","944":"[FR] Diff text files on comparison","945":"[FR] Run MLFlow Project on Azure","946":"[FR] Decorate flask endpoints to add monitoring\/authentication","947":"Dockerized Model Training with MLflow without building new docker in run time.","948":"[BUG] can't run MLFlow project on Windows","949":"Assume IAM Role in another account to store MLFlow Artifact on S3 bucket","950":"[Feature Request] Passing additional POST information to scoring_server","951":"Adding custom models to docker environment ","952":"[Feature request] Support to filter on start_time and end_time column in UI","953":"override nginx listening port and gunicorn server","954":"Does mlflow  support DAG workflow\uff1f","955":"UI add an artifact view on notebooks","956":"Add delete artifact\/model","957":"Log artifacts with step","958":"MLflow Python get_experiment does not return list[RunInfo]","959":"Document supported npm versions for JS dev environment","960":"[RFC] Supporting Oracle databases as backing stores","961":"Feature request: integrate with KFServing","962":"Feature request: Coarser level of organization in Tracking.","963":"C# API","964":"Feature request: in the ui select minimum and maximum of a metric","965":"Compare runs from different experiments","966":"Handle Spark vector columns in pyfunc predictions","967":"cli command option backend-store-uri add sql driver support","968":"Add tag with used Conda environment","969":"Clarify open-source project governance in CONTRIBUTIONS ?","970":"Make mlflow params editable in the UI","971":"Refactor search utils","972":"Update experiment_id from int64 to string, and move default behavior into respective stores","973":"Add Java client for runs\/log-batch REST API","974":"output of the server changed","975":"Managing Experiments from mlflow ui","976":" Error in process_initialize(self, private, command, args, stdin, stdout, : Command not found","977":"Adding conda.yaml and MLProject and updating train_predict.py","978":"MLflow worker timeout when opening UI","979":"FTP client check for existing folders and corrected retrbinary syntax","980":"Integrate Data Versioning","981":"Deploy to Google Cloud Platform (GCP)","982":"Saving user-specific filters and user views","983":"Feature request: Link to child runs on run page","984":"Feature request: Allow arbitrary depth in experiment table view","985":"Released container","986":"Feature request: Multi-user support for tracking and UI","987":"Enhancement: Add ability to log failure reason","988":"Be able to set run output path","989":"Add categorial plot in compare view","990":"Can't install mlflow in amazon sagemaker notebook","991":"Setting up Binder and Notebook","992":"Use reselect selectors to compute derived data in JS components","993":"Support for calling R\/Python models from Python\/R","994":"Filter out UID, GID etc when tarring project for upload to DBFS during Databricks execution","995":"Cannot generate sdk\/Mlflow*.js from protobuf definitions","996":"REST API should return 4xx codes when error is caused by client","997":"Add support for logging environment of the run.","998":"Feature Request: Give MLFlow Experiment overview UI option to display average metric value instead of latest logged value","999":"Feature request: allow user to control order of parameters in tracking UI"},"state":{"0":"open","1":"open","2":"open","3":"open","4":"open","5":"open","6":"open","7":"open","8":"open","9":"open","10":"open","11":"open","12":"open","13":"open","14":"open","15":"open","16":"open","17":"open","18":"open","19":"open","20":"open","21":"open","22":"open","23":"open","24":"open","25":"open","26":"open","27":"open","28":"open","29":"open","30":"open","31":"open","32":"open","33":"open","34":"open","35":"open","36":"open","37":"open","38":"open","39":"open","40":"open","41":"open","42":"open","43":"open","44":"open","45":"open","46":"open","47":"open","48":"open","49":"open","50":"open","51":"open","52":"open","53":"open","54":"open","55":"open","56":"open","57":"open","58":"open","59":"open","60":"open","61":"open","62":"open","63":"open","64":"open","65":"open","66":"open","67":"open","68":"open","69":"open","70":"open","71":"open","72":"open","73":"open","74":"open","75":"open","76":"open","77":"open","78":"open","79":"open","80":"open","81":"open","82":"open","83":"open","84":"open","85":"open","86":"open","87":"open","88":"open","89":"open","90":"open","91":"open","92":"open","93":"open","94":"open","95":"open","96":"open","97":"open","98":"open","99":"open","100":"open","101":"open","102":"open","103":"open","104":"open","105":"open","106":"open","107":"open","108":"open","109":"open","110":"open","111":"open","112":"open","113":"open","114":"open","115":"open","116":"open","117":"open","118":"open","119":"open","120":"open","121":"open","122":"open","123":"open","124":"open","125":"open","126":"open","127":"open","128":"open","129":"open","130":"open","131":"open","132":"open","133":"open","134":"open","135":"open","136":"open","137":"open","138":"open","139":"open","140":"open","141":"open","142":"open","143":"open","144":"open","145":"open","146":"open","147":"open","148":"open","149":"open","150":"open","151":"open","152":"open","153":"open","154":"open","155":"open","156":"open","157":"open","158":"open","159":"open","160":"open","161":"open","162":"open","163":"open","164":"open","165":"open","166":"open","167":"open","168":"open","169":"open","170":"open","171":"open","172":"open","173":"open","174":"open","175":"open","176":"open","177":"open","178":"open","179":"open","180":"open","181":"open","182":"open","183":"open","184":"open","185":"open","186":"open","187":"open","188":"open","189":"open","190":"open","191":"open","192":"open","193":"open","194":"open","195":"open","196":"open","197":"open","198":"open","199":"open","200":"open","201":"open","202":"open","203":"open","204":"open","205":"open","206":"open","207":"open","208":"open","209":"open","210":"open","211":"open","212":"open","213":"open","214":"open","215":"open","216":"open","217":"open","218":"open","219":"open","220":"open","221":"open","222":"open","223":"open","224":"open","225":"open","226":"open","227":"open","228":"open","229":"open","230":"open","231":"open","232":"open","233":"open","234":"open","235":"open","236":"open","237":"open","238":"open","239":"open","240":"open","241":"open","242":"open","243":"open","244":"open","245":"open","246":"open","247":"open","248":"open","249":"open","250":"open","251":"open","252":"open","253":"open","254":"open","255":"open","256":"open","257":"open","258":"open","259":"open","260":"open","261":"open","262":"open","263":"open","264":"open","265":"open","266":"open","267":"open","268":"open","269":"open","270":"open","271":"open","272":"open","273":"open","274":"open","275":"open","276":"open","277":"open","278":"open","279":"open","280":"open","281":"open","282":"open","283":"open","284":"open","285":"open","286":"open","287":"open","288":"open","289":"open","290":"open","291":"open","292":"open","293":"open","294":"open","295":"open","296":"open","297":"open","298":"open","299":"open","300":"open","301":"open","302":"open","303":"open","304":"open","305":"open","306":"open","307":"open","308":"open","309":"open","310":"open","311":"open","312":"open","313":"open","314":"open","315":"open","316":"open","317":"open","318":"open","319":"open","320":"open","321":"open","322":"open","323":"open","324":"open","325":"open","326":"open","327":"open","328":"open","329":"open","330":"open","331":"open","332":"open","333":"open","334":"open","335":"open","336":"open","337":"open","338":"open","339":"open","340":"open","341":"open","342":"open","343":"open","344":"open","345":"open","346":"open","347":"open","348":"open","349":"open","350":"open","351":"open","352":"open","353":"open","354":"open","355":"open","356":"open","357":"open","358":"open","359":"open","360":"open","361":"open","362":"open","363":"open","364":"open","365":"open","366":"open","367":"open","368":"open","369":"open","370":"open","371":"open","372":"open","373":"open","374":"open","375":"open","376":"open","377":"open","378":"open","379":"open","380":"open","381":"open","382":"open","383":"open","384":"open","385":"open","386":"open","387":"open","388":"open","389":"open","390":"open","391":"open","392":"open","393":"open","394":"open","395":"open","396":"open","397":"open","398":"open","399":"open","400":"open","401":"open","402":"open","403":"open","404":"open","405":"open","406":"open","407":"open","408":"open","409":"open","410":"open","411":"open","412":"open","413":"open","414":"open","415":"open","416":"open","417":"open","418":"open","419":"open","420":"open","421":"open","422":"open","423":"open","424":"open","425":"open","426":"open","427":"open","428":"open","429":"open","430":"open","431":"open","432":"open","433":"open","434":"open","435":"open","436":"open","437":"open","438":"open","439":"open","440":"open","441":"open","442":"open","443":"open","444":"open","445":"open","446":"open","447":"open","448":"open","449":"open","450":"open","451":"open","452":"open","453":"open","454":"open","455":"open","456":"open","457":"open","458":"open","459":"open","460":"open","461":"open","462":"open","463":"open","464":"open","465":"open","466":"open","467":"open","468":"open","469":"open","470":"open","471":"open","472":"open","473":"open","474":"open","475":"open","476":"open","477":"open","478":"open","479":"open","480":"open","481":"open","482":"open","483":"open","484":"open","485":"open","486":"open","487":"open","488":"open","489":"open","490":"open","491":"open","492":"open","493":"open","494":"open","495":"open","496":"open","497":"open","498":"open","499":"open","500":"open","501":"open","502":"open","503":"open","504":"open","505":"open","506":"open","507":"open","508":"open","509":"open","510":"open","511":"open","512":"open","513":"open","514":"open","515":"open","516":"open","517":"open","518":"open","519":"open","520":"open","521":"open","522":"open","523":"open","524":"open","525":"open","526":"open","527":"open","528":"open","529":"open","530":"open","531":"open","532":"open","533":"open","534":"open","535":"open","536":"open","537":"open","538":"open","539":"open","540":"open","541":"open","542":"open","543":"open","544":"open","545":"open","546":"open","547":"open","548":"open","549":"open","550":"open","551":"open","552":"open","553":"open","554":"open","555":"open","556":"open","557":"open","558":"open","559":"open","560":"open","561":"open","562":"open","563":"open","564":"open","565":"open","566":"open","567":"open","568":"open","569":"open","570":"open","571":"open","572":"open","573":"open","574":"open","575":"open","576":"open","577":"open","578":"open","579":"open","580":"open","581":"open","582":"open","583":"open","584":"open","585":"open","586":"open","587":"open","588":"open","589":"open","590":"open","591":"open","592":"open","593":"open","594":"open","595":"open","596":"open","597":"open","598":"open","599":"open","600":"open","601":"open","602":"open","603":"open","604":"open","605":"open","606":"open","607":"open","608":"open","609":"open","610":"open","611":"open","612":"open","613":"open","614":"open","615":"open","616":"open","617":"open","618":"open","619":"open","620":"open","621":"open","622":"open","623":"open","624":"open","625":"open","626":"open","627":"open","628":"open","629":"open","630":"open","631":"open","632":"open","633":"open","634":"open","635":"open","636":"open","637":"open","638":"open","639":"open","640":"open","641":"open","642":"open","643":"open","644":"open","645":"open","646":"open","647":"open","648":"open","649":"open","650":"open","651":"open","652":"open","653":"open","654":"open","655":"open","656":"open","657":"open","658":"open","659":"open","660":"open","661":"open","662":"open","663":"open","664":"open","665":"open","666":"open","667":"open","668":"open","669":"open","670":"open","671":"open","672":"open","673":"open","674":"open","675":"open","676":"open","677":"open","678":"open","679":"open","680":"open","681":"open","682":"open","683":"open","684":"open","685":"open","686":"open","687":"open","688":"open","689":"open","690":"open","691":"open","692":"open","693":"open","694":"open","695":"open","696":"open","697":"open","698":"open","699":"open","700":"open","701":"open","702":"open","703":"open","704":"open","705":"open","706":"open","707":"open","708":"open","709":"open","710":"open","711":"open","712":"open","713":"open","714":"open","715":"open","716":"open","717":"open","718":"open","719":"open","720":"open","721":"open","722":"open","723":"open","724":"open","725":"open","726":"open","727":"open","728":"open","729":"open","730":"open","731":"open","732":"open","733":"open","734":"open","735":"open","736":"open","737":"open","738":"open","739":"open","740":"open","741":"open","742":"open","743":"open","744":"open","745":"open","746":"open","747":"open","748":"open","749":"open","750":"open","751":"open","752":"open","753":"open","754":"open","755":"open","756":"open","757":"open","758":"open","759":"open","760":"open","761":"open","762":"open","763":"open","764":"open","765":"open","766":"open","767":"open","768":"open","769":"open","770":"open","771":"open","772":"open","773":"open","774":"open","775":"open","776":"open","777":"open","778":"open","779":"open","780":"open","781":"open","782":"open","783":"open","784":"open","785":"open","786":"open","787":"open","788":"open","789":"open","790":"open","791":"open","792":"open","793":"open","794":"open","795":"open","796":"open","797":"open","798":"open","799":"open","800":"open","801":"open","802":"open","803":"open","804":"open","805":"open","806":"open","807":"open","808":"open","809":"open","810":"open","811":"open","812":"open","813":"open","814":"open","815":"open","816":"open","817":"open","818":"open","819":"open","820":"open","821":"open","822":"open","823":"open","824":"open","825":"open","826":"open","827":"open","828":"open","829":"open","830":"open","831":"open","832":"open","833":"open","834":"open","835":"open","836":"open","837":"open","838":"open","839":"open","840":"open","841":"open","842":"open","843":"open","844":"open","845":"open","846":"open","847":"open","848":"open","849":"open","850":"open","851":"open","852":"open","853":"open","854":"open","855":"open","856":"open","857":"open","858":"open","859":"open","860":"open","861":"open","862":"open","863":"open","864":"open","865":"open","866":"open","867":"open","868":"open","869":"open","870":"open","871":"open","872":"open","873":"open","874":"open","875":"open","876":"open","877":"open","878":"open","879":"open","880":"open","881":"open","882":"open","883":"open","884":"open","885":"open","886":"open","887":"open","888":"open","889":"open","890":"open","891":"open","892":"open","893":"open","894":"open","895":"open","896":"open","897":"open","898":"open","899":"open","900":"open","901":"open","902":"open","903":"open","904":"open","905":"open","906":"open","907":"open","908":"open","909":"open","910":"open","911":"open","912":"open","913":"open","914":"open","915":"open","916":"open","917":"open","918":"open","919":"open","920":"open","921":"open","922":"open","923":"open","924":"open","925":"open","926":"open","927":"open","928":"open","929":"open","930":"open","931":"open","932":"open","933":"open","934":"open","935":"open","936":"open","937":"open","938":"open","939":"open","940":"open","941":"open","942":"open","943":"open","944":"open","945":"open","946":"open","947":"open","948":"open","949":"open","950":"open","951":"open","952":"open","953":"open","954":"open","955":"open","956":"open","957":"open","958":"open","959":"open","960":"open","961":"open","962":"open","963":"open","964":"open","965":"open","966":"open","967":"open","968":"open","969":"open","970":"open","971":"open","972":"open","973":"open","974":"open","975":"open","976":"open","977":"open","978":"open","979":"open","980":"open","981":"open","982":"open","983":"open","984":"open","985":"open","986":"open","987":"open","988":"open","989":"open","990":"open","991":"open","992":"open","993":"open","994":"open","995":"open","996":"open","997":"open","998":"open","999":"open"},"locked":{"0":false,"1":false,"2":false,"3":false,"4":false,"5":false,"6":false,"7":false,"8":false,"9":false,"10":false,"11":false,"12":false,"13":false,"14":false,"15":false,"16":false,"17":false,"18":false,"19":false,"20":false,"21":false,"22":false,"23":false,"24":false,"25":false,"26":false,"27":false,"28":false,"29":false,"30":false,"31":false,"32":false,"33":false,"34":false,"35":false,"36":false,"37":false,"38":false,"39":false,"40":false,"41":false,"42":false,"43":false,"44":false,"45":false,"46":false,"47":false,"48":false,"49":false,"50":false,"51":false,"52":false,"53":false,"54":false,"55":false,"56":false,"57":false,"58":false,"59":false,"60":false,"61":false,"62":false,"63":false,"64":false,"65":false,"66":false,"67":false,"68":false,"69":false,"70":false,"71":false,"72":false,"73":false,"74":false,"75":false,"76":false,"77":false,"78":false,"79":false,"80":false,"81":false,"82":false,"83":false,"84":false,"85":false,"86":false,"87":false,"88":false,"89":false,"90":false,"91":false,"92":false,"93":false,"94":false,"95":false,"96":false,"97":false,"98":false,"99":false,"100":false,"101":false,"102":false,"103":false,"104":false,"105":false,"106":false,"107":false,"108":false,"109":false,"110":false,"111":false,"112":false,"113":false,"114":false,"115":false,"116":false,"117":false,"118":false,"119":false,"120":false,"121":false,"122":false,"123":false,"124":false,"125":false,"126":false,"127":false,"128":false,"129":false,"130":false,"131":false,"132":false,"133":false,"134":false,"135":false,"136":false,"137":false,"138":false,"139":false,"140":false,"141":false,"142":false,"143":false,"144":false,"145":false,"146":false,"147":false,"148":false,"149":false,"150":false,"151":false,"152":false,"153":false,"154":false,"155":false,"156":false,"157":false,"158":false,"159":false,"160":false,"161":false,"162":false,"163":false,"164":false,"165":false,"166":false,"167":false,"168":false,"169":false,"170":false,"171":false,"172":false,"173":false,"174":false,"175":false,"176":false,"177":false,"178":false,"179":false,"180":false,"181":false,"182":false,"183":false,"184":false,"185":false,"186":false,"187":false,"188":false,"189":false,"190":false,"191":false,"192":false,"193":false,"194":false,"195":false,"196":false,"197":false,"198":false,"199":false,"200":false,"201":false,"202":false,"203":false,"204":false,"205":false,"206":false,"207":false,"208":false,"209":false,"210":false,"211":false,"212":false,"213":false,"214":false,"215":false,"216":false,"217":false,"218":false,"219":false,"220":false,"221":false,"222":false,"223":false,"224":false,"225":false,"226":false,"227":false,"228":false,"229":false,"230":false,"231":false,"232":false,"233":false,"234":false,"235":false,"236":false,"237":false,"238":false,"239":false,"240":false,"241":false,"242":false,"243":false,"244":false,"245":false,"246":false,"247":false,"248":false,"249":false,"250":false,"251":false,"252":false,"253":false,"254":false,"255":false,"256":false,"257":false,"258":false,"259":false,"260":false,"261":false,"262":false,"263":false,"264":false,"265":false,"266":false,"267":false,"268":false,"269":false,"270":false,"271":false,"272":false,"273":false,"274":false,"275":false,"276":false,"277":false,"278":false,"279":false,"280":false,"281":false,"282":false,"283":false,"284":false,"285":false,"286":false,"287":false,"288":false,"289":false,"290":false,"291":false,"292":false,"293":false,"294":false,"295":false,"296":false,"297":false,"298":false,"299":false,"300":false,"301":false,"302":false,"303":false,"304":false,"305":false,"306":false,"307":false,"308":false,"309":false,"310":false,"311":false,"312":false,"313":false,"314":false,"315":false,"316":false,"317":false,"318":false,"319":false,"320":false,"321":false,"322":false,"323":false,"324":false,"325":false,"326":false,"327":false,"328":false,"329":false,"330":false,"331":false,"332":false,"333":false,"334":false,"335":false,"336":false,"337":false,"338":false,"339":false,"340":false,"341":false,"342":false,"343":false,"344":false,"345":false,"346":false,"347":false,"348":false,"349":false,"350":false,"351":false,"352":false,"353":false,"354":false,"355":false,"356":false,"357":false,"358":false,"359":false,"360":false,"361":false,"362":false,"363":false,"364":false,"365":false,"366":false,"367":false,"368":false,"369":false,"370":false,"371":false,"372":false,"373":false,"374":false,"375":false,"376":false,"377":false,"378":false,"379":false,"380":false,"381":false,"382":false,"383":false,"384":false,"385":false,"386":false,"387":false,"388":false,"389":false,"390":false,"391":false,"392":false,"393":false,"394":false,"395":false,"396":false,"397":false,"398":false,"399":false,"400":false,"401":false,"402":false,"403":false,"404":false,"405":false,"406":false,"407":false,"408":false,"409":false,"410":false,"411":false,"412":false,"413":false,"414":false,"415":false,"416":false,"417":false,"418":false,"419":false,"420":false,"421":false,"422":false,"423":false,"424":false,"425":false,"426":false,"427":false,"428":false,"429":false,"430":false,"431":false,"432":false,"433":false,"434":false,"435":false,"436":false,"437":false,"438":false,"439":false,"440":false,"441":false,"442":false,"443":false,"444":false,"445":false,"446":false,"447":false,"448":false,"449":false,"450":false,"451":false,"452":false,"453":false,"454":false,"455":false,"456":false,"457":false,"458":false,"459":false,"460":false,"461":false,"462":false,"463":false,"464":false,"465":false,"466":false,"467":false,"468":false,"469":false,"470":false,"471":false,"472":false,"473":false,"474":false,"475":false,"476":false,"477":false,"478":false,"479":false,"480":false,"481":false,"482":false,"483":false,"484":false,"485":false,"486":false,"487":false,"488":false,"489":false,"490":false,"491":false,"492":false,"493":false,"494":false,"495":false,"496":false,"497":false,"498":false,"499":false,"500":false,"501":false,"502":false,"503":false,"504":false,"505":false,"506":false,"507":false,"508":false,"509":false,"510":false,"511":false,"512":false,"513":false,"514":false,"515":false,"516":false,"517":false,"518":false,"519":false,"520":false,"521":false,"522":false,"523":false,"524":false,"525":false,"526":false,"527":false,"528":false,"529":false,"530":false,"531":false,"532":false,"533":false,"534":false,"535":false,"536":false,"537":false,"538":false,"539":false,"540":false,"541":false,"542":false,"543":false,"544":false,"545":false,"546":false,"547":false,"548":false,"549":false,"550":false,"551":false,"552":false,"553":false,"554":false,"555":false,"556":false,"557":false,"558":false,"559":false,"560":false,"561":false,"562":false,"563":false,"564":false,"565":false,"566":false,"567":false,"568":false,"569":false,"570":false,"571":false,"572":false,"573":false,"574":false,"575":false,"576":false,"577":false,"578":false,"579":false,"580":false,"581":false,"582":false,"583":false,"584":false,"585":false,"586":false,"587":false,"588":false,"589":false,"590":false,"591":false,"592":false,"593":false,"594":false,"595":false,"596":false,"597":false,"598":false,"599":false,"600":false,"601":false,"602":false,"603":false,"604":false,"605":false,"606":false,"607":false,"608":false,"609":false,"610":false,"611":false,"612":false,"613":false,"614":false,"615":false,"616":false,"617":false,"618":false,"619":false,"620":false,"621":false,"622":false,"623":false,"624":false,"625":false,"626":false,"627":false,"628":false,"629":false,"630":false,"631":false,"632":false,"633":false,"634":false,"635":false,"636":false,"637":false,"638":false,"639":false,"640":false,"641":false,"642":false,"643":false,"644":false,"645":false,"646":false,"647":false,"648":false,"649":false,"650":false,"651":false,"652":false,"653":false,"654":false,"655":false,"656":false,"657":false,"658":false,"659":false,"660":false,"661":false,"662":false,"663":false,"664":false,"665":false,"666":false,"667":false,"668":false,"669":false,"670":false,"671":false,"672":false,"673":false,"674":false,"675":false,"676":false,"677":false,"678":false,"679":false,"680":false,"681":false,"682":false,"683":false,"684":false,"685":false,"686":false,"687":false,"688":false,"689":false,"690":false,"691":false,"692":false,"693":false,"694":false,"695":false,"696":false,"697":false,"698":false,"699":false,"700":false,"701":false,"702":false,"703":false,"704":false,"705":false,"706":false,"707":false,"708":false,"709":false,"710":false,"711":false,"712":false,"713":false,"714":false,"715":false,"716":false,"717":false,"718":false,"719":false,"720":false,"721":false,"722":false,"723":false,"724":false,"725":false,"726":false,"727":false,"728":false,"729":false,"730":false,"731":false,"732":false,"733":false,"734":false,"735":false,"736":false,"737":false,"738":false,"739":false,"740":false,"741":false,"742":false,"743":false,"744":false,"745":false,"746":false,"747":false,"748":false,"749":false,"750":false,"751":false,"752":false,"753":false,"754":false,"755":false,"756":false,"757":false,"758":false,"759":false,"760":false,"761":false,"762":false,"763":false,"764":false,"765":false,"766":false,"767":false,"768":false,"769":false,"770":false,"771":false,"772":false,"773":false,"774":false,"775":false,"776":false,"777":false,"778":false,"779":false,"780":false,"781":false,"782":false,"783":false,"784":false,"785":false,"786":false,"787":false,"788":false,"789":false,"790":false,"791":false,"792":false,"793":false,"794":false,"795":false,"796":false,"797":false,"798":false,"799":false,"800":false,"801":false,"802":false,"803":false,"804":false,"805":false,"806":false,"807":false,"808":false,"809":false,"810":false,"811":false,"812":false,"813":false,"814":false,"815":false,"816":false,"817":false,"818":false,"819":false,"820":false,"821":false,"822":false,"823":false,"824":false,"825":false,"826":false,"827":false,"828":false,"829":false,"830":false,"831":false,"832":false,"833":false,"834":false,"835":false,"836":false,"837":false,"838":false,"839":false,"840":false,"841":false,"842":false,"843":false,"844":false,"845":false,"846":false,"847":false,"848":false,"849":false,"850":false,"851":false,"852":false,"853":false,"854":false,"855":false,"856":false,"857":false,"858":false,"859":false,"860":false,"861":false,"862":false,"863":false,"864":false,"865":false,"866":false,"867":false,"868":false,"869":false,"870":false,"871":false,"872":false,"873":false,"874":false,"875":false,"876":false,"877":false,"878":false,"879":false,"880":false,"881":false,"882":false,"883":false,"884":false,"885":false,"886":false,"887":false,"888":false,"889":false,"890":false,"891":false,"892":false,"893":false,"894":false,"895":false,"896":false,"897":false,"898":false,"899":false,"900":false,"901":false,"902":false,"903":false,"904":false,"905":false,"906":false,"907":false,"908":false,"909":false,"910":false,"911":false,"912":false,"913":false,"914":false,"915":false,"916":false,"917":false,"918":false,"919":false,"920":false,"921":false,"922":false,"923":false,"924":false,"925":false,"926":false,"927":false,"928":false,"929":false,"930":false,"931":false,"932":false,"933":false,"934":false,"935":false,"936":false,"937":false,"938":false,"939":false,"940":false,"941":false,"942":false,"943":false,"944":false,"945":false,"946":false,"947":false,"948":false,"949":false,"950":false,"951":false,"952":false,"953":false,"954":false,"955":false,"956":false,"957":false,"958":false,"959":false,"960":false,"961":false,"962":false,"963":false,"964":false,"965":false,"966":false,"967":false,"968":false,"969":false,"970":false,"971":false,"972":false,"973":false,"974":false,"975":false,"976":false,"977":false,"978":false,"979":false,"980":false,"981":false,"982":false,"983":false,"984":false,"985":false,"986":false,"987":false,"988":false,"989":false,"990":false,"991":false,"992":false,"993":false,"994":false,"995":false,"996":false,"997":false,"998":false,"999":false},"assignee":{"0":null,"1":null,"2":null,"3":null,"4":null,"5":null,"6":null,"7":null,"8":null,"9":null,"10":null,"11":null,"12":null,"13":null,"14":null,"15":null,"16":null,"17":null,"18":null,"19":null,"20":null,"21":null,"22":null,"23":null,"24":null,"25":null,"26":null,"27":null,"28":null,"29":null,"30":null,"31":null,"32":{"login":"ankit-db","id":52183359,"node_id":"MDQ6VXNlcjUyMTgzMzU5","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/52183359?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/ankit-db","html_url":"https:\/\/github.com\/ankit-db","followers_url":"https:\/\/api.github.com\/users\/ankit-db\/followers","following_url":"https:\/\/api.github.com\/users\/ankit-db\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/ankit-db\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/ankit-db\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/ankit-db\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/ankit-db\/orgs","repos_url":"https:\/\/api.github.com\/users\/ankit-db\/repos","events_url":"https:\/\/api.github.com\/users\/ankit-db\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/ankit-db\/received_events","type":"User","site_admin":false},"33":null,"34":null,"35":null,"36":null,"37":null,"38":null,"39":null,"40":null,"41":null,"42":null,"43":null,"44":null,"45":null,"46":null,"47":null,"48":null,"49":null,"50":null,"51":null,"52":null,"53":null,"54":null,"55":null,"56":null,"57":null,"58":null,"59":null,"60":null,"61":null,"62":null,"63":null,"64":null,"65":null,"66":null,"67":null,"68":null,"69":null,"70":null,"71":null,"72":null,"73":null,"74":null,"75":null,"76":null,"77":null,"78":null,"79":null,"80":null,"81":null,"82":null,"83":null,"84":null,"85":{"login":"daanknoope","id":8389610,"node_id":"MDQ6VXNlcjgzODk2MTA=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8389610?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/daanknoope","html_url":"https:\/\/github.com\/daanknoope","followers_url":"https:\/\/api.github.com\/users\/daanknoope\/followers","following_url":"https:\/\/api.github.com\/users\/daanknoope\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/daanknoope\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/daanknoope\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/daanknoope\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/daanknoope\/orgs","repos_url":"https:\/\/api.github.com\/users\/daanknoope\/repos","events_url":"https:\/\/api.github.com\/users\/daanknoope\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/daanknoope\/received_events","type":"User","site_admin":false},"86":null,"87":null,"88":null,"89":null,"90":null,"91":null,"92":null,"93":null,"94":null,"95":null,"96":null,"97":null,"98":null,"99":null,"100":null,"101":null,"102":null,"103":null,"104":null,"105":null,"106":null,"107":null,"108":null,"109":null,"110":null,"111":null,"112":null,"113":null,"114":null,"115":null,"116":null,"117":null,"118":null,"119":null,"120":null,"121":null,"122":null,"123":null,"124":{"login":"mohamad-arabi","id":73549313,"node_id":"MDQ6VXNlcjczNTQ5MzEz","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/73549313?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/mohamad-arabi","html_url":"https:\/\/github.com\/mohamad-arabi","followers_url":"https:\/\/api.github.com\/users\/mohamad-arabi\/followers","following_url":"https:\/\/api.github.com\/users\/mohamad-arabi\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/mohamad-arabi\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/mohamad-arabi\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/mohamad-arabi\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/mohamad-arabi\/orgs","repos_url":"https:\/\/api.github.com\/users\/mohamad-arabi\/repos","events_url":"https:\/\/api.github.com\/users\/mohamad-arabi\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/mohamad-arabi\/received_events","type":"User","site_admin":false},"125":null,"126":null,"127":null,"128":null,"129":null,"130":null,"131":null,"132":null,"133":null,"134":null,"135":null,"136":null,"137":null,"138":null,"139":null,"140":null,"141":null,"142":null,"143":null,"144":null,"145":null,"146":null,"147":null,"148":null,"149":null,"150":null,"151":null,"152":null,"153":null,"154":null,"155":null,"156":null,"157":null,"158":null,"159":null,"160":{"login":"ankit-db","id":52183359,"node_id":"MDQ6VXNlcjUyMTgzMzU5","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/52183359?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/ankit-db","html_url":"https:\/\/github.com\/ankit-db","followers_url":"https:\/\/api.github.com\/users\/ankit-db\/followers","following_url":"https:\/\/api.github.com\/users\/ankit-db\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/ankit-db\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/ankit-db\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/ankit-db\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/ankit-db\/orgs","repos_url":"https:\/\/api.github.com\/users\/ankit-db\/repos","events_url":"https:\/\/api.github.com\/users\/ankit-db\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/ankit-db\/received_events","type":"User","site_admin":false},"161":null,"162":null,"163":null,"164":null,"165":null,"166":null,"167":null,"168":null,"169":null,"170":null,"171":null,"172":null,"173":null,"174":null,"175":null,"176":null,"177":null,"178":null,"179":null,"180":null,"181":{"login":"bali0019","id":18537688,"node_id":"MDQ6VXNlcjE4NTM3Njg4","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/18537688?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/bali0019","html_url":"https:\/\/github.com\/bali0019","followers_url":"https:\/\/api.github.com\/users\/bali0019\/followers","following_url":"https:\/\/api.github.com\/users\/bali0019\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/bali0019\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/bali0019\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/bali0019\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/bali0019\/orgs","repos_url":"https:\/\/api.github.com\/users\/bali0019\/repos","events_url":"https:\/\/api.github.com\/users\/bali0019\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/bali0019\/received_events","type":"User","site_admin":false},"182":null,"183":{"login":"coder-freestyle","id":60594457,"node_id":"MDQ6VXNlcjYwNTk0NDU3","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/60594457?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/coder-freestyle","html_url":"https:\/\/github.com\/coder-freestyle","followers_url":"https:\/\/api.github.com\/users\/coder-freestyle\/followers","following_url":"https:\/\/api.github.com\/users\/coder-freestyle\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/coder-freestyle\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/coder-freestyle\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/coder-freestyle\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/coder-freestyle\/orgs","repos_url":"https:\/\/api.github.com\/users\/coder-freestyle\/repos","events_url":"https:\/\/api.github.com\/users\/coder-freestyle\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/coder-freestyle\/received_events","type":"User","site_admin":false},"184":{"login":"WeichenXu123","id":19235986,"node_id":"MDQ6VXNlcjE5MjM1OTg2","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/19235986?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/WeichenXu123","html_url":"https:\/\/github.com\/WeichenXu123","followers_url":"https:\/\/api.github.com\/users\/WeichenXu123\/followers","following_url":"https:\/\/api.github.com\/users\/WeichenXu123\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/WeichenXu123\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/WeichenXu123\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/WeichenXu123\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/WeichenXu123\/orgs","repos_url":"https:\/\/api.github.com\/users\/WeichenXu123\/repos","events_url":"https:\/\/api.github.com\/users\/WeichenXu123\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/WeichenXu123\/received_events","type":"User","site_admin":false},"185":null,"186":null,"187":null,"188":null,"189":null,"190":null,"191":null,"192":null,"193":null,"194":null,"195":null,"196":null,"197":null,"198":null,"199":null,"200":null,"201":null,"202":null,"203":null,"204":null,"205":null,"206":null,"207":null,"208":null,"209":null,"210":null,"211":null,"212":null,"213":null,"214":null,"215":null,"216":null,"217":null,"218":null,"219":null,"220":null,"221":null,"222":null,"223":null,"224":null,"225":null,"226":null,"227":null,"228":null,"229":null,"230":null,"231":null,"232":null,"233":null,"234":null,"235":null,"236":null,"237":null,"238":null,"239":null,"240":null,"241":null,"242":null,"243":null,"244":null,"245":null,"246":null,"247":null,"248":null,"249":null,"250":null,"251":null,"252":null,"253":null,"254":null,"255":null,"256":null,"257":null,"258":null,"259":null,"260":null,"261":null,"262":null,"263":null,"264":null,"265":null,"266":null,"267":null,"268":null,"269":{"login":"apurva-koti","id":51172624,"node_id":"MDQ6VXNlcjUxMTcyNjI0","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/51172624?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/apurva-koti","html_url":"https:\/\/github.com\/apurva-koti","followers_url":"https:\/\/api.github.com\/users\/apurva-koti\/followers","following_url":"https:\/\/api.github.com\/users\/apurva-koti\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/apurva-koti\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/apurva-koti\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/apurva-koti\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/apurva-koti\/orgs","repos_url":"https:\/\/api.github.com\/users\/apurva-koti\/repos","events_url":"https:\/\/api.github.com\/users\/apurva-koti\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/apurva-koti\/received_events","type":"User","site_admin":false},"270":null,"271":null,"272":null,"273":null,"274":null,"275":null,"276":null,"277":null,"278":null,"279":null,"280":null,"281":null,"282":null,"283":null,"284":null,"285":null,"286":null,"287":null,"288":null,"289":null,"290":null,"291":null,"292":null,"293":null,"294":null,"295":null,"296":null,"297":null,"298":null,"299":null,"300":null,"301":null,"302":null,"303":null,"304":null,"305":null,"306":null,"307":null,"308":null,"309":null,"310":null,"311":{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/39497902?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dbczumar","html_url":"https:\/\/github.com\/dbczumar","followers_url":"https:\/\/api.github.com\/users\/dbczumar\/followers","following_url":"https:\/\/api.github.com\/users\/dbczumar\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dbczumar\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dbczumar\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dbczumar\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dbczumar\/orgs","repos_url":"https:\/\/api.github.com\/users\/dbczumar\/repos","events_url":"https:\/\/api.github.com\/users\/dbczumar\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dbczumar\/received_events","type":"User","site_admin":false},"312":null,"313":null,"314":null,"315":null,"316":null,"317":null,"318":null,"319":null,"320":null,"321":null,"322":null,"323":null,"324":null,"325":null,"326":null,"327":null,"328":null,"329":null,"330":null,"331":null,"332":null,"333":null,"334":null,"335":null,"336":null,"337":null,"338":null,"339":null,"340":null,"341":null,"342":null,"343":null,"344":null,"345":null,"346":null,"347":null,"348":null,"349":null,"350":{"login":"dmatrix","id":1117597,"node_id":"MDQ6VXNlcjExMTc1OTc=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/1117597?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dmatrix","html_url":"https:\/\/github.com\/dmatrix","followers_url":"https:\/\/api.github.com\/users\/dmatrix\/followers","following_url":"https:\/\/api.github.com\/users\/dmatrix\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dmatrix\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dmatrix\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dmatrix\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dmatrix\/orgs","repos_url":"https:\/\/api.github.com\/users\/dmatrix\/repos","events_url":"https:\/\/api.github.com\/users\/dmatrix\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dmatrix\/received_events","type":"User","site_admin":false},"351":null,"352":{"login":"dmatrix","id":1117597,"node_id":"MDQ6VXNlcjExMTc1OTc=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/1117597?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dmatrix","html_url":"https:\/\/github.com\/dmatrix","followers_url":"https:\/\/api.github.com\/users\/dmatrix\/followers","following_url":"https:\/\/api.github.com\/users\/dmatrix\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dmatrix\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dmatrix\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dmatrix\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dmatrix\/orgs","repos_url":"https:\/\/api.github.com\/users\/dmatrix\/repos","events_url":"https:\/\/api.github.com\/users\/dmatrix\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dmatrix\/received_events","type":"User","site_admin":false},"353":null,"354":null,"355":null,"356":null,"357":null,"358":null,"359":null,"360":null,"361":null,"362":null,"363":null,"364":null,"365":null,"366":null,"367":null,"368":null,"369":null,"370":null,"371":null,"372":null,"373":null,"374":null,"375":null,"376":null,"377":null,"378":null,"379":null,"380":null,"381":null,"382":null,"383":null,"384":null,"385":null,"386":null,"387":null,"388":null,"389":null,"390":null,"391":null,"392":null,"393":null,"394":null,"395":null,"396":null,"397":null,"398":null,"399":null,"400":null,"401":null,"402":null,"403":null,"404":null,"405":null,"406":null,"407":null,"408":{"login":"ankit-db","id":52183359,"node_id":"MDQ6VXNlcjUyMTgzMzU5","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/52183359?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/ankit-db","html_url":"https:\/\/github.com\/ankit-db","followers_url":"https:\/\/api.github.com\/users\/ankit-db\/followers","following_url":"https:\/\/api.github.com\/users\/ankit-db\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/ankit-db\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/ankit-db\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/ankit-db\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/ankit-db\/orgs","repos_url":"https:\/\/api.github.com\/users\/ankit-db\/repos","events_url":"https:\/\/api.github.com\/users\/ankit-db\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/ankit-db\/received_events","type":"User","site_admin":false},"409":null,"410":null,"411":null,"412":null,"413":null,"414":null,"415":null,"416":null,"417":null,"418":null,"419":null,"420":null,"421":null,"422":null,"423":null,"424":{"login":"lorenzwalthert","id":10477073,"node_id":"MDQ6VXNlcjEwNDc3MDcz","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/10477073?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/lorenzwalthert","html_url":"https:\/\/github.com\/lorenzwalthert","followers_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/followers","following_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/orgs","repos_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/repos","events_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/received_events","type":"User","site_admin":false},"425":null,"426":null,"427":null,"428":null,"429":null,"430":null,"431":null,"432":null,"433":null,"434":null,"435":null,"436":null,"437":null,"438":null,"439":null,"440":null,"441":null,"442":null,"443":null,"444":null,"445":null,"446":null,"447":null,"448":null,"449":null,"450":null,"451":null,"452":null,"453":null,"454":null,"455":null,"456":null,"457":null,"458":null,"459":null,"460":null,"461":null,"462":null,"463":null,"464":null,"465":null,"466":null,"467":null,"468":null,"469":{"login":"lorenzwalthert","id":10477073,"node_id":"MDQ6VXNlcjEwNDc3MDcz","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/10477073?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/lorenzwalthert","html_url":"https:\/\/github.com\/lorenzwalthert","followers_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/followers","following_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/orgs","repos_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/repos","events_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/received_events","type":"User","site_admin":false},"470":{"login":"yitao-li","id":405346,"node_id":"MDQ6VXNlcjQwNTM0Ng==","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/405346?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/yitao-li","html_url":"https:\/\/github.com\/yitao-li","followers_url":"https:\/\/api.github.com\/users\/yitao-li\/followers","following_url":"https:\/\/api.github.com\/users\/yitao-li\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/yitao-li\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/yitao-li\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/yitao-li\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/yitao-li\/orgs","repos_url":"https:\/\/api.github.com\/users\/yitao-li\/repos","events_url":"https:\/\/api.github.com\/users\/yitao-li\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/yitao-li\/received_events","type":"User","site_admin":false},"471":null,"472":null,"473":null,"474":null,"475":null,"476":{"login":"yitao-li","id":405346,"node_id":"MDQ6VXNlcjQwNTM0Ng==","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/405346?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/yitao-li","html_url":"https:\/\/github.com\/yitao-li","followers_url":"https:\/\/api.github.com\/users\/yitao-li\/followers","following_url":"https:\/\/api.github.com\/users\/yitao-li\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/yitao-li\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/yitao-li\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/yitao-li\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/yitao-li\/orgs","repos_url":"https:\/\/api.github.com\/users\/yitao-li\/repos","events_url":"https:\/\/api.github.com\/users\/yitao-li\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/yitao-li\/received_events","type":"User","site_admin":false},"477":null,"478":{"login":"harupy","id":17039389,"node_id":"MDQ6VXNlcjE3MDM5Mzg5","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/17039389?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/harupy","html_url":"https:\/\/github.com\/harupy","followers_url":"https:\/\/api.github.com\/users\/harupy\/followers","following_url":"https:\/\/api.github.com\/users\/harupy\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/harupy\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/harupy\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/harupy\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/harupy\/orgs","repos_url":"https:\/\/api.github.com\/users\/harupy\/repos","events_url":"https:\/\/api.github.com\/users\/harupy\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/harupy\/received_events","type":"User","site_admin":false},"479":null,"480":null,"481":null,"482":null,"483":null,"484":null,"485":null,"486":null,"487":null,"488":null,"489":null,"490":null,"491":null,"492":null,"493":null,"494":null,"495":null,"496":null,"497":null,"498":null,"499":null,"500":null,"501":null,"502":null,"503":null,"504":null,"505":null,"506":null,"507":null,"508":null,"509":null,"510":null,"511":null,"512":null,"513":null,"514":null,"515":null,"516":null,"517":null,"518":null,"519":null,"520":null,"521":null,"522":null,"523":null,"524":null,"525":null,"526":null,"527":null,"528":null,"529":null,"530":null,"531":null,"532":null,"533":null,"534":null,"535":null,"536":null,"537":null,"538":null,"539":null,"540":null,"541":null,"542":null,"543":null,"544":null,"545":null,"546":null,"547":null,"548":null,"549":null,"550":null,"551":null,"552":null,"553":null,"554":null,"555":null,"556":null,"557":null,"558":null,"559":null,"560":null,"561":null,"562":null,"563":null,"564":null,"565":null,"566":null,"567":null,"568":null,"569":null,"570":null,"571":null,"572":null,"573":null,"574":null,"575":null,"576":null,"577":null,"578":null,"579":null,"580":null,"581":null,"582":null,"583":null,"584":null,"585":null,"586":null,"587":null,"588":null,"589":null,"590":null,"591":null,"592":null,"593":null,"594":null,"595":null,"596":null,"597":null,"598":null,"599":null,"600":{"login":"ankit-db","id":52183359,"node_id":"MDQ6VXNlcjUyMTgzMzU5","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/52183359?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/ankit-db","html_url":"https:\/\/github.com\/ankit-db","followers_url":"https:\/\/api.github.com\/users\/ankit-db\/followers","following_url":"https:\/\/api.github.com\/users\/ankit-db\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/ankit-db\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/ankit-db\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/ankit-db\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/ankit-db\/orgs","repos_url":"https:\/\/api.github.com\/users\/ankit-db\/repos","events_url":"https:\/\/api.github.com\/users\/ankit-db\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/ankit-db\/received_events","type":"User","site_admin":false},"601":null,"602":null,"603":null,"604":null,"605":null,"606":null,"607":{"login":"apurva-koti","id":51172624,"node_id":"MDQ6VXNlcjUxMTcyNjI0","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/51172624?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/apurva-koti","html_url":"https:\/\/github.com\/apurva-koti","followers_url":"https:\/\/api.github.com\/users\/apurva-koti\/followers","following_url":"https:\/\/api.github.com\/users\/apurva-koti\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/apurva-koti\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/apurva-koti\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/apurva-koti\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/apurva-koti\/orgs","repos_url":"https:\/\/api.github.com\/users\/apurva-koti\/repos","events_url":"https:\/\/api.github.com\/users\/apurva-koti\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/apurva-koti\/received_events","type":"User","site_admin":false},"608":null,"609":null,"610":null,"611":null,"612":null,"613":null,"614":null,"615":null,"616":null,"617":null,"618":null,"619":null,"620":null,"621":null,"622":null,"623":null,"624":null,"625":null,"626":{"login":"zhidongqu-db","id":64800904,"node_id":"MDQ6VXNlcjY0ODAwOTA0","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/64800904?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/zhidongqu-db","html_url":"https:\/\/github.com\/zhidongqu-db","followers_url":"https:\/\/api.github.com\/users\/zhidongqu-db\/followers","following_url":"https:\/\/api.github.com\/users\/zhidongqu-db\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/zhidongqu-db\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/zhidongqu-db\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/zhidongqu-db\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/zhidongqu-db\/orgs","repos_url":"https:\/\/api.github.com\/users\/zhidongqu-db\/repos","events_url":"https:\/\/api.github.com\/users\/zhidongqu-db\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/zhidongqu-db\/received_events","type":"User","site_admin":false},"627":{"login":"ankit-db","id":52183359,"node_id":"MDQ6VXNlcjUyMTgzMzU5","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/52183359?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/ankit-db","html_url":"https:\/\/github.com\/ankit-db","followers_url":"https:\/\/api.github.com\/users\/ankit-db\/followers","following_url":"https:\/\/api.github.com\/users\/ankit-db\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/ankit-db\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/ankit-db\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/ankit-db\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/ankit-db\/orgs","repos_url":"https:\/\/api.github.com\/users\/ankit-db\/repos","events_url":"https:\/\/api.github.com\/users\/ankit-db\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/ankit-db\/received_events","type":"User","site_admin":false},"628":null,"629":null,"630":null,"631":null,"632":null,"633":null,"634":null,"635":null,"636":null,"637":null,"638":null,"639":{"login":"dmatrix","id":1117597,"node_id":"MDQ6VXNlcjExMTc1OTc=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/1117597?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dmatrix","html_url":"https:\/\/github.com\/dmatrix","followers_url":"https:\/\/api.github.com\/users\/dmatrix\/followers","following_url":"https:\/\/api.github.com\/users\/dmatrix\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dmatrix\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dmatrix\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dmatrix\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dmatrix\/orgs","repos_url":"https:\/\/api.github.com\/users\/dmatrix\/repos","events_url":"https:\/\/api.github.com\/users\/dmatrix\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dmatrix\/received_events","type":"User","site_admin":false},"640":null,"641":null,"642":{"login":"avflor","id":18666312,"node_id":"MDQ6VXNlcjE4NjY2MzEy","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/18666312?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/avflor","html_url":"https:\/\/github.com\/avflor","followers_url":"https:\/\/api.github.com\/users\/avflor\/followers","following_url":"https:\/\/api.github.com\/users\/avflor\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/avflor\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/avflor\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/avflor\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/avflor\/orgs","repos_url":"https:\/\/api.github.com\/users\/avflor\/repos","events_url":"https:\/\/api.github.com\/users\/avflor\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/avflor\/received_events","type":"User","site_admin":false},"643":null,"644":null,"645":null,"646":null,"647":null,"648":null,"649":null,"650":null,"651":{"login":"dmatrix","id":1117597,"node_id":"MDQ6VXNlcjExMTc1OTc=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/1117597?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dmatrix","html_url":"https:\/\/github.com\/dmatrix","followers_url":"https:\/\/api.github.com\/users\/dmatrix\/followers","following_url":"https:\/\/api.github.com\/users\/dmatrix\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dmatrix\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dmatrix\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dmatrix\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dmatrix\/orgs","repos_url":"https:\/\/api.github.com\/users\/dmatrix\/repos","events_url":"https:\/\/api.github.com\/users\/dmatrix\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dmatrix\/received_events","type":"User","site_admin":false},"652":null,"653":null,"654":null,"655":null,"656":null,"657":null,"658":null,"659":null,"660":null,"661":null,"662":null,"663":null,"664":null,"665":null,"666":null,"667":null,"668":{"login":"javierluraschi","id":3478847,"node_id":"MDQ6VXNlcjM0Nzg4NDc=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/3478847?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/javierluraschi","html_url":"https:\/\/github.com\/javierluraschi","followers_url":"https:\/\/api.github.com\/users\/javierluraschi\/followers","following_url":"https:\/\/api.github.com\/users\/javierluraschi\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/javierluraschi\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/javierluraschi\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/javierluraschi\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/javierluraschi\/orgs","repos_url":"https:\/\/api.github.com\/users\/javierluraschi\/repos","events_url":"https:\/\/api.github.com\/users\/javierluraschi\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/javierluraschi\/received_events","type":"User","site_admin":false},"669":null,"670":null,"671":null,"672":null,"673":null,"674":null,"675":null,"676":null,"677":{"login":"Zangr","id":6811562,"node_id":"MDQ6VXNlcjY4MTE1NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/6811562?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/Zangr","html_url":"https:\/\/github.com\/Zangr","followers_url":"https:\/\/api.github.com\/users\/Zangr\/followers","following_url":"https:\/\/api.github.com\/users\/Zangr\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/Zangr\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/Zangr\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/Zangr\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/Zangr\/orgs","repos_url":"https:\/\/api.github.com\/users\/Zangr\/repos","events_url":"https:\/\/api.github.com\/users\/Zangr\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/Zangr\/received_events","type":"User","site_admin":false},"678":null,"679":null,"680":null,"681":null,"682":null,"683":null,"684":null,"685":{"login":"sueann","id":4411489,"node_id":"MDQ6VXNlcjQ0MTE0ODk=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/4411489?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/sueann","html_url":"https:\/\/github.com\/sueann","followers_url":"https:\/\/api.github.com\/users\/sueann\/followers","following_url":"https:\/\/api.github.com\/users\/sueann\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/sueann\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/sueann\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/sueann\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/sueann\/orgs","repos_url":"https:\/\/api.github.com\/users\/sueann\/repos","events_url":"https:\/\/api.github.com\/users\/sueann\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/sueann\/received_events","type":"User","site_admin":false},"686":{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/39497902?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dbczumar","html_url":"https:\/\/github.com\/dbczumar","followers_url":"https:\/\/api.github.com\/users\/dbczumar\/followers","following_url":"https:\/\/api.github.com\/users\/dbczumar\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dbczumar\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dbczumar\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dbczumar\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dbczumar\/orgs","repos_url":"https:\/\/api.github.com\/users\/dbczumar\/repos","events_url":"https:\/\/api.github.com\/users\/dbczumar\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dbczumar\/received_events","type":"User","site_admin":false},"687":null,"688":null,"689":null,"690":null,"691":null,"692":null,"693":null,"694":null,"695":null,"696":null,"697":null,"698":null,"699":null,"700":null,"701":null,"702":null,"703":null,"704":null,"705":null,"706":null,"707":null,"708":null,"709":null,"710":null,"711":null,"712":null,"713":null,"714":null,"715":null,"716":null,"717":null,"718":null,"719":null,"720":null,"721":null,"722":null,"723":null,"724":null,"725":null,"726":null,"727":null,"728":null,"729":null,"730":null,"731":null,"732":null,"733":null,"734":null,"735":null,"736":null,"737":null,"738":null,"739":null,"740":null,"741":null,"742":null,"743":null,"744":null,"745":null,"746":null,"747":null,"748":null,"749":null,"750":null,"751":null,"752":null,"753":null,"754":null,"755":null,"756":null,"757":null,"758":{"login":"andychow-db","id":58712524,"node_id":"MDQ6VXNlcjU4NzEyNTI0","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/58712524?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/andychow-db","html_url":"https:\/\/github.com\/andychow-db","followers_url":"https:\/\/api.github.com\/users\/andychow-db\/followers","following_url":"https:\/\/api.github.com\/users\/andychow-db\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/andychow-db\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/andychow-db\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/andychow-db\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/andychow-db\/orgs","repos_url":"https:\/\/api.github.com\/users\/andychow-db\/repos","events_url":"https:\/\/api.github.com\/users\/andychow-db\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/andychow-db\/received_events","type":"User","site_admin":false},"759":null,"760":null,"761":null,"762":null,"763":null,"764":{"login":"dmatrix","id":1117597,"node_id":"MDQ6VXNlcjExMTc1OTc=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/1117597?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dmatrix","html_url":"https:\/\/github.com\/dmatrix","followers_url":"https:\/\/api.github.com\/users\/dmatrix\/followers","following_url":"https:\/\/api.github.com\/users\/dmatrix\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dmatrix\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dmatrix\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dmatrix\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dmatrix\/orgs","repos_url":"https:\/\/api.github.com\/users\/dmatrix\/repos","events_url":"https:\/\/api.github.com\/users\/dmatrix\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dmatrix\/received_events","type":"User","site_admin":false},"765":null,"766":null,"767":{"login":"smurching","id":2358483,"node_id":"MDQ6VXNlcjIzNTg0ODM=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/2358483?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/smurching","html_url":"https:\/\/github.com\/smurching","followers_url":"https:\/\/api.github.com\/users\/smurching\/followers","following_url":"https:\/\/api.github.com\/users\/smurching\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/smurching\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/smurching\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/smurching\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/smurching\/orgs","repos_url":"https:\/\/api.github.com\/users\/smurching\/repos","events_url":"https:\/\/api.github.com\/users\/smurching\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/smurching\/received_events","type":"User","site_admin":false},"768":null,"769":null,"770":null,"771":null,"772":null,"773":null,"774":{"login":"andychow-db","id":58712524,"node_id":"MDQ6VXNlcjU4NzEyNTI0","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/58712524?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/andychow-db","html_url":"https:\/\/github.com\/andychow-db","followers_url":"https:\/\/api.github.com\/users\/andychow-db\/followers","following_url":"https:\/\/api.github.com\/users\/andychow-db\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/andychow-db\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/andychow-db\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/andychow-db\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/andychow-db\/orgs","repos_url":"https:\/\/api.github.com\/users\/andychow-db\/repos","events_url":"https:\/\/api.github.com\/users\/andychow-db\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/andychow-db\/received_events","type":"User","site_admin":false},"775":null,"776":null,"777":null,"778":null,"779":{"login":"Zangr","id":6811562,"node_id":"MDQ6VXNlcjY4MTE1NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/6811562?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/Zangr","html_url":"https:\/\/github.com\/Zangr","followers_url":"https:\/\/api.github.com\/users\/Zangr\/followers","following_url":"https:\/\/api.github.com\/users\/Zangr\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/Zangr\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/Zangr\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/Zangr\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/Zangr\/orgs","repos_url":"https:\/\/api.github.com\/users\/Zangr\/repos","events_url":"https:\/\/api.github.com\/users\/Zangr\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/Zangr\/received_events","type":"User","site_admin":false},"780":null,"781":null,"782":null,"783":null,"784":null,"785":null,"786":null,"787":null,"788":{"login":"smurching","id":2358483,"node_id":"MDQ6VXNlcjIzNTg0ODM=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/2358483?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/smurching","html_url":"https:\/\/github.com\/smurching","followers_url":"https:\/\/api.github.com\/users\/smurching\/followers","following_url":"https:\/\/api.github.com\/users\/smurching\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/smurching\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/smurching\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/smurching\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/smurching\/orgs","repos_url":"https:\/\/api.github.com\/users\/smurching\/repos","events_url":"https:\/\/api.github.com\/users\/smurching\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/smurching\/received_events","type":"User","site_admin":false},"789":null,"790":null,"791":null,"792":null,"793":{"login":"AveshCSingh","id":1208791,"node_id":"MDQ6VXNlcjEyMDg3OTE=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/1208791?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/AveshCSingh","html_url":"https:\/\/github.com\/AveshCSingh","followers_url":"https:\/\/api.github.com\/users\/AveshCSingh\/followers","following_url":"https:\/\/api.github.com\/users\/AveshCSingh\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/AveshCSingh\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/AveshCSingh\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/AveshCSingh\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/AveshCSingh\/orgs","repos_url":"https:\/\/api.github.com\/users\/AveshCSingh\/repos","events_url":"https:\/\/api.github.com\/users\/AveshCSingh\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/AveshCSingh\/received_events","type":"User","site_admin":false},"794":{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/39497902?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dbczumar","html_url":"https:\/\/github.com\/dbczumar","followers_url":"https:\/\/api.github.com\/users\/dbczumar\/followers","following_url":"https:\/\/api.github.com\/users\/dbczumar\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dbczumar\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dbczumar\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dbczumar\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dbczumar\/orgs","repos_url":"https:\/\/api.github.com\/users\/dbczumar\/repos","events_url":"https:\/\/api.github.com\/users\/dbczumar\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dbczumar\/received_events","type":"User","site_admin":false},"795":null,"796":null,"797":{"login":"ankit-db","id":52183359,"node_id":"MDQ6VXNlcjUyMTgzMzU5","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/52183359?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/ankit-db","html_url":"https:\/\/github.com\/ankit-db","followers_url":"https:\/\/api.github.com\/users\/ankit-db\/followers","following_url":"https:\/\/api.github.com\/users\/ankit-db\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/ankit-db\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/ankit-db\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/ankit-db\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/ankit-db\/orgs","repos_url":"https:\/\/api.github.com\/users\/ankit-db\/repos","events_url":"https:\/\/api.github.com\/users\/ankit-db\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/ankit-db\/received_events","type":"User","site_admin":false},"798":null,"799":null,"800":null,"801":null,"802":null,"803":null,"804":null,"805":null,"806":null,"807":null,"808":null,"809":{"login":"smurching","id":2358483,"node_id":"MDQ6VXNlcjIzNTg0ODM=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/2358483?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/smurching","html_url":"https:\/\/github.com\/smurching","followers_url":"https:\/\/api.github.com\/users\/smurching\/followers","following_url":"https:\/\/api.github.com\/users\/smurching\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/smurching\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/smurching\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/smurching\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/smurching\/orgs","repos_url":"https:\/\/api.github.com\/users\/smurching\/repos","events_url":"https:\/\/api.github.com\/users\/smurching\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/smurching\/received_events","type":"User","site_admin":false},"810":null,"811":null,"812":null,"813":{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/39497902?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dbczumar","html_url":"https:\/\/github.com\/dbczumar","followers_url":"https:\/\/api.github.com\/users\/dbczumar\/followers","following_url":"https:\/\/api.github.com\/users\/dbczumar\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dbczumar\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dbczumar\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dbczumar\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dbczumar\/orgs","repos_url":"https:\/\/api.github.com\/users\/dbczumar\/repos","events_url":"https:\/\/api.github.com\/users\/dbczumar\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dbczumar\/received_events","type":"User","site_admin":false},"814":{"login":"tomasatdatabricks","id":33237569,"node_id":"MDQ6VXNlcjMzMjM3NTY5","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/33237569?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/tomasatdatabricks","html_url":"https:\/\/github.com\/tomasatdatabricks","followers_url":"https:\/\/api.github.com\/users\/tomasatdatabricks\/followers","following_url":"https:\/\/api.github.com\/users\/tomasatdatabricks\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/tomasatdatabricks\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/tomasatdatabricks\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/tomasatdatabricks\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/tomasatdatabricks\/orgs","repos_url":"https:\/\/api.github.com\/users\/tomasatdatabricks\/repos","events_url":"https:\/\/api.github.com\/users\/tomasatdatabricks\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/tomasatdatabricks\/received_events","type":"User","site_admin":false},"815":null,"816":null,"817":null,"818":{"login":"smurching","id":2358483,"node_id":"MDQ6VXNlcjIzNTg0ODM=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/2358483?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/smurching","html_url":"https:\/\/github.com\/smurching","followers_url":"https:\/\/api.github.com\/users\/smurching\/followers","following_url":"https:\/\/api.github.com\/users\/smurching\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/smurching\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/smurching\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/smurching\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/smurching\/orgs","repos_url":"https:\/\/api.github.com\/users\/smurching\/repos","events_url":"https:\/\/api.github.com\/users\/smurching\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/smurching\/received_events","type":"User","site_admin":false},"819":null,"820":null,"821":null,"822":null,"823":null,"824":null,"825":null,"826":{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/39497902?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dbczumar","html_url":"https:\/\/github.com\/dbczumar","followers_url":"https:\/\/api.github.com\/users\/dbczumar\/followers","following_url":"https:\/\/api.github.com\/users\/dbczumar\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dbczumar\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dbczumar\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dbczumar\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dbczumar\/orgs","repos_url":"https:\/\/api.github.com\/users\/dbczumar\/repos","events_url":"https:\/\/api.github.com\/users\/dbczumar\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dbczumar\/received_events","type":"User","site_admin":false},"827":null,"828":null,"829":{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/39497902?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dbczumar","html_url":"https:\/\/github.com\/dbczumar","followers_url":"https:\/\/api.github.com\/users\/dbczumar\/followers","following_url":"https:\/\/api.github.com\/users\/dbczumar\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dbczumar\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dbczumar\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dbczumar\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dbczumar\/orgs","repos_url":"https:\/\/api.github.com\/users\/dbczumar\/repos","events_url":"https:\/\/api.github.com\/users\/dbczumar\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dbczumar\/received_events","type":"User","site_admin":false},"830":null,"831":null,"832":null,"833":null,"834":null,"835":null,"836":null,"837":null,"838":null,"839":{"login":"Zangr","id":6811562,"node_id":"MDQ6VXNlcjY4MTE1NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/6811562?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/Zangr","html_url":"https:\/\/github.com\/Zangr","followers_url":"https:\/\/api.github.com\/users\/Zangr\/followers","following_url":"https:\/\/api.github.com\/users\/Zangr\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/Zangr\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/Zangr\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/Zangr\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/Zangr\/orgs","repos_url":"https:\/\/api.github.com\/users\/Zangr\/repos","events_url":"https:\/\/api.github.com\/users\/Zangr\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/Zangr\/received_events","type":"User","site_admin":false},"840":null,"841":null,"842":null,"843":null,"844":null,"845":{"login":"sueann","id":4411489,"node_id":"MDQ6VXNlcjQ0MTE0ODk=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/4411489?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/sueann","html_url":"https:\/\/github.com\/sueann","followers_url":"https:\/\/api.github.com\/users\/sueann\/followers","following_url":"https:\/\/api.github.com\/users\/sueann\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/sueann\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/sueann\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/sueann\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/sueann\/orgs","repos_url":"https:\/\/api.github.com\/users\/sueann\/repos","events_url":"https:\/\/api.github.com\/users\/sueann\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/sueann\/received_events","type":"User","site_admin":false},"846":null,"847":null,"848":null,"849":{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/39497902?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dbczumar","html_url":"https:\/\/github.com\/dbczumar","followers_url":"https:\/\/api.github.com\/users\/dbczumar\/followers","following_url":"https:\/\/api.github.com\/users\/dbczumar\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dbczumar\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dbczumar\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dbczumar\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dbczumar\/orgs","repos_url":"https:\/\/api.github.com\/users\/dbczumar\/repos","events_url":"https:\/\/api.github.com\/users\/dbczumar\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dbczumar\/received_events","type":"User","site_admin":false},"850":{"login":"dmatrix","id":1117597,"node_id":"MDQ6VXNlcjExMTc1OTc=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/1117597?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dmatrix","html_url":"https:\/\/github.com\/dmatrix","followers_url":"https:\/\/api.github.com\/users\/dmatrix\/followers","following_url":"https:\/\/api.github.com\/users\/dmatrix\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dmatrix\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dmatrix\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dmatrix\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dmatrix\/orgs","repos_url":"https:\/\/api.github.com\/users\/dmatrix\/repos","events_url":"https:\/\/api.github.com\/users\/dmatrix\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dmatrix\/received_events","type":"User","site_admin":false},"851":null,"852":null,"853":null,"854":null,"855":null,"856":null,"857":null,"858":{"login":"ankit-db","id":52183359,"node_id":"MDQ6VXNlcjUyMTgzMzU5","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/52183359?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/ankit-db","html_url":"https:\/\/github.com\/ankit-db","followers_url":"https:\/\/api.github.com\/users\/ankit-db\/followers","following_url":"https:\/\/api.github.com\/users\/ankit-db\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/ankit-db\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/ankit-db\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/ankit-db\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/ankit-db\/orgs","repos_url":"https:\/\/api.github.com\/users\/ankit-db\/repos","events_url":"https:\/\/api.github.com\/users\/ankit-db\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/ankit-db\/received_events","type":"User","site_admin":false},"859":null,"860":null,"861":null,"862":null,"863":{"login":"gioa","id":1960721,"node_id":"MDQ6VXNlcjE5NjA3MjE=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/1960721?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/gioa","html_url":"https:\/\/github.com\/gioa","followers_url":"https:\/\/api.github.com\/users\/gioa\/followers","following_url":"https:\/\/api.github.com\/users\/gioa\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/gioa\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/gioa\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/gioa\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/gioa\/orgs","repos_url":"https:\/\/api.github.com\/users\/gioa\/repos","events_url":"https:\/\/api.github.com\/users\/gioa\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/gioa\/received_events","type":"User","site_admin":false},"864":null,"865":null,"866":null,"867":null,"868":null,"869":null,"870":null,"871":null,"872":null,"873":null,"874":null,"875":null,"876":null,"877":null,"878":null,"879":null,"880":null,"881":null,"882":null,"883":null,"884":null,"885":null,"886":null,"887":null,"888":null,"889":null,"890":null,"891":null,"892":null,"893":{"login":"AveshCSingh","id":1208791,"node_id":"MDQ6VXNlcjEyMDg3OTE=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/1208791?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/AveshCSingh","html_url":"https:\/\/github.com\/AveshCSingh","followers_url":"https:\/\/api.github.com\/users\/AveshCSingh\/followers","following_url":"https:\/\/api.github.com\/users\/AveshCSingh\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/AveshCSingh\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/AveshCSingh\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/AveshCSingh\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/AveshCSingh\/orgs","repos_url":"https:\/\/api.github.com\/users\/AveshCSingh\/repos","events_url":"https:\/\/api.github.com\/users\/AveshCSingh\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/AveshCSingh\/received_events","type":"User","site_admin":false},"894":null,"895":null,"896":null,"897":null,"898":null,"899":null,"900":null,"901":{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/39497902?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dbczumar","html_url":"https:\/\/github.com\/dbczumar","followers_url":"https:\/\/api.github.com\/users\/dbczumar\/followers","following_url":"https:\/\/api.github.com\/users\/dbczumar\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dbczumar\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dbczumar\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dbczumar\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dbczumar\/orgs","repos_url":"https:\/\/api.github.com\/users\/dbczumar\/repos","events_url":"https:\/\/api.github.com\/users\/dbczumar\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dbczumar\/received_events","type":"User","site_admin":false},"902":null,"903":null,"904":null,"905":null,"906":null,"907":null,"908":null,"909":null,"910":null,"911":null,"912":null,"913":null,"914":null,"915":null,"916":null,"917":null,"918":null,"919":null,"920":null,"921":null,"922":null,"923":null,"924":null,"925":null,"926":null,"927":null,"928":null,"929":null,"930":null,"931":null,"932":null,"933":null,"934":null,"935":null,"936":null,"937":null,"938":{"login":"smurching","id":2358483,"node_id":"MDQ6VXNlcjIzNTg0ODM=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/2358483?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/smurching","html_url":"https:\/\/github.com\/smurching","followers_url":"https:\/\/api.github.com\/users\/smurching\/followers","following_url":"https:\/\/api.github.com\/users\/smurching\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/smurching\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/smurching\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/smurching\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/smurching\/orgs","repos_url":"https:\/\/api.github.com\/users\/smurching\/repos","events_url":"https:\/\/api.github.com\/users\/smurching\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/smurching\/received_events","type":"User","site_admin":false},"939":null,"940":null,"941":null,"942":null,"943":null,"944":null,"945":null,"946":null,"947":null,"948":{"login":"aarondav","id":1400247,"node_id":"MDQ6VXNlcjE0MDAyNDc=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/1400247?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/aarondav","html_url":"https:\/\/github.com\/aarondav","followers_url":"https:\/\/api.github.com\/users\/aarondav\/followers","following_url":"https:\/\/api.github.com\/users\/aarondav\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/aarondav\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/aarondav\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/aarondav\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/aarondav\/orgs","repos_url":"https:\/\/api.github.com\/users\/aarondav\/repos","events_url":"https:\/\/api.github.com\/users\/aarondav\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/aarondav\/received_events","type":"User","site_admin":false},"949":null,"950":null,"951":null,"952":null,"953":null,"954":null,"955":{"login":"Zangr","id":6811562,"node_id":"MDQ6VXNlcjY4MTE1NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/6811562?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/Zangr","html_url":"https:\/\/github.com\/Zangr","followers_url":"https:\/\/api.github.com\/users\/Zangr\/followers","following_url":"https:\/\/api.github.com\/users\/Zangr\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/Zangr\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/Zangr\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/Zangr\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/Zangr\/orgs","repos_url":"https:\/\/api.github.com\/users\/Zangr\/repos","events_url":"https:\/\/api.github.com\/users\/Zangr\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/Zangr\/received_events","type":"User","site_admin":false},"956":null,"957":null,"958":null,"959":null,"960":null,"961":null,"962":null,"963":null,"964":null,"965":null,"966":null,"967":null,"968":null,"969":{"login":"dmatrix","id":1117597,"node_id":"MDQ6VXNlcjExMTc1OTc=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/1117597?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dmatrix","html_url":"https:\/\/github.com\/dmatrix","followers_url":"https:\/\/api.github.com\/users\/dmatrix\/followers","following_url":"https:\/\/api.github.com\/users\/dmatrix\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dmatrix\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dmatrix\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dmatrix\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dmatrix\/orgs","repos_url":"https:\/\/api.github.com\/users\/dmatrix\/repos","events_url":"https:\/\/api.github.com\/users\/dmatrix\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dmatrix\/received_events","type":"User","site_admin":false},"970":null,"971":null,"972":null,"973":null,"974":{"login":"smurching","id":2358483,"node_id":"MDQ6VXNlcjIzNTg0ODM=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/2358483?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/smurching","html_url":"https:\/\/github.com\/smurching","followers_url":"https:\/\/api.github.com\/users\/smurching\/followers","following_url":"https:\/\/api.github.com\/users\/smurching\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/smurching\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/smurching\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/smurching\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/smurching\/orgs","repos_url":"https:\/\/api.github.com\/users\/smurching\/repos","events_url":"https:\/\/api.github.com\/users\/smurching\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/smurching\/received_events","type":"User","site_admin":false},"975":null,"976":null,"977":null,"978":null,"979":null,"980":null,"981":null,"982":null,"983":{"login":"Zangr","id":6811562,"node_id":"MDQ6VXNlcjY4MTE1NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/6811562?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/Zangr","html_url":"https:\/\/github.com\/Zangr","followers_url":"https:\/\/api.github.com\/users\/Zangr\/followers","following_url":"https:\/\/api.github.com\/users\/Zangr\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/Zangr\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/Zangr\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/Zangr\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/Zangr\/orgs","repos_url":"https:\/\/api.github.com\/users\/Zangr\/repos","events_url":"https:\/\/api.github.com\/users\/Zangr\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/Zangr\/received_events","type":"User","site_admin":false},"984":null,"985":null,"986":{"login":"smurching","id":2358483,"node_id":"MDQ6VXNlcjIzNTg0ODM=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/2358483?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/smurching","html_url":"https:\/\/github.com\/smurching","followers_url":"https:\/\/api.github.com\/users\/smurching\/followers","following_url":"https:\/\/api.github.com\/users\/smurching\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/smurching\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/smurching\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/smurching\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/smurching\/orgs","repos_url":"https:\/\/api.github.com\/users\/smurching\/repos","events_url":"https:\/\/api.github.com\/users\/smurching\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/smurching\/received_events","type":"User","site_admin":false},"987":null,"988":null,"989":null,"990":null,"991":null,"992":null,"993":null,"994":null,"995":null,"996":null,"997":{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/39497902?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dbczumar","html_url":"https:\/\/github.com\/dbczumar","followers_url":"https:\/\/api.github.com\/users\/dbczumar\/followers","following_url":"https:\/\/api.github.com\/users\/dbczumar\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dbczumar\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dbczumar\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dbczumar\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dbczumar\/orgs","repos_url":"https:\/\/api.github.com\/users\/dbczumar\/repos","events_url":"https:\/\/api.github.com\/users\/dbczumar\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dbczumar\/received_events","type":"User","site_admin":false},"998":null,"999":null},"assignees":{"0":[],"1":[],"2":[],"3":[],"4":[],"5":[],"6":[],"7":[],"8":[],"9":[],"10":[],"11":[],"12":[],"13":[],"14":[],"15":[],"16":[],"17":[],"18":[],"19":[],"20":[],"21":[],"22":[],"23":[],"24":[],"25":[],"26":[],"27":[],"28":[],"29":[],"30":[],"31":[],"32":[{"login":"ankit-db","id":52183359,"node_id":"MDQ6VXNlcjUyMTgzMzU5","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/52183359?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/ankit-db","html_url":"https:\/\/github.com\/ankit-db","followers_url":"https:\/\/api.github.com\/users\/ankit-db\/followers","following_url":"https:\/\/api.github.com\/users\/ankit-db\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/ankit-db\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/ankit-db\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/ankit-db\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/ankit-db\/orgs","repos_url":"https:\/\/api.github.com\/users\/ankit-db\/repos","events_url":"https:\/\/api.github.com\/users\/ankit-db\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/ankit-db\/received_events","type":"User","site_admin":false}],"33":[],"34":[],"35":[],"36":[],"37":[],"38":[],"39":[],"40":[],"41":[],"42":[],"43":[],"44":[],"45":[],"46":[],"47":[],"48":[],"49":[],"50":[],"51":[],"52":[],"53":[],"54":[],"55":[],"56":[],"57":[],"58":[],"59":[],"60":[],"61":[],"62":[],"63":[],"64":[],"65":[],"66":[],"67":[],"68":[],"69":[],"70":[],"71":[],"72":[],"73":[],"74":[],"75":[],"76":[],"77":[],"78":[],"79":[],"80":[],"81":[],"82":[],"83":[],"84":[],"85":[{"login":"daanknoope","id":8389610,"node_id":"MDQ6VXNlcjgzODk2MTA=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8389610?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/daanknoope","html_url":"https:\/\/github.com\/daanknoope","followers_url":"https:\/\/api.github.com\/users\/daanknoope\/followers","following_url":"https:\/\/api.github.com\/users\/daanknoope\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/daanknoope\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/daanknoope\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/daanknoope\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/daanknoope\/orgs","repos_url":"https:\/\/api.github.com\/users\/daanknoope\/repos","events_url":"https:\/\/api.github.com\/users\/daanknoope\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/daanknoope\/received_events","type":"User","site_admin":false}],"86":[],"87":[],"88":[],"89":[],"90":[],"91":[],"92":[],"93":[],"94":[],"95":[],"96":[],"97":[],"98":[],"99":[],"100":[],"101":[],"102":[],"103":[],"104":[],"105":[],"106":[],"107":[],"108":[],"109":[],"110":[],"111":[],"112":[],"113":[],"114":[],"115":[],"116":[],"117":[],"118":[],"119":[],"120":[],"121":[],"122":[],"123":[],"124":[{"login":"mohamad-arabi","id":73549313,"node_id":"MDQ6VXNlcjczNTQ5MzEz","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/73549313?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/mohamad-arabi","html_url":"https:\/\/github.com\/mohamad-arabi","followers_url":"https:\/\/api.github.com\/users\/mohamad-arabi\/followers","following_url":"https:\/\/api.github.com\/users\/mohamad-arabi\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/mohamad-arabi\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/mohamad-arabi\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/mohamad-arabi\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/mohamad-arabi\/orgs","repos_url":"https:\/\/api.github.com\/users\/mohamad-arabi\/repos","events_url":"https:\/\/api.github.com\/users\/mohamad-arabi\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/mohamad-arabi\/received_events","type":"User","site_admin":false}],"125":[],"126":[],"127":[],"128":[],"129":[],"130":[],"131":[],"132":[],"133":[],"134":[],"135":[],"136":[],"137":[],"138":[],"139":[],"140":[],"141":[],"142":[],"143":[],"144":[],"145":[],"146":[],"147":[],"148":[],"149":[],"150":[],"151":[],"152":[],"153":[],"154":[],"155":[],"156":[],"157":[],"158":[],"159":[],"160":[{"login":"ankit-db","id":52183359,"node_id":"MDQ6VXNlcjUyMTgzMzU5","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/52183359?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/ankit-db","html_url":"https:\/\/github.com\/ankit-db","followers_url":"https:\/\/api.github.com\/users\/ankit-db\/followers","following_url":"https:\/\/api.github.com\/users\/ankit-db\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/ankit-db\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/ankit-db\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/ankit-db\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/ankit-db\/orgs","repos_url":"https:\/\/api.github.com\/users\/ankit-db\/repos","events_url":"https:\/\/api.github.com\/users\/ankit-db\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/ankit-db\/received_events","type":"User","site_admin":false}],"161":[],"162":[],"163":[],"164":[],"165":[],"166":[],"167":[],"168":[],"169":[],"170":[],"171":[],"172":[],"173":[],"174":[],"175":[],"176":[],"177":[],"178":[],"179":[],"180":[],"181":[{"login":"bali0019","id":18537688,"node_id":"MDQ6VXNlcjE4NTM3Njg4","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/18537688?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/bali0019","html_url":"https:\/\/github.com\/bali0019","followers_url":"https:\/\/api.github.com\/users\/bali0019\/followers","following_url":"https:\/\/api.github.com\/users\/bali0019\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/bali0019\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/bali0019\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/bali0019\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/bali0019\/orgs","repos_url":"https:\/\/api.github.com\/users\/bali0019\/repos","events_url":"https:\/\/api.github.com\/users\/bali0019\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/bali0019\/received_events","type":"User","site_admin":false}],"182":[],"183":[{"login":"coder-freestyle","id":60594457,"node_id":"MDQ6VXNlcjYwNTk0NDU3","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/60594457?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/coder-freestyle","html_url":"https:\/\/github.com\/coder-freestyle","followers_url":"https:\/\/api.github.com\/users\/coder-freestyle\/followers","following_url":"https:\/\/api.github.com\/users\/coder-freestyle\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/coder-freestyle\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/coder-freestyle\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/coder-freestyle\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/coder-freestyle\/orgs","repos_url":"https:\/\/api.github.com\/users\/coder-freestyle\/repos","events_url":"https:\/\/api.github.com\/users\/coder-freestyle\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/coder-freestyle\/received_events","type":"User","site_admin":false}],"184":[{"login":"WeichenXu123","id":19235986,"node_id":"MDQ6VXNlcjE5MjM1OTg2","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/19235986?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/WeichenXu123","html_url":"https:\/\/github.com\/WeichenXu123","followers_url":"https:\/\/api.github.com\/users\/WeichenXu123\/followers","following_url":"https:\/\/api.github.com\/users\/WeichenXu123\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/WeichenXu123\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/WeichenXu123\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/WeichenXu123\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/WeichenXu123\/orgs","repos_url":"https:\/\/api.github.com\/users\/WeichenXu123\/repos","events_url":"https:\/\/api.github.com\/users\/WeichenXu123\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/WeichenXu123\/received_events","type":"User","site_admin":false}],"185":[],"186":[],"187":[],"188":[],"189":[],"190":[],"191":[],"192":[],"193":[],"194":[],"195":[],"196":[],"197":[],"198":[],"199":[],"200":[],"201":[],"202":[],"203":[],"204":[],"205":[],"206":[],"207":[],"208":[],"209":[],"210":[],"211":[],"212":[],"213":[],"214":[],"215":[],"216":[],"217":[],"218":[],"219":[],"220":[],"221":[],"222":[],"223":[],"224":[],"225":[],"226":[],"227":[],"228":[],"229":[],"230":[],"231":[],"232":[],"233":[],"234":[],"235":[],"236":[],"237":[],"238":[],"239":[],"240":[],"241":[],"242":[],"243":[],"244":[],"245":[],"246":[],"247":[],"248":[],"249":[],"250":[],"251":[],"252":[],"253":[],"254":[],"255":[],"256":[],"257":[],"258":[],"259":[],"260":[],"261":[],"262":[],"263":[],"264":[],"265":[],"266":[],"267":[],"268":[],"269":[{"login":"apurva-koti","id":51172624,"node_id":"MDQ6VXNlcjUxMTcyNjI0","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/51172624?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/apurva-koti","html_url":"https:\/\/github.com\/apurva-koti","followers_url":"https:\/\/api.github.com\/users\/apurva-koti\/followers","following_url":"https:\/\/api.github.com\/users\/apurva-koti\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/apurva-koti\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/apurva-koti\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/apurva-koti\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/apurva-koti\/orgs","repos_url":"https:\/\/api.github.com\/users\/apurva-koti\/repos","events_url":"https:\/\/api.github.com\/users\/apurva-koti\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/apurva-koti\/received_events","type":"User","site_admin":false}],"270":[],"271":[],"272":[],"273":[],"274":[],"275":[],"276":[],"277":[],"278":[],"279":[],"280":[],"281":[],"282":[],"283":[],"284":[],"285":[],"286":[],"287":[],"288":[],"289":[],"290":[],"291":[],"292":[],"293":[],"294":[],"295":[],"296":[],"297":[],"298":[],"299":[],"300":[],"301":[],"302":[],"303":[],"304":[],"305":[],"306":[],"307":[],"308":[],"309":[],"310":[],"311":[{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/39497902?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dbczumar","html_url":"https:\/\/github.com\/dbczumar","followers_url":"https:\/\/api.github.com\/users\/dbczumar\/followers","following_url":"https:\/\/api.github.com\/users\/dbczumar\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dbczumar\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dbczumar\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dbczumar\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dbczumar\/orgs","repos_url":"https:\/\/api.github.com\/users\/dbczumar\/repos","events_url":"https:\/\/api.github.com\/users\/dbczumar\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dbczumar\/received_events","type":"User","site_admin":false}],"312":[],"313":[],"314":[],"315":[],"316":[],"317":[],"318":[],"319":[],"320":[],"321":[],"322":[],"323":[],"324":[],"325":[],"326":[],"327":[],"328":[],"329":[],"330":[],"331":[],"332":[],"333":[],"334":[],"335":[],"336":[],"337":[],"338":[],"339":[],"340":[],"341":[],"342":[],"343":[],"344":[],"345":[],"346":[],"347":[],"348":[],"349":[],"350":[{"login":"dmatrix","id":1117597,"node_id":"MDQ6VXNlcjExMTc1OTc=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/1117597?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dmatrix","html_url":"https:\/\/github.com\/dmatrix","followers_url":"https:\/\/api.github.com\/users\/dmatrix\/followers","following_url":"https:\/\/api.github.com\/users\/dmatrix\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dmatrix\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dmatrix\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dmatrix\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dmatrix\/orgs","repos_url":"https:\/\/api.github.com\/users\/dmatrix\/repos","events_url":"https:\/\/api.github.com\/users\/dmatrix\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dmatrix\/received_events","type":"User","site_admin":false}],"351":[],"352":[{"login":"dmatrix","id":1117597,"node_id":"MDQ6VXNlcjExMTc1OTc=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/1117597?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dmatrix","html_url":"https:\/\/github.com\/dmatrix","followers_url":"https:\/\/api.github.com\/users\/dmatrix\/followers","following_url":"https:\/\/api.github.com\/users\/dmatrix\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dmatrix\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dmatrix\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dmatrix\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dmatrix\/orgs","repos_url":"https:\/\/api.github.com\/users\/dmatrix\/repos","events_url":"https:\/\/api.github.com\/users\/dmatrix\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dmatrix\/received_events","type":"User","site_admin":false}],"353":[],"354":[],"355":[],"356":[],"357":[],"358":[],"359":[],"360":[],"361":[],"362":[],"363":[],"364":[],"365":[],"366":[],"367":[],"368":[],"369":[],"370":[],"371":[],"372":[],"373":[],"374":[],"375":[],"376":[],"377":[],"378":[],"379":[],"380":[],"381":[],"382":[],"383":[],"384":[],"385":[],"386":[],"387":[],"388":[],"389":[],"390":[],"391":[],"392":[],"393":[],"394":[],"395":[],"396":[],"397":[],"398":[],"399":[],"400":[],"401":[],"402":[],"403":[],"404":[],"405":[],"406":[],"407":[],"408":[{"login":"ankit-db","id":52183359,"node_id":"MDQ6VXNlcjUyMTgzMzU5","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/52183359?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/ankit-db","html_url":"https:\/\/github.com\/ankit-db","followers_url":"https:\/\/api.github.com\/users\/ankit-db\/followers","following_url":"https:\/\/api.github.com\/users\/ankit-db\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/ankit-db\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/ankit-db\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/ankit-db\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/ankit-db\/orgs","repos_url":"https:\/\/api.github.com\/users\/ankit-db\/repos","events_url":"https:\/\/api.github.com\/users\/ankit-db\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/ankit-db\/received_events","type":"User","site_admin":false}],"409":[],"410":[],"411":[],"412":[],"413":[],"414":[],"415":[],"416":[],"417":[],"418":[],"419":[],"420":[],"421":[],"422":[],"423":[],"424":[{"login":"lorenzwalthert","id":10477073,"node_id":"MDQ6VXNlcjEwNDc3MDcz","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/10477073?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/lorenzwalthert","html_url":"https:\/\/github.com\/lorenzwalthert","followers_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/followers","following_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/orgs","repos_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/repos","events_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/received_events","type":"User","site_admin":false}],"425":[],"426":[],"427":[],"428":[],"429":[],"430":[],"431":[],"432":[],"433":[],"434":[],"435":[],"436":[],"437":[],"438":[],"439":[],"440":[],"441":[],"442":[],"443":[],"444":[],"445":[],"446":[],"447":[],"448":[],"449":[],"450":[],"451":[],"452":[],"453":[],"454":[],"455":[],"456":[],"457":[],"458":[],"459":[],"460":[],"461":[],"462":[],"463":[],"464":[],"465":[],"466":[],"467":[],"468":[],"469":[{"login":"lorenzwalthert","id":10477073,"node_id":"MDQ6VXNlcjEwNDc3MDcz","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/10477073?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/lorenzwalthert","html_url":"https:\/\/github.com\/lorenzwalthert","followers_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/followers","following_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/orgs","repos_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/repos","events_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/lorenzwalthert\/received_events","type":"User","site_admin":false}],"470":[{"login":"yitao-li","id":405346,"node_id":"MDQ6VXNlcjQwNTM0Ng==","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/405346?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/yitao-li","html_url":"https:\/\/github.com\/yitao-li","followers_url":"https:\/\/api.github.com\/users\/yitao-li\/followers","following_url":"https:\/\/api.github.com\/users\/yitao-li\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/yitao-li\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/yitao-li\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/yitao-li\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/yitao-li\/orgs","repos_url":"https:\/\/api.github.com\/users\/yitao-li\/repos","events_url":"https:\/\/api.github.com\/users\/yitao-li\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/yitao-li\/received_events","type":"User","site_admin":false}],"471":[],"472":[],"473":[],"474":[],"475":[],"476":[{"login":"yitao-li","id":405346,"node_id":"MDQ6VXNlcjQwNTM0Ng==","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/405346?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/yitao-li","html_url":"https:\/\/github.com\/yitao-li","followers_url":"https:\/\/api.github.com\/users\/yitao-li\/followers","following_url":"https:\/\/api.github.com\/users\/yitao-li\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/yitao-li\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/yitao-li\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/yitao-li\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/yitao-li\/orgs","repos_url":"https:\/\/api.github.com\/users\/yitao-li\/repos","events_url":"https:\/\/api.github.com\/users\/yitao-li\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/yitao-li\/received_events","type":"User","site_admin":false}],"477":[],"478":[{"login":"harupy","id":17039389,"node_id":"MDQ6VXNlcjE3MDM5Mzg5","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/17039389?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/harupy","html_url":"https:\/\/github.com\/harupy","followers_url":"https:\/\/api.github.com\/users\/harupy\/followers","following_url":"https:\/\/api.github.com\/users\/harupy\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/harupy\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/harupy\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/harupy\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/harupy\/orgs","repos_url":"https:\/\/api.github.com\/users\/harupy\/repos","events_url":"https:\/\/api.github.com\/users\/harupy\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/harupy\/received_events","type":"User","site_admin":false}],"479":[],"480":[],"481":[],"482":[],"483":[],"484":[],"485":[],"486":[],"487":[],"488":[],"489":[],"490":[],"491":[],"492":[],"493":[],"494":[],"495":[],"496":[],"497":[],"498":[],"499":[],"500":[],"501":[],"502":[],"503":[],"504":[],"505":[],"506":[],"507":[],"508":[],"509":[],"510":[],"511":[],"512":[],"513":[],"514":[],"515":[],"516":[],"517":[],"518":[],"519":[],"520":[],"521":[],"522":[],"523":[],"524":[],"525":[],"526":[],"527":[],"528":[],"529":[],"530":[],"531":[],"532":[],"533":[],"534":[],"535":[],"536":[],"537":[],"538":[],"539":[],"540":[],"541":[],"542":[],"543":[],"544":[],"545":[],"546":[],"547":[],"548":[],"549":[],"550":[],"551":[],"552":[],"553":[],"554":[],"555":[],"556":[],"557":[],"558":[],"559":[],"560":[],"561":[],"562":[],"563":[],"564":[],"565":[],"566":[],"567":[],"568":[],"569":[],"570":[],"571":[],"572":[],"573":[],"574":[],"575":[],"576":[],"577":[],"578":[],"579":[],"580":[],"581":[],"582":[],"583":[],"584":[],"585":[],"586":[],"587":[],"588":[],"589":[],"590":[],"591":[],"592":[],"593":[],"594":[],"595":[],"596":[],"597":[],"598":[],"599":[],"600":[{"login":"ankit-db","id":52183359,"node_id":"MDQ6VXNlcjUyMTgzMzU5","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/52183359?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/ankit-db","html_url":"https:\/\/github.com\/ankit-db","followers_url":"https:\/\/api.github.com\/users\/ankit-db\/followers","following_url":"https:\/\/api.github.com\/users\/ankit-db\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/ankit-db\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/ankit-db\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/ankit-db\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/ankit-db\/orgs","repos_url":"https:\/\/api.github.com\/users\/ankit-db\/repos","events_url":"https:\/\/api.github.com\/users\/ankit-db\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/ankit-db\/received_events","type":"User","site_admin":false}],"601":[],"602":[],"603":[],"604":[],"605":[],"606":[],"607":[{"login":"apurva-koti","id":51172624,"node_id":"MDQ6VXNlcjUxMTcyNjI0","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/51172624?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/apurva-koti","html_url":"https:\/\/github.com\/apurva-koti","followers_url":"https:\/\/api.github.com\/users\/apurva-koti\/followers","following_url":"https:\/\/api.github.com\/users\/apurva-koti\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/apurva-koti\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/apurva-koti\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/apurva-koti\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/apurva-koti\/orgs","repos_url":"https:\/\/api.github.com\/users\/apurva-koti\/repos","events_url":"https:\/\/api.github.com\/users\/apurva-koti\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/apurva-koti\/received_events","type":"User","site_admin":false}],"608":[],"609":[],"610":[],"611":[],"612":[],"613":[],"614":[],"615":[],"616":[],"617":[],"618":[],"619":[],"620":[],"621":[],"622":[],"623":[],"624":[],"625":[],"626":[{"login":"zhidongqu-db","id":64800904,"node_id":"MDQ6VXNlcjY0ODAwOTA0","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/64800904?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/zhidongqu-db","html_url":"https:\/\/github.com\/zhidongqu-db","followers_url":"https:\/\/api.github.com\/users\/zhidongqu-db\/followers","following_url":"https:\/\/api.github.com\/users\/zhidongqu-db\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/zhidongqu-db\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/zhidongqu-db\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/zhidongqu-db\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/zhidongqu-db\/orgs","repos_url":"https:\/\/api.github.com\/users\/zhidongqu-db\/repos","events_url":"https:\/\/api.github.com\/users\/zhidongqu-db\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/zhidongqu-db\/received_events","type":"User","site_admin":false}],"627":[{"login":"ankit-db","id":52183359,"node_id":"MDQ6VXNlcjUyMTgzMzU5","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/52183359?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/ankit-db","html_url":"https:\/\/github.com\/ankit-db","followers_url":"https:\/\/api.github.com\/users\/ankit-db\/followers","following_url":"https:\/\/api.github.com\/users\/ankit-db\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/ankit-db\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/ankit-db\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/ankit-db\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/ankit-db\/orgs","repos_url":"https:\/\/api.github.com\/users\/ankit-db\/repos","events_url":"https:\/\/api.github.com\/users\/ankit-db\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/ankit-db\/received_events","type":"User","site_admin":false}],"628":[],"629":[],"630":[],"631":[],"632":[],"633":[],"634":[],"635":[],"636":[],"637":[],"638":[],"639":[{"login":"dmatrix","id":1117597,"node_id":"MDQ6VXNlcjExMTc1OTc=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/1117597?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dmatrix","html_url":"https:\/\/github.com\/dmatrix","followers_url":"https:\/\/api.github.com\/users\/dmatrix\/followers","following_url":"https:\/\/api.github.com\/users\/dmatrix\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dmatrix\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dmatrix\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dmatrix\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dmatrix\/orgs","repos_url":"https:\/\/api.github.com\/users\/dmatrix\/repos","events_url":"https:\/\/api.github.com\/users\/dmatrix\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dmatrix\/received_events","type":"User","site_admin":false}],"640":[],"641":[],"642":[{"login":"avflor","id":18666312,"node_id":"MDQ6VXNlcjE4NjY2MzEy","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/18666312?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/avflor","html_url":"https:\/\/github.com\/avflor","followers_url":"https:\/\/api.github.com\/users\/avflor\/followers","following_url":"https:\/\/api.github.com\/users\/avflor\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/avflor\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/avflor\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/avflor\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/avflor\/orgs","repos_url":"https:\/\/api.github.com\/users\/avflor\/repos","events_url":"https:\/\/api.github.com\/users\/avflor\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/avflor\/received_events","type":"User","site_admin":false}],"643":[],"644":[],"645":[],"646":[],"647":[],"648":[],"649":[],"650":[],"651":[{"login":"dmatrix","id":1117597,"node_id":"MDQ6VXNlcjExMTc1OTc=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/1117597?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dmatrix","html_url":"https:\/\/github.com\/dmatrix","followers_url":"https:\/\/api.github.com\/users\/dmatrix\/followers","following_url":"https:\/\/api.github.com\/users\/dmatrix\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dmatrix\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dmatrix\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dmatrix\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dmatrix\/orgs","repos_url":"https:\/\/api.github.com\/users\/dmatrix\/repos","events_url":"https:\/\/api.github.com\/users\/dmatrix\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dmatrix\/received_events","type":"User","site_admin":false}],"652":[],"653":[],"654":[],"655":[],"656":[],"657":[],"658":[],"659":[],"660":[],"661":[],"662":[],"663":[],"664":[],"665":[],"666":[],"667":[],"668":[{"login":"javierluraschi","id":3478847,"node_id":"MDQ6VXNlcjM0Nzg4NDc=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/3478847?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/javierluraschi","html_url":"https:\/\/github.com\/javierluraschi","followers_url":"https:\/\/api.github.com\/users\/javierluraschi\/followers","following_url":"https:\/\/api.github.com\/users\/javierluraschi\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/javierluraschi\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/javierluraschi\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/javierluraschi\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/javierluraschi\/orgs","repos_url":"https:\/\/api.github.com\/users\/javierluraschi\/repos","events_url":"https:\/\/api.github.com\/users\/javierluraschi\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/javierluraschi\/received_events","type":"User","site_admin":false}],"669":[],"670":[],"671":[],"672":[],"673":[],"674":[],"675":[],"676":[],"677":[{"login":"Zangr","id":6811562,"node_id":"MDQ6VXNlcjY4MTE1NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/6811562?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/Zangr","html_url":"https:\/\/github.com\/Zangr","followers_url":"https:\/\/api.github.com\/users\/Zangr\/followers","following_url":"https:\/\/api.github.com\/users\/Zangr\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/Zangr\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/Zangr\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/Zangr\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/Zangr\/orgs","repos_url":"https:\/\/api.github.com\/users\/Zangr\/repos","events_url":"https:\/\/api.github.com\/users\/Zangr\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/Zangr\/received_events","type":"User","site_admin":false},{"login":"ankit-db","id":52183359,"node_id":"MDQ6VXNlcjUyMTgzMzU5","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/52183359?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/ankit-db","html_url":"https:\/\/github.com\/ankit-db","followers_url":"https:\/\/api.github.com\/users\/ankit-db\/followers","following_url":"https:\/\/api.github.com\/users\/ankit-db\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/ankit-db\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/ankit-db\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/ankit-db\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/ankit-db\/orgs","repos_url":"https:\/\/api.github.com\/users\/ankit-db\/repos","events_url":"https:\/\/api.github.com\/users\/ankit-db\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/ankit-db\/received_events","type":"User","site_admin":false}],"678":[],"679":[],"680":[],"681":[],"682":[],"683":[],"684":[],"685":[{"login":"sueann","id":4411489,"node_id":"MDQ6VXNlcjQ0MTE0ODk=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/4411489?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/sueann","html_url":"https:\/\/github.com\/sueann","followers_url":"https:\/\/api.github.com\/users\/sueann\/followers","following_url":"https:\/\/api.github.com\/users\/sueann\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/sueann\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/sueann\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/sueann\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/sueann\/orgs","repos_url":"https:\/\/api.github.com\/users\/sueann\/repos","events_url":"https:\/\/api.github.com\/users\/sueann\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/sueann\/received_events","type":"User","site_admin":false},{"login":"mparkhe","id":6900999,"node_id":"MDQ6VXNlcjY5MDA5OTk=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/6900999?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/mparkhe","html_url":"https:\/\/github.com\/mparkhe","followers_url":"https:\/\/api.github.com\/users\/mparkhe\/followers","following_url":"https:\/\/api.github.com\/users\/mparkhe\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/mparkhe\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/mparkhe\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/mparkhe\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/mparkhe\/orgs","repos_url":"https:\/\/api.github.com\/users\/mparkhe\/repos","events_url":"https:\/\/api.github.com\/users\/mparkhe\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/mparkhe\/received_events","type":"User","site_admin":false}],"686":[{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/39497902?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dbczumar","html_url":"https:\/\/github.com\/dbczumar","followers_url":"https:\/\/api.github.com\/users\/dbczumar\/followers","following_url":"https:\/\/api.github.com\/users\/dbczumar\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dbczumar\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dbczumar\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dbczumar\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dbczumar\/orgs","repos_url":"https:\/\/api.github.com\/users\/dbczumar\/repos","events_url":"https:\/\/api.github.com\/users\/dbczumar\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dbczumar\/received_events","type":"User","site_admin":false}],"687":[],"688":[],"689":[],"690":[],"691":[],"692":[],"693":[],"694":[],"695":[],"696":[],"697":[],"698":[],"699":[],"700":[],"701":[],"702":[],"703":[],"704":[],"705":[],"706":[],"707":[],"708":[],"709":[],"710":[],"711":[],"712":[],"713":[],"714":[],"715":[],"716":[],"717":[],"718":[],"719":[],"720":[],"721":[],"722":[],"723":[],"724":[],"725":[],"726":[],"727":[],"728":[],"729":[],"730":[],"731":[],"732":[],"733":[],"734":[],"735":[],"736":[],"737":[],"738":[],"739":[],"740":[],"741":[],"742":[],"743":[],"744":[],"745":[],"746":[],"747":[],"748":[],"749":[],"750":[],"751":[],"752":[],"753":[],"754":[],"755":[],"756":[],"757":[],"758":[{"login":"andychow-db","id":58712524,"node_id":"MDQ6VXNlcjU4NzEyNTI0","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/58712524?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/andychow-db","html_url":"https:\/\/github.com\/andychow-db","followers_url":"https:\/\/api.github.com\/users\/andychow-db\/followers","following_url":"https:\/\/api.github.com\/users\/andychow-db\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/andychow-db\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/andychow-db\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/andychow-db\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/andychow-db\/orgs","repos_url":"https:\/\/api.github.com\/users\/andychow-db\/repos","events_url":"https:\/\/api.github.com\/users\/andychow-db\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/andychow-db\/received_events","type":"User","site_admin":false}],"759":[],"760":[],"761":[],"762":[],"763":[],"764":[{"login":"dmatrix","id":1117597,"node_id":"MDQ6VXNlcjExMTc1OTc=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/1117597?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dmatrix","html_url":"https:\/\/github.com\/dmatrix","followers_url":"https:\/\/api.github.com\/users\/dmatrix\/followers","following_url":"https:\/\/api.github.com\/users\/dmatrix\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dmatrix\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dmatrix\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dmatrix\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dmatrix\/orgs","repos_url":"https:\/\/api.github.com\/users\/dmatrix\/repos","events_url":"https:\/\/api.github.com\/users\/dmatrix\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dmatrix\/received_events","type":"User","site_admin":false}],"765":[],"766":[],"767":[{"login":"smurching","id":2358483,"node_id":"MDQ6VXNlcjIzNTg0ODM=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/2358483?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/smurching","html_url":"https:\/\/github.com\/smurching","followers_url":"https:\/\/api.github.com\/users\/smurching\/followers","following_url":"https:\/\/api.github.com\/users\/smurching\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/smurching\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/smurching\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/smurching\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/smurching\/orgs","repos_url":"https:\/\/api.github.com\/users\/smurching\/repos","events_url":"https:\/\/api.github.com\/users\/smurching\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/smurching\/received_events","type":"User","site_admin":false}],"768":[],"769":[],"770":[],"771":[],"772":[],"773":[],"774":[{"login":"andychow-db","id":58712524,"node_id":"MDQ6VXNlcjU4NzEyNTI0","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/58712524?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/andychow-db","html_url":"https:\/\/github.com\/andychow-db","followers_url":"https:\/\/api.github.com\/users\/andychow-db\/followers","following_url":"https:\/\/api.github.com\/users\/andychow-db\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/andychow-db\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/andychow-db\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/andychow-db\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/andychow-db\/orgs","repos_url":"https:\/\/api.github.com\/users\/andychow-db\/repos","events_url":"https:\/\/api.github.com\/users\/andychow-db\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/andychow-db\/received_events","type":"User","site_admin":false}],"775":[],"776":[],"777":[],"778":[],"779":[{"login":"Zangr","id":6811562,"node_id":"MDQ6VXNlcjY4MTE1NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/6811562?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/Zangr","html_url":"https:\/\/github.com\/Zangr","followers_url":"https:\/\/api.github.com\/users\/Zangr\/followers","following_url":"https:\/\/api.github.com\/users\/Zangr\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/Zangr\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/Zangr\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/Zangr\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/Zangr\/orgs","repos_url":"https:\/\/api.github.com\/users\/Zangr\/repos","events_url":"https:\/\/api.github.com\/users\/Zangr\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/Zangr\/received_events","type":"User","site_admin":false}],"780":[],"781":[],"782":[],"783":[],"784":[],"785":[],"786":[],"787":[],"788":[{"login":"smurching","id":2358483,"node_id":"MDQ6VXNlcjIzNTg0ODM=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/2358483?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/smurching","html_url":"https:\/\/github.com\/smurching","followers_url":"https:\/\/api.github.com\/users\/smurching\/followers","following_url":"https:\/\/api.github.com\/users\/smurching\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/smurching\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/smurching\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/smurching\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/smurching\/orgs","repos_url":"https:\/\/api.github.com\/users\/smurching\/repos","events_url":"https:\/\/api.github.com\/users\/smurching\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/smurching\/received_events","type":"User","site_admin":false}],"789":[],"790":[],"791":[],"792":[],"793":[{"login":"AveshCSingh","id":1208791,"node_id":"MDQ6VXNlcjEyMDg3OTE=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/1208791?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/AveshCSingh","html_url":"https:\/\/github.com\/AveshCSingh","followers_url":"https:\/\/api.github.com\/users\/AveshCSingh\/followers","following_url":"https:\/\/api.github.com\/users\/AveshCSingh\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/AveshCSingh\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/AveshCSingh\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/AveshCSingh\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/AveshCSingh\/orgs","repos_url":"https:\/\/api.github.com\/users\/AveshCSingh\/repos","events_url":"https:\/\/api.github.com\/users\/AveshCSingh\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/AveshCSingh\/received_events","type":"User","site_admin":false}],"794":[{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/39497902?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dbczumar","html_url":"https:\/\/github.com\/dbczumar","followers_url":"https:\/\/api.github.com\/users\/dbczumar\/followers","following_url":"https:\/\/api.github.com\/users\/dbczumar\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dbczumar\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dbczumar\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dbczumar\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dbczumar\/orgs","repos_url":"https:\/\/api.github.com\/users\/dbczumar\/repos","events_url":"https:\/\/api.github.com\/users\/dbczumar\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dbczumar\/received_events","type":"User","site_admin":false}],"795":[],"796":[],"797":[{"login":"ankit-db","id":52183359,"node_id":"MDQ6VXNlcjUyMTgzMzU5","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/52183359?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/ankit-db","html_url":"https:\/\/github.com\/ankit-db","followers_url":"https:\/\/api.github.com\/users\/ankit-db\/followers","following_url":"https:\/\/api.github.com\/users\/ankit-db\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/ankit-db\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/ankit-db\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/ankit-db\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/ankit-db\/orgs","repos_url":"https:\/\/api.github.com\/users\/ankit-db\/repos","events_url":"https:\/\/api.github.com\/users\/ankit-db\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/ankit-db\/received_events","type":"User","site_admin":false}],"798":[],"799":[],"800":[],"801":[],"802":[],"803":[],"804":[],"805":[],"806":[],"807":[],"808":[],"809":[{"login":"smurching","id":2358483,"node_id":"MDQ6VXNlcjIzNTg0ODM=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/2358483?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/smurching","html_url":"https:\/\/github.com\/smurching","followers_url":"https:\/\/api.github.com\/users\/smurching\/followers","following_url":"https:\/\/api.github.com\/users\/smurching\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/smurching\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/smurching\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/smurching\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/smurching\/orgs","repos_url":"https:\/\/api.github.com\/users\/smurching\/repos","events_url":"https:\/\/api.github.com\/users\/smurching\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/smurching\/received_events","type":"User","site_admin":false}],"810":[],"811":[],"812":[],"813":[{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/39497902?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dbczumar","html_url":"https:\/\/github.com\/dbczumar","followers_url":"https:\/\/api.github.com\/users\/dbczumar\/followers","following_url":"https:\/\/api.github.com\/users\/dbczumar\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dbczumar\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dbczumar\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dbczumar\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dbczumar\/orgs","repos_url":"https:\/\/api.github.com\/users\/dbczumar\/repos","events_url":"https:\/\/api.github.com\/users\/dbczumar\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dbczumar\/received_events","type":"User","site_admin":false}],"814":[{"login":"tomasatdatabricks","id":33237569,"node_id":"MDQ6VXNlcjMzMjM3NTY5","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/33237569?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/tomasatdatabricks","html_url":"https:\/\/github.com\/tomasatdatabricks","followers_url":"https:\/\/api.github.com\/users\/tomasatdatabricks\/followers","following_url":"https:\/\/api.github.com\/users\/tomasatdatabricks\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/tomasatdatabricks\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/tomasatdatabricks\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/tomasatdatabricks\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/tomasatdatabricks\/orgs","repos_url":"https:\/\/api.github.com\/users\/tomasatdatabricks\/repos","events_url":"https:\/\/api.github.com\/users\/tomasatdatabricks\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/tomasatdatabricks\/received_events","type":"User","site_admin":false}],"815":[],"816":[],"817":[],"818":[{"login":"smurching","id":2358483,"node_id":"MDQ6VXNlcjIzNTg0ODM=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/2358483?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/smurching","html_url":"https:\/\/github.com\/smurching","followers_url":"https:\/\/api.github.com\/users\/smurching\/followers","following_url":"https:\/\/api.github.com\/users\/smurching\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/smurching\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/smurching\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/smurching\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/smurching\/orgs","repos_url":"https:\/\/api.github.com\/users\/smurching\/repos","events_url":"https:\/\/api.github.com\/users\/smurching\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/smurching\/received_events","type":"User","site_admin":false}],"819":[],"820":[],"821":[],"822":[],"823":[],"824":[],"825":[],"826":[{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/39497902?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dbczumar","html_url":"https:\/\/github.com\/dbczumar","followers_url":"https:\/\/api.github.com\/users\/dbczumar\/followers","following_url":"https:\/\/api.github.com\/users\/dbczumar\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dbczumar\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dbczumar\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dbczumar\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dbczumar\/orgs","repos_url":"https:\/\/api.github.com\/users\/dbczumar\/repos","events_url":"https:\/\/api.github.com\/users\/dbczumar\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dbczumar\/received_events","type":"User","site_admin":false}],"827":[],"828":[],"829":[{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/39497902?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dbczumar","html_url":"https:\/\/github.com\/dbczumar","followers_url":"https:\/\/api.github.com\/users\/dbczumar\/followers","following_url":"https:\/\/api.github.com\/users\/dbczumar\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dbczumar\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dbczumar\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dbczumar\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dbczumar\/orgs","repos_url":"https:\/\/api.github.com\/users\/dbczumar\/repos","events_url":"https:\/\/api.github.com\/users\/dbczumar\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dbczumar\/received_events","type":"User","site_admin":false}],"830":[],"831":[],"832":[],"833":[],"834":[],"835":[],"836":[],"837":[],"838":[],"839":[{"login":"Zangr","id":6811562,"node_id":"MDQ6VXNlcjY4MTE1NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/6811562?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/Zangr","html_url":"https:\/\/github.com\/Zangr","followers_url":"https:\/\/api.github.com\/users\/Zangr\/followers","following_url":"https:\/\/api.github.com\/users\/Zangr\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/Zangr\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/Zangr\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/Zangr\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/Zangr\/orgs","repos_url":"https:\/\/api.github.com\/users\/Zangr\/repos","events_url":"https:\/\/api.github.com\/users\/Zangr\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/Zangr\/received_events","type":"User","site_admin":false}],"840":[],"841":[],"842":[],"843":[],"844":[],"845":[{"login":"sueann","id":4411489,"node_id":"MDQ6VXNlcjQ0MTE0ODk=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/4411489?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/sueann","html_url":"https:\/\/github.com\/sueann","followers_url":"https:\/\/api.github.com\/users\/sueann\/followers","following_url":"https:\/\/api.github.com\/users\/sueann\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/sueann\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/sueann\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/sueann\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/sueann\/orgs","repos_url":"https:\/\/api.github.com\/users\/sueann\/repos","events_url":"https:\/\/api.github.com\/users\/sueann\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/sueann\/received_events","type":"User","site_admin":false}],"846":[],"847":[],"848":[],"849":[{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/39497902?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dbczumar","html_url":"https:\/\/github.com\/dbczumar","followers_url":"https:\/\/api.github.com\/users\/dbczumar\/followers","following_url":"https:\/\/api.github.com\/users\/dbczumar\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dbczumar\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dbczumar\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dbczumar\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dbczumar\/orgs","repos_url":"https:\/\/api.github.com\/users\/dbczumar\/repos","events_url":"https:\/\/api.github.com\/users\/dbczumar\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dbczumar\/received_events","type":"User","site_admin":false}],"850":[{"login":"dmatrix","id":1117597,"node_id":"MDQ6VXNlcjExMTc1OTc=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/1117597?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dmatrix","html_url":"https:\/\/github.com\/dmatrix","followers_url":"https:\/\/api.github.com\/users\/dmatrix\/followers","following_url":"https:\/\/api.github.com\/users\/dmatrix\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dmatrix\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dmatrix\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dmatrix\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dmatrix\/orgs","repos_url":"https:\/\/api.github.com\/users\/dmatrix\/repos","events_url":"https:\/\/api.github.com\/users\/dmatrix\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dmatrix\/received_events","type":"User","site_admin":false}],"851":[],"852":[],"853":[],"854":[],"855":[],"856":[],"857":[],"858":[{"login":"ankit-db","id":52183359,"node_id":"MDQ6VXNlcjUyMTgzMzU5","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/52183359?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/ankit-db","html_url":"https:\/\/github.com\/ankit-db","followers_url":"https:\/\/api.github.com\/users\/ankit-db\/followers","following_url":"https:\/\/api.github.com\/users\/ankit-db\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/ankit-db\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/ankit-db\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/ankit-db\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/ankit-db\/orgs","repos_url":"https:\/\/api.github.com\/users\/ankit-db\/repos","events_url":"https:\/\/api.github.com\/users\/ankit-db\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/ankit-db\/received_events","type":"User","site_admin":false}],"859":[],"860":[],"861":[],"862":[],"863":[{"login":"gioa","id":1960721,"node_id":"MDQ6VXNlcjE5NjA3MjE=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/1960721?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/gioa","html_url":"https:\/\/github.com\/gioa","followers_url":"https:\/\/api.github.com\/users\/gioa\/followers","following_url":"https:\/\/api.github.com\/users\/gioa\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/gioa\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/gioa\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/gioa\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/gioa\/orgs","repos_url":"https:\/\/api.github.com\/users\/gioa\/repos","events_url":"https:\/\/api.github.com\/users\/gioa\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/gioa\/received_events","type":"User","site_admin":false},{"login":"Zangr","id":6811562,"node_id":"MDQ6VXNlcjY4MTE1NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/6811562?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/Zangr","html_url":"https:\/\/github.com\/Zangr","followers_url":"https:\/\/api.github.com\/users\/Zangr\/followers","following_url":"https:\/\/api.github.com\/users\/Zangr\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/Zangr\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/Zangr\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/Zangr\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/Zangr\/orgs","repos_url":"https:\/\/api.github.com\/users\/Zangr\/repos","events_url":"https:\/\/api.github.com\/users\/Zangr\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/Zangr\/received_events","type":"User","site_admin":false}],"864":[],"865":[],"866":[],"867":[],"868":[],"869":[],"870":[],"871":[],"872":[],"873":[],"874":[],"875":[],"876":[],"877":[],"878":[],"879":[],"880":[],"881":[],"882":[],"883":[],"884":[],"885":[],"886":[],"887":[],"888":[],"889":[],"890":[],"891":[],"892":[],"893":[{"login":"AveshCSingh","id":1208791,"node_id":"MDQ6VXNlcjEyMDg3OTE=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/1208791?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/AveshCSingh","html_url":"https:\/\/github.com\/AveshCSingh","followers_url":"https:\/\/api.github.com\/users\/AveshCSingh\/followers","following_url":"https:\/\/api.github.com\/users\/AveshCSingh\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/AveshCSingh\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/AveshCSingh\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/AveshCSingh\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/AveshCSingh\/orgs","repos_url":"https:\/\/api.github.com\/users\/AveshCSingh\/repos","events_url":"https:\/\/api.github.com\/users\/AveshCSingh\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/AveshCSingh\/received_events","type":"User","site_admin":false}],"894":[],"895":[],"896":[],"897":[],"898":[],"899":[],"900":[],"901":[{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/39497902?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dbczumar","html_url":"https:\/\/github.com\/dbczumar","followers_url":"https:\/\/api.github.com\/users\/dbczumar\/followers","following_url":"https:\/\/api.github.com\/users\/dbczumar\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dbczumar\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dbczumar\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dbczumar\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dbczumar\/orgs","repos_url":"https:\/\/api.github.com\/users\/dbczumar\/repos","events_url":"https:\/\/api.github.com\/users\/dbczumar\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dbczumar\/received_events","type":"User","site_admin":false}],"902":[],"903":[],"904":[],"905":[],"906":[],"907":[],"908":[],"909":[],"910":[],"911":[],"912":[],"913":[],"914":[],"915":[],"916":[],"917":[],"918":[],"919":[],"920":[],"921":[],"922":[],"923":[],"924":[],"925":[],"926":[],"927":[],"928":[],"929":[],"930":[],"931":[],"932":[],"933":[],"934":[],"935":[],"936":[],"937":[],"938":[{"login":"smurching","id":2358483,"node_id":"MDQ6VXNlcjIzNTg0ODM=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/2358483?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/smurching","html_url":"https:\/\/github.com\/smurching","followers_url":"https:\/\/api.github.com\/users\/smurching\/followers","following_url":"https:\/\/api.github.com\/users\/smurching\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/smurching\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/smurching\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/smurching\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/smurching\/orgs","repos_url":"https:\/\/api.github.com\/users\/smurching\/repos","events_url":"https:\/\/api.github.com\/users\/smurching\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/smurching\/received_events","type":"User","site_admin":false}],"939":[],"940":[],"941":[],"942":[],"943":[],"944":[],"945":[],"946":[],"947":[],"948":[{"login":"aarondav","id":1400247,"node_id":"MDQ6VXNlcjE0MDAyNDc=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/1400247?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/aarondav","html_url":"https:\/\/github.com\/aarondav","followers_url":"https:\/\/api.github.com\/users\/aarondav\/followers","following_url":"https:\/\/api.github.com\/users\/aarondav\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/aarondav\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/aarondav\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/aarondav\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/aarondav\/orgs","repos_url":"https:\/\/api.github.com\/users\/aarondav\/repos","events_url":"https:\/\/api.github.com\/users\/aarondav\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/aarondav\/received_events","type":"User","site_admin":false}],"949":[],"950":[],"951":[],"952":[],"953":[],"954":[],"955":[{"login":"Zangr","id":6811562,"node_id":"MDQ6VXNlcjY4MTE1NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/6811562?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/Zangr","html_url":"https:\/\/github.com\/Zangr","followers_url":"https:\/\/api.github.com\/users\/Zangr\/followers","following_url":"https:\/\/api.github.com\/users\/Zangr\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/Zangr\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/Zangr\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/Zangr\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/Zangr\/orgs","repos_url":"https:\/\/api.github.com\/users\/Zangr\/repos","events_url":"https:\/\/api.github.com\/users\/Zangr\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/Zangr\/received_events","type":"User","site_admin":false}],"956":[],"957":[],"958":[],"959":[],"960":[],"961":[],"962":[],"963":[],"964":[],"965":[],"966":[],"967":[],"968":[],"969":[{"login":"dmatrix","id":1117597,"node_id":"MDQ6VXNlcjExMTc1OTc=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/1117597?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dmatrix","html_url":"https:\/\/github.com\/dmatrix","followers_url":"https:\/\/api.github.com\/users\/dmatrix\/followers","following_url":"https:\/\/api.github.com\/users\/dmatrix\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dmatrix\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dmatrix\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dmatrix\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dmatrix\/orgs","repos_url":"https:\/\/api.github.com\/users\/dmatrix\/repos","events_url":"https:\/\/api.github.com\/users\/dmatrix\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dmatrix\/received_events","type":"User","site_admin":false}],"970":[],"971":[],"972":[],"973":[],"974":[{"login":"smurching","id":2358483,"node_id":"MDQ6VXNlcjIzNTg0ODM=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/2358483?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/smurching","html_url":"https:\/\/github.com\/smurching","followers_url":"https:\/\/api.github.com\/users\/smurching\/followers","following_url":"https:\/\/api.github.com\/users\/smurching\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/smurching\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/smurching\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/smurching\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/smurching\/orgs","repos_url":"https:\/\/api.github.com\/users\/smurching\/repos","events_url":"https:\/\/api.github.com\/users\/smurching\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/smurching\/received_events","type":"User","site_admin":false}],"975":[],"976":[],"977":[],"978":[],"979":[],"980":[],"981":[],"982":[],"983":[{"login":"Zangr","id":6811562,"node_id":"MDQ6VXNlcjY4MTE1NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/6811562?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/Zangr","html_url":"https:\/\/github.com\/Zangr","followers_url":"https:\/\/api.github.com\/users\/Zangr\/followers","following_url":"https:\/\/api.github.com\/users\/Zangr\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/Zangr\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/Zangr\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/Zangr\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/Zangr\/orgs","repos_url":"https:\/\/api.github.com\/users\/Zangr\/repos","events_url":"https:\/\/api.github.com\/users\/Zangr\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/Zangr\/received_events","type":"User","site_admin":false}],"984":[],"985":[],"986":[{"login":"smurching","id":2358483,"node_id":"MDQ6VXNlcjIzNTg0ODM=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/2358483?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/smurching","html_url":"https:\/\/github.com\/smurching","followers_url":"https:\/\/api.github.com\/users\/smurching\/followers","following_url":"https:\/\/api.github.com\/users\/smurching\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/smurching\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/smurching\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/smurching\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/smurching\/orgs","repos_url":"https:\/\/api.github.com\/users\/smurching\/repos","events_url":"https:\/\/api.github.com\/users\/smurching\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/smurching\/received_events","type":"User","site_admin":false}],"987":[],"988":[],"989":[],"990":[],"991":[],"992":[],"993":[],"994":[],"995":[],"996":[],"997":[{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/39497902?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/dbczumar","html_url":"https:\/\/github.com\/dbczumar","followers_url":"https:\/\/api.github.com\/users\/dbczumar\/followers","following_url":"https:\/\/api.github.com\/users\/dbczumar\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/dbczumar\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/dbczumar\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/dbczumar\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/dbczumar\/orgs","repos_url":"https:\/\/api.github.com\/users\/dbczumar\/repos","events_url":"https:\/\/api.github.com\/users\/dbczumar\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/dbczumar\/received_events","type":"User","site_admin":false}],"998":[],"999":[]},"comments":{"0":0,"1":1,"2":0,"3":2,"4":2,"5":0,"6":4,"7":6,"8":1,"9":2,"10":2,"11":1,"12":0,"13":2,"14":2,"15":4,"16":2,"17":0,"18":1,"19":8,"20":4,"21":2,"22":0,"23":1,"24":0,"25":0,"26":2,"27":7,"28":0,"29":0,"30":3,"31":2,"32":0,"33":0,"34":1,"35":0,"36":1,"37":0,"38":0,"39":0,"40":0,"41":0,"42":1,"43":3,"44":0,"45":0,"46":0,"47":0,"48":1,"49":1,"50":0,"51":5,"52":3,"53":0,"54":0,"55":0,"56":0,"57":0,"58":1,"59":0,"60":0,"61":0,"62":3,"63":0,"64":0,"65":0,"66":3,"67":0,"68":0,"69":0,"70":6,"71":0,"72":3,"73":0,"74":3,"75":2,"76":0,"77":0,"78":0,"79":0,"80":0,"81":1,"82":0,"83":2,"84":1,"85":7,"86":0,"87":3,"88":0,"89":1,"90":0,"91":0,"92":2,"93":0,"94":1,"95":0,"96":0,"97":0,"98":0,"99":2,"100":1,"101":1,"102":1,"103":0,"104":1,"105":2,"106":0,"107":0,"108":0,"109":5,"110":0,"111":0,"112":0,"113":1,"114":5,"115":0,"116":0,"117":1,"118":2,"119":3,"120":1,"121":3,"122":0,"123":4,"124":0,"125":0,"126":4,"127":3,"128":0,"129":7,"130":0,"131":1,"132":3,"133":0,"134":0,"135":4,"136":1,"137":2,"138":2,"139":0,"140":0,"141":0,"142":0,"143":0,"144":1,"145":0,"146":0,"147":0,"148":0,"149":0,"150":0,"151":3,"152":2,"153":2,"154":1,"155":0,"156":0,"157":8,"158":0,"159":0,"160":7,"161":1,"162":0,"163":1,"164":0,"165":1,"166":1,"167":2,"168":0,"169":0,"170":0,"171":1,"172":1,"173":1,"174":0,"175":0,"176":0,"177":2,"178":1,"179":1,"180":8,"181":15,"182":0,"183":5,"184":1,"185":5,"186":1,"187":0,"188":0,"189":0,"190":0,"191":0,"192":0,"193":0,"194":0,"195":0,"196":0,"197":1,"198":0,"199":3,"200":4,"201":6,"202":6,"203":0,"204":0,"205":2,"206":0,"207":2,"208":1,"209":3,"210":1,"211":5,"212":0,"213":2,"214":0,"215":0,"216":0,"217":0,"218":0,"219":0,"220":0,"221":1,"222":0,"223":1,"224":0,"225":0,"226":0,"227":0,"228":1,"229":0,"230":2,"231":0,"232":2,"233":1,"234":1,"235":5,"236":0,"237":0,"238":0,"239":0,"240":0,"241":0,"242":0,"243":0,"244":0,"245":0,"246":6,"247":1,"248":3,"249":0,"250":0,"251":0,"252":0,"253":0,"254":2,"255":0,"256":0,"257":0,"258":2,"259":1,"260":0,"261":0,"262":0,"263":0,"264":0,"265":1,"266":2,"267":0,"268":0,"269":1,"270":0,"271":3,"272":0,"273":3,"274":0,"275":5,"276":2,"277":0,"278":1,"279":2,"280":0,"281":2,"282":3,"283":2,"284":1,"285":1,"286":1,"287":1,"288":0,"289":0,"290":0,"291":0,"292":0,"293":3,"294":3,"295":0,"296":0,"297":4,"298":1,"299":0,"300":0,"301":2,"302":2,"303":0,"304":0,"305":0,"306":1,"307":0,"308":0,"309":0,"310":2,"311":7,"312":1,"313":2,"314":1,"315":4,"316":0,"317":7,"318":1,"319":4,"320":0,"321":0,"322":0,"323":6,"324":2,"325":3,"326":1,"327":5,"328":0,"329":1,"330":2,"331":1,"332":0,"333":1,"334":1,"335":1,"336":12,"337":0,"338":3,"339":3,"340":0,"341":1,"342":2,"343":0,"344":5,"345":4,"346":1,"347":1,"348":2,"349":1,"350":6,"351":3,"352":8,"353":2,"354":1,"355":1,"356":0,"357":0,"358":2,"359":0,"360":4,"361":2,"362":9,"363":1,"364":1,"365":1,"366":0,"367":10,"368":2,"369":0,"370":1,"371":3,"372":4,"373":3,"374":8,"375":1,"376":0,"377":0,"378":3,"379":0,"380":1,"381":2,"382":0,"383":0,"384":2,"385":2,"386":6,"387":0,"388":3,"389":1,"390":0,"391":1,"392":4,"393":0,"394":1,"395":2,"396":0,"397":0,"398":1,"399":3,"400":2,"401":3,"402":1,"403":4,"404":0,"405":2,"406":7,"407":1,"408":1,"409":0,"410":5,"411":1,"412":12,"413":0,"414":0,"415":0,"416":0,"417":1,"418":1,"419":1,"420":18,"421":1,"422":17,"423":0,"424":0,"425":0,"426":1,"427":0,"428":3,"429":4,"430":0,"431":1,"432":7,"433":0,"434":6,"435":6,"436":4,"437":0,"438":0,"439":4,"440":10,"441":3,"442":5,"443":2,"444":0,"445":0,"446":3,"447":2,"448":8,"449":0,"450":0,"451":3,"452":5,"453":0,"454":0,"455":0,"456":0,"457":4,"458":0,"459":3,"460":2,"461":2,"462":0,"463":6,"464":0,"465":0,"466":1,"467":0,"468":1,"469":1,"470":0,"471":3,"472":1,"473":5,"474":3,"475":3,"476":5,"477":1,"478":24,"479":2,"480":1,"481":1,"482":1,"483":7,"484":1,"485":0,"486":0,"487":4,"488":0,"489":4,"490":1,"491":0,"492":0,"493":2,"494":1,"495":3,"496":0,"497":1,"498":1,"499":0,"500":0,"501":2,"502":1,"503":0,"504":2,"505":2,"506":3,"507":1,"508":2,"509":2,"510":2,"511":1,"512":1,"513":1,"514":0,"515":2,"516":0,"517":3,"518":0,"519":1,"520":0,"521":0,"522":9,"523":2,"524":5,"525":1,"526":3,"527":1,"528":0,"529":2,"530":2,"531":2,"532":5,"533":1,"534":0,"535":2,"536":17,"537":3,"538":0,"539":0,"540":0,"541":3,"542":6,"543":2,"544":1,"545":0,"546":3,"547":0,"548":0,"549":3,"550":3,"551":4,"552":2,"553":2,"554":0,"555":0,"556":1,"557":3,"558":0,"559":1,"560":0,"561":17,"562":1,"563":0,"564":10,"565":1,"566":1,"567":2,"568":1,"569":11,"570":2,"571":2,"572":1,"573":0,"574":6,"575":0,"576":0,"577":1,"578":1,"579":4,"580":0,"581":3,"582":2,"583":2,"584":0,"585":2,"586":0,"587":0,"588":2,"589":10,"590":3,"591":3,"592":2,"593":1,"594":6,"595":1,"596":2,"597":7,"598":0,"599":1,"600":1,"601":0,"602":4,"603":1,"604":0,"605":3,"606":0,"607":9,"608":3,"609":1,"610":1,"611":0,"612":0,"613":2,"614":20,"615":2,"616":1,"617":7,"618":5,"619":3,"620":0,"621":1,"622":0,"623":2,"624":0,"625":1,"626":3,"627":2,"628":4,"629":4,"630":4,"631":0,"632":0,"633":2,"634":1,"635":1,"636":1,"637":24,"638":0,"639":2,"640":2,"641":3,"642":2,"643":7,"644":4,"645":0,"646":0,"647":17,"648":1,"649":0,"650":7,"651":0,"652":0,"653":6,"654":10,"655":1,"656":1,"657":3,"658":2,"659":1,"660":14,"661":0,"662":0,"663":4,"664":4,"665":2,"666":1,"667":0,"668":8,"669":3,"670":5,"671":2,"672":2,"673":16,"674":3,"675":3,"676":5,"677":6,"678":3,"679":1,"680":6,"681":1,"682":14,"683":9,"684":1,"685":3,"686":6,"687":3,"688":2,"689":5,"690":1,"691":2,"692":1,"693":3,"694":6,"695":2,"696":0,"697":1,"698":3,"699":1,"700":1,"701":6,"702":7,"703":2,"704":1,"705":2,"706":2,"707":9,"708":0,"709":3,"710":1,"711":3,"712":4,"713":6,"714":7,"715":3,"716":9,"717":15,"718":5,"719":1,"720":0,"721":9,"722":7,"723":6,"724":1,"725":1,"726":2,"727":9,"728":0,"729":6,"730":2,"731":7,"732":4,"733":2,"734":2,"735":8,"736":1,"737":4,"738":4,"739":3,"740":6,"741":5,"742":1,"743":0,"744":1,"745":4,"746":2,"747":9,"748":8,"749":17,"750":2,"751":3,"752":3,"753":5,"754":2,"755":7,"756":6,"757":5,"758":1,"759":3,"760":0,"761":6,"762":3,"763":6,"764":1,"765":6,"766":5,"767":5,"768":9,"769":1,"770":1,"771":3,"772":1,"773":9,"774":1,"775":1,"776":1,"777":10,"778":1,"779":12,"780":3,"781":1,"782":4,"783":5,"784":0,"785":8,"786":1,"787":5,"788":4,"789":1,"790":3,"791":0,"792":6,"793":1,"794":10,"795":3,"796":5,"797":6,"798":0,"799":6,"800":7,"801":15,"802":0,"803":6,"804":4,"805":6,"806":0,"807":2,"808":4,"809":4,"810":1,"811":3,"812":0,"813":7,"814":3,"815":3,"816":1,"817":9,"818":11,"819":0,"820":0,"821":2,"822":14,"823":4,"824":12,"825":8,"826":3,"827":3,"828":14,"829":10,"830":1,"831":1,"832":0,"833":4,"834":6,"835":1,"836":0,"837":3,"838":9,"839":11,"840":2,"841":0,"842":8,"843":4,"844":11,"845":6,"846":3,"847":12,"848":2,"849":1,"850":1,"851":1,"852":1,"853":1,"854":3,"855":0,"856":4,"857":6,"858":5,"859":4,"860":6,"861":0,"862":9,"863":1,"864":1,"865":3,"866":14,"867":0,"868":0,"869":0,"870":10,"871":5,"872":5,"873":2,"874":7,"875":3,"876":2,"877":5,"878":1,"879":2,"880":2,"881":4,"882":0,"883":11,"884":4,"885":7,"886":0,"887":1,"888":2,"889":4,"890":3,"891":3,"892":2,"893":0,"894":11,"895":10,"896":0,"897":2,"898":2,"899":3,"900":8,"901":8,"902":2,"903":19,"904":16,"905":3,"906":0,"907":8,"908":0,"909":3,"910":8,"911":3,"912":1,"913":2,"914":4,"915":1,"916":12,"917":3,"918":6,"919":6,"920":8,"921":11,"922":0,"923":4,"924":1,"925":2,"926":1,"927":10,"928":22,"929":7,"930":10,"931":2,"932":3,"933":6,"934":1,"935":0,"936":0,"937":13,"938":5,"939":1,"940":2,"941":3,"942":1,"943":2,"944":3,"945":2,"946":1,"947":0,"948":15,"949":10,"950":1,"951":3,"952":3,"953":3,"954":12,"955":24,"956":1,"957":14,"958":1,"959":3,"960":3,"961":7,"962":5,"963":9,"964":3,"965":18,"966":2,"967":0,"968":4,"969":11,"970":0,"971":1,"972":2,"973":0,"974":0,"975":17,"976":31,"977":0,"978":24,"979":0,"980":14,"981":13,"982":8,"983":2,"984":2,"985":5,"986":8,"987":2,"988":2,"989":0,"990":1,"991":5,"992":0,"993":0,"994":0,"995":1,"996":0,"997":3,"998":2,"999":5},"created_at":{"0":1646306256000,"1":1646276038000,"2":1646269657000,"3":1646235959000,"4":1646136042000,"5":1646055658000,"6":1645924535000,"7":1645861157000,"8":1645774636000,"9":1645741625000,"10":1645576163000,"11":1645399546000,"12":1645231139000,"13":1645184432000,"14":1645116188000,"15":1644964620000,"16":1644925151000,"17":1644906905000,"18":1644873442000,"19":1644839086000,"20":1644619622000,"21":1644592913000,"22":1644454595000,"23":1644401276000,"24":1644384450000,"25":1644242821000,"26":1644198069000,"27":1644162064000,"28":1644015043000,"29":1643806669000,"30":1643805607000,"31":1643761058000,"32":1643752921000,"33":1643739970000,"34":1643733021000,"35":1643704480000,"36":1643571358000,"37":1643412338000,"38":1643369298000,"39":1643279235000,"40":1643131492000,"41":1643017429000,"42":1642782778000,"43":1642751764000,"44":1642718478000,"45":1642506657000,"46":1642504182000,"47":1642399067000,"48":1642273060000,"49":1642158882000,"50":1642100176000,"51":1642081488000,"52":1642066044000,"53":1642031892000,"54":1641987362000,"55":1641909362000,"56":1641891046000,"57":1641843780000,"58":1641757385000,"59":1641594827000,"60":1641546929000,"61":1641525564000,"62":1641463340000,"63":1641435557000,"64":1641419160000,"65":1641381667000,"66":1641283514000,"67":1641222028000,"68":1641206892000,"69":1640868524000,"70":1640809771000,"71":1640779657000,"72":1640649395000,"73":1640615678000,"74":1640524985000,"75":1640408655000,"76":1640239624000,"77":1640172636000,"78":1640143887000,"79":1640071161000,"80":1639996991000,"81":1639958419000,"82":1639687195000,"83":1639672456000,"84":1639598622000,"85":1639586739000,"86":1639583780000,"87":1639576482000,"88":1639566436000,"89":1639261269000,"90":1639090157000,"91":1638931500000,"92":1638902113000,"93":1638881447000,"94":1638783751000,"95":1638782538000,"96":1638557141000,"97":1638523299000,"98":1638458433000,"99":1638387028000,"100":1638314538000,"101":1638273627000,"102":1638271462000,"103":1638121186000,"104":1638106431000,"105":1637953647000,"106":1637935066000,"107":1637753721000,"108":1637741793000,"109":1637677318000,"110":1637607041000,"111":1637559626000,"112":1637297786000,"113":1637270400000,"114":1637241148000,"115":1637139191000,"116":1637118901000,"117":1637067686000,"118":1636988358000,"119":1636987434000,"120":1636775293000,"121":1636747776000,"122":1636706268000,"123":1636677137000,"124":1636593470000,"125":1636524826000,"126":1636471598000,"127":1636471256000,"128":1636363904000,"129":1636133340000,"130":1636012450000,"131":1635952534000,"132":1635930302000,"133":1635910707000,"134":1635901020000,"135":1635872557000,"136":1635777610000,"137":1635776331000,"138":1635764664000,"139":1635703853000,"140":1635677861000,"141":1635661507000,"142":1635484288000,"143":1635477751000,"144":1635437414000,"145":1635361823000,"146":1635328583000,"147":1635278282000,"148":1635168770000,"149":1634818475000,"150":1634798568000,"151":1634794425000,"152":1634719193000,"153":1634715193000,"154":1634668750000,"155":1634233369000,"156":1634213443000,"157":1634163619000,"158":1634142241000,"159":1634124458000,"160":1634085047000,"161":1634041045000,"162":1634037950000,"163":1634021419000,"164":1633863895000,"165":1633859512000,"166":1633701102000,"167":1633621418000,"168":1633554445000,"169":1633530408000,"170":1633419764000,"171":1633368572000,"172":1633348541000,"173":1633076831000,"174":1632906541000,"175":1632821783000,"176":1632388335000,"177":1632173750000,"178":1632133709000,"179":1632009701000,"180":1631973847000,"181":1631923322000,"182":1631871729000,"183":1631848529000,"184":1631836888000,"185":1631825035000,"186":1631804463000,"187":1631769303000,"188":1631768862000,"189":1631735050000,"190":1631733805000,"191":1631731952000,"192":1631720558000,"193":1631713032000,"194":1631712308000,"195":1631699306000,"196":1631614251000,"197":1631558616000,"198":1631517067000,"199":1631339222000,"200":1631004670000,"201":1630999781000,"202":1630591264000,"203":1630508161000,"204":1630392054000,"205":1630389679000,"206":1630323983000,"207":1630310236000,"208":1630118512000,"209":1630057942000,"210":1629992791000,"211":1629975986000,"212":1629810334000,"213":1629486611000,"214":1629367525000,"215":1629138549000,"216":1628794172000,"217":1628754858000,"218":1628702007000,"219":1628687044000,"220":1628666023000,"221":1628591460000,"222":1628562953000,"223":1628485894000,"224":1628194618000,"225":1628172550000,"226":1628142731000,"227":1628090908000,"228":1628086020000,"229":1628077367000,"230":1628070713000,"231":1628032859000,"232":1628018904000,"233":1627994283000,"234":1627981529000,"235":1627910822000,"236":1627763849000,"237":1627568004000,"238":1627544073000,"239":1627514905000,"240":1627461823000,"241":1627439411000,"242":1627377851000,"243":1627308618000,"244":1627299469000,"245":1627073604000,"246":1627066858000,"247":1627065866000,"248":1626991401000,"249":1626899311000,"250":1626853455000,"251":1626715497000,"252":1626701727000,"253":1626475371000,"254":1626374894000,"255":1626324355000,"256":1626165650000,"257":1626163685000,"258":1625757159000,"259":1625639151000,"260":1625512833000,"261":1625501147000,"262":1625464381000,"263":1625229336000,"264":1625172521000,"265":1625055591000,"266":1624992824000,"267":1624609238000,"268":1624547201000,"269":1624519827000,"270":1624479758000,"271":1624472506000,"272":1624449177000,"273":1624426711000,"274":1624297469000,"275":1624260773000,"276":1624113619000,"277":1623966150000,"278":1623927872000,"279":1623829733000,"280":1623820144000,"281":1623770074000,"282":1623749633000,"283":1623726880000,"284":1623572389000,"285":1623511399000,"286":1623342823000,"287":1623278548000,"288":1623271328000,"289":1623250293000,"290":1623062064000,"291":1623060553000,"292":1622739890000,"293":1622648809000,"294":1622611467000,"295":1622537387000,"296":1622357826000,"297":1622283339000,"298":1622231504000,"299":1622206217000,"300":1622130305000,"301":1622105885000,"302":1622045255000,"303":1621958628000,"304":1621938545000,"305":1621860689000,"306":1621247921000,"307":1621242174000,"308":1621031498000,"309":1620935868000,"310":1620901908000,"311":1620891734000,"312":1620811132000,"313":1620758922000,"314":1620584176000,"315":1620414549000,"316":1620394609000,"317":1620385348000,"318":1620378678000,"319":1620377092000,"320":1620360574000,"321":1620319456000,"322":1620275280000,"323":1620189428000,"324":1620093050000,"325":1619795155000,"326":1619642007000,"327":1619623809000,"328":1619531214000,"329":1619215509000,"330":1619124543000,"331":1619029721000,"332":1618964834000,"333":1618958827000,"334":1618909584000,"335":1618783030000,"336":1618769019000,"337":1618391410000,"338":1618335175000,"339":1618328977000,"340":1618218547000,"341":1617999878000,"342":1617914946000,"343":1617399297000,"344":1617190855000,"345":1617114666000,"346":1617106117000,"347":1617053313000,"348":1617025889000,"349":1616742102000,"350":1616638772000,"351":1616608630000,"352":1616605997000,"353":1616443791000,"354":1616426277000,"355":1616350258000,"356":1616344574000,"357":1616132782000,"358":1616001373000,"359":1615942094000,"360":1615822714000,"361":1615791365000,"362":1615712017000,"363":1615327010000,"364":1615305863000,"365":1615263296000,"366":1614791014000,"367":1614641316000,"368":1614384780000,"369":1614372442000,"370":1614312151000,"371":1614158897000,"372":1614086737000,"373":1614025572000,"374":1613876468000,"375":1613875436000,"376":1613785565000,"377":1613772731000,"378":1613753442000,"379":1613753094000,"380":1613752248000,"381":1613747743000,"382":1613685017000,"383":1613590323000,"384":1613560077000,"385":1613379962000,"386":1613119654000,"387":1613077552000,"388":1613053895000,"389":1612864028000,"390":1612828103000,"391":1612808805000,"392":1612800317000,"393":1612798183000,"394":1612761937000,"395":1612700374000,"396":1612644064000,"397":1612574086000,"398":1612450243000,"399":1612441815000,"400":1612431101000,"401":1612407841000,"402":1612375173000,"403":1612364435000,"404":1612326438000,"405":1612296215000,"406":1612283319000,"407":1612194373000,"408":1612179308000,"409":1611906833000,"410":1611867354000,"411":1611851416000,"412":1611847711000,"413":1611840995000,"414":1611761764000,"415":1611741812000,"416":1611737121000,"417":1611690891000,"418":1611550200000,"419":1611348794000,"420":1611230261000,"421":1611088884000,"422":1611088221000,"423":1610971931000,"424":1610714624000,"425":1610685415000,"426":1610485350000,"427":1610484759000,"428":1610477531000,"429":1610475509000,"430":1610433536000,"431":1610390082000,"432":1610368378000,"433":1610204406000,"434":1610138684000,"435":1610129114000,"436":1610115688000,"437":1610102078000,"438":1610076493000,"439":1610031273000,"440":1609998463000,"441":1609985193000,"442":1609946163000,"443":1609875868000,"444":1609756093000,"445":1609630882000,"446":1609601087000,"447":1609501476000,"448":1609348169000,"449":1609347699000,"450":1609121703000,"451":1608841302000,"452":1608674403000,"453":1608605309000,"454":1608405646000,"455":1608341539000,"456":1608278575000,"457":1608257693000,"458":1608206713000,"459":1608146554000,"460":1608130009000,"461":1608038476000,"462":1608027875000,"463":1608005135000,"464":1608003180000,"465":1607973818000,"466":1607971783000,"467":1607936180000,"468":1607920925000,"469":1607733008000,"470":1607697801000,"471":1607606379000,"472":1607598702000,"473":1607557940000,"474":1607528192000,"475":1607519912000,"476":1607373954000,"477":1607360337000,"478":1607264896000,"479":1607179582000,"480":1607008876000,"481":1606961049000,"482":1606960704000,"483":1606933853000,"484":1606917279000,"485":1606916484000,"486":1606847569000,"487":1606792938000,"488":1606711550000,"489":1606664426000,"490":1606477990000,"491":1606477714000,"492":1606463714000,"493":1606463189000,"494":1606388077000,"495":1606227908000,"496":1606227157000,"497":1606109112000,"498":1605950684000,"499":1605825914000,"500":1605763238000,"501":1605718999000,"502":1605686944000,"503":1605648083000,"504":1605465279000,"505":1605463515000,"506":1605448025000,"507":1605346260000,"508":1605340253000,"509":1605303354000,"510":1605297422000,"511":1605295426000,"512":1605286283000,"513":1605273811000,"514":1605264475000,"515":1605124216000,"516":1605116946000,"517":1605099089000,"518":1605004753000,"519":1604930657000,"520":1604930641000,"521":1604900526000,"522":1604488110000,"523":1604471161000,"524":1604443599000,"525":1604412022000,"526":1604410254000,"527":1604397620000,"528":1604333426000,"529":1604261897000,"530":1604258980000,"531":1604188279000,"532":1603618188000,"533":1603567326000,"534":1603455954000,"535":1603438600000,"536":1603403219000,"537":1603402492000,"538":1603394289000,"539":1603393538000,"540":1603392705000,"541":1603314874000,"542":1603289552000,"543":1603283946000,"544":1603277946000,"545":1603277471000,"546":1603171240000,"547":1603108945000,"548":1603103614000,"549":1603095460000,"550":1603087831000,"551":1602776149000,"552":1602705282000,"553":1602664565000,"554":1602627496000,"555":1602562502000,"556":1602505906000,"557":1602505858000,"558":1602286632000,"559":1602077780000,"560":1602037119000,"561":1601745156000,"562":1601636791000,"563":1601565554000,"564":1601563029000,"565":1601544330000,"566":1601536142000,"567":1601529972000,"568":1601529016000,"569":1601510298000,"570":1601480940000,"571":1601480936000,"572":1601447374000,"573":1601381496000,"574":1601050808000,"575":1601028622000,"576":1601028380000,"577":1600988376000,"578":1600978972000,"579":1600816965000,"580":1600768176000,"581":1600511903000,"582":1600377505000,"583":1600377067000,"584":1600375197000,"585":1600348457000,"586":1600257045000,"587":1600249976000,"588":1600149167000,"589":1600085038000,"590":1599847640000,"591":1599845500000,"592":1599834572000,"593":1599833932000,"594":1599489711000,"595":1599486518000,"596":1599383827000,"597":1599333873000,"598":1599239991000,"599":1599239806000,"600":1599144975000,"601":1599143720000,"602":1599121368000,"603":1599081221000,"604":1599049586000,"605":1598965025000,"606":1598963800000,"607":1598889508000,"608":1598719414000,"609":1598681958000,"610":1598634401000,"611":1598532902000,"612":1598450384000,"613":1598439143000,"614":1598432674000,"615":1598323964000,"616":1598300584000,"617":1598280694000,"618":1598125886000,"619":1598120663000,"620":1598109502000,"621":1598063818000,"622":1597979243000,"623":1597914374000,"624":1597891717000,"625":1597876543000,"626":1597857084000,"627":1597742801000,"628":1597742702000,"629":1597741835000,"630":1597701641000,"631":1597564182000,"632":1597563203000,"633":1597436788000,"634":1597402535000,"635":1597346166000,"636":1597278800000,"637":1597150505000,"638":1597024771000,"639":1596794884000,"640":1596744435000,"641":1596598975000,"642":1596578905000,"643":1596537828000,"644":1596495370000,"645":1596494220000,"646":1596212439000,"647":1596198011000,"648":1596142964000,"649":1596142589000,"650":1596137764000,"651":1596063291000,"652":1595976294000,"653":1595847289000,"654":1595831820000,"655":1595480193000,"656":1595478736000,"657":1595432853000,"658":1595413008000,"659":1595405957000,"660":1595321761000,"661":1595251186000,"662":1595197068000,"663":1595002004000,"664":1594998370000,"665":1594987885000,"666":1594775086000,"667":1594760237000,"668":1594745978000,"669":1594707600000,"670":1594310546000,"671":1594278920000,"672":1594191066000,"673":1594175449000,"674":1594169363000,"675":1594145959000,"676":1594065863000,"677":1593789253000,"678":1593771892000,"679":1593704711000,"680":1593616706000,"681":1593603199000,"682":1593507232000,"683":1593462107000,"684":1593452956000,"685":1593446008000,"686":1593375125000,"687":1593304526000,"688":1593171960000,"689":1593105575000,"690":1592985580000,"691":1592978940000,"692":1592888407000,"693":1592840246000,"694":1592801182000,"695":1592732074000,"696":1592701009000,"697":1592569743000,"698":1592562666000,"699":1592524887000,"700":1592506068000,"701":1592423538000,"702":1592359248000,"703":1592322267000,"704":1592284327000,"705":1592230112000,"706":1592100162000,"707":1591989555000,"708":1591917466000,"709":1591866064000,"710":1591711400000,"711":1591627965000,"712":1591470003000,"713":1591260725000,"714":1590678250000,"715":1590647052000,"716":1590514140000,"717":1590254678000,"718":1590220299000,"719":1590110753000,"720":1589837143000,"721":1589814703000,"722":1589814082000,"723":1589785617000,"724":1589779125000,"725":1589577507000,"726":1589557024000,"727":1589552607000,"728":1589552395000,"729":1589550585000,"730":1589497779000,"731":1589489283000,"732":1589446721000,"733":1589444928000,"734":1589439068000,"735":1589411687000,"736":1589372263000,"737":1589341392000,"738":1589285725000,"739":1589271427000,"740":1589255575000,"741":1588974339000,"742":1588866533000,"743":1588866318000,"744":1588835794000,"745":1588778437000,"746":1588592234000,"747":1588273928000,"748":1588236431000,"749":1588189546000,"750":1588175232000,"751":1587945130000,"752":1587934763000,"753":1587697579000,"754":1587521280000,"755":1587401156000,"756":1587370764000,"757":1587208846000,"758":1587192409000,"759":1587153904000,"760":1587065026000,"761":1587064577000,"762":1587053270000,"763":1586912663000,"764":1586867533000,"765":1586846970000,"766":1586809449000,"767":1586808248000,"768":1586678350000,"769":1586352700000,"770":1586274083000,"771":1586244848000,"772":1586074563000,"773":1586049428000,"774":1586033335000,"775":1585828719000,"776":1585822325000,"777":1585602381000,"778":1585500721000,"779":1585329349000,"780":1585151916000,"781":1585058343000,"782":1584982527000,"783":1584914616000,"784":1584747813000,"785":1584589060000,"786":1584532044000,"787":1584021239000,"788":1583963039000,"789":1583532479000,"790":1583482207000,"791":1583362962000,"792":1583360324000,"793":1583357138000,"794":1583351661000,"795":1583341923000,"796":1583226065000,"797":1583075498000,"798":1582996669000,"799":1582818602000,"800":1582783982000,"801":1582747030000,"802":1582711089000,"803":1582640887000,"804":1582572753000,"805":1582506654000,"806":1582326271000,"807":1582229887000,"808":1582209131000,"809":1582170072000,"810":1582164861000,"811":1582145909000,"812":1582132065000,"813":1582130815000,"814":1582128064000,"815":1582102170000,"816":1582020027000,"817":1581693197000,"818":1581564144000,"819":1581562809000,"820":1581532756000,"821":1581433843000,"822":1581353049000,"823":1581112704000,"824":1580972477000,"825":1580909903000,"826":1580773466000,"827":1580764822000,"828":1580759977000,"829":1580737122000,"830":1580723189000,"831":1580722252000,"832":1580386769000,"833":1580385269000,"834":1580221345000,"835":1580145500000,"836":1579688854000,"837":1579597715000,"838":1579092234000,"839":1579065647000,"840":1579014979000,"841":1578937790000,"842":1578802238000,"843":1578795238000,"844":1578467494000,"845":1578347404000,"846":1578317437000,"847":1578120551000,"848":1578072418000,"849":1577718645000,"850":1577468409000,"851":1577467233000,"852":1577367303000,"853":1577211993000,"854":1577094950000,"855":1576775486000,"856":1576592269000,"857":1576498586000,"858":1576498210000,"859":1576209231000,"860":1576078463000,"861":1575992383000,"862":1575982851000,"863":1575938415000,"864":1575890686000,"865":1575581914000,"866":1575552414000,"867":1575498729000,"868":1575496640000,"869":1575481765000,"870":1575455190000,"871":1575072885000,"872":1575048640000,"873":1575026507000,"874":1574883864000,"875":1574770886000,"876":1574756694000,"877":1574728001000,"878":1574596441000,"879":1574330020000,"880":1574302999000,"881":1574265297000,"882":1574153116000,"883":1574102662000,"884":1574093198000,"885":1574049166000,"886":1573901379000,"887":1573687656000,"888":1573638381000,"889":1573566813000,"890":1573303370000,"891":1573063451000,"892":1572517059000,"893":1572443666000,"894":1572369323000,"895":1572090358000,"896":1571995860000,"897":1571917637000,"898":1571832370000,"899":1571777830000,"900":1571658077000,"901":1571645971000,"902":1571545501000,"903":1571397658000,"904":1571257124000,"905":1571217727000,"906":1571172899000,"907":1571057694000,"908":1570963973000,"909":1570695970000,"910":1570691553000,"911":1570570086000,"912":1570444195000,"913":1570057131000,"914":1570031301000,"915":1569337693000,"916":1569275440000,"917":1569068632000,"918":1568812733000,"919":1568735097000,"920":1568729228000,"921":1568341149000,"922":1568260038000,"923":1568118292000,"924":1568066721000,"925":1568033998000,"926":1568032877000,"927":1568029120000,"928":1567682478000,"929":1567607596000,"930":1567598831000,"931":1567592626000,"932":1567576150000,"933":1567458625000,"934":1567014720000,"935":1566829061000,"936":1566370242000,"937":1566276550000,"938":1566133313000,"939":1565978629000,"940":1565927231000,"941":1565745524000,"942":1565646881000,"943":1565554516000,"944":1565466049000,"945":1565254604000,"946":1564991428000,"947":1564740868000,"948":1564148805000,"949":1563988080000,"950":1563916111000,"951":1563870122000,"952":1563796841000,"953":1563479641000,"954":1562751642000,"955":1562604264000,"956":1562597858000,"957":1562597325000,"958":1561823401000,"959":1561500832000,"960":1560959261000,"961":1560799122000,"962":1560781192000,"963":1560578521000,"964":1559938536000,"965":1559836424000,"966":1559823633000,"967":1559734155000,"968":1558016576000,"969":1557663656000,"970":1555642660000,"971":1555349196000,"972":1554260585000,"973":1553888449000,"974":1553255622000,"975":1553251934000,"976":1552840059000,"977":1551714815000,"978":1551185215000,"979":1551086852000,"980":1549296834000,"981":1549296545000,"982":1548350772000,"983":1548267271000,"984":1548267157000,"985":1548099159000,"986":1542755805000,"987":1538161226000,"988":1537975655000,"989":1537888735000,"990":1536829259000,"991":1536595459000,"992":1536045856000,"993":1535755031000,"994":1534494717000,"995":1534270811000,"996":1533746423000,"997":1533324367000,"998":1531769556000,"999":1530301923000},"updated_at":{"0":1646306568000,"1":1646277423000,"2":1646320630000,"3":1646274741000,"4":1646277015000,"5":1646305768000,"6":1646197523000,"7":1646266129000,"8":1646121944000,"9":1645811352000,"10":1646275106000,"11":1645757608000,"12":1645231145000,"13":1646218017000,"14":1646197901000,"15":1646122121000,"16":1645433664000,"17":1645112163000,"18":1645746606000,"19":1645470341000,"20":1645826474000,"21":1645827285000,"22":1644454638000,"23":1644401510000,"24":1644384450000,"25":1644242880000,"26":1646217751000,"27":1646186371000,"28":1644015058000,"29":1643806680000,"30":1643918704000,"31":1644343443000,"32":1643753305000,"33":1643740463000,"34":1644612597000,"35":1643704581000,"36":1643593430000,"37":1643412354000,"38":1644603133000,"39":1643279250000,"40":1646244972000,"41":1643017682000,"42":1646234670000,"43":1644915646000,"44":1642718660000,"45":1642744068000,"46":1642824180000,"47":1642785096000,"48":1642394946000,"49":1642641280000,"50":1643355768000,"51":1642449504000,"52":1643394179000,"53":1642086630000,"54":1641988015000,"55":1641924016000,"56":1642785315000,"57":1641962608000,"58":1644226246000,"59":1641594828000,"60":1641547005000,"61":1641525636000,"62":1642529089000,"63":1641435576000,"64":1641419160000,"65":1641381684000,"66":1646046026000,"67":1641222028000,"68":1641206892000,"69":1640868540000,"70":1644296105000,"71":1640779707000,"72":1641211512000,"73":1640615678000,"74":1640582359000,"75":1640452051000,"76":1640239624000,"77":1640173380000,"78":1640143887000,"79":1644322130000,"80":1639997522000,"81":1640142718000,"82":1639726001000,"83":1640138090000,"84":1640029617000,"85":1643840338000,"86":1639583795000,"87":1642151405000,"88":1639568870000,"89":1639261286000,"90":1644321129000,"91":1643354483000,"92":1638917223000,"93":1638882314000,"94":1639145674000,"95":1638782879000,"96":1638559376000,"97":1638523299000,"98":1638463155000,"99":1638454675000,"100":1645757995000,"101":1638918642000,"102":1639349466000,"103":1638137370000,"104":1639571232000,"105":1645030275000,"106":1637935081000,"107":1637753899000,"108":1637741793000,"109":1638910539000,"110":1637607432000,"111":1638289108000,"112":1637297786000,"113":1645820039000,"114":1645221747000,"115":1637139191000,"116":1637120689000,"117":1638517747000,"118":1641271056000,"119":1641447483000,"120":1636912799000,"121":1637856940000,"122":1636706504000,"123":1641280811000,"124":1636594344000,"125":1636525003000,"126":1641144673000,"127":1641896217000,"128":1636363937000,"129":1636743001000,"130":1641331983000,"131":1644326549000,"132":1635955913000,"133":1635910707000,"134":1635901020000,"135":1636585101000,"136":1639489525000,"137":1636131689000,"138":1636321710000,"139":1635703868000,"140":1635677878000,"141":1635726864000,"142":1635484692000,"143":1635477751000,"144":1635438398000,"145":1635361823000,"146":1635328597000,"147":1635278299000,"148":1635168788000,"149":1634818489000,"150":1634798568000,"151":1638606752000,"152":1641270891000,"153":1634915246000,"154":1634923656000,"155":1634233369000,"156":1634921617000,"157":1636028505000,"158":1634142257000,"159":1634124458000,"160":1635357962000,"161":1634922067000,"162":1634922654000,"163":1637629305000,"164":1645110110000,"165":1634918986000,"166":1633701341000,"167":1636990654000,"168":1633554445000,"169":1633530408000,"170":1633419810000,"171":1641294443000,"172":1646089238000,"173":1635322169000,"174":1632906557000,"175":1633712091000,"176":1632388373000,"177":1632259879000,"178":1632412660000,"179":1632076728000,"180":1646247444000,"181":1646268687000,"182":1631872131000,"183":1642717526000,"184":1632743348000,"185":1634797987000,"186":1631804793000,"187":1631769321000,"188":1631768931000,"189":1631735063000,"190":1631733823000,"191":1631733261000,"192":1631788438000,"193":1631713061000,"194":1631712308000,"195":1631781623000,"196":1631614264000,"197":1631614613000,"198":1631517157000,"199":1632155944000,"200":1631283537000,"201":1637359135000,"202":1631617047000,"203":1630508161000,"204":1630392068000,"205":1632179087000,"206":1630323983000,"207":1631851772000,"208":1640067057000,"209":1630396722000,"210":1630388754000,"211":1630572725000,"212":1630567796000,"213":1637314739000,"214":1629367539000,"215":1629138565000,"216":1628872772000,"217":1629198981000,"218":1628702007000,"219":1628687136000,"220":1628667806000,"221":1634905466000,"222":1628562970000,"223":1630083065000,"224":1628194618000,"225":1628229824000,"226":1628142799000,"227":1628090926000,"228":1633075741000,"229":1628079020000,"230":1631552642000,"231":1628032859000,"232":1628879609000,"233":1627998272000,"234":1635235897000,"235":1634687305000,"236":1627763935000,"237":1627568122000,"238":1627650483000,"239":1627514905000,"240":1627461938000,"241":1627439426000,"242":1627377923000,"243":1627308667000,"244":1627299897000,"245":1627073604000,"246":1637961371000,"247":1630083593000,"248":1627800738000,"249":1626899331000,"250":1626853463000,"251":1626715554000,"252":1626702291000,"253":1626475389000,"254":1626705639000,"255":1626324381000,"256":1631256033000,"257":1626453667000,"258":1640013580000,"259":1626454417000,"260":1625512846000,"261":1644394270000,"262":1625464683000,"263":1625229403000,"264":1625194375000,"265":1637055075000,"266":1627933485000,"267":1624609238000,"268":1624550024000,"269":1624998890000,"270":1624479758000,"271":1626061787000,"272":1624450650000,"273":1627916261000,"274":1624297469000,"275":1630498813000,"276":1631642828000,"277":1623966310000,"278":1645447763000,"279":1624010156000,"280":1623820856000,"281":1627764388000,"282":1626444607000,"283":1623726940000,"284":1626550988000,"285":1623774042000,"286":1623399621000,"287":1643297963000,"288":1623271343000,"289":1623250310000,"290":1623062160000,"291":1623060553000,"292":1622824307000,"293":1623267750000,"294":1632598157000,"295":1622537387000,"296":1622357826000,"297":1627449629000,"298":1636143933000,"299":1622208137000,"300":1623169292000,"301":1622198192000,"302":1625581577000,"303":1626425820000,"304":1621938545000,"305":1621860689000,"306":1624866750000,"307":1621242323000,"308":1621031498000,"309":1620935882000,"310":1621329728000,"311":1639077290000,"312":1625147919000,"313":1620808723000,"314":1620924926000,"315":1622750359000,"316":1620394625000,"317":1621258075000,"318":1626220755000,"319":1622187340000,"320":1620618609000,"321":1620324226000,"322":1620707172000,"323":1635380348000,"324":1624005330000,"325":1620059633000,"326":1643226674000,"327":1638874848000,"328":1619617748000,"329":1619746093000,"330":1619125775000,"331":1619126627000,"332":1618964904000,"333":1634018531000,"334":1619875928000,"335":1618856345000,"336":1635251944000,"337":1618391434000,"338":1627914807000,"339":1646238339000,"340":1618218571000,"341":1618330797000,"342":1620090378000,"343":1620926427000,"344":1627666058000,"345":1641483651000,"346":1617381272000,"347":1617299464000,"348":1617814498000,"349":1617300004000,"350":1642210457000,"351":1628091713000,"352":1641434895000,"353":1627666868000,"354":1616601701000,"355":1630491036000,"356":1616344574000,"357":1616132801000,"358":1617138527000,"359":1615942094000,"360":1616586034000,"361":1615860876000,"362":1644418001000,"363":1615400657000,"364":1632417229000,"365":1615312345000,"366":1614791031000,"367":1631949575000,"368":1615906372000,"369":1627666111000,"370":1615312464000,"371":1616003533000,"372":1645631496000,"373":1629490568000,"374":1631183749000,"375":1614963641000,"376":1613785579000,"377":1613772746000,"378":1645297550000,"379":1613753109000,"380":1613752385000,"381":1627666239000,"382":1613685072000,"383":1627666442000,"384":1641148851000,"385":1639747074000,"386":1614372869000,"387":1613077566000,"388":1613987824000,"389":1613179349000,"390":1612828253000,"391":1614604164000,"392":1636743568000,"393":1612798202000,"394":1613452598000,"395":1613698034000,"396":1612721286000,"397":1613070774000,"398":1612511506000,"399":1631272295000,"400":1629291923000,"401":1641331969000,"402":1612475340000,"403":1612480230000,"404":1612327613000,"405":1613228632000,"406":1641750758000,"407":1627666409000,"408":1626456466000,"409":1612288171000,"410":1634746901000,"411":1627666463000,"412":1623746569000,"413":1611840995000,"414":1611761781000,"415":1611741812000,"416":1611739242000,"417":1611692553000,"418":1627665414000,"419":1611372900000,"420":1642635486000,"421":1611112589000,"422":1644861040000,"423":1610971946000,"424":1610732419000,"425":1610729668000,"426":1610494053000,"427":1610486313000,"428":1641764603000,"429":1644969135000,"430":1612496493000,"431":1610405571000,"432":1612428073000,"433":1610204421000,"434":1614878052000,"435":1620633890000,"436":1621845320000,"437":1610102078000,"438":1610076509000,"439":1610458569000,"440":1617181579000,"441":1643220642000,"442":1612442095000,"443":1611708836000,"444":1609756106000,"445":1609641308000,"446":1619832700000,"447":1637074836000,"448":1619644375000,"449":1609347795000,"450":1609121733000,"451":1626185690000,"452":1616172810000,"453":1608605537000,"454":1608605248000,"455":1608341554000,"456":1608606733000,"457":1608607942000,"458":1608206728000,"459":1617365076000,"460":1608200425000,"461":1608168565000,"462":1609754509000,"463":1634137233000,"464":1608003197000,"465":1627666534000,"466":1613070831000,"467":1607936180000,"468":1609755714000,"469":1608233544000,"470":1607724007000,"471":1607951009000,"472":1607621783000,"473":1635106332000,"474":1607625353000,"475":1610078937000,"476":1607455224000,"477":1609834697000,"478":1646299452000,"479":1645436268000,"480":1612721443000,"481":1607034321000,"482":1607035183000,"483":1622975191000,"484":1607078828000,"485":1606916906000,"486":1606847569000,"487":1625026592000,"488":1608904471000,"489":1636022782000,"490":1609755892000,"491":1606477747000,"492":1606470943000,"493":1610710346000,"494":1619875793000,"495":1619043442000,"496":1606227188000,"497":1626788381000,"498":1606329028000,"499":1605828878000,"500":1605763254000,"501":1618333228000,"502":1605895826000,"503":1605648099000,"504":1618333223000,"505":1618333219000,"506":1620812274000,"507":1605601285000,"508":1618333210000,"509":1606151518000,"510":1618333206000,"511":1618333198000,"512":1605646390000,"513":1614677723000,"514":1627666565000,"515":1617896352000,"516":1605116963000,"517":1641374294000,"518":1644322500000,"519":1611045620000,"520":1604930762000,"521":1605032908000,"522":1605944788000,"523":1604497918000,"524":1623704064000,"525":1605646446000,"526":1617829392000,"527":1606023646000,"528":1604978048000,"529":1618333192000,"530":1604496124000,"531":1627666756000,"532":1604976392000,"533":1618489182000,"534":1603456140000,"535":1606366020000,"536":1634642325000,"537":1604077078000,"538":1608238924000,"539":1608238906000,"540":1603392721000,"541":1604150288000,"542":1605312873000,"543":1607504892000,"544":1603287926000,"545":1603384106000,"546":1638200821000,"547":1603108961000,"548":1603103771000,"549":1635519569000,"550":1619470147000,"551":1602794247000,"552":1602834061000,"553":1602834037000,"554":1602627513000,"555":1602562502000,"556":1602520685000,"557":1602556518000,"558":1602286632000,"559":1602201383000,"560":1602037119000,"561":1634186283000,"562":1601904869000,"563":1601565598000,"564":1627900236000,"565":1601885155000,"566":1601571044000,"567":1601577486000,"568":1601570474000,"569":1646043170000,"570":1623760110000,"571":1601986127000,"572":1601447446000,"573":1601381514000,"574":1641540321000,"575":1605523068000,"576":1601028380000,"577":1630005133000,"578":1601053311000,"579":1601052714000,"580":1600768192000,"581":1644425738000,"582":1602134466000,"583":1600461310000,"584":1600383056000,"585":1636558064000,"586":1601918144000,"587":1600249992000,"588":1610038059000,"589":1613751689000,"590":1600400661000,"591":1644477766000,"592":1624977838000,"593":1624353063000,"594":1606737824000,"595":1599587004000,"596":1607450542000,"597":1631536455000,"598":1599240006000,"599":1599589487000,"600":1599843717000,"601":1599143740000,"602":1628104015000,"603":1620912413000,"604":1599089125000,"605":1607354622000,"606":1598975607000,"607":1641892226000,"608":1644999371000,"609":1643322715000,"610":1598634775000,"611":1598532917000,"612":1598450399000,"613":1598456479000,"614":1622026585000,"615":1598978175000,"616":1607450651000,"617":1601318681000,"618":1599501959000,"619":1608207044000,"620":1598109517000,"621":1600725467000,"622":1598332347000,"623":1638185889000,"624":1597929562000,"625":1597961944000,"626":1598324638000,"627":1599843638000,"628":1620912472000,"629":1597853233000,"630":1602605574000,"631":1597564196000,"632":1597563218000,"633":1597681551000,"634":1646222376000,"635":1597348323000,"636":1602560360000,"637":1597159406000,"638":1598328779000,"639":1596827468000,"640":1596789993000,"641":1598986328000,"642":1603278313000,"643":1596643314000,"644":1597249250000,"645":1600121127000,"646":1596213080000,"647":1620844430000,"648":1596179193000,"649":1596239259000,"650":1596217031000,"651":1596472901000,"652":1596006398000,"653":1597564736000,"654":1600152681000,"655":1596415386000,"656":1603278269000,"657":1596706552000,"658":1595466865000,"659":1597652700000,"660":1639065782000,"661":1596544491000,"662":1595228782000,"663":1595368132000,"664":1626870927000,"665":1619465961000,"666":1637680302000,"667":1594985638000,"668":1639979358000,"669":1595279980000,"670":1594919227000,"671":1594999855000,"672":1618920030000,"673":1597436463000,"674":1621504025000,"675":1595571408000,"676":1607613623000,"677":1597026262000,"678":1641992487000,"679":1594408079000,"680":1642063369000,"681":1595373629000,"682":1646072087000,"683":1631498581000,"684":1594982830000,"685":1620766889000,"686":1594074098000,"687":1619469951000,"688":1608002215000,"689":1595437748000,"690":1594708354000,"691":1595471562000,"692":1630005196000,"693":1596706959000,"694":1604581991000,"695":1595414817000,"696":1594408101000,"697":1594172204000,"698":1602698002000,"699":1595280349000,"700":1592506381000,"701":1594408105000,"702":1645735759000,"703":1605237186000,"704":1594337900000,"705":1594999185000,"706":1610139515000,"707":1612181113000,"708":1598986357000,"709":1621855811000,"710":1612187581000,"711":1594338806000,"712":1594228246000,"713":1641984744000,"714":1598972679000,"715":1619609148000,"716":1594408118000,"717":1620463060000,"718":1641375757000,"719":1631414670000,"720":1594675432000,"721":1614079904000,"722":1634562320000,"723":1599720712000,"724":1594408123000,"725":1595061356000,"726":1594369546000,"727":1596762245000,"728":1594610833000,"729":1594685127000,"730":1603278220000,"731":1603386449000,"732":1600825946000,"733":1596022756000,"734":1638774537000,"735":1624379424000,"736":1591218401000,"737":1594702217000,"738":1594685391000,"739":1595204901000,"740":1612867913000,"741":1603568332000,"742":1589481006000,"743":1589496423000,"744":1594077418000,"745":1610839122000,"746":1620658221000,"747":1608626315000,"748":1630928465000,"749":1631560909000,"750":1589209238000,"751":1607385695000,"752":1594983546000,"753":1594984972000,"754":1595365244000,"755":1622803385000,"756":1639597402000,"757":1594615919000,"758":1595021490000,"759":1594985129000,"760":1594615955000,"761":1611955784000,"762":1589410596000,"763":1625843048000,"764":1594742017000,"765":1594679604000,"766":1608276389000,"767":1634271269000,"768":1644268163000,"769":1591883364000,"770":1594617134000,"771":1620355920000,"772":1595136652000,"773":1645624751000,"774":1595280720000,"775":1594229308000,"776":1594617177000,"777":1630661850000,"778":1594617527000,"779":1595965879000,"780":1620666973000,"781":1594617549000,"782":1588587176000,"783":1627459493000,"784":1594991156000,"785":1588375293000,"786":1594728875000,"787":1613578689000,"788":1588523653000,"789":1595627545000,"790":1594702220000,"791":1595238788000,"792":1595271976000,"793":1594681971000,"794":1620900383000,"795":1587938553000,"796":1594985857000,"797":1594074507000,"798":1594944836000,"799":1637050506000,"800":1643919335000,"801":1614917119000,"802":1593644298000,"803":1595439462000,"804":1602027946000,"805":1626207824000,"806":1595061167000,"807":1595283859000,"808":1584926753000,"809":1629375343000,"810":1630005351000,"811":1594618822000,"812":1594230351000,"813":1617024897000,"814":1604948084000,"815":1640113789000,"816":1594618849000,"817":1612367163000,"818":1642320318000,"819":1594230417000,"820":1594675558000,"821":1610779595000,"822":1639082402000,"823":1594986619000,"824":1641364157000,"825":1616171510000,"826":1618154034000,"827":1595240367000,"828":1624024708000,"829":1612786740000,"830":1594986935000,"831":1595366190000,"832":1580386769000,"833":1617710868000,"834":1595049310000,"835":1625669415000,"836":1595441632000,"837":1594969447000,"838":1587065655000,"839":1640528812000,"840":1594619047000,"841":1594679256000,"842":1594675605000,"843":1631793524000,"844":1594987106000,"845":1636836294000,"846":1594676483000,"847":1595240511000,"848":1621411718000,"849":1595366830000,"850":1594335889000,"851":1594231845000,"852":1579374501000,"853":1594619114000,"854":1598961179000,"855":1594675859000,"856":1584746171000,"857":1600934958000,"858":1632777704000,"859":1594902750000,"860":1620208672000,"861":1575992929000,"862":1594619171000,"863":1588624006000,"864":1594620205000,"865":1594945370000,"866":1638480082000,"867":1595204519000,"868":1575542718000,"869":1624524180000,"870":1600237167000,"871":1594078339000,"872":1594620026000,"873":1595442484000,"874":1635435041000,"875":1595442557000,"876":1594619830000,"877":1594987364000,"878":1595021676000,"879":1584746643000,"880":1594619817000,"881":1594743541000,"882":1594242758000,"883":1634113309000,"884":1645093191000,"885":1594080749000,"886":1594619749000,"887":1595061433000,"888":1594987668000,"889":1594619719000,"890":1594243191000,"891":1619424461000,"892":1599052523000,"893":1594243353000,"894":1598474900000,"895":1604527152000,"896":1594243432000,"897":1594662034000,"898":1594987914000,"899":1594619374000,"900":1644087651000,"901":1594879748000,"902":1594662295000,"903":1636468816000,"904":1632824796000,"905":1594678468000,"906":1595268909000,"907":1643444366000,"908":1595366895000,"909":1596135984000,"910":1594081775000,"911":1629587179000,"912":1595284458000,"913":1591252862000,"914":1642289546000,"915":1569341352000,"916":1636512455000,"917":1594245513000,"918":1594621360000,"919":1627458818000,"920":1642622017000,"921":1609249597000,"922":1594945438000,"923":1594988083000,"924":1568067323000,"925":1594988426000,"926":1594988519000,"927":1596718973000,"928":1646060079000,"929":1569225945000,"930":1610228067000,"931":1594620688000,"932":1574264905000,"933":1594620661000,"934":1594620650000,"935":1595442765000,"936":1595204566000,"937":1594678524000,"938":1594409947000,"939":1594988643000,"940":1566605984000,"941":1594246132000,"942":1594246244000,"943":1589415431000,"944":1594401860000,"945":1595283090000,"946":1610095134000,"947":1595283122000,"948":1613711422000,"949":1633956289000,"950":1593643551000,"951":1631769974000,"952":1606151370000,"953":1564163474000,"954":1642621983000,"955":1579032449000,"956":1593643822000,"957":1617371630000,"958":1594246562000,"959":1594679012000,"960":1598843950000,"961":1634698866000,"962":1594662434000,"963":1600690998000,"964":1607041373000,"965":1644621666000,"966":1627469493000,"967":1559734155000,"968":1584745518000,"969":1594084846000,"970":1594989104000,"971":1556850302000,"972":1594662461000,"973":1594246589000,"974":1554946169000,"975":1645183914000,"976":1596814987000,"977":1555256076000,"978":1646121306000,"979":1551087990000,"980":1635811592000,"981":1630383150000,"982":1631607196000,"983":1614714822000,"984":1616531212000,"985":1610478095000,"986":1635436921000,"987":1629732512000,"988":1593644116000,"989":1594989408000,"990":1595021848000,"991":1584745272000,"992":1594989462000,"993":1595284034000,"994":1591399656000,"995":1591399365000,"996":1591399242000,"997":1591399052000,"998":1591398762000,"999":1591398434000},"closed_at":{"0":null,"1":null,"2":null,"3":null,"4":null,"5":null,"6":null,"7":null,"8":null,"9":null,"10":null,"11":null,"12":null,"13":null,"14":null,"15":null,"16":null,"17":null,"18":null,"19":null,"20":null,"21":null,"22":null,"23":null,"24":null,"25":null,"26":null,"27":null,"28":null,"29":null,"30":null,"31":null,"32":null,"33":null,"34":null,"35":null,"36":null,"37":null,"38":null,"39":null,"40":null,"41":null,"42":null,"43":null,"44":null,"45":null,"46":null,"47":null,"48":null,"49":null,"50":null,"51":null,"52":null,"53":null,"54":null,"55":null,"56":null,"57":null,"58":null,"59":null,"60":null,"61":null,"62":null,"63":null,"64":null,"65":null,"66":null,"67":null,"68":null,"69":null,"70":null,"71":null,"72":null,"73":null,"74":null,"75":null,"76":null,"77":null,"78":null,"79":null,"80":null,"81":null,"82":null,"83":null,"84":null,"85":null,"86":null,"87":null,"88":null,"89":null,"90":null,"91":null,"92":null,"93":null,"94":null,"95":null,"96":null,"97":null,"98":null,"99":null,"100":null,"101":null,"102":null,"103":null,"104":null,"105":null,"106":null,"107":null,"108":null,"109":null,"110":null,"111":null,"112":null,"113":null,"114":null,"115":null,"116":null,"117":null,"118":null,"119":null,"120":null,"121":null,"122":null,"123":null,"124":null,"125":null,"126":null,"127":null,"128":null,"129":null,"130":null,"131":null,"132":null,"133":null,"134":null,"135":null,"136":null,"137":null,"138":null,"139":null,"140":null,"141":null,"142":null,"143":null,"144":null,"145":null,"146":null,"147":null,"148":null,"149":null,"150":null,"151":null,"152":null,"153":null,"154":null,"155":null,"156":null,"157":null,"158":null,"159":null,"160":null,"161":null,"162":null,"163":null,"164":null,"165":null,"166":null,"167":null,"168":null,"169":null,"170":null,"171":null,"172":null,"173":null,"174":null,"175":null,"176":null,"177":null,"178":null,"179":null,"180":null,"181":null,"182":null,"183":null,"184":null,"185":null,"186":null,"187":null,"188":null,"189":null,"190":null,"191":null,"192":null,"193":null,"194":null,"195":null,"196":null,"197":null,"198":null,"199":null,"200":null,"201":null,"202":null,"203":null,"204":null,"205":null,"206":null,"207":null,"208":null,"209":null,"210":null,"211":null,"212":null,"213":null,"214":null,"215":null,"216":null,"217":null,"218":null,"219":null,"220":null,"221":null,"222":null,"223":null,"224":null,"225":null,"226":null,"227":null,"228":null,"229":null,"230":null,"231":null,"232":null,"233":null,"234":null,"235":null,"236":null,"237":null,"238":null,"239":null,"240":null,"241":null,"242":null,"243":null,"244":null,"245":null,"246":null,"247":null,"248":null,"249":null,"250":null,"251":null,"252":null,"253":null,"254":null,"255":null,"256":null,"257":null,"258":null,"259":null,"260":null,"261":null,"262":null,"263":null,"264":null,"265":null,"266":null,"267":null,"268":null,"269":null,"270":null,"271":null,"272":null,"273":null,"274":null,"275":null,"276":null,"277":null,"278":null,"279":null,"280":null,"281":null,"282":null,"283":null,"284":null,"285":null,"286":null,"287":null,"288":null,"289":null,"290":null,"291":null,"292":null,"293":null,"294":null,"295":null,"296":null,"297":null,"298":null,"299":null,"300":null,"301":null,"302":null,"303":null,"304":null,"305":null,"306":null,"307":null,"308":null,"309":null,"310":null,"311":null,"312":null,"313":null,"314":null,"315":null,"316":null,"317":null,"318":null,"319":null,"320":null,"321":null,"322":null,"323":null,"324":null,"325":null,"326":null,"327":null,"328":null,"329":null,"330":null,"331":null,"332":null,"333":null,"334":null,"335":null,"336":null,"337":null,"338":null,"339":null,"340":null,"341":null,"342":null,"343":null,"344":null,"345":null,"346":null,"347":null,"348":null,"349":null,"350":null,"351":null,"352":null,"353":null,"354":null,"355":null,"356":null,"357":null,"358":null,"359":null,"360":null,"361":null,"362":null,"363":null,"364":null,"365":null,"366":null,"367":null,"368":null,"369":null,"370":null,"371":null,"372":null,"373":null,"374":null,"375":null,"376":null,"377":null,"378":null,"379":null,"380":null,"381":null,"382":null,"383":null,"384":null,"385":null,"386":null,"387":null,"388":null,"389":null,"390":null,"391":null,"392":null,"393":null,"394":null,"395":null,"396":null,"397":null,"398":null,"399":null,"400":null,"401":null,"402":null,"403":null,"404":null,"405":null,"406":null,"407":null,"408":null,"409":null,"410":null,"411":null,"412":null,"413":null,"414":null,"415":null,"416":null,"417":null,"418":null,"419":null,"420":null,"421":null,"422":null,"423":null,"424":null,"425":null,"426":null,"427":null,"428":null,"429":null,"430":null,"431":null,"432":null,"433":null,"434":null,"435":null,"436":null,"437":null,"438":null,"439":null,"440":null,"441":null,"442":null,"443":null,"444":null,"445":null,"446":null,"447":null,"448":null,"449":null,"450":null,"451":null,"452":null,"453":null,"454":null,"455":null,"456":null,"457":null,"458":null,"459":null,"460":null,"461":null,"462":null,"463":null,"464":null,"465":null,"466":null,"467":null,"468":null,"469":null,"470":null,"471":null,"472":null,"473":null,"474":null,"475":null,"476":null,"477":null,"478":null,"479":null,"480":null,"481":null,"482":null,"483":null,"484":null,"485":null,"486":null,"487":null,"488":null,"489":null,"490":null,"491":null,"492":null,"493":null,"494":null,"495":null,"496":null,"497":null,"498":null,"499":null,"500":null,"501":null,"502":null,"503":null,"504":null,"505":null,"506":null,"507":null,"508":null,"509":null,"510":null,"511":null,"512":null,"513":null,"514":null,"515":null,"516":null,"517":null,"518":null,"519":null,"520":null,"521":null,"522":null,"523":null,"524":null,"525":null,"526":null,"527":null,"528":null,"529":null,"530":null,"531":null,"532":null,"533":null,"534":null,"535":null,"536":null,"537":null,"538":null,"539":null,"540":null,"541":null,"542":null,"543":null,"544":null,"545":null,"546":null,"547":null,"548":null,"549":null,"550":null,"551":null,"552":null,"553":null,"554":null,"555":null,"556":null,"557":null,"558":null,"559":null,"560":null,"561":null,"562":null,"563":null,"564":null,"565":null,"566":null,"567":null,"568":null,"569":null,"570":null,"571":null,"572":null,"573":null,"574":null,"575":null,"576":null,"577":null,"578":null,"579":null,"580":null,"581":null,"582":null,"583":null,"584":null,"585":null,"586":null,"587":null,"588":null,"589":null,"590":null,"591":null,"592":null,"593":null,"594":null,"595":null,"596":null,"597":null,"598":null,"599":null,"600":null,"601":null,"602":null,"603":null,"604":null,"605":null,"606":null,"607":null,"608":null,"609":null,"610":null,"611":null,"612":null,"613":null,"614":null,"615":null,"616":null,"617":null,"618":null,"619":null,"620":null,"621":null,"622":null,"623":null,"624":null,"625":null,"626":null,"627":null,"628":null,"629":null,"630":null,"631":null,"632":null,"633":null,"634":null,"635":null,"636":null,"637":null,"638":null,"639":null,"640":null,"641":null,"642":null,"643":null,"644":null,"645":null,"646":null,"647":null,"648":null,"649":null,"650":null,"651":null,"652":null,"653":null,"654":null,"655":null,"656":null,"657":null,"658":null,"659":null,"660":null,"661":null,"662":null,"663":null,"664":null,"665":null,"666":null,"667":null,"668":null,"669":null,"670":null,"671":null,"672":null,"673":null,"674":null,"675":null,"676":null,"677":null,"678":null,"679":null,"680":null,"681":null,"682":null,"683":null,"684":null,"685":null,"686":null,"687":null,"688":null,"689":null,"690":null,"691":null,"692":null,"693":null,"694":null,"695":null,"696":null,"697":null,"698":null,"699":null,"700":null,"701":null,"702":null,"703":null,"704":null,"705":null,"706":null,"707":null,"708":null,"709":null,"710":null,"711":null,"712":null,"713":null,"714":null,"715":null,"716":null,"717":null,"718":null,"719":null,"720":null,"721":null,"722":null,"723":null,"724":null,"725":null,"726":null,"727":null,"728":null,"729":null,"730":null,"731":null,"732":null,"733":null,"734":null,"735":null,"736":null,"737":null,"738":null,"739":null,"740":null,"741":null,"742":null,"743":null,"744":null,"745":null,"746":null,"747":null,"748":null,"749":null,"750":null,"751":null,"752":null,"753":null,"754":null,"755":null,"756":null,"757":null,"758":null,"759":null,"760":null,"761":null,"762":null,"763":null,"764":null,"765":null,"766":null,"767":null,"768":null,"769":null,"770":null,"771":null,"772":null,"773":null,"774":null,"775":null,"776":null,"777":null,"778":null,"779":null,"780":null,"781":null,"782":null,"783":null,"784":null,"785":null,"786":null,"787":null,"788":null,"789":null,"790":null,"791":null,"792":null,"793":null,"794":null,"795":null,"796":null,"797":null,"798":null,"799":null,"800":null,"801":null,"802":null,"803":null,"804":null,"805":null,"806":null,"807":null,"808":null,"809":null,"810":null,"811":null,"812":null,"813":null,"814":null,"815":null,"816":null,"817":null,"818":null,"819":null,"820":null,"821":null,"822":null,"823":null,"824":null,"825":null,"826":null,"827":null,"828":null,"829":null,"830":null,"831":null,"832":null,"833":null,"834":null,"835":null,"836":null,"837":null,"838":null,"839":null,"840":null,"841":null,"842":null,"843":null,"844":null,"845":null,"846":null,"847":null,"848":null,"849":null,"850":null,"851":null,"852":null,"853":null,"854":null,"855":null,"856":null,"857":null,"858":null,"859":null,"860":null,"861":null,"862":null,"863":null,"864":null,"865":null,"866":null,"867":null,"868":null,"869":null,"870":null,"871":null,"872":null,"873":null,"874":null,"875":null,"876":null,"877":null,"878":null,"879":null,"880":null,"881":null,"882":null,"883":null,"884":null,"885":null,"886":null,"887":null,"888":null,"889":null,"890":null,"891":null,"892":null,"893":null,"894":null,"895":null,"896":null,"897":null,"898":null,"899":null,"900":null,"901":null,"902":null,"903":null,"904":null,"905":null,"906":null,"907":null,"908":null,"909":null,"910":null,"911":null,"912":null,"913":null,"914":null,"915":null,"916":null,"917":null,"918":null,"919":null,"920":null,"921":null,"922":null,"923":null,"924":null,"925":null,"926":null,"927":null,"928":null,"929":null,"930":null,"931":null,"932":null,"933":null,"934":null,"935":null,"936":null,"937":null,"938":null,"939":null,"940":null,"941":null,"942":null,"943":null,"944":null,"945":null,"946":null,"947":null,"948":null,"949":null,"950":null,"951":null,"952":null,"953":null,"954":null,"955":null,"956":null,"957":null,"958":null,"959":null,"960":null,"961":null,"962":null,"963":null,"964":null,"965":null,"966":null,"967":null,"968":null,"969":null,"970":null,"971":null,"972":null,"973":null,"974":null,"975":null,"976":null,"977":null,"978":null,"979":null,"980":null,"981":null,"982":null,"983":null,"984":null,"985":null,"986":null,"987":null,"988":null,"989":null,"990":null,"991":null,"992":null,"993":null,"994":null,"995":null,"996":null,"997":null,"998":null,"999":null},"body":{"0":"Signed-off-by: Weichen Xu <weichen.xu@databricks.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nImprove infer model type method for default evaluator.\r\n\r\n## How is this patch tested?\r\n\r\nUT.\r\n\r\n## Does this PR change the documentation?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Make sure the changed pages \/ sections render correctly by following the steps below.\r\n\r\n1. Check the status of the `ci\/circleci: build_doc` check. If it's successful, proceed to the\r\n   next step, otherwise fix it.\r\n2. Click `Details` on the right to open the job page of CircleCI.\r\n3. Click the `Artifacts` tab.\r\n4. Click `docs\/build\/html\/index.html`.\r\n5. Find the changed pages \/ sections and make sure they render correctly.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","1":"Signed-off-by: dbczumar <corey.zumar@databricks.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\n(Please fill in changes proposed in this fix)\r\n\r\n## How is this patch tested?\r\n\r\n(Details)\r\n\r\n## Does this PR change the documentation?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Make sure the changed pages \/ sections render correctly by following the steps below.\r\n\r\n1. Check the status of the `ci\/circleci: build_doc` check. If it's successful, proceed to the\r\n   next step, otherwise fix it.\r\n2. Click `Details` on the right to open the job page of CircleCI.\r\n3. Click the `Artifacts` tab.\r\n4. Click `docs\/build\/html\/index.html`.\r\n5. Find the changed pages \/ sections and make sure they render correctly.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","2":"Signed-off-by: harupy <17039389+harupy@users.noreply.github.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\n- Fixes https:\/\/github.com\/mlflow\/mlflow\/issues\/3785\r\n- Create index on `run_uuid` columns for PostgreSQL to improve SQL operations.\r\n\r\n## How is this patch tested?\r\n\r\nThank you @mberr for investigating the impact of creating an index: https:\/\/github.com\/mlflow\/mlflow\/issues\/3785#issuecomment-1057075533\r\n\r\n## Does this PR change the documentation?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Make sure the changed pages \/ sections render correctly by following the steps below.\r\n\r\n1. Check the status of the `ci\/circleci: build_doc` check. If it's successful, proceed to the\r\n   next step, otherwise fix it.\r\n2. Click `Details` on the right to open the job page of CircleCI.\r\n3. Click the `Artifacts` tab.\r\n4. Click `docs\/build\/html\/index.html`.\r\n5. Find the changed pages \/ sections and make sure they render correctly.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [x] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","3":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**:\r\n- **Python version**:\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","4":"Add ENV variables to control GCS upload\/download chunk size and timeouts\r\n(fixes GCS timeouts for uploads\/downloads with slow transfer speeds -> more info #3478 )\r\n\r\nPartial fix to https:\/\/github.com\/mlflow\/mlflow\/issues\/3478\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nAdd ENV variables to control GCS upload\/download chunk size and timeouts. Implementation details are open for discussion.\r\n\r\n## How is this patch tested?\r\n\r\nNot yet. \r\n\r\n## Does this PR change the documentation?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Make sure the changed pages \/ sections render correctly by following the steps below.\r\n\r\n1. Check the status of the `ci\/circleci: build_doc` check. If it's successful, proceed to the\r\n   next step, otherwise fix it.\r\n2. Click `Details` on the right to open the job page of CircleCI.\r\n3. Click the `Artifacts` tab.\r\n4. Click `docs\/build\/html\/index.html`.\r\n5. Find the changed pages \/ sections and make sure they render correctly.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nEnvironment variables MLFLOW_GCS_DEFAULT_TIMEOUT, MLFLOW_GCS_UPLOAD_CHUNK_SIZE, MLFLOW_GCS_DOWNLOAD_CHUNK_SIZE added to control GCS artifact storage\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [x] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes","5":"Signed-off-by: Weichen Xu <weichen.xu@databricks.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nPrototype restoring model dependencies for `pyfunc.load_model` and `pyfunc.spark_udf`\r\n\r\n## How is this patch tested?\r\n\r\nManually.\r\n\r\n(1) Log a model first:\r\n```\r\nimport mlflow\r\nfrom sklearn.linear_model import LogisticRegression\r\nfrom sklearn.datasets import make_classification\r\nimport sklearn.metrics\r\n\r\nX, y = make_classification(n_samples=100, n_classes=3, n_informative=3, random_state=1)\r\n\r\n\"\"\"\r\nmlflow.sklearn.autolog()\r\n\r\nwith mlflow.start_run() as run:\r\n    model = LogisticRegression(\r\n        solver='liblinear',\r\n        max_iter=1,\r\n        C=0.5,\r\n    ).fit(X, y)\r\n\r\nprint(run.info.run_id)\r\n```\r\n\r\n(2): load model with `restore_python_env` set to be `True`\r\n\r\n```\r\nimport mlflow\r\nfrom sklearn.linear_model import LogisticRegression\r\nfrom sklearn.datasets import make_classification\r\nimport sklearn.metrics\r\n\r\nX, y = make_classification(n_samples=100, n_classes=3, n_informative=3, random_state=1)\r\n\r\nm = mlflow.pyfunc.load_model(\r\n    'runs:\/{run_id}\/model',  # sklearn model, sklearn version 1.0.2\r\n    restore_python_env=True,\r\n)\r\nprint(type(m))\r\n\r\ny_pred = m.predict(X)\r\n\r\nprint(f\"precision={sklearn.metrics.precision_score(y, y_pred, average='micro')}\")\r\n```\r\n\r\n## Does this PR change the documentation?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Make sure the changed pages \/ sections render correctly by following the steps below.\r\n\r\n1. Check the status of the `ci\/circleci: build_doc` check. If it's successful, proceed to the\r\n   next step, otherwise fix it.\r\n2. Click `Details` on the right to open the job page of CircleCI.\r\n3. Click the `Artifacts` tab.\r\n4. Click `docs\/build\/html\/index.html`.\r\n5. Find the changed pages \/ sections and make sure they render correctly.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","6":"Hi,\r\n\r\nI am working on an object detection project that uses Yolov5 with weights.pt format.  We can't store the weights locally, so I came up with a solution with mlflow that downloads the weights from an experiment run in mlflow based on tags we created. I know this isn't the intented way to use mlflow, and I should be registering the model and placing this into the model registry.\r\n\r\nWhen making predictions we run the following line from the cli.\r\n\r\n`python detect.py --weights path_to_weights --source path_to_image`\r\n\r\nIn production, this application could be containerized with docker and orchestrated with kubernetes.\r\n\r\nCan anyone suggest the best way to register the weights.pt to mlflow and download them from mlflow?\r\n\r\n","7":"CloudPickle officially states: \"Using cloudpickle for long-term object storage is not supported and strongly discouraged.\"\r\n\r\nFixes https:\/\/github.com\/mlflow\/mlflow\/issues\/5419\r\nFixes https:\/\/github.com\/mlflow\/mlflow\/issues\/5420\r\n\r\nSigned-off-by: Alexey Volkov <alexey.volkov@ark-kun.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\n(Please fill in changes proposed in this fix)\r\n\r\n## How is this patch tested?\r\n\r\n(Details)\r\n\r\n## Does this PR change the documentation?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Make sure the changed pages \/ sections render correctly by following the steps below.\r\n\r\n1. Check the status of the `ci\/circleci: build_doc` check. If it's successful, proceed to the\r\n   next step, otherwise fix it.\r\n2. Click `Details` on the right to open the job page of CircleCI.\r\n3. Click the `Artifacts` tab.\r\n4. Click `docs\/build\/html\/index.html`.\r\n5. Find the changed pages \/ sections and make sure they render correctly.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","8":"Current Artifact support preview HTML and image,\r\nBut \"Html\" seem no support load image in Artifact, ex:\r\n<img src=\"image_in_artifacts.png\"\/>\r\n\r\nCan we support it?","9":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [x] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: `No`\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: `Linux Ubuntu 20.04 LTS`\r\n- **MLflow installed from (source or binary)**: `No`\r\n- **MLflow version (run ``mlflow --version``)**: `1.23.1`\r\n- **Python version**: `3.8.12`\r\n- **npm version, if running the dev UI**: `NA`\r\n- **Exact command to reproduce**: `mlflow models serve -m \"models:\/....\"`\r\n\r\n### Describe the problem\r\nWhen building an fastai model that returns multiple classes probabilities, you can successfully train and log the model using `mlflow.fastai` API. To run the given model, you can successfully use:\r\n\r\n`mlflow.fastai.load_model(....)`\r\n\r\nHowever, when using the flavor `pyfunc` or when serving the model (`mlflow models serve` uses the `pyfunc` flavor), if the model returns multiple probabilities (for instance 2), it results in the following exception being raised:\r\n\r\n`ValueError: 1 columns passed, passed data had 2 columns.`\r\n\r\nThis seems to be related with the implementation of `_FastaiModelWrapper`, which expects the model to return one single column of data:\r\n\r\n```python\r\nclass _FastaiModelWrapper:\r\n    def __init__(self, learner):\r\n        self.learner = learner\r\n\r\n    def predict(self, dataframe):\r\n        dl = self.learner.dls.test_dl(dataframe)\r\n        preds, _ = self.learner.get_preds(dl=dl)\r\n        return pd.DataFrame(map(np.array, preds.numpy()), columns=[\"predictions\"])\r\n```\r\n\r\nSince `pd.DataFrame` will iterate over the data structure, if the model returns multiple predictions (for instance, the probabilities of each class), then the number of columns won't match the shape of the data.\r\n\r\nOne way to avoid `pd.DataFrame` to parse the internal returned structure from the model is to construct a `pd.Series` instead of a `pd.DataFrame`, and then convert it to a `pd.DataFrame`. I propose to introduce the following change:\r\n\r\n```python\r\n    def predict(self, dataframe):\r\n        dl = self.learner.dls.test_dl(dataframe)\r\n        preds, _ = self.learner.get_preds(dl=dl)\r\n        return pd.Series(map(np.array, preds.numpy())).to_frame(\"predictions\")\r\n```\r\n\r\n### Code to reproduce issue\r\nThe following model will throw the error:\r\n\r\n```python\r\nimport mlflow\r\nimport torch\r\nimport fastai\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom fastai.vision.core import load_image\r\n\r\nfrom fastai.vision.all import *\r\nfrom fastai.vision.data import ImageDataLoaders\r\n\r\npath = untar_data(URLs.DOGS, dest=\"\/tmp\/.fastai\") #fastai==2.4.1\r\nimage_files = get_image_files(path)\r\n\r\n## Loading the dataset\r\ndata_loader= ImageDataLoaders.from_folder(path, item_tfms=Resize(224), batch_tfms=Normalize.from_stats(*imagenet_stats))\r\n\r\n## Building the model\r\nlearn = cnn_learner(data_loader, models.resnet34, metrics=accuracy)\r\nlearn.fine_tune(1, 0.6e-3)\r\n\r\n## Try the model\r\nsample_img = load_image(image_files[1])\r\ndl_model = learn.dls.test_dl([np.array(sample_img)])\r\nreal_preds, _ = learn.get_preds(dl=dl_model)\r\n\r\n## Log the model\r\nfrom mlflow.models.signature import infer_signature\r\n\r\nsignature = infer_signature(np.array(sample_img), real_preds.detach().numpy())\r\nmlflow.fastai.log_model(learn, \"model\", signature=signature, registered_model_name=\"cats_vs_dogs\")\r\n\r\n## Load the model using pyfunc\r\nmlflow.pyfunc.load_model(\"models:\/cats_vs_dogs\/1\")\r\nmiflow.pyfunc.predict(np.array(sample_img))\r\n```\r\n\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","10":"Signed-off-by: Mark Zhang <mark.zhang@databricks.com>\r\n\r\n## Note\r\nUpdates to examples and further documentations will be done in a separate PR due to the size of this PR. \r\n\r\n## A notable implementation detail:\r\nWhen a user's custom metric function produces an artifact file and pass its local path, for example `\/some\/dir\/image.csv` with the artifact name `someplot` for a dataset `example_dataset`. The behavior described in this PR is to log the artifact with the following file name on an artifact repository:\r\n```\r\nsomeplot_on_data_example_dataset.csv\r\n``` \r\nThis is the convention followed by all of the internally generated artifacts (from DefaultEvaluator). An implementation detail to note is that we first make a copy of the artifact file supplied by the user and save it to a temporary directory. Then, we rename the copy of that artifact to the defined format:\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/2c0d13db6c677f1023a9a2a1776aca9e32aebe3d\/mlflow\/models\/evaluation\/default_evaluator.py#L77\r\nFinally, we upload the copy through `mlflow.log_artifact`. Although it is possible to directly upload to the repository from the user provided artifact file by modifying the implementation of `log_artifact` for every artifact repository. But I think that requires an unnecessary amount of changes. Let me know if there are better ways of handling this. Thanks!\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nAdded function for custom metrics to support auto detection and loading of user produced artifacts.\r\n\r\n## How is this patch tested?\r\n\r\nWrote many unit tests in mlflow\/tests\/models\/test_default_evaluator.py\r\n\r\n## Does this PR change the documentation?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Make sure the changed pages \/ sections render correctly by following the steps below.\r\n\r\n1. Check the status of the `ci\/circleci: build_doc` check. If it's successful, proceed to the\r\n   next step, otherwise fix it.\r\n2. Click `Details` on the right to open the job page of CircleCI.\r\n3. Click the `Artifacts` tab.\r\n4. Click `docs\/build\/html\/index.html`.\r\n5. Find the changed pages \/ sections and make sure they render correctly.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nThis PR extends the custom metrics support first introduced in https:\/\/github.com\/mlflow\/mlflow\/pull\/5389 by enabling the ability to detect and load artifacts produced by user's custom metric functions. Note that a follow up PR is required to expose this functionality to the API.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n\r\n\r\nTagging: @apurva-koti @dbczumar @jinzhang21 @WeichenXu123.","11":"## Willingness to contribute\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nUser Interface (`mlflow ui`)  displaying multiple plots instead of just one.\r\n\r\n## Motivation\r\n\r\nCurrently the Tracking UI seems to allow 1 plot only.\r\nMultiple metrics can be plotted there, but in cases where metrics are on very different scales (e.g. different losses, learning rate, accuracy, etc.) the visualization is poor.\r\n\r\nSwitching being different metrics of interest, back-and-forth, manually, is not very user friendly.\r\n\r\nAllowing multiple plots would improve the experiment tracking immensely.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n","12":"Signed-off-by: Liang Zhang <liang.zhang@databricks.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\n(Please fill in changes proposed in this fix)\r\n\r\n## How is this patch tested?\r\n\r\n(Details)\r\n\r\n## Does this PR change the documentation?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Make sure the changed pages \/ sections render correctly by following the steps below.\r\n\r\n1. Check the status of the `ci\/circleci: build_doc` check. If it's successful, proceed to the\r\n   next step, otherwise fix it.\r\n2. Click `Details` on the right to open the job page of CircleCI.\r\n3. Click the `Artifacts` tab.\r\n4. Click `docs\/build\/html\/index.html`.\r\n5. Find the changed pages \/ sections and make sure they render correctly.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","13":"Can we integrate vertex AI with mlflow ? If yes, how ? ","14":"Hello,\r\nI am currently trying to develop a solution for registry of the MLmodels. Already had a tracking server running in a filebased tracking system and wanted to get the registry going aswell, so trying to use a mysql db. \r\nThe question is: is there a way to maintain the tracking of the experiments on both servers? (save the mlflow entities on both file:\/\/ and mysql:\/\/ servers, so that if the DB goes down, the user can continue it's experiments\/tracking on the file based, without any historic info lost).\r\nFrom what I tried, i'm only being able to track on the DB server or on the filebased server. ","15":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ X] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nTo be able to download time-series of metrics logged to mlflow as a csv. Whatever data can be visualized on the line plot in the mlflow experiment tracker Metrics pane will able to be download as csv for more detailed analysis or visualization. \r\n- Why is this use case valuable to support for MLflow users in general?\r\nMetrics time series can be very useful for model selection and diagnosis. By viewing the time-corrected covariation between metrics, it will allow users to gain further insight into the model. Additionally, having a csv allows users flexibility to visualize and analyze these valuable metrics in whichever method they choose.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nGaining further insight into the model selection process. Additionally to help understand what metrics may be redundant or misleading.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nThe data is already stored somewhere in mlflow, but it is just not easily accessible to the user.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [X ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n\r\nJust make whatever data is used to create existing visualization available to the user for download. I think it would be a very small adjustment. ","16":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nFor cases where POST request latency is not the case or a custom inference logic is implemented, the default timeout (60s) of scoring server is not sufficient and a client asking for a response will lead to the following errors.\r\n```\r\nProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\r\nConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\r\n```\r\n\r\n## Motivation\r\n- What is the use case for this feature? Timeout is hardcoded in scoring server. [link to code](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/pyfunc\/scoring_server\/__init__.py#L358)\r\n- Why is this use case valuable to support for MLflow users in general? We would probably wish to set a timeout for the scoring server\r\n- Why is this use case valuable to support for your project(s) or organization? We have implemented a pyfunc model with custom inference logic and stateful model serving architecture. For applications where latency is not the case, it would be nice to opt for the desired scoring server timeout.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient) It's not implemented, though we have kept a fork MLFlow version and set a timeout argument to handle this case \r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nWe can probably \r\n1. create a new `--timeout` argument in `models serve` [command](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/models\/cli.py#L35)\r\n2. remove the hardcoded timeout and create a new parser for timeout argument in scoring server [init](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/pyfunc\/scoring_server\/__init__.py#L358)","17":"Signed-off-by: harupy <17039389+harupy@users.noreply.github.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nvirtualenv prototype\r\n\r\n## How is this patch tested?\r\n\r\n(Details)\r\n\r\n## Does this PR change the documentation?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Make sure the changed pages \/ sections render correctly by following the steps below.\r\n\r\n1. Check the status of the `ci\/circleci: build_doc` check. If it's successful, proceed to the\r\n   next step, otherwise fix it.\r\n2. Click `Details` on the right to open the job page of CircleCI.\r\n3. Click the `Artifacts` tab.\r\n4. Click `docs\/build\/html\/index.html`.\r\n5. Find the changed pages \/ sections and make sure they render correctly.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","18":"## What changes are proposed in this pull request?\r\n\r\n(Please fill in changes proposed in this fix)\r\n\r\n## How is this patch tested?\r\n\r\n(Details)\r\n\r\n## Does this PR change the documentation?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Make sure the changed pages \/ sections render correctly by following the steps below.\r\n\r\n1. Check the status of the `ci\/circleci: build_doc` check. If it's successful, proceed to the\r\n   next step, otherwise fix it.\r\n2. Click `Details` on the right to open the job page of CircleCI.\r\n3. Click the `Artifacts` tab.\r\n4. Click `docs\/build\/html\/index.html`.\r\n5. Find the changed pages \/ sections and make sure they render correctly.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","19":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nI apologise in advance as I am probably just using MLFlow wrong, so please educate me if there are better ways of achieving my goal :)\r\n\r\nMy goal is to register a Model with both Schema and custom Tags.\r\n\r\nI have been using `create_model_version` using the example from [here](https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.tracking.html#mlflow.tracking.MlflowClient.create_model_version). The problem is I do not get the Schema even though I set signature in `mlflow.sklearn.log_model`.\r\n\r\nI am able to get the Schema set when I register the model using `mlflow.sklearn.log_model` by setting `registered_model_name`, however then I cannot find an elegant way of setting the tags.\r\nWhen running log_model it prints the resulting version number, but it does not return it in the modelInfo object, so I cannot find an elegant solution to how to set the tags afterwards using `set_model_version_tag`, I currently use `get_registered_model` and just assume the latest is the one I just registered.\r\n\r\nIf this is just not me using MLFlow wrong I believe this can be solved in two ways:\r\n- tags added as a parameter to all log_model functions\r\n- registered_model_version returned as part of ModelInfo when setting `registered_model_name` in `log_model`\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nAbility to elegantly both set both Schema and tags on a registered model\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","20":"### Willingness to contribute\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [X] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Microsoft Windows 10 Home Version 21H2\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.23.1\r\n- **Python version**: 3.9.4\r\n- **npm version, if running the dev UI**: N\/A\r\n- **Exact command to reproduce**: see below\r\n\r\n### Describe the problem\r\nCalling mlflow.sklearn.log_model function raises `TypeError: expected string or bytes-like object`.\r\n\r\n### Code to reproduce issue\r\n```\r\nimport mlflow\r\nmlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\r\nmlflow.set_experiment(MLFLOW_EXPERIMENT)\r\nfrom sklearn.datasets import load_iris\r\nfrom sklearn import tree\r\niris = load_iris()\r\nsk_model = tree.DecisionTreeClassifier()\r\nsk_model = sk_model.fit(iris.data, iris.target)\r\nmlflow.sklearn.log_model(sk_model, str(\"sk_models\"))\r\n```\r\n\r\n### Other info \/ logs\r\nThis seems to be due to `importlib_metadata.version` function, which tries to get the installed version of scikit-learn, but it returns None. I have installed scikit-learn 1.0.2 through `pip install scikit-learn`, and the following code correctly prints 1.0.2:\r\n```\r\nimport sklearn\r\nprint(sklearn.__version__)\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [X] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","21":"## What changes are proposed in this pull request?\r\n\r\nWhen running on Kubernetes, the environment variables provided in the MLproject file are not taken into account.\r\n\r\n```\r\ndocker_env:\r\n  image: mlflow-docker-example-environment\r\n  environment: [[\"NEW_ENV_VAR\", \"new_var_value\"], \"VAR_TO_COPY_FROM_HOST_ENVIRONMENT\"]\r\n```\r\n\r\nfrom: https:\/\/www.mlflow.org\/docs\/latest\/projects.html#specifying-an-environment\r\n\r\n## How is this patch tested?\r\n\r\nManually.\r\n\r\n## Does this PR change the documentation?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Make sure the changed pages \/ sections render correctly by following the steps below.\r\n\r\n1. Check the status of the `ci\/circleci: build_doc` check. If it's successful, proceed to the\r\n   next step, otherwise fix it.\r\n2. Click `Details` on the right to open the job page of CircleCI.\r\n3. Click the `Artifacts` tab.\r\n4. Click `docs\/build\/html\/index.html`.\r\n5. Find the changed pages \/ sections and make sure they render correctly.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nInject the environment variables provided in the MLproject into the Docker image when running on Kubernetes\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [x] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","22":"- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Microsoft Windows 10 Version 20H2\r\n- **MLflow installed from (source or binary)**: pip\r\n- **MLflow version (run ``mlflow --version``)**: 1.22.0\r\n- **Python version**: 3.8.5\r\n- **npm version, if running the dev UI**: 7.11.0\r\n- **Exact command to reproduce**: \"mlflow ui\" -> navigate to an experiment with over 100 run results\r\n\r\n### Describe the problem\r\nMLFlow UI only displays 100 run results for 100+ run experiments. Clicking \"Load more\" in the UI loads additional runs. However, those additional runs immediately disappear as soon as you try to sort by a column in the table, thus defeating the point of loading more results into the table. \r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [x] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","23":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [X] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\nNo\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n[ Python 3.9 Dockerimage](https:\/\/hub.docker.com\/layers\/python\/library\/python\/3.9\/images\/sha256-cffe05d2e4135f5893fa96754fd672d314ae48b160e072f9c4d42843daeedfc4?context=explore)\r\n- **MLflow installed from (source or binary)**:\r\nPip\r\n- **MLflow version (run ``mlflow --version``)**:\r\n1.22.0\r\n- **Python version**:\r\n3.9\r\n- **npm version, if running the dev UI**:\r\n\/\r\n- **Exact command to reproduce**:\r\nDownload a scatter plot\r\n\r\n### Describe the problem\r\nWhen I compare multiple runs in the tracking UI and create a scatter plot, it displays correctly. Then when I download the chart, the data points are missing from the chart.\r\n\r\n### Code to reproduce issue\r\n\/\r\n\r\n### Other info \/ logs\r\nI got a ``Failed to load resource`` error in the console in Safari's development tools when I pressed the plot's download button. A base64 data string (probably from the plot) is also displayed. \r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","24":"I am using `mlflow version 1.22.0.` \r\nHow can I pass namespace to mlflow experiment in PAZ notebook such that I can see experiment from ai platform.\r\nCurrently I am using this: \r\n\r\n```\r\nimport os\r\nimport mlflow\r\nos.environ['GIT_PYTHON_REFRESH']='quiet'\r\nmlflow.set_tracking_uri(os.environ['MLFLOW_TRACKING_URL'])\r\nprint(os.environ['MLFLOW_TRACKING_URL'])\r\nexperiment_id = mlflow.create_experiment(\"Experiment\")\r\nexperiment = mlflow.get_experiment(experiment_id)\r\nprint(\"Name: {}\".format(experiment.name))\r\nprint(\"Experiment_id: {}\".format(experiment.experiment_id))\r\nprint(\"Artifact Location: {}\".format(experiment.artifact_location))\r\nprint(\"Tags: {}\".format(experiment.tags))\r\nprint(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\r\nmlflow.set_experiment('Experiment')\r\n```\r\n\r\nBut I want to tag it to to user namespace something like: \r\n\r\n`mlflow.set_experiment('Experiment',os.environ['USER'])`\r\n\r\n`Error: MlflowException: Must specify exactly one of: `experiment_id` or `experiment_name`.`\r\n\r\n**I want to use same version of mlflow. Is there another way to tag USER?**\r\n\r\nAlso in MLFLOW UI, I see blank `Run Name`, `Version`, `Models`. How to se these values for different runs?\r\n\r\nI want to do something like `mlflow.run_name('RUN1')`, `mlflow.Models('Model1')`\r\n\r\nI am not using `mlflow.start(...)` as hugging face automatically  tracks it.\r\n\r\n\r\n\r\n\r\n\r\n","25":"\r\n![image](https:\/\/user-images.githubusercontent.com\/27057946\/152803441-cdb73a60-2603-4686-91df-ceb99633727f.png)\r\n\r\n\r\nWhen a run name is quite long it is impossible to see it even from page sources. ","26":"I have 2 keras model store locally, so i registerd both of them as 1 combined model. I am able to register the model into AML workspace as well as creating a endpoint by simply specifying my score.py to call both model to return one results. \r\nCalling it as an endpoint works perfectly fine\r\n\r\nHowever for retraining purpose, i want to load the model from mdoel registery but hit multiple issue.\r\nModel Name : Neural-model\r\nVersion: 3\r\nrun_id : xxxx\r\nFolder path for model 1: \/model\/type\/\r\nFolder path for model 2: \/model\/classification\/\r\n\r\n\r\n**I tried:**\r\n\r\nrun_id='xxxx'\r\nrun=\"runs:\/{}\".format(run_id)\r\nkeras_model = mlflow.keras.load_model(run + \"\/model\/type\/\/\")\r\n\r\nError:\r\nMlflowException: Could not find an \"MLmodel\" configuration file at \"\/tmp\/tmpv9jiqje9\/model\/type\/\"\r\n\r\n**i tried using model URI as well:**\r\n\r\n#model_uri='models:\/Neural-model\/3'\r\nclassifier_model = mlflow.keras.load_model(model_uri=model_uri,compile=False)\r\n\r\nError:\r\n\r\nRestException: BAD_REQUEST: Response: {'Error': {'Code': 'UserError', 'Severity': None, 'Message': 'Model source model must be a directory containing an mlflow MLmodel.', 'MessageFormat': None, 'MessageParameters': None, 'ReferenceCode': None, 'DetailsUri': None, 'Target': None, 'Details': [], 'InnerError': None, 'DebugInfo': None, 'AdditionalInfo': None}, 'Correlation': {'operation': '481ee7c36a8d5b44a4114a4cc9de7cf3', 'request': 'f7a15b107e89454e'}, 'Environment': 'southeastasia', 'Location': 'southeastasia', 'Time': '2022-02-04T02:33:51.0933512+00:00', 'ComponentName': 'mlflow', 'error_code': 'BAD_REQUEST'}\r\n\r\n\r\nThe first method cannot find my model while the second cannot point to the model i want that is registerd.\r\nAny idea how to overcome multiple model deployment issue?\r\n\r\n","27":"WIP. Opening this PR to refer back to in #5208 \r\n\r\n## What changes are proposed in this pull request?\r\n\r\nThis PR is a first pass at adding JSON validation against a predetermined schema, in an effort to make error handling more friendly for users. The end goal is to return `HTTP 400` for bad parameters instead of `500`, which happens currently (at least for most endpoints)\r\n\r\n## How is this patch tested?\r\n\r\nWIP -- Not tested yet. What is the best way to test changes like this?\r\n\r\n## Does this PR change the documentation?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Make sure the changed pages \/ sections render correctly by following the steps below.\r\n\r\n1. Check the status of the `ci\/circleci: build_doc` check. If it's successful, proceed to the\r\n   next step, otherwise fix it.\r\n2. Click `Details` on the right to open the job page of CircleCI.\r\n3. Click the `Artifacts` tab.\r\n4. Click `docs\/build\/html\/index.html`.\r\n5. Find the changed pages \/ sections and make sure they render correctly.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [x] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","28":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [X] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n`CreateExperiments` permits attaching tags to an experiment.  But I can't find a way to filter experiments using those tags:\r\n- `ListExperiments` has no parameters for filtering\r\n- there isn't a `SearchExperiments` endpoint\r\n\r\n## Motivation\r\n- What is the use case for this feature?  I want to be able to organize experiments from different users and organizations.  Tags are often promising, but without a way to retrieve experiments based on tags, I don't see a way to use them.\r\n- Why is this use case valuable to support for MLflow users in general?  I'm probably not the only person who'd like to enable different users and organizations to be able to filter the experiments.\r\n- Why is this use case valuable to support for your project(s) or organization?  Different users may share the same MLflow installation, and want to look at their own experiments.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient) Not sure how to answer this: it's not implemented, so it's hard to do :)  Client side filtering of the API responses is possible so long as the number of experiments and users are small.  But as those grow over time, I expect it to be unwieldy and slow.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [X] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nCurrently, I'm focused only on the API - there's some new UI possibility here, but I'm going to ignore those issues for now.\r\n\r\nTwo approaches occur to me.\r\n\r\n### `SearchExperiments`\r\n\r\n`SearchExperiments` could be added, by analogy with e.g. `SearchRuns`.  This would involve implementing the search functionality at [1] for experiments.  This way, experiment search has a similar developer experience to other search endpoints.\r\n\r\nThis would allow callers to get a filtered list by tag using an expression like: `tags.<key> = <value>`.  Since the search syntax already supports boolean combinations, it'd be easy to implement a filtered view of experiments.\r\n\r\nPros:\r\n- suffices for my use-case\r\n- extends existing search features\r\n- the `Search...` endpoints use `POST`, so no encoding is needed\r\n\r\nCons:\r\n- more powerful than I need\r\n- some preferences exist against this design, e.g. [2]\r\n\r\n### `ListExperiments`\r\n\r\n`ListExperiments` could be extended with a `tags` parameter that accepts a (default empty) list of key-value pairs.  Those pair would *all* be applied as filters on the sqlalchemy query.\r\n\r\nThis would allow callers to get a filtered list by using an argument like `[<key>=<value>]`.  Since filtering by multiple tags is often useful, this should be a list so no expression parsing is required.  Each key-value pair would translate to a sqlalchemy filter on the underlying query.\r\n\r\nPros:\r\n- suffices for my use-case\r\n- simpler interface and probably implementation\r\n- searching by tag conjunction is a common paradigm\r\n\r\nCons:\r\n- `ListExpressions` uses GET, so the key value pairs need to be url-encoded\r\n- different developer experience when filtering experiments vs e.g. runs\r\n\r\n\r\n[1] - https:\/\/mlflow.org\/docs\/latest\/search-syntax.html\r\n[2] - https:\/\/github.com\/mlflow\/mlflow\/pull\/3881#issuecomment-754053632\r\n","29":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\n\r\n- [x] Yes. I can contribute a fix for this bug independently.\r\n\r\n### System information\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.22.0\r\n\r\n### Describe the problem\r\n\r\nWhen searching for runs using the `search_runs` API:\r\n\r\n```\r\nmlflow.search_runs([experiment_id], order_by=[\"metrics.m DESC\"])\r\n```\r\n\r\nThe given metric name in the `order_by` clause is not validated in any way. If it starts with `metrics.` and is properly quoted then using a non-existing metric name will happily return the list sorted by the default ordering (date).\r\n\r\n### Code to reproduce issue\r\n\r\n```\r\nmlflow.search_runs([experiment_id], order_by=[\"metrics.this_is_an_invalid_metric DESC\"])\r\n```\r\n\r\n### Other info \/ logs\r\n\r\nThese seem to be the only places where the search clauses are validated and the current code only checks the syntax of clauses about `metrics`:\r\n\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/HEAD\/mlflow\/utils\/search_utils.py#L153-L170\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/HEAD\/mlflow\/utils\/search_utils.py#L461-L480\r\n\r\nIf testing the available metrics is difficult then maybe it's worth validating the results to make sure the at least one of the returned rows has a metric with the given name.\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [x] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry","30":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nCurrently, the required entry script for deployment of models onto the `azureml` ecosystem from `mlflow` is hardwired as a text string, and configurable using the `mlflow.pyfunc` functions for each model flavour. However, the current function to decoding JSON input data only supports Schema types associated with Pandas Dataframe tabular data, and does not for example, support the use **TFServing type tensor structures** which are important for image based applications.\r\n\r\nThe current string which is hard coded into the `mlflow.azureml.__init__.py` file is as follows:\r\n\r\n```python\r\nimport pandas as pd\r\nfrom azureml.core.model import Model\r\nfrom mlflow.pyfunc import load_model\r\nfrom mlflow.pyfunc.scoring_server import parse_json_input, _get_jsonable_obj\r\n\r\ndef init():\r\n    global model\r\n    model_path = Model.get_model_path(model_name=\"{model_name}\", version={model_version})\r\n    model = load_model(model_path)\r\n\r\ndef run(json_input):\r\n    input_df = parse_json_input(json_input=json_input, orient=\"split\")\r\n    return _get_jsonable_obj(model.predict(input_df), pandas_orient=\"records\")\r\n```\r\n\r\nThe [`parse_json_input`](https:\/\/github.com\/mlflow\/mlflow\/blob\/1335164d20a6521dd4ebfe3f361d19fe9672efcf\/mlflow\/pyfunc\/scoring_server\/__init__.py#L116) function, which comes form the module `mlflow.pyfunc.scoring_server`, has only the ability to handle Pandas Dataframe tabular data, and thus does not convert input JSON content to tensor (numpy ndarray) type objects. It doesn't support the TFServing tensor format, which would allow for decoding of these types of structures.\r\n\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n\r\nA simple extension of a use case here is the ability to tensor type inputs as defined by the Tensorspec Schema type, and support the deserialization of numpy ndarrays, such as images. This opens up the potential for any type of application which uses ndarray objects as inputs, such as CNN applications.\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\n\r\nIt broadens the scope of the types of models that can be deployed on AzureML using the model agnostic infrastructure developed through the `mlflow.pyfunc` flavours.\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n\r\nPotential for many different types of models, not just Pandas dataframe tabular based data structures as input.\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nThe current implementation of the entry script is defined as a hard coded string in the `mlflow.azureml` module and cannot be overwritten or modified by any functional call. Therefore, the limitations of what data types can be deserialized by the JSON deserialization function used cannot be circumvented without changes to the said the module.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [x] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n\r\nOne potential solution to the problem is to use existing functionality that has been developed for other deployment types in the `mlflow` package. A number of JSON deserialization functions are contained within the `mlflow.pyfunc.scoring_serving` module which do have the ability to decode TFServing type tensor formats, and convert these to numpy ndarrays from the specified `mlflow.types.Schema`.\r\n\r\nIf an input of a numpy ndarray representing an image (e.g. shape of `image` is `(3,800,600)` array) is encapsulated and serialized in the following way (using the TFServing definintion):\r\n\r\n```python\r\npayload = {\r\n            'instances' : [\r\n                image.tolist()\r\n                ]\r\n        }\r\npayload = str.encode(json.dumps(payload)))\r\n```\r\n\r\nThen using the `mlflow.pyfunc.scoring_server` module function [`infer_and_parse_json_input()`](https:\/\/github.com\/mlflow\/mlflow\/blob\/1335164d20a6521dd4ebfe3f361d19fe9672efcf\/mlflow\/pyfunc\/scoring_server\/__init__.py#L76) in the entry script does result in successful decoding of the above JSON serialized numpy ndarray back to the correct sized object, which can then be passed to loaded model function for inference.\r\n\r\nA notional modification to the entry script could potentially be as simple as:\r\n\r\n```python\r\nimport pandas as pd\r\nfrom azureml.core.model import Model\r\nfrom mlflow.pyfunc import load_model\r\nfrom mlflow.pyfunc.scoring_server import infer_and_parse_json_input, _get_jsonable_obj\r\n\r\ndef init():\r\n    global model\r\n    model_path = Model.get_model_path(model_name=\"{model_name}\", version={model_version})\r\n    model = load_model(model_path)\r\n\r\ndef run(json_input):\r\n    input = infer_and_parse_json_input(json_input=json_input, orient=\"split\")\r\n    return _get_jsonable_obj(model.predict(input), pandas_orient=\"records\")\r\n```\r\n\r\nLocal testing of this functionality appears to be successful in decoding the JSON serialized image back to a `numpy ndarray` and was successfully accepted by a `PyTorch ONNX` model that takes `numpy ndarray` image representations as input.\r\n\r\nThere are a few issues to iron out, including the additional dimension returned by the `infer_and_parse_json_input()` function, that is a shape of `(1,3,nx,ny)` instead of the transmitted `(3,nx,ny)`. A simple `numpy.squeeze()` application solves this issue, however, `input` may not be only be a `numpy ndarray` so some digging into the `infer_and_parse_json_input()` function is required to see why.\r\n","31":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**: pip?\r\n- **MLflow version (run ``mlflow --version``)**: 1.23.1\r\n- **Python version**: 3.8\r\n- **npm version, if running the dev UI**: n\/a\r\n- **Exact command to reproduce**: see code below\r\n\r\n\r\n### Describe the problem\r\n\r\nWhen calling `fit` with a tensorflow dataset with a batch operation applied, the mlflow tracking ui records batch size of None, not the correct batch size. Note that [the fit docs](https:\/\/keras.io\/api\/models\/model_training_apis\/#fit-method) instruct to not supply `batch_size` when the input data is a dataset:\r\n> batch_size: ... Do not specify the batch_size if your data is in the form of datasets, generators, or keras.utils.Sequence instances\r\n\r\nThe cause of this appears to be [this line](https:\/\/github.com\/mlflow\/mlflow\/blob\/1335164d20a6521dd4ebfe3f361d19fe9672efcf\/mlflow\/tensorflow\/__init__.py#L860) in the patched fit function for auto-logging, which logs the batch_size param, regardless of whether the input to fit was a batched dataset.\r\n\r\n### Code to reproduce issue\r\n\r\n```python\r\nimport mlflow\r\nimport tensorflow as tf\r\n\r\n\r\ndef gen():\r\n    for i in range(10):\r\n        yield i, -i\r\n\r\ndataset = tf.data.Dataset.from_generator(\r\n    gen,\r\n    output_signature=(\r\n        tf.TensorSpec(shape=(), dtype=tf.float32),\r\n        tf.TensorSpec(shape=(), dtype=tf.float32),\r\n    )\r\n)\r\ndataset = dataset.batch(2)\r\n\r\nmlflow.tensorflow.autolog()\r\n\r\nmodel = tf.keras.Sequential()\r\nmodel.add(tf.keras.layers.Dense(1, input_shape=(1,)))\r\nmodel.compile(loss=\"mse\")\r\nmodel.fit(dataset, epochs=10)\r\n```\r\n### Other info \/ logs\r\n\r\nN\/A\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","32":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nParallelize the download of artifact files from ModelsArtifactRepository.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n\r\nModelsArtifactRepository.download_artifacts() currently access files in a single-threaded way.  For models with only a few artifacts, this is ok, however there are models out there with a great number of files.  This causes the initial download of the model to take much longer than it ideally should.\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\n\r\nFaster download times for large models.\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n\r\nIf our customer can download their large models faster, it will allow them to train\/develop models faster and distribute them to a wider user base.\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nThe existing MLFlow implementation currently doesn't parallelize these operations, causing the file I\/O to become a bottleneck.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n\r\n\r\nInterfaces\r\n\r\n\r\nLanguages \r\n\r\n\r\nIntegrations\r\n\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","33":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nBeing able to identify a custom `predict_proba` function from a custom pyfunc model to be able to fully use the \"default\" evaluators with pyfunc models and not only with sklearn models.\r\n \r\n## Motivation\r\n- What is the use case for this feature?\r\nIncrease the range of models that can use the \"default\" evaluators when running `mlflow.evaluate`\r\n- Why is this use case valuable to support for MLflow users in general?\r\nIt is I believe something easy to unlock that could be used by anyone building their own custom model with pyfunc\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nWe would like to use all the evaluators in the group of \"default\" evaluators with our custom pyfunc classifier.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nThis is currently not easy to achieve as we would have to define our own evaluators.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nI propose to modify [this function](https:\/\/github.com\/mlflow\/mlflow\/blob\/af1df139aa107830fbfbc79e515df15f8f6e9f55\/mlflow\/models\/evaluation\/default_evaluator.py#L40) in https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/models\/evaluation\/default_evaluator.py to just detect a `predict_proba` within a pyfunc model.\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","34":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: yes -- custom Pyfunc model\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: 1.22.0\r\n- **Python version**: 3.9\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: \r\n\r\n### Describe the problem\r\nI am running an evaluation of my model using `mlflow.evaluate` function. Here is the command used:\r\n```\r\nmlflow.evaluate(\r\n    model=model,  # custom pyfunc model\r\n    data=data.head(), # pandas dataframe\r\n    targets=\"label\",\r\n    model_type=\"classifier\",\r\n    dataset_name=\"test\",\r\n    dataset_path=args.data_uri,\r\n    evaluators=[\"default\"],\r\n)\r\n```\r\nAnd I run on the following error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"evaluate.py\", line 42, in <module>\r\n    feature_names=[\"text\"]\r\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/models\/evaluation\/base.py\", line 807, in evaluate\r\n    feature_names=feature_names,\r\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/models\/evaluation\/base.py\", line 317, in __init__\r\n    if isinstance(data, spark_df_type):\r\nTypeError: isinstance() arg 2 must be a type or tuple of types\r\n```\r\nThe origin of this error seems to come from this part of the code in https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/models\/evaluation\/base.py in `EvaluationDataset`:\r\n```\r\nif \"pyspark\" in sys.modules:\r\n    from pyspark.sql import DataFrame as SparkDataFrame\r\n\r\n    supported_dataframe_types = (pd.DataFrame, SparkDataFrame)\r\n    spark_df_type = SparkDataFrame\r\nelse:\r\n    supported_dataframe_types = (pd.DataFrame,)\r\n    spark_df_type = None\r\n```\r\nSo if pyspark is not installed in your modules it will throw the above error because `spark_df_type` is `None`. I believe that pyspark should not be a requirement here and that we should have a check before running `isinstance(data, spark_df_type)`\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","35":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [*] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 4.14.243-185.433.amzn2.x86_64\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**:1.17.0\r\n- **Python version**: 3.7.9\r\n\r\n### Describe the problem\r\n![image](https:\/\/user-images.githubusercontent.com\/61279516\/151935647-361f40a8-c516-48f4-8c45-34b5f590528a.png)\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/61279516\/151936434-0839443e-cd30-4a0c-9b26-239d4dcb23ec.png)\r\n\r\n\r\n\r\nGetting different inference time from the same model on same input when I run it independently and when I run it by wrapping in mlflow\r\n\r\nI am getting 2ms\/prediction from xgb when i run it independently on a input of shape (100,14) and when i wrap it in mlflow my response time from model gets increased to 20-60ms per prediction for same input size.\r\n\r\n@lichenran1234 @maitre-matt \r\n\r\n\r\n","36":"Hi,\r\n\r\nI installed MLflow in my one node Kubernetes cluster. It needs 400MB of RAM after fresh install\r\nand without any load. That is a lot...\r\n\r\nA fresh Postgres install needs 34Mi and MinIO only 115Mi.\r\n\r\nI am using MLflow 1-23-1 with external Postgres and MinIO.\r\nI am starting it with:\r\n\r\n```text\r\n        command:\r\n          - mlflow\r\n          - server\r\n          - -h\r\n          - \"0.0.0.0\"\r\n          - --backend-store-uri\r\n          - \"postgresql:\/\/$(DB_NAME):$(DB_PASSWORD)@$(DB_HOST)\/$(DB_NAME)\"\r\n          - --default-artifact-root\r\n          - \"s3:\/\/mlflow\/\"\r\n```\r\n\r\nIs there any way you could reduce memory usage or tell me how I can tune it?","37":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [X] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nRequest improvement to log-scale labels within metric plots by converting to standard scientific notation.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- Interactive plotting of machine learning runs. Improvement obviates need for UI's like Tensorboard.\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Enhances dynamic analysis of metrics.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Helps keep my sanity and better conveys plot information\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n- Do not expect this fix to be difficult. However, personally unable to determine where plot labels are generated in source files. Not fluent in JS. \r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [X] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nAt present, it is difficult to read plots that are log-scaled due to the chosen formatting of text units (e.g. \\mu for micro 10^-6). This request is to convert log scaling according to standard convention (e.g. 4e-3) as more commonly found in plotting applications such Tensorboard. In addition, I think the style choice of larger text for integer exponent bases is non-standard. Uniform font desired.\r\n\r\nMLFlow log scaling (non-standard):\r\n![image](https:\/\/user-images.githubusercontent.com\/50338490\/151634400-23a73e5d-5db5-4a7a-a4ca-7b4b4a3d8026.png)\r\n\r\nTensorboard log scaling (standard):\r\n![image](https:\/\/user-images.githubusercontent.com\/50338490\/151634510-21d4ee84-4f11-4126-85df-0dfc31fd7570.png)\r\n\r\nThanks!\r\n","38":"### Willingness to contribute\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\nOS: Fedora 31\r\nMLFlow version: 1.22.0\r\nPython: 3.7.9\r\n\r\nTrain a model and store it in a\r\n\r\n### Describe the problem\r\nI've trained a Prophet model and store it in a Wasabi bucket without a problem using MLFlow's Python API. When I load it, I get an exception. I have no problem when using a personal S3 bucket, but using a Wasabi server gives problems. \r\n\r\n### Logs\r\n```\r\nTraceback (most recent call last):\r\n  File \"run_mlflow_predictions.py\", line 93, in <module>\r\n    df_forecast = load_model(run_id)\r\n  File \"run_mlflow_predictions.py\", line 73, in load_model\r\n    loaded_model = prophet.load_model(model_path)\r\n  File \"xxx\/mlflow\/venv\/lib64\/python3.7\/site-packages\/mlflow\/prophet.py\", line 285, in load_model\r\n    local_model_path = _download_artifact_from_uri(artifact_uri=model_uri, output_path=dst_path)\r\n  File \"xxx\/mlflow\/venv\/lib64\/python3.7\/site-packages\/mlflow\/tracking\/artifact_utils.py\", line 96, in _download_artifact_from_uri\r\n    artifact_path=artifact_path, dst_path=output_path\r\n  File \"xxx\/venv\/lib64\/python3.7\/site-packages\/mlflow\/store\/artifact\/runs_artifact_repo.py\", line 125, in download_artifacts\r\n    return self.repo.download_artifacts(artifact_path, dst_path)\r\n  File \"xxx\/venv\/lib64\/python3.7\/site-packages\/mlflow\/store\/artifact\/artifact_repo.py\", line 179, in download_artifacts\r\n    if self._is_directory(artifact_path):\r\n  File \"xxx\/venv\/lib64\/python3.7\/site-packages\/mlflow\/store\/artifact\/artifact_repo.py\", line 61, in _is_directory\r\n    listing = self.list_artifacts(artifact_path)\r\n  File \"xxx\/venv\/lib64\/python3.7\/site-packages\/mlflow\/store\/artifact\/http_artifact_repo.py\", line 47, in list_artifacts\r\n    head, tail = self.artifact_uri.split(sep, maxsplit=1)\r\nValueError: not enough values to unpack (expected 2, got 1)\r\n```\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support","39":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\nCurrently, the method `client.set_model_version_tag` only accepts an integer value for the parameter `version`. However, downstream jobs that refer to a model in the model registry often refer to it by `stage` instead of `version`. It would simplify things if the `set_model_version_tag` method would accept the stage name in addition to the version as well.\r\n\r\nExample:\r\n```python\r\nclient.set_model_version_tag(name=\"my-model\", version=\"staging\", key=\"mykey\", value=\"myvalue\")\r\n```\r\n\r\nCurrently, if someone now wants to set a tag for a `production` model, the person would first have to look up the `model version` for that model before it can set the tag. \r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nAllow `client.set_model_version_tag` to accept `staging,production,archived` as values for the `version` parameter as well, or add an additional parameter called `stage` that can be used instead of `version`.\r\n\r\n## Motivation\r\n- What is the use case for this feature? _It makes MLflow simpler to use_\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","40":"## What changes are proposed in this pull request?\r\nEnable plugin approach to enable default experiments framework\r\n\r\n## How is this patch tested?\r\n- [x] Created a job with the mlflow wheel: and [creating the job experiment was successful](https:\/\/dbc-98e50cb7-ce96.dev.databricks.com\/?o=868247350988813#job\/429899706490992\/run\/261100988457345).\r\n- [x] Created a [notebook experiment](https:\/\/dbc-98e50cb7-ce96.dev.databricks.com\/?o=868247350988813#notebook\/1142404851242222\/command\/1142404851242223) as well.\r\n- [x] Tests added\r\n\r\n## Does this PR change the documentation?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Make sure the changed pages \/ sections render correctly by following the steps below.\r\n\r\n1. Check the status of the `ci\/circleci: build_doc` check. If it's successful, proceed to the\r\n   next step, otherwise fix it.\r\n2. Click `Details` on the right to open the job page of CircleCI.\r\n3. Click the `Artifacts` tab.\r\n4. Click `docs\/build\/html\/index.html`.\r\n5. Find the changed pages \/ sections and make sure they render correctly.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","41":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux\r\n- **MLflow installed from (source or binary)**: binary \r\n- **MLflow version (run ``mlflow --version``)**: 1.23.0\r\n- **Python version**: 3.8\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: `mlflow run <Repo> -v <OldCommitID>`\r\n\r\n### Describe the problem\r\nMLflow projects is used for packaging data science code in a reusable and reproducible way. However, I tried to use MLflow projects to run old commit and it did not work.\r\n\r\n### Code to reproduce issue\r\n`mlflow run <Repo> -v <OldCommitID>`\r\n\r\n### Other info \/ logs\r\n`ERROR mlflow.cli: === Unable to checkout version <OldCommitID> of git repo <Repo> - please ensure that the version exists in the repo. `\r\n\r\n` stderr: 'fatal: reference is not a tree: <OldCommitID>' ===`\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","42":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Server running on Ubuntu 20.04, attempt to save model from Windows 10\r\n- **MLflow installed from (source or binary)**: `pip install mlflow`\r\n- **MLflow version (run ``mlflow --version``)**: 1.23\r\n- **Python version**: 3.8.10\r\n- **npm version, if running the dev UI**: N\/A\r\n- **Exact command to reproduce**: \r\n  - On server side: `mlflow server  --serve-artifacts --host 0.0.0.0 -p 5020    --artifacts-destination .\/mlartifacts --gunicorn-opts \"--log-level debug\"\r\n  - On client side, mlflow installed via `git clone` and `pip install -e .\/`. Use the `mlflow_artifacts` example, so command is `python example.py`\r\n\r\n### Describe the problem\r\nI expect to be able to save artifacts from the `mlflow_artifacts` example to the server running on a separate machine. Instead I get errors relating to the URI. \r\n\r\nOnly running the example code from the same machine works. \r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nOn an ubuntu machine, run the server command:\r\n```bash\r\nmlflow server  --serve-artifacts --host 0.0.0.0 -p 5020    --artifacts-destination .\/mlartifacts     --gunicorn-opts \"--log-level debug\"\r\n```\r\n(Note that adding the option `--default-artifact-root http:\/\/<server-ip>:5020\/api\/2.0\/mlflow-artifacts\/artifacts\/experiments` doesn't change a thing)\r\n\r\nOn a windows machine:\r\n```powershell\r\n$env:MLFLOW_TRACKING_URI=\"http:\/\/<ip-of-server>:5020\/\"\r\ncd examples\/mlflow_artifacts\/\r\npython example.py\r\n```\r\n\r\nThe result is the following error:\r\n\r\n```python\r\nConnectionError: HTTPConnectionPool(host='0.0.0.0', port=5020): Max retries exceeded with url: \/api\/2.0\/mlflow-artifacts\/artifacts\/experiments\/0\/ef5c9d97f4504cc494413c4d5cf048f7\/artifacts\/a.txt (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002464D5AC700>: Failed to establish a new connection: [WinError 10049] The requested address is not valid in its context'))\r\n```\r\n\r\nI think the hint is in the HTTPConnectionPool, which seems to be looking for a localhost (0.0.0.0) rather than the server name. Since this is being passed to the client on a different machine, which isn't running a server, the client can't save the artifact. \r\n\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```bash\r\n---------------------------------------------------------------------------\r\nOSError                                   Traceback (most recent call last)\r\nFile ~\\Miniconda3\\envs\\mlflow\\lib\\site-packages\\urllib3\\connection.py:174, in HTTPConnection._new_conn(self)\r\n    173 try:\r\n--> 174     conn = connection.create_connection(\r\n    175         (self._dns_host, self.port), self.timeout, **extra_kw\r\n    176     )\r\n    178 except SocketTimeout:\r\n\r\nFile ~\\Miniconda3\\envs\\mlflow\\lib\\site-packages\\urllib3\\util\\connection.py:96, in create_connection(address, timeout, source_address, socket_options)\r\n     95 if err is not None:\r\n---> 96     raise err\r\n     98 raise socket.error(\"getaddrinfo returns an empty list\")\r\n\r\nFile ~\\Miniconda3\\envs\\mlflow\\lib\\site-packages\\urllib3\\util\\connection.py:86, in create_connection(address, timeout, source_address, socket_options)\r\n     85     sock.bind(source_address)\r\n---> 86 sock.connect(sa)\r\n     87 return sock\r\n\r\nOSError: [WinError 10049] The requested address is not valid in its context\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nNewConnectionError                        Traceback (most recent call last)\r\nFile ~\\Miniconda3\\envs\\mlflow\\lib\\site-packages\\urllib3\\connectionpool.py:699, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\r\n    698 # Make the request on the httplib connection object.\r\n--> 699 httplib_response = self._make_request(\r\n    700     conn,\r\n    701     method,\r\n    702     url,\r\n    703     timeout=timeout_obj,\r\n    704     body=body,\r\n    705     headers=headers,\r\n    706     chunked=chunked,\r\n    707 )\r\n    709 # If we're going to release the connection in ``finally:``, then\r\n    710 # the response doesn't need to know about the connection. Otherwise\r\n    711 # it will also try to release it and we'll have a double-release\r\n    712 # mess.\r\n\r\nFile ~\\Miniconda3\\envs\\mlflow\\lib\\site-packages\\urllib3\\connectionpool.py:394, in HTTPConnectionPool._make_request(self, conn, method, url, timeout, chunked, **httplib_request_kw)\r\n    393     else:\r\n--> 394         conn.request(method, url, **httplib_request_kw)\r\n    396 # We are swallowing BrokenPipeError (errno.EPIPE) since the server is\r\n    397 # legitimately able to close the connection after sending a valid response.\r\n    398 # With this behaviour, the received response is still readable.\r\n\r\nFile ~\\Miniconda3\\envs\\mlflow\\lib\\site-packages\\urllib3\\connection.py:239, in HTTPConnection.request(self, method, url, body, headers)\r\n    238     headers[\"User-Agent\"] = _get_default_user_agent()\r\n--> 239 super(HTTPConnection, self).request(method, url, body=body, headers=headers)\r\n\r\nFile ~\\Miniconda3\\envs\\mlflow\\lib\\http\\client.py:1279, in HTTPConnection.request(self, method, url, body, headers, encode_chunked)\r\n   1278 \"\"\"Send a complete request to the server.\"\"\"\r\n-> 1279 self._send_request(method, url, body, headers, encode_chunked)\r\n\r\nFile ~\\Miniconda3\\envs\\mlflow\\lib\\http\\client.py:1325, in HTTPConnection._send_request(self, method, url, body, headers, encode_chunked)\r\n   1324     body = _encode(body, 'body')\r\n-> 1325 self.endheaders(body, encode_chunked=encode_chunked)\r\n\r\nFile ~\\Miniconda3\\envs\\mlflow\\lib\\http\\client.py:1274, in HTTPConnection.endheaders(self, message_body, encode_chunked)\r\n   1273     raise CannotSendHeader()\r\n-> 1274 self._send_output(message_body, encode_chunked=encode_chunked)\r\n\r\nFile ~\\Miniconda3\\envs\\mlflow\\lib\\http\\client.py:1034, in HTTPConnection._send_output(self, message_body, encode_chunked)\r\n   1033 del self._buffer[:]\r\n-> 1034 self.send(msg)\r\n   1036 if message_body is not None:\r\n   1037\r\n   1038     # create a consistent interface to message_body\r\n\r\nFile ~\\Miniconda3\\envs\\mlflow\\lib\\http\\client.py:974, in HTTPConnection.send(self, data)\r\n    973 if self.auto_open:\r\n--> 974     self.connect()\r\n    975 else:\r\n\r\nFile ~\\Miniconda3\\envs\\mlflow\\lib\\site-packages\\urllib3\\connection.py:205, in HTTPConnection.connect(self)\r\n    204 def connect(self):\r\n--> 205     conn = self._new_conn()\r\n    206     self._prepare_conn(conn)\r\n\r\nFile ~\\Miniconda3\\envs\\mlflow\\lib\\site-packages\\urllib3\\connection.py:186, in HTTPConnection._new_conn(self)\r\n    185 except SocketError as e:\r\n--> 186     raise NewConnectionError(\r\n    187         self, \"Failed to establish a new connection: %s\" % e\r\n    188     )\r\n    190 return conn\r\n\r\nNewConnectionError: <urllib3.connection.HTTPConnection object at 0x000002464D5AC700>: Failed to establish a new connection: [WinError 10049] The requested address is not valid in its context\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nMaxRetryError                             Traceback (most recent call last)\r\nFile ~\\Miniconda3\\envs\\mlflow\\lib\\site-packages\\requests\\adapters.py:439, in HTTPAdapter.send(self, request, stream, timeout, verify, cert, proxies)\r\n    438 if not chunked:\r\n--> 439     resp = conn.urlopen(\r\n    440         method=request.method,\r\n    441         url=url,\r\n    442         body=request.body,\r\n    443         headers=request.headers,\r\n    444         redirect=False,\r\n    445         assert_same_host=False,\r\n    446         preload_content=False,\r\n    447         decode_content=False,\r\n    448         retries=self.max_retries,\r\n    449         timeout=timeout\r\n    450     )\r\n    452 # Send the request.\r\n    453 else:\r\n\r\nFile ~\\Miniconda3\\envs\\mlflow\\lib\\site-packages\\urllib3\\connectionpool.py:755, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\r\n    753     e = ProtocolError(\"Connection aborted.\", e)\r\n--> 755 retries = retries.increment(\r\n    756     method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\r\n    757 )\r\n    758 retries.sleep()\r\n\r\nFile ~\\Miniconda3\\envs\\mlflow\\lib\\site-packages\\urllib3\\util\\retry.py:574, in Retry.increment(self, method, url, response, error, _pool, _stacktrace)\r\n    573 if new_retry.is_exhausted():\r\n--> 574     raise MaxRetryError(_pool, url, error or ResponseError(cause))\r\n    576 log.debug(\"Incremented Retry for (url='%s'): %r\", url, new_retry)\r\n\r\nMaxRetryError: HTTPConnectionPool(host='0.0.0.0', port=5020): Max retries exceeded with url: \/api\/2.0\/mlflow-artifacts\/artifacts\/experiments\/0\/ef5c9d97f4504cc494413c4d5cf048f7\/artifacts\/a.txt (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002464D5AC700>: Failed to establish a new connection: [WinError 10049] The requested address is not valid in its context'))\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [x] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","43":"## What changes are proposed in this pull request?\r\n\r\nthe way that model serve, prepare-env, etc get the download uri if we store the models in GCS. instead of returning the normal GCS path, we are going to return the signed url so we dont need to use SA to get the models for model serve.\r\n\r\n## How is this patch tested?\r\n\r\n- deploy mlflow service\r\n- test the endpoint using curl\r\n```\r\ncurl 'https:\/\/<mlflow-url>\/api\/2.0\/preview\/mlflow\/model-versions\/get-download-uri?name=<model_name>&version=<model_version>&use_signed_url=True'\r\n```\r\n- or deploy model service with additional parameter`--use-signed-url`\r\n```\r\nmlflow models serve --model-uri models:\/<model_name>\/<model_stage> -h 0.0.0.0 -p 3021 --use-signed-url\r\n```\r\n\r\n## Does this PR change the documentation?\r\n\r\n- [X] No. You can skip the rest of this section.\r\n- [ ] Yes. Make sure the changed pages \/ sections render correctly by following the steps below.\r\n\r\n1. Check the status of the `ci\/circleci: build_doc` check. If it's successful, proceed to the\r\n   next step, otherwise fix it.\r\n2. Click `Details` on the right to open the job page of CircleCI.\r\n3. Click the `Artifacts` tab.\r\n4. Click `docs\/build\/html\/index.html`.\r\n5. Find the changed pages \/ sections and make sure they render correctly.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [X] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [X] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [X] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [X] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [X] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [X] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","44":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: 1.22.0\r\n- **Python version**: 3.9.1\r\n- **npm version, if running the dev UI**: Don't know\r\n- **Exact command to reproduce**: see below\r\n\r\n### Describe the problem\r\n\r\nTrying to search by tag by following the example in the tags field results in the error message\r\n\r\n`INVALID_PARAMETER_VALUE: Search filter 'name ilike '%%' AND tags.key='value'' contains multiple expressions. Expected search filter with single comparison operator. e.g. name='myModelName'`\r\n\r\n![Screen Shot 2022-01-20 at 5 39 21 PM](https:\/\/user-images.githubusercontent.com\/800945\/150433434-1f258779-6b1b-4574-b530-30537cd11d77.png)\r\n\r\n### Code to reproduce issue\r\nN\/A\r\n\r\n### Other info \/ logs\r\n`INVALID_PARAMETER_VALUE: Search filter 'name ilike '%%' AND tags.key='value'' contains multiple expressions. Expected search filter with single comparison operator. e.g. name='myModelName'` is displayed in the UI.\r\n\r\nWe're using MySQL.\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [x] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","45":"Signed-off-by: harupy <hkawamura0130@gmail.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nRemove deprecated `mlflow.pyfunc.load_pyfunc`.\r\n\r\n## How is this patch tested?\r\n\r\nExisting tests\r\n\r\n## Does this PR change the documentation?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Make sure the changed pages \/ sections render correctly by following the steps below.\r\n\r\n1. Check the status of the `ci\/circleci: build_doc` check. If it's successful, proceed to the\r\n   next step, otherwise fix it.\r\n2. Click `Details` on the right to open the job page of CircleCI.\r\n3. Click the `Artifacts` tab.\r\n4. Click `docs\/build\/html\/index.html`.\r\n5. Find the changed pages \/ sections and make sure they render correctly.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n`mlflow.pyfunc.load_pyfunc` has been removed.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [x] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","46":"Signed-off-by: harupy <hkawamura0130@gmail.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nCloses #4045\r\n\r\nRemove numpy type aliases that were marked as deprecated in numpy 1.20.0:\r\nhttps:\/\/numpy.org\/devdocs\/release\/1.20.0-notes.html#deprecations\r\n\r\n<img src=\"https:\/\/user-images.githubusercontent.com\/17039389\/150464220-ae46922e-7a2c-40cc-87bb-f101f066d539.png\" width=\"70%\">\r\n\r\n- `np.int` might need some considerations.\r\n\r\n## How is this patch tested?\r\n\r\nExisting tests\r\n\r\n## Does this PR change the documentation?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Make sure the changed pages \/ sections render correctly by following the steps below.\r\n\r\n1. Check the status of the `ci\/circleci: build_doc` check. If it's successful, proceed to the\r\n   next step, otherwise fix it.\r\n2. Click `Details` on the right to open the job page of CircleCI.\r\n3. Click the `Artifacts` tab.\r\n4. Click `docs\/build\/html\/index.html`.\r\n5. Find the changed pages \/ sections and make sure they render correctly.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","47":"## What changes are proposed in this pull request?\r\n\r\n(Please fill in changes proposed in this fix)\r\n\r\n## How is this patch tested?\r\n\r\n(Details)\r\n\r\n## Does this PR change the documentation?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Make sure the changed pages \/ sections render correctly by following the steps below.\r\n\r\n1. Check the status of the `ci\/circleci: build_doc` check. If it's successful, proceed to the\r\n   next step, otherwise fix it.\r\n2. Click `Details` on the right to open the job page of CircleCI.\r\n3. Click the `Artifacts` tab.\r\n4. Click `docs\/build\/html\/index.html`.\r\n5. Find the changed pages \/ sections and make sure they render correctly.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","48":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 20.04.3\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.22.0\r\n- **Python version**: 3.8\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: `client.create_registered_model('Test')\r\n`\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\nMlflow client throws error every time I try to create_registered_model if tracking_uri and registry_uri are passed as parameters to MlflowClient instance. However if tracking_uri and registry_uri are set as env variables there is no error.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\nimport mlflow\r\n\r\nMLFLOW_S3_ENDPOINT_URL = 'example'\r\nMLFLOW_TRACKING_URI = 'example'\r\n\r\nclient = mlflow.tracking.MlflowClient(tracking_uri=MLFLOW_TRACKING_URI, registry_uri=MLFLOW_S3_ENDPOINT_URL)\r\n\r\nclient.create_registered_model('test')\r\n```\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n```\r\n---------------------------------------------------------------------------\r\nMlflowException                           Traceback (most recent call last)\r\n\/tmp\/ipykernel_24697\/2664497627.py in <module>\r\n----> 1 client.create_registered_model('Test')\r\n\r\n~\/.local\/share\/virtualenvs\/mt-demand-forecast-Zq_G97Q2\/lib\/python3.8\/site-packages\/mlflow\/tracking\/client.py in create_registered_model(self, name, tags, description)\r\n   1656             description: This sentiment analysis model classifies the tone-happy, sad, angry.\r\n   1657         \"\"\"\r\n-> 1658         return self._get_registry_client().create_registered_model(name, tags, description)\r\n   1659 \r\n   1660     def rename_registered_model(self, name: str, new_name: str) -> RegisteredModel:\r\n\r\n~\/.local\/share\/virtualenvs\/mt-demand-forecast-Zq_G97Q2\/lib\/python3.8\/site-packages\/mlflow\/tracking\/_model_registry\/client.py in create_registered_model(self, name, tags, description)\r\n     57         tags = tags if tags else {}\r\n     58         tags = [RegisteredModelTag(key, str(value)) for key, value in tags.items()]\r\n---> 59         return self.store.create_registered_model(name, tags, description)\r\n     60 \r\n     61     def update_registered_model(self, name, description):\r\n\r\n~\/.local\/share\/virtualenvs\/mt-demand-forecast-Zq_G97Q2\/lib\/python3.8\/site-packages\/mlflow\/store\/model_registry\/rest_store.py in create_registered_model(self, name, tags, description)\r\n     81             CreateRegisteredModel(name=name, tags=proto_tags, description=description)\r\n     82         )\r\n---> 83         response_proto = self._call_endpoint(CreateRegisteredModel, req_body)\r\n     84         return RegisteredModel.from_proto(response_proto.registered_model)\r\n     85 \r\n\r\n~\/.local\/share\/virtualenvs\/mt-demand-forecast-Zq_G97Q2\/lib\/python3.8\/site-packages\/mlflow\/store\/model_registry\/rest_store.py in _call_endpoint(self, api, json_body, call_all_endpoints)\r\n     62         else:\r\n     63             endpoint, method = _METHOD_TO_INFO[api]\r\n---> 64             return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)\r\n     65 \r\n     66     # CRUD API for RegisteredModel objects\r\n\r\n~\/.local\/share\/virtualenvs\/mt-demand-forecast-Zq_G97Q2\/lib\/python3.8\/site-packages\/mlflow\/utils\/rest_utils.py in call_endpoint(host_creds, endpoint, method, json_body, response_proto)\r\n    227             host_creds=host_creds, endpoint=endpoint, method=method, json=json_body\r\n    228         )\r\n--> 229     response = verify_rest_response(response, endpoint)\r\n    230     js_dict = json.loads(response.text)\r\n    231     parse_dict(js_dict=js_dict, message=response_proto)\r\n\r\n~\/.local\/share\/virtualenvs\/mt-demand-forecast-Zq_G97Q2\/lib\/python3.8\/site-packages\/mlflow\/utils\/rest_utils.py in verify_rest_response(response, endpoint)\r\n    173                 response.status_code,\r\n    174             )\r\n--> 175             raise MlflowException(\"%s. Response body: '%s'\" % (base_msg, response.text))\r\n    176 \r\n    177     # Skip validation for endpoints (e.g. DBFS file-download API) which may return a non-JSON\r\n\r\nMlflowException: API request to endpoint \/api\/2.0\/preview\/mlflow\/registered-models\/create failed with error code 405 != 200. Response body: '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<Error><Code>MethodNotAllowed<\/Code><Message>The specified method is not allowed against this resource.<\/Message><Resource>\/api\/2.0\/preview\/mlflow\/registered-models\/create<\/Resource><RequestId>109ef7057479979a<\/RequestId><Method>POST<\/Method><\/Error>'\r\n```\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n","49":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [X] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nIn the mlflow package, implemnt a `log_array_metric(name, array)` function. It will be equivalent to:\r\n```\r\nfor i, val in enumerate(array):\r\n     mlflow.log_metric(name, val, step=i) \r\n```\r\nThe implementation should rely on the log_batch function of MlflowClient object in order to reduce the number of calls to the mlflow server\r\n\r\n## Motivation\r\n\r\nIt is a common use case to log a loss after a training. Currently, it is necessary to write the loop. This FR would remove some boiler plate code.\r\nThe loop generates N remote calls to the mlflow server (N = size of the array). For my personal use-case, logging 1000 points takes 90 s. If I use log_batch method from the mflowclient, it takes 4s.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","50":"https:\/\/github.com\/mlflow\/mlflow\/blob\/dab955c02f762852a0e4ec8cf01c7baaffdf598d\/mlflow\/utils\/databricks_utils.py#L322\r\n\r\n**Issue:**\r\n\r\nIf user is setting secret scopes in Databricks for their remote registry (rather than the Databricks CLI), and configures them incorrectly, the error message incorrectly says it is the result of a malformed Databricks CLI profile.\r\n\r\n**Steps to reproduce:**\r\n\r\n1) Set registry_uri mlflow.set_registry_uri(registry_uri) to \"databricks:\/\/non-existent-scope:prefix\" (i.e. to a scope that does not exist)\r\n2) Attempt to register model.\r\n\r\n**Expected results:**\r\n\r\nAn error message indicating the scope doesn't exist, scope secrets are not correctly configured, could not reach workspace-id, etc.\r\n\r\n**Actual results:**\r\n\r\nGot malformed Databricks CLI profile 'MLFlowRegistry'\r\n\r\n","51":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 18.04)**: Linux(Ubuntu)\r\n- **MLflow installed from (source or binary)**:pip\r\n- **MLflow version (run ``mlflow --version``)**:1.22.0\r\n- **Python version**:3.8 and 3.9\r\n- **Exact command to reproduce**: ~\/Documents\/git_cloned\/Github\/Machine-Learning-Engineering-with-MLflow\/Chapter01\/stockpred > mlflow models serve -m runs:\/c3fe1649dc284a9d82fbdb037666fc03\/model_random_forest\r\n\r\n### Describe the problem\r\nAnytime I try to serve the model locally with the command above which creates a new conda environment and serves the model within that particular environment the environment build fails because the pip a\/some dependencies fails to install. and I can't tell exactly why this dependencies fail \r\n\r\n### Code to reproduce issue\r\n`conda.yaml`\r\n\r\n```\r\nchannels:\r\n- conda-forge\r\ndependencies:\r\n- python=3.9.7\r\n- pip\r\n- pip:\r\n  - mlflow==1.22.0\r\n  - cloudpickle==2.0.0\r\n  - scikit-learn==1.0.2\r\nname: mlflow-env\r\n```\r\n`requirements.txt`\r\n```\r\nmlflow==1.22.0\r\ncloudpickle==2.0.0\r\nscikit-learn==1.0.2\r\n```\r\n### Other info \/ logs\r\n ```\r\n2022\/01\/13 11:52:01 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\r\n2022\/01\/13 11:52:03 INFO mlflow.utils.conda: === Creating conda environment mlflow-04d87ea036b44c4189dc1f3a9f0d282b85dfcf87 ===\r\nCollecting package metadata (repodata.json): done\r\nSolving environment: done\r\nPreparing transaction: done\r\nVerifying transaction: done\r\nExecuting transaction: done\r\nInstalling pip dependencies: failed\r\n\r\n# >>>>>>>>>>>>>>>>>>>>>> ERROR REPORT <<<<<<<<<<<<<<<<<<<<<<\r\n\r\n    Traceback (most recent call last):\r\n      File \"\/home\/nwoke\/anaconda3\/lib\/python3.9\/site-packages\/conda\/exceptions.py\", line 1080, in __call__\r\n        return func(*args, **kwargs)\r\n      File \"\/home\/nwoke\/anaconda3\/lib\/python3.9\/site-packages\/conda_env\/cli\/main.py\", line 80, in do_call\r\n        exit_code = getattr(module, func_name)(args, parser)\r\n      File \"\/home\/nwoke\/anaconda3\/lib\/python3.9\/site-packages\/conda_env\/cli\/main_create.py\", line 141, in execute\r\n        result[installer_type] = installer.install(prefix, pkg_specs, args, env)\r\n      File \"\/home\/nwoke\/anaconda3\/lib\/python3.9\/site-packages\/conda_env\/installers\/pip.py\", line 70, in install\r\n        return _pip_install_via_requirements(*args, **kwargs)\r\n      File \"\/home\/nwoke\/anaconda3\/lib\/python3.9\/site-packages\/conda_env\/installers\/pip.py\", line 44, in _pip_install_via_requirements\r\n        requirements = Utf8NamedTemporaryFile(mode='w',\r\n      File \"\/home\/nwoke\/anaconda3\/lib\/python3.9\/site-packages\/conda\/auxlib\/compat.py\", line 88, in Utf8NamedTemporaryFile\r\n        return NamedTemporaryFile(\r\n      File \"\/home\/nwoke\/anaconda3\/lib\/python3.9\/tempfile.py\", line 541, in NamedTemporaryFile\r\n        (fd, name) = _mkstemp_inner(dir, prefix, suffix, flags, output_type)\r\n      File \"\/home\/nwoke\/anaconda3\/lib\/python3.9\/tempfile.py\", line 251, in _mkstemp_inner\r\n        fd = _os.open(file, flags, 0o600)\r\n    PermissionError: [Errno 13] Permission denied: '\/home\/nwoke\/Documents\/git_cloned\/Github\/Machine-Learning-Engineering-with-MLflow\/Chapter01\/stockpred\/mlruns\/0\/c3fe1649dc284a9d82fbdb037666fc03\/artifacts\/model_random_forest\/condaenv.89qb6n18.requirements.txt'\r\n\r\n`$ \/home\/nwoke\/anaconda3\/bin\/conda-env create -n mlflow-04d87ea036b44c4189dc1f3a9f0d282b85dfcf87 --file \/home\/nwoke\/Documents\/git_cloned\/Github\/Machine-Learning-Engineering-with-MLflow\/Chapter01\/stockpred\/mlruns\/0\/c3fe1649dc284a9d82fbdb037666fc03\/artifacts\/model_random_forest\/conda.yaml`\r\n\r\n  environment variables:\r\n                 CIO_TEST=<not set>\r\n  CONDA_AUTO_UPDATE_CONDA=false\r\n                CONDA_EXE=\/home\/nwoke\/anaconda3\/bin\/conda\r\n         CONDA_PYTHON_EXE=\/home\/nwoke\/anaconda3\/bin\/python\r\n               CONDA_ROOT=\/home\/nwoke\/anaconda3\r\n              CONDA_SHLVL=0\r\n           CURL_CA_BUNDLE=<not set>\r\n            DEFAULTS_PATH=\/usr\/share\/gconf\/ubuntu.default.path\r\n       LIBVA_DRIVERS_PATH=\/opt\/intel\/mediasdk\/lib64\r\n           MANDATORY_PATH=\/usr\/share\/gconf\/ubuntu.mandatory.path\r\n                     PATH=\/home\/nwoke\/anaconda3\/condabin:\/home\/nwoke\/.local\/bin:\/usr\/local\/sbin:\r\n                          \/usr\/local\/bin:\/usr\/sbin:\/usr\/bin:\/sbin:\/bin:\/usr\/games:\/usr\/local\/gam\r\n                          es:\/snap\/bin:\/home\/nwoke\/.dotnet\/tools\r\n       REQUESTS_CA_BUNDLE=<not set>\r\n            SSL_CERT_FILE=<not set>\r\n               WINDOWPATH=2\r\n\r\n     active environment : None\r\n            shell level : 0\r\n       user config file : \/home\/nwoke\/.condarc\r\n populated config files : \/home\/nwoke\/.condarc\r\n          conda version : 4.11.0\r\n    conda-build version : 3.21.5\r\n         python version : 3.9.7.final.0\r\n       virtual packages : __linux=5.4.0=0\r\n                          __glibc=2.27=0\r\n                          __unix=0=0\r\n                          __archspec=1=x86_64\r\n       base environment : \/home\/nwoke\/anaconda3  (writable)\r\n      conda av data dir : \/home\/nwoke\/anaconda3\/etc\/conda\r\n  conda av metadata url : None\r\n           channel URLs : https:\/\/conda.anaconda.org\/conda-forge\/linux-64\r\n                          https:\/\/conda.anaconda.org\/conda-forge\/noarch\r\n                          https:\/\/repo.anaconda.com\/pkgs\/main\/linux-64\r\n                          https:\/\/repo.anaconda.com\/pkgs\/main\/noarch\r\n                          https:\/\/repo.anaconda.com\/pkgs\/r\/linux-64\r\n                          https:\/\/repo.anaconda.com\/pkgs\/r\/noarch\r\n          package cache : \/home\/nwoke\/anaconda3\/pkgs\r\n                          \/home\/nwoke\/.conda\/pkgs\r\n       envs directories : \/home\/nwoke\/anaconda3\/envs\r\n                          \/home\/nwoke\/opt\/anaconda3\/envs\r\n                          \/home\/nwoke\/.conda\/envs\r\n               platform : linux-64\r\n             user-agent : conda\/4.11.0 requests\/2.26.0 CPython\/3.9.7 Linux\/5.4.0-94-generic ubuntu\/18.04.6 glibc\/2.27\r\n                UID:GID : 1000:1000\r\n             netrc file : None\r\n           offline mode : False\r\n\r\n\r\nAn unexpected error has occurred. Conda has prepared the above report.\r\n\r\nTraceback (most recent call last):\r\n  File \"\/home\/nwoke\/.local\/bin\/mlflow\", line 8, in <module>\r\n    sys.exit(cli())\r\n  File \"\/home\/nwoke\/.local\/lib\/python3.8\/site-packages\/click\/core.py\", line 1128, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\/home\/nwoke\/.local\/lib\/python3.8\/site-packages\/click\/core.py\", line 1053, in main\r\n    rv = self.invoke(ctx)\r\n  File \"\/home\/nwoke\/.local\/lib\/python3.8\/site-packages\/click\/core.py\", line 1659, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/home\/nwoke\/.local\/lib\/python3.8\/site-packages\/click\/core.py\", line 1659, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/home\/nwoke\/.local\/lib\/python3.8\/site-packages\/click\/core.py\", line 1395, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\/home\/nwoke\/.local\/lib\/python3.8\/site-packages\/click\/core.py\", line 754, in invoke\r\n    return __callback(*args, **kwargs)\r\n  File \"\/home\/nwoke\/.local\/lib\/python3.8\/site-packages\/mlflow\/models\/cli.py\", line 57, in serve\r\n    return _get_flavor_backend(\r\n  File \"\/home\/nwoke\/.local\/lib\/python3.8\/site-packages\/mlflow\/pyfunc\/backend.py\", line 78, in serve\r\n    return _execute_in_conda_env(\r\n  File \"\/home\/nwoke\/.local\/lib\/python3.8\/site-packages\/mlflow\/pyfunc\/backend.py\", line 144, in _execute_in_conda_env\r\n    conda_env_name = get_or_create_conda_env(conda_env_path, env_id=env_id)\r\n  File \"\/home\/nwoke\/.local\/lib\/python3.8\/site-packages\/mlflow\/utils\/conda.py\", line 135, in get_or_create_conda_env\r\n    process.exec_cmd(\r\n  File \"\/home\/nwoke\/.local\/lib\/python3.8\/site-packages\/mlflow\/utils\/process.py\", line 40, in exec_cmd\r\n    raise ShellCommandException(\"Non-zero exitcode: %s\" % (exit_code))\r\nmlflow.utils.process.ShellCommandException: Non-zero exitcode: 1\r\n```\r\n\r\n\r\n","52":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.04.3 LTS\r\n- **MLflow installed from (source or binary)**: pip\r\n- **MLflow version (run ``mlflow --version``)**: mlflow, version 1.22.0\r\n- **Python version**: Python 3.8.12\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: `python example.py`\r\n- **Tensorflow version**: 2.7\r\n\r\n### Describe the problem\r\nWhenever I try to use mlflow with TensorFlow's mirrored strategy, the destructor throws an exception related to Multiprocessing. This error occurs even when using a single GPU.\r\n\r\n### Code to reproduce issue\r\n```python\r\n#! \/usr\/bin\/env python\r\n\r\nimport mlflow\r\nimport tensorflow as tf\r\n\r\nif tf.config.list_physical_devices('GPU'):\r\n    strategy = tf.distribute.MirroredStrategy()\r\nelse:  # Use the Default Strategy\r\n    strategy = tf.distribute.get_strategy()\r\n\r\n\r\ndef main():\r\n    return\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\n### Other info \/ logs\r\n\r\n## Output\r\n\r\n```\r\nException ignored in: <function Pool.__del__ at 0x7f791ce11820>\r\nTraceback (most recent call last):\r\n  File \"\/home\/homeGlobal\/lcampos\/anaconda3\/envs\/base-tf-cuda-env\/lib\/python3.8\/multiprocessing\/pool.py\", line 268, in __del__\r\n  File \"\/home\/homeGlobal\/lcampos\/anaconda3\/envs\/base-tf-cuda-env\/lib\/python3.8\/multiprocessing\/queues.py\", line 362, in put\r\nAttributeError: 'NoneType' object has no attribute 'dumps'\r\n```\r\n\r\n\r\n## Conda environment\r\nhttps:\/\/gist.github.com\/LucasCampos\/129db886abca17a76561edc912670e2a\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging","53":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [x] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:  No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: All\r\n- **MLflow installed from (source or binary)**: Binary (wheel)\r\n- **MLflow version (run ``mlflow --version``)**: 1.22.0\r\n- **Python version**: All\r\n- **npm version, if running the dev UI**: N\/A\r\n- **Exact command to reproduce**: See below\r\n\r\n### Describe the problem\r\nThe implementation of the Keras pyfunc [calls keras.Model.predict](https:\/\/github.com\/mlflow\/mlflow\/blob\/364aca7daf0fcee3ec407ae0b1b16d9cb3085081\/mlflow\/keras.py#L462-L465) which is designed for large-scale batch prediction (docs: https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/Model#predict). Calling the model as a function directly is orders of magnitude faster and still works on batches of inputs.\r\n\r\n### Code to reproduce issue\r\n```python\r\nimport sklearn.datasets as datasets\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\nimport mlflow\r\n\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense\r\nfrom tensorflow.keras.optimizers import SGD\r\n\r\n\r\niris = datasets.load_iris()\r\ndata = pd.DataFrame(\r\n    data=np.c_[iris[\"data\"], iris[\"target\"]], columns=iris[\"feature_names\"] + [\"target\"]\r\n)\r\ny = data[\"target\"]\r\nx = data.drop(\"target\", axis=1)\r\n\r\nmodel = Sequential()\r\nmodel.add(Dense(3, input_dim=4))\r\nmodel.add(Dense(1))\r\nmodel.compile(loss=\"mean_squared_error\", optimizer=SGD())\r\nmodel.fit(x.values, y.values)\r\nmlflow.keras.save_model(model, \"keras_model\")\r\n\r\nmodel_loaded = mlflow.pyfunc.load_model(\"keras_model\")\r\n\r\n# call keras.Model predict method\r\n# %timeit model_loaded._model_impl.keras_model.predict(x.values)\r\n# 30.1 ms \u00b1 4.37 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each)\r\n\r\n# call keras.Model as function\r\n# %timeit model_loaded._model_impl.keras_model(x.values)\r\n# 556 \u00b5s \u00b1 13.3 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each)\r\n\r\n# assert parity between calling methods\r\n# np.allclose(model_loaded._model_impl.keras_model.predict(x.values), model_loaded._model_impl.keras_model(x.values))\r\n# True\r\n```\r\n\r\nI don't think this makes a difference in TensorFlow <2.0 since the graph is executed correctly, but in >=2.0, a large amount of setup happens under-the-hood when calling `keras.Model.predict` leading to the slowdown observed here.\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations","54":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nCurrently, if you would want to make predictions with your model as UDF, only a double, array of doubles, or array of strings is supported. My proposal would be to extend the model output format to more complex output structures, which can be defined using a Spark schema or using the mlflow output signature.\r\n\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nMaking model predictions when you have loaded your model as UDF.\r\n- Why is this use case valuable to support for MLflow users in general?\r\nFor example, a model output of `[0.8, 0.9, 2012]`, is much less robust and less flexible than a model output of `{'extracted_x': 2012, 'probabilities': {'label_x': 0.8, 'label_y': 0.9}]`.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n\r\n\r\n\r\n","55":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [X] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: docker image python:3.8-slim-buster\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.22 for the client and server\r\n- **Python version**: 3.8\r\n- **npm version, if running the dev UI**: \r\n- **Exact command to reproduce**: \r\n```\r\nmodel = load_model(\"models:\/{}\/Production\".format(name_registry_model))\r\n```\r\n\r\n### Describe the problem\r\nI am having a weird problem trying to load a model from the uri \"models:\/{}\/Production\" after register the trained model **using the python mlflow cli register_model**.\r\nThe weird part is that when I register the model using the mlflow visual interface, I don't have any problem with it.\r\n\r\n### Code to reproduce issue\r\n```\r\nimport mlflow\r\nfrom kedro_mlflow.config import get_mlflow_config\r\n\r\nmlflow_config = get_mlflow_config()\r\nid_experiment = 0 ##any id you have\r\nname_registry_model = '' ##any registered model you have\r\n\r\n\r\nmlflow_cli = mlflow.tracking.MlflowClient(tracking_uri=mlflow_config.mlflow_tracking_uri)\r\nlast_run = mlflow_cli.search_runs(\r\n                id_experiment , \r\n                run_view_type=mlflow.entities.ViewType.ACTIVE_ONLY, \r\n                order_by=['attribute.start_time DESC'], \r\n                max_results=1)[0]\r\n\r\nmlflow_cli = mlflow.tracking.MlflowClient(tracking_uri=mlflow_config.mlflow_tracking_uri)\r\nmodel_updated_uri = \"runs:\/{}\/{}\".format(last_run.info.run_id, name_experiment)\r\n    new_registry = mlflow.register_model(\r\n    model_updated_uri,\r\n    name_registry_model, \r\n    await_registration_for = 0\r\n)\r\nmlflow_cli.transition_model_version_stage(name_registry_model, new_registry.version, 'production', archive_existing_versions=True)\r\n\r\nmodel = load_model(\"models:\/{}\/Production\".format(name_registry_model))\r\n```\r\n\r\n### Other info \/ logs \/ error message\r\n```\r\nClientError                               Traceback (most recent call last)\r\n~\\AppData\\Local\\Temp\/ipykernel_20040\/3865171810.py in <module>\r\n----> 1 modelo = load_model(\"models:\/{}\/Production\")\r\n      2 modelo\r\n\r\n~\\miniconda3\\envs\\env-dona-herminia\\lib\\site-packages\\mlflow\\pyfunc\\_init_.py in load_model(model_uri, suppress_warnings)\r\n    649                               messages will be emitted.\r\n    650     :param dst_path: The local filesystem path to which to download the model artifact.\r\n--> 651                      This directory must already exist. If unspecified, a local output\r\n    652                      path will be created.\r\n    653     \"\"\"\r\n\r\n~\\miniconda3\\envs\\env-dona-herminia\\lib\\site-packages\\mlflow\\tracking\\artifact_utils.py in _download_artifact_from_uri(artifact_uri, output_path)\r\n     82         prefix = parsed_uri.scheme + \":\"\r\n     83         parsed_uri = parsed_uri._replace(scheme=\"\")\r\n---> 84 \r\n     85     # For models:\/ URIs, it doesn't make sense to initialize a ModelsArtifactRepository with only\r\n     86     # the model name portion of the URI, then call download_artifacts with the version info.\r\n\r\n~\\miniconda3\\envs\\env-dona-herminia\\lib\\site-packages\\mlflow\\store\\artifact\\models_artifact_repo.py in download_artifacts(self, artifact_path, dst_path)\r\n    108         :return: Absolute path of the local filesystem location containing the desired artifacts.\r\n    109         \"\"\"\r\n--> 110         return self.repo.download_artifacts(artifact_path, dst_path)\r\n    111 \r\n    112     def _download_file(self, remote_file_path, local_path):\r\n\r\n~\\miniconda3\\envs\\env-dona-herminia\\lib\\site-packages\\mlflow\\store\\artifact\\artifact_repo.py in download_artifacts(self, artifact_path, dst_path)\r\n    182             )\r\n    183         else:\r\n--> 184             return download_artifact(src_artifact_path=artifact_path, dst_local_dir_path=dst_path)\r\n    185 \r\n    186     @abstractmethod\r\n\r\n~\\miniconda3\\envs\\env-dona-herminia\\lib\\site-packages\\mlflow\\store\\artifact\\artifact_repo.py in download_artifact(src_artifact_path, dst_local_dir_path)\r\n    128             )\r\n    129             self._download_file(\r\n--> 130                 remote_file_path=src_artifact_path, local_path=local_destination_file_path\r\n    131             )\r\n    132             return local_destination_file_path\r\n\r\n~\\miniconda3\\envs\\env-dona-herminia\\lib\\site-packages\\mlflow\\store\\artifact\\s3_artifact_repo.py in _download_file(self, remote_file_path, local_path)\r\n    156         s3_full_path = posixpath.join(s3_root_path, remote_file_path)\r\n    157         s3_client = self._get_s3_client()\r\n--> 158         s3_client.download_file(bucket, s3_full_path, local_path)\r\n    159 \r\n    160     def delete_artifacts(self, artifact_path=None):\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\boto3\\s3\\inject.py in download_file(self, Bucket, Key, Filename, ExtraArgs, Callback, Config)\r\n    170         return transfer.download_file(\r\n    171             bucket=Bucket, key=Key, filename=Filename,\r\n--> 172             extra_args=ExtraArgs, callback=Callback)\r\n    173 \r\n    174 \r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\boto3\\s3\\transfer.py in download_file(self, bucket, key, filename, extra_args, callback)\r\n    305             bucket, key, filename, extra_args, subscribers)\r\n    306         try:\r\n--> 307             future.result()\r\n    308         # This is for backwards compatibility where when retries are\r\n    309         # exceeded we need to throw the same error from boto3 instead of\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\s3transfer\\futures.py in result(self)\r\n    104             # however if a KeyboardInterrupt is raised we want want to exit\r\n    105             # out of this and propogate the exception.\r\n--> 106             return self._coordinator.result()\r\n    107         except KeyboardInterrupt as e:\r\n    108             self.cancel()\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\s3transfer\\futures.py in result(self)\r\n    263         # final result.\r\n    264         if self._exception:\r\n--> 265             raise self._exception\r\n    266         return self._result\r\n    267 \r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\s3transfer\\tasks.py in _main(self, transfer_future, **kwargs)\r\n    253             # Call the submit method to start submitting tasks to execute the\r\n    254             # transfer.\r\n--> 255             self._submit(transfer_future=transfer_future, **kwargs)\r\n    256         except BaseException as e:\r\n    257             # If there was an exception raised during the submission of task\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\s3transfer\\download.py in _submit(self, client, config, osutil, request_executor, io_executor, transfer_future, bandwidth_limiter)\r\n    341                 Bucket=transfer_future.meta.call_args.bucket,\r\n    342                 Key=transfer_future.meta.call_args.key,\r\n--> 343                 **transfer_future.meta.call_args.extra_args\r\n    344             )\r\n    345             transfer_future.meta.provide_transfer_size(\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\botocore\\client.py in _api_call(self, *args, **kwargs)\r\n    384                     \"%s() only accepts keyword arguments.\" % py_operation_name)\r\n    385             # The \"self\" in this scope is referring to the BaseClient.\r\n--> 386             return self._make_api_call(operation_name, kwargs)\r\n    387 \r\n    388         _api_call._name_ = str(py_operation_name)\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\botocore\\client.py in _make_api_call(self, operation_name, api_params)\r\n    703             error_code = parsed_response.get(\"Error\", {}).get(\"Code\")\r\n    704             error_class = self.exceptions.from_code(error_code)\r\n--> 705             raise error_class(parsed_response, operation_name)\r\n    706         else:\r\n    707             return parsed_response\r\n\r\nClientError: An error occurred (404) when calling the HeadObject operation: Not Found\r\n```\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [X] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\n\r\n\r\n","56":"## What changes are proposed in this pull request?\r\n\r\nMark \"Changing param values is not allowed\" as User initiated failure exception type\r\n\r\n## How is this patch tested?\r\n\r\nN\/A\r\n\r\n## Does this PR change the documentation?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Make sure the changed pages \/ sections render correctly by following the steps below.\r\n\r\n1. Check the status of the `ci\/circleci: build_doc` check. If it's successful, proceed to the\r\n   next step, otherwise fix it.\r\n2. Click `Details` on the right to open the job page of CircleCI.\r\n3. Click the `Artifacts` tab.\r\n4. Click `docs\/build\/html\/index.html`.\r\n5. Find the changed pages \/ sections and make sure they render correctly.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","57":"I'm working with MLflow version **1.22.0** and I'm trying to log a TensorFlow model which is in the SavedModel format. When I run the command:\r\n\r\n`mlflow.tensorflow.log_model(tf_saved_model_dir=export_dir, tf_meta_graph_tags=[\"serve\"], artifact_path=\"mlruns\/0\/0dcc80caa5be4574a92a26306e24cdb8\/artifacts\/model\", tf_signature_def_key=None)`\r\n\r\nI get the following error:\r\n\r\n```\r\n2022\/01\/10 14:37:29 INFO mlflow.tensorflow: Validating the specified TensorFlow model by attempting to load it in a new TensorFlow graph...\r\nWARNING:tensorflow:From \/mnt\/3\/shares\/biobert\/miniconda3\/envs\/biobert\/lib\/python3.7\/site-packages\/mlflow\/tensorflow\/__init__.py:405: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"\/mnt\/3\/shares\/biobert\/miniconda3\/envs\/biobert\/lib\/python3.7\/site-packages\/mlflow\/utils\/annotations.py\", line 62, in wrapper\r\n    return func(**kwargs)\r\n  File \"\/mnt\/3\/shares\/biobert\/miniconda3\/envs\/biobert\/lib\/python3.7\/site-packages\/mlflow\/tensorflow\/__init__.py\", line 193, in log_model\r\n    extra_pip_requirements=extra_pip_requirements,\r\n  File \"\/mnt\/3\/shares\/biobert\/miniconda3\/envs\/biobert\/lib\/python3.7\/site-packages\/mlflow\/models\/model.py\", line 187, in log\r\n    flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\r\n  File \"\/mnt\/3\/shares\/biobert\/miniconda3\/envs\/biobert\/lib\/python3.7\/site-packages\/mlflow\/utils\/annotations.py\", line 62, in wrapper\r\n    return func(**kwargs)\r\n  File \"\/mnt\/3\/shares\/biobert\/miniconda3\/envs\/biobert\/lib\/python3.7\/site-packages\/mlflow\/tensorflow\/__init__.py\", line 263, in save_model\r\n    tf_signature_def_key=tf_signature_def_key,\r\n  File \"\/mnt\/3\/shares\/biobert\/miniconda3\/envs\/biobert\/lib\/python3.7\/site-packages\/mlflow\/tensorflow\/__init__.py\", line 330, in _validate_saved_model\r\n    tf_signature_def_key=tf_signature_def_key,\r\n  File \"\/mnt\/3\/shares\/biobert\/miniconda3\/envs\/biobert\/lib\/python3.7\/site-packages\/mlflow\/tensorflow\/__init__.py\", line 405, in _load_tensorflow_saved_model\r\n    tags=tf_meta_graph_tags, export_dir=tf_saved_model_dir\r\n  File \"\/mnt\/3\/shares\/biobert\/miniconda3\/envs\/biobert\/lib\/python3.7\/site-packages\/tensorflow_core\/python\/util\/deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\nTypeError: load() missing 1 required positional argument: 'sess'\r\n```\r\n\r\nA similar issue is occurring with the command **mlflow.tensorflow.save_model** as well. Was \"**sess**\" required in previous versions? I found some references to this parameter in the MLflow Documentation.\r\n\r\nNote that I'm able to load the model with the TensorFlow library, without passing through MLflow.\r\n\r\nThank you in advance for your help!","58":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nAdding an `--include-all` flag to the `mlflow artifacts download` command would facilitate more flexible use MLFlow in CI\/CD flows by linking relative model paths to run artifacts directly. \r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n\r\n  ML teams orchestrate regular retraining runs in a workflow manager. When adopting MLFlow for tracking these runs, there is a ton of flexibility for workable promotion processes that MLFlow's ModelRegistry and tagging system can facilitate.  \r\n  \r\n  For example, when running CI on a staging branch, we can include a make command that calls `mlflow artifacts download --artifact-uri models:\/my_model\/Staging --include-all` to grab any artifacts required for serving, testing, or reporting. \r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\n\r\n    It makes integrating the ModelRegistry with automated testing easier. \r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n\r\n    It makes integrating the ModelRegistry with automated testing easier. \r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n    Rather than being a component of the CLI, we write a script. While this is not difficult, having this feature in the CLI would better enable model testing.\r\n\r\n```Python\r\nfrom mlflow.store.artifact.models_artifact_repo import ModelsArtifactRepository\r\n\r\nmodel_uri = \"models:\/my_model\/Production\"\r\nmodel_path = ModelsArtifactRepository.get_underlying_uri(model_uri)\r\nartifacts_path = model_path.strip('\/model')\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nThe `ArtifactRepositoryRegistry` interface is great and I wouldn't want to modify it for this small quality-of-life improvement. It would muddy the distinction between a `RunsArtifactRepository` and a `ModelsArtifactRepository`. \r\n\r\nOne implementation path would look like the following:\r\n\r\n**1.  Add the `include-all` flag to the `mlflow artifacts download` command**\r\n```Python\r\n@commands.command(\"download\")\r\n@click.option(\"--run-id\", \"-r\", help=\"Run ID from which to download\")\r\n@click.option(\r\n    \"--artifact-path\",\r\n    \"-a\",\r\n    help=\"For use with Run ID: if specified, a path relative to the run's root \"\r\n    \"directory to download\",\r\n)\r\n@click.option(\r\n    \"--artifact-uri\",\r\n    \"-u\",\r\n    help=\"URI pointing to the artifact file or artifacts directory; use as an \"\r\n    \"alternative to specifying --run_id and --artifact-path\",\r\n)\r\n@click.option(\"--include-all\/--no-include-all\", default=False)\r\ndef download_artifacts(run_id, artifact_path, artifact_uri, include_all):\r\n    \"\"\"\r\n    Download an artifact file or directory to a local directory.\r\n    The output is the name of the file or directory on the local disk.\r\n\r\n    The ``include-all`` flag allows users to pull all artifacts from a\r\n    run using a relative model uri like models:\/<model>\/Staging\r\n\r\n    Either ``--run-id`` or ``--artifact-uri`` must be provided.\r\n    \"\"\"\r\n    if run_id is None and artifact_uri is None:\r\n        _logger.error(\"Either ``--run-id`` or ``--artifact-uri`` must be provided.\")\r\n        sys.exit(1)\r\n\r\n    if run_id is not None and not include_all:\r\n        _logger.error(\"The ``-no-include-all`` flag only works with ``--artifact-uri``\")\r\n        sys.exit(1)\r\n\r\n    if artifact_uri is not None:\r\n        print(_download_artifact_from_uri(artifact_uri, include_all=include_all))\r\n        return\r\n\r\n    artifact_path = artifact_path if artifact_path is not None else \"\"\r\n    store = _get_store()\r\n    artifact_uri = store.get_run(run_id).info.artifact_uri\r\n    artifact_repo = get_artifact_repository(artifact_uri)\r\n    artifact_location = artifact_repo.download_artifacts(artifact_path)\r\n    print(artifact_location)\r\n```\r\n\r\n**2.  Adjust how this flag is handled in `_download_artifact_from_uri`**\r\n```Python\r\ndef _download_artifact_from_uri(artifact_uri, output_path=None, include_all=False):\r\n    \"\"\"\r\n    :param artifact_uri: The *absolute* URI of the artifact to download.\r\n    :param output_path: The local filesystem path to which to download the artifact. If unspecified,\r\n                        a local output path will be created.\r\n    \"\"\"\r\n    if os.path.exists(artifact_uri):\r\n        if os.name != \"nt\":\r\n            # If we're dealing with local files, just reference the direct pathing.\r\n            # non-nt-based file systems can directly reference path information, while nt-based\r\n            # systems need to url-encode special characters in directory listings to be able to\r\n            # resolve them (i.e., spaces converted to %20 within a file name or path listing)\r\n            root_uri = os.path.dirname(artifact_uri)\r\n            artifact_path = os.path.basename(artifact_uri)\r\n            return get_artifact_repository(artifact_uri=root_uri).download_artifacts(\r\n                artifact_path=artifact_path, dst_path=output_path\r\n            )\r\n        else:  # if we're dealing with nt-based systems, we need to utilize pathname2url to encode.\r\n            artifact_uri = path_to_local_file_uri(artifact_uri)\r\n\r\n    parsed_uri = urllib.parse.urlparse(str(artifact_uri))\r\n    prefix = \"\"\r\n    if parsed_uri.scheme and not parsed_uri.path.startswith(\"\/\"):\r\n        # relative path is a special case, urllib does not reconstruct it properly\r\n        prefix = parsed_uri.scheme + \":\"\r\n        parsed_uri = parsed_uri._replace(scheme=\"\")\r\n\r\n    # For models:\/ URIs, it doesn't make sense to initialize a ModelsArtifactRepository with only\r\n    # the model name portion of the URI, then call download_artifacts with the version info.\r\n    if ModelsArtifactRepository.is_models_uri(artifact_uri):\r\n        # Prototyped change would be here\r\n        if include_all:\r\n            model_only_artifact_uri = ModelsArtifactRepository.get_underlying_uri(artifact_uri)\r\n            artifact_uri = model_only_artifact_uri.strip(\"\/model\")\r\n        root_uri = artifact_uri\r\n        artifact_path = \"\"\r\n    else:\r\n        artifact_path = posixpath.basename(parsed_uri.path)\r\n        parsed_uri = parsed_uri._replace(path=posixpath.dirname(parsed_uri.path))\r\n        root_uri = prefix + urllib.parse.urlunparse(parsed_uri)\r\n\r\n    return get_artifact_repository(artifact_uri=root_uri).download_artifacts(\r\n        artifact_path=artifact_path, dst_path=output_path\r\n    )\r\n\r\n```\r\n","59":"Bumps [protobuf-java](https:\/\/github.com\/protocolbuffers\/protobuf) from 3.6.0 to 3.16.1.\n<details>\n<summary>Release notes<\/summary>\n<p><em>Sourced from <a href=\"https:\/\/github.com\/protocolbuffers\/protobuf\/releases\">protobuf-java's releases<\/a>.<\/em><\/p>\n<blockquote>\n<h2>Protocol Buffers v3.16.1<\/h2>\n<h1>Java<\/h1>\n<ul>\n<li>Improve performance characteristics of UnknownFieldSet parsing (<a href=\"https:\/\/github-redirect.dependabot.com\/protocolbuffers\/protobuf\/issues\/9371\">#9371<\/a>)<\/li>\n<\/ul>\n<h2>Protocol Buffers v3.16.0<\/h2>\n<h1>C++<\/h1>\n<ul>\n<li>Fix compiler warnings issue found in conformance_test_runner <a href=\"https:\/\/github-redirect.dependabot.com\/protocolbuffers\/protobuf\/issues\/8189\">#8189<\/a> (<a href=\"https:\/\/github-redirect.dependabot.com\/protocolbuffers\/protobuf\/issues\/8190\">#8190<\/a>)<\/li>\n<li>Fix MinGW-w64 build issues. (<a href=\"https:\/\/github-redirect.dependabot.com\/protocolbuffers\/protobuf\/issues\/8286\">#8286<\/a>)<\/li>\n<li>[Protoc] C++ Resolved an issue where NO_DESTROY and CONSTINIT are in incorrect order (<a href=\"https:\/\/github-redirect.dependabot.com\/protocolbuffers\/protobuf\/issues\/8296\">#8296<\/a>)<\/li>\n<li>Fix PROTOBUF_CONSTINIT macro redefinition (<a href=\"https:\/\/github-redirect.dependabot.com\/protocolbuffers\/protobuf\/issues\/8323\">#8323<\/a>)<\/li>\n<li>Delete StringPiecePod (<a href=\"https:\/\/github-redirect.dependabot.com\/protocolbuffers\/protobuf\/issues\/8353\">#8353<\/a>)<\/li>\n<li>Fix gcc error: comparison of unsigned expression in '&gt;= 0' is always \u2026 (<a href=\"https:\/\/github-redirect.dependabot.com\/protocolbuffers\/protobuf\/issues\/8309\">#8309<\/a>)<\/li>\n<li>Fix cmake install on iOS (<a href=\"https:\/\/github-redirect.dependabot.com\/protocolbuffers\/protobuf\/issues\/8301\">#8301<\/a>)<\/li>\n<li>Create a CMake option to control whether or not RTTI is enabled (<a href=\"https:\/\/github-redirect.dependabot.com\/protocolbuffers\/protobuf\/issues\/8347\">#8347<\/a>)<\/li>\n<li>Fix endian.h location on FreeBSD (<a href=\"https:\/\/github-redirect.dependabot.com\/protocolbuffers\/protobuf\/issues\/8351\">#8351<\/a>)<\/li>\n<li>Refactor util::Status (<a href=\"https:\/\/github-redirect.dependabot.com\/protocolbuffers\/protobuf\/issues\/8354\">#8354<\/a>)<\/li>\n<li>Make util::Status more similar to absl::Status (<a href=\"https:\/\/github-redirect.dependabot.com\/protocolbuffers\/protobuf\/issues\/8405\">#8405<\/a>)<\/li>\n<li>Fix -Wsuggest-destructor-override for generated C++ proto classes. (<a href=\"https:\/\/github-redirect.dependabot.com\/protocolbuffers\/protobuf\/issues\/8408\">#8408<\/a>)<\/li>\n<li>Refactor StatusOr and StringPiece (<a href=\"https:\/\/github-redirect.dependabot.com\/protocolbuffers\/protobuf\/issues\/8406\">#8406<\/a>)<\/li>\n<li>Refactor uint128 (<a href=\"https:\/\/github-redirect.dependabot.com\/protocolbuffers\/protobuf\/issues\/8416\">#8416<\/a>)<\/li>\n<li>The ::pb namespace is no longer exposed due to conflicts.<\/li>\n<li>Allow MessageDifferencer::TreatAsSet() (and friends) to override previous\ncalls instead of crashing.<\/li>\n<li>Reduce the size of generated proto headers for protos with <code>string<\/code> or\n<code>bytes<\/code> fields.<\/li>\n<li>Move arena() operation on uncommon path to out-of-line routine<\/li>\n<li>For iterator-pair function parameter types, take both iterators by value.<\/li>\n<li>Code-space savings and perhaps some modest performance improvements in\nRepeatedPtrField.<\/li>\n<li>Eliminate nullptr check from every tag parse.<\/li>\n<li>Remove unused _$name$<em>cached_byte_size<\/em> fields.<\/li>\n<li>Serialize extension ranges together when not broken by a proto field in the\nmiddle.<\/li>\n<li>Do out-of-line allocation and deallocation of string object in ArenaString.<\/li>\n<li>Streamline ParseContext::ParseMessage<!-- raw HTML omitted --> to avoid code bloat and improve\nperformance.<\/li>\n<li>New member functions RepeatedField::Assign, RepeatedPtrField::{Add, Assign}.<\/li>\n<li>Fix undefined behavior warning due to innocuous uninitialization of value\non an error path.<\/li>\n<li>Avoid expensive inlined code space for encoding message length for messages\n<blockquote>\n<p>= 128 bytes and instead do a procedure call to a shared out-of-line routine.<\/p>\n<\/blockquote>\n<\/li>\n<li>util::DefaultFieldComparator will be final in a future version of protobuf.\nSubclasses should inherit from SimpleFieldComparator instead.<\/li>\n<\/ul>\n<h1>C#<\/h1>\n<ul>\n<li>Add .NET 5 target and improve WriteString performance with SIMD (<a href=\"https:\/\/github-redirect.dependabot.com\/protocolbuffers\/protobuf\/issues\/8147\">#8147<\/a>)<\/li>\n<\/ul>\n<h1>Java<\/h1>\n<ul>\n<li>deps: update JUnit and Truth (<a href=\"https:\/\/github-redirect.dependabot.com\/protocolbuffers\/protobuf\/issues\/8319\">#8319<\/a>)<\/li>\n<li>Detect invalid overflow of byteLimit and return InvalidProtocolBufferException as documented.<\/li>\n<\/ul>\n<!-- raw HTML omitted -->\n<\/blockquote>\n<p>... (truncated)<\/p>\n<\/details>\n<details>\n<summary>Commits<\/summary>\n<ul>\n<li><a href=\"https:\/\/github.com\/protocolbuffers\/protobuf\/commit\/791a4355c365bd92720160671a7491be168055cb\"><code>791a435<\/code><\/a> Update protobuf version<\/li>\n<li><a href=\"https:\/\/github.com\/protocolbuffers\/protobuf\/commit\/e8918723cfecb60082f067a98df0a16ffc003b62\"><code>e891872<\/code><\/a> Update CHANGES.txt for 3.16.1 release<\/li>\n<li><a href=\"https:\/\/github.com\/protocolbuffers\/protobuf\/commit\/f554ccaa514967232cc494cf22947e1c73ca747f\"><code>f554cca<\/code><\/a> Improve performance of parsing unknown fields in Java (<a href=\"https:\/\/github-redirect.dependabot.com\/protocolbuffers\/protobuf\/issues\/9371\">#9371<\/a>)<\/li>\n<li><a href=\"https:\/\/github.com\/protocolbuffers\/protobuf\/commit\/2dc747c574b68a808ea4699d26942c8132fe2b09\"><code>2dc747c<\/code><\/a> Update PHP release notes and update version to 3.16.0 (<a href=\"https:\/\/github-redirect.dependabot.com\/protocolbuffers\/protobuf\/issues\/8573\">#8573<\/a>)<\/li>\n<li><a href=\"https:\/\/github.com\/protocolbuffers\/protobuf\/commit\/debc03dfc5d71d7d642dd1c8f7d1c04b36e8a065\"><code>debc03d<\/code><\/a> Update protobuf version to 3.16.0-rc2 (<a href=\"https:\/\/github-redirect.dependabot.com\/protocolbuffers\/protobuf\/issues\/8556\">#8556<\/a>)<\/li>\n<li><a href=\"https:\/\/github.com\/protocolbuffers\/protobuf\/commit\/17b0fb9149109e22d56cfa27f1f17b04508ea726\"><code>17b0fb9<\/code><\/a> Make update_version.py compatible with Python 3 (<a href=\"https:\/\/github-redirect.dependabot.com\/protocolbuffers\/protobuf\/issues\/8555\">#8555<\/a>)<\/li>\n<li><a href=\"https:\/\/github.com\/protocolbuffers\/protobuf\/commit\/4aa425c6c5eb7914582ebd67ab8ecac464bdf271\"><code>4aa425c<\/code><\/a> Cherry-pick <a href=\"https:\/\/github-redirect.dependabot.com\/protocolbuffers\/protobuf\/issues\/8356\">#8356<\/a> into 3.16.x (<a href=\"https:\/\/github-redirect.dependabot.com\/protocolbuffers\/protobuf\/issues\/8518\">#8518<\/a>)<\/li>\n<li><a href=\"https:\/\/github.com\/protocolbuffers\/protobuf\/commit\/e8b78f8208971a28e566198d38e43ad5f49a9009\"><code>e8b78f8<\/code><\/a> Fixed memory leak of Ruby arena objects. (<a href=\"https:\/\/github-redirect.dependabot.com\/protocolbuffers\/protobuf\/issues\/8465\">#8465<\/a>)<\/li>\n<li><a href=\"https:\/\/github.com\/protocolbuffers\/protobuf\/commit\/7689f00ba8d1e818f2a8e7a4bf24577d9ccd5d84\"><code>7689f00<\/code><\/a> Update protobuf version (<a href=\"https:\/\/github-redirect.dependabot.com\/protocolbuffers\/protobuf\/issues\/8448\">#8448<\/a>)<\/li>\n<li><a href=\"https:\/\/github.com\/protocolbuffers\/protobuf\/commit\/6099c6505d73681bf98a5c5d8908cb5c3fd1bab9\"><code>6099c65<\/code><\/a> Updated CHANGES.txt for 3.16.0 (<a href=\"https:\/\/github-redirect.dependabot.com\/protocolbuffers\/protobuf\/issues\/8456\">#8456<\/a>)<\/li>\n<li>Additional commits viewable in <a href=\"https:\/\/github.com\/protocolbuffers\/protobuf\/compare\/v3.6.0...v3.16.1\">compare view<\/a><\/li>\n<\/ul>\n<\/details>\n<br \/>\n\n\n[![Dependabot compatibility score](https:\/\/dependabot-badges.githubapp.com\/badges\/compatibility_score?dependency-name=com.google.protobuf:protobuf-java&package-manager=maven&previous-version=3.6.0&new-version=3.16.1)](https:\/\/docs.github.com\/en\/github\/managing-security-vulnerabilities\/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[\/\/]: # (dependabot-automerge-start)\n[\/\/]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options<\/summary>\n<br \/>\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n\nYou can disable automated security fix PRs for this repo from the [Security Alerts page](https:\/\/github.com\/mlflow\/mlflow\/network\/alerts).\n\n<\/details>","60":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [X] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nThe browser overview of a single run comes with the displayal of artifcats - one of them being the 'model' artifact. Conveniently, this also comes with code snippets on how to use the model at hand for predictions. As of now, these code snippets [seem hard to adapt](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/server\/js\/src\/experiment-tracking\/components\/artifact-view-components\/ShowArtifactLoggedModelView.js#L90-L121). For some users, the currently generated code snippets are not applicable and it would be desirable to change the snippets to custom code.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nA priori, a user will believe the code snippets to be correct and applicable - in some scenarios, e.g. when there are further dependencies for prediction such as a chaining of models, it doesn't. In these cases, it would be desirable to overwrite the generated code snippets. Moreover, other aspects, such as data loading, could be included if desired.\r\n- Why is this use case valuable to support for MLflow users in general?\r\nBeing able to customize these snippets could e.g. also allow to allow for some lines on data loading to be included. This, in turn, would make the snippets more complete and valuable.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nFor new team members especially, it can be quite confusing to display and advertise code snippets which are not applicable for the setup at hand since the mistake is easily assumed to lie on the user end. Independently of that, it seems undesirable to suggest approaches which are not applicable or simply 'don't work' due to particularities of the use case.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nMy understanding is that these code snippets are more or less hardcoded in javascript on the server side and not able to be defined via the python interface on the client side. See https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/server\/js\/src\/experiment-tracking\/components\/artifact-view-components\/ShowArtifactLoggedModelView.js#L90-L121\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [X] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [X] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nThe section at hand can be seen in the screenshot below:\r\n![Screenshot 2022-01-07 095232](https:\/\/user-images.githubusercontent.com\/43778085\/148520178-8fd8c275-c2e6-460e-baf7-e0187148bc11.png)\r\n\r\n","61":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [X] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nto have a way to get the model file from GCS by using signed url\r\n\r\n## Motivation\r\n- What is the use case for this feature? please refer to the detail section below\r\n- Why is this use case valuable to support for MLflow users in general? please refer to the detail section below\r\n- Why is this use case valuable to support for your project(s) or organization? please refer to the detail section below \r\n- Why is it currently difficult to achieve this use case? please refer to the detail section below \r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [X] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [X] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [X] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\nlet's take a look at the current deployment view of the model development flow with MLFlow.\r\n![mlflow-deployment](https:\/\/user-images.githubusercontent.com\/32842826\/148482528-af6b0a35-1769-4532-adfb-08a8bda369c6.png)\r\nthe picture above shows the high-level of system deployment view while ignoring several detailed components such as relational databases. Here are several important points which are related to this:\r\n- In this context, each model service components are a completely different service. They aren't replicas.\r\n- The VPC in yellow are the user artefacts, while the purple ones are managed by the our team.\r\n- MLFlow service is exposed through a public API that is only accessible by other internal services. We use openresty as the proxy.\r\n- Google Cloud Storage (GCS) doesn't lie inside the VPC. It's accessible through the internet. But, it's protected by a perimeter.\r\n\r\nNext, let's zoom into the main use case of this system, which is to fetch models from the MLFlow service.\r\n![mlflow-deployment (2)](https:\/\/user-images.githubusercontent.com\/32842826\/148485032-145eca4d-c719-4adf-ace9-2a3d210b1d5e.png)\r\nthe picture above shows the flow of the main use case of this system. The flow happens sequentially, but each request can be parallelized. Here is the detail of the flow:\r\n1.  MLFlow returns the GCS URL of the model, not the model itself.\r\n2.  Next, the model service requests the file to the GCS.\r\n3. GCS returns the requested files.\r\n\r\nyou can see the problem lies when the users need to get the model file directly to GCS. they can't do that due to the perimeter.\r\n","62":"I am trying to start the mlflow ui in the notebook (using !mlfloe ui) but the server page of mlflow  is :\r\n\r\nSomething went wrong\r\nIf this error persists, please report an issue here.\r\n\r\nwhet seems to be the problem? \r\n\r\nthanks for you help:)\r\n![image](https:\/\/user-images.githubusercontent.com\/96474496\/148365262-a9424df7-9a11-4d20-8784-f53522e0c9d9.png)\r\n","63":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [X] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No \r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OSX 12.1\r\n- **MLflow installed from (source or binary)**: Source\r\n- **MLflow version (run ``mlflow --version``)**: 1.22.1.dev0\r\n- **Python version**: 3.7.10\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: `mlflow.create_experiment(\" \")`\r\n\r\n### Describe the problem\r\n\r\nIn a conversation resolving a documentation issue [here](https:\/\/github.com\/mlflow\/mlflow\/issues\/4199#issuecomment-1006221093), we realized that we can create an experiment name with an empty string (ie. `\" \"`), and this was indicated to be a [bug](https:\/\/github.com\/mlflow\/mlflow\/issues\/4199#issuecomment-1006221093). \r\n\r\n### Code to reproduce issue\r\n\r\n```\r\nPython 3.7.10 (default, Feb 26 2021, 10:16:00)\r\n[Clang 10.0.0 ] :: Anaconda, Inc. on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import mlflow\r\n>>> mlflow.__version__\r\n'1.22.1.dev0'\r\n>>> experiment_id = mlflow.create_experiment(\" \")\r\n>>> experiment_id\r\n'1'\r\n>>> experiment = mlflow.get_experiment(experiment_id)\r\n>>> experiment.name\r\n' '\r\n>>> experiment.experiment_id\r\n'1'\r\n>>> experiment.lifecycle_stage\r\n'active'\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [X] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","64":"Hello and Happy New Year 2022! :tada: \r\nJust wondering if you already heard about quite the new **Pytorch Lightning (PL) ecosystem CI** where we would like to invite you to... You can check out our blog post about it: [Stay Ahead of Breaking Changes with the New Lightning Ecosystem CI](https:\/\/devblog.pytorchlightning.ai\/stay-ahead-of-breaking-changes-with-the-new-lightning-ecosystem-ci-b7e1cf78a6c7) :zap: \r\nWe already have joined integration between PL and your logger, so we would like to level it up. At this moment, we are running tests with your latest version, but it may accidentally happen that your next version will be incompatible with our next release version... :confused:  But here we have a solution - ecosystem CI with testing both - your and our latest development head we can find it very early and prevent releasing eventually bad version... :+1: \r\n\r\n### What is needed to do?\r\n- have some tests, including PL integration\r\n- add config to ecosystem CI - https:\/\/github.com\/PyTorchLightning\/ecosystem-ci\r\n\r\n### What will you get?\r\n- scheduled nightly testing configured development\/stable heads\r\n- slack notification if something went wrong\r\n- testing also on multi-GPU machine","65":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nAdd versioning of MLroject file specification and add support to mlflow working with different versions of MLproject file. \r\n\r\n## Motivation\r\nToday mlflow uses single file format. In this approach, it is necessary to maintain backward compatibility when adding a new feature. For example, there is feature request #4246 (adding poetry to create environment). To implement it we need to add another if condition to [here](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/projects\/_project_spec.py#L38)\r\n```python\r\n    docker_env = yaml_obj.get(\"docker_env\")\r\n    if docker_env:\r\n   ...\r\n    # Validate config if conda_env parameter is present\r\n    conda_path = yaml_obj.get(\"conda_env\")\r\n    if conda_path and docker_env:\r\n        raise ExecutionException(\"Project cannot contain both a docker and \" \"conda environment.\")\r\n```\r\nThat approach will look not great and in my opinion it better to add environment field to MLproject file, something like this\r\n```yaml\r\nenv:\r\n  type: docker\r\n  image: python:3.7\r\n```\r\nor \r\n```yaml\r\nenv:\r\n  type: conda\r\n  file: conda.yaml\r\n```\r\nThis type of change will break backaward compability. To get good user experience of using projects explicit information about used version of the file should be given.\r\n\r\nThus, proposal will next: add version field to MLproject file and add mlflow support of using different version of MLproject file specification. For example, like it uses in [docker compose file](https:\/\/docs.docker.com\/compose\/compose-file\/) and [kubernetes apiVersion field](https:\/\/kubernetes.io\/docs\/concepts\/overview\/working-with-objects\/kubernetes-objects\/).  \r\nTo save backaward campability of current version it posible to maintain current functionality without  adding version field in file. To use new functionality user have to add version field to MLproject file.\r\n\r\nFiles in package projects will be affected (I can add more details if needed).  \r\n\r\nNext pros and cons \r\nPros:\r\n- possibility to break backward compatibility and add new features with less effort\r\n- explicit information which functionality is available for installed version of mlflow\r\n\r\nCons:\r\n- user should know version of MLproject file specification (using of major+minor versioning with compatibility for major version can help to reduce this problem).\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","66":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nCurrently, MLFlow's spark flavor only support saving\/logging classes that are `Models`, and it means even those popular `Transformers` like `Bucketizer` can't call save\/log\/predict. Could you support `Transformers` since both of them belong to `Pipeline` and it makes more sense if we can just call the same behavior for models and transformers.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nSave, log and inference with spark transformers.\r\n- Why is this use case valuable to support for MLflow users in general?\r\nMLFlow spark already support `models`, and transformers are just like models that can be put into pipelines.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nIt makes models and transformers behaviors consistent, and users can keep track of them using mlflow following the same pattern.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nMlflow spark currently has a strict check that only classes of type `pyspark.ml.model` can be passed to the following save_model function, so for transformers we must wrap it as pipeline model in order to save it, which makes the process more complicated. So if you could add transformers into the `_validate_model` function then it can directly be saved by mlflow.spark.save_model.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nWe want to support all pyspark ml Transformers with the ability to save, log and load with mlflow.spark. For example, VectorAssembler class is a typical type of Transformer that merges multiple columns into a vector column. And Transformers can be a stage of PipelineModel. So the suggested change is as follows:\r\n\r\nFor file mlflow\/spark.py we change the _validate_model to support Transformer:\r\n\r\n```\r\ndef _validate_model(spark_model):\r\n    from pyspark.ml.util import MLReadable, MLWritable\r\n    from pyspark.ml import Model as PySparkModel\r\n    from pyspark.ml import Transformer as PySparkTransformer\r\n\r\n    if (\r\n        (\r\n            not isinstance(spark_model, PySparkModel)\r\n            and not isinstance(spark_model, PySparkTransformer)\r\n        )\r\n        or not isinstance(spark_model, MLReadable)\r\n        or not isinstance(spark_model, MLWritable)\r\n    ):\r\n        raise MlflowException(\r\n            \"Cannot serialize this model. MLflow can only save descendants of pyspark.Model\"\r\n            \"that implement MLWritable and MLReadable.\",\r\n            INVALID_PARAMETER_VALUE,\r\n        )\r\n```\r\n\r\nAs we can see in save_model function:\r\n`if not isinstance(spark_model, PipelineModel):\r\n        spark_model = PipelineModel([spark_model])`\r\nAnd Transformers can also be put here so save_model will just work. log_model is the same.\r\nFor load_model it will finally load the PipelineModel back so the Transformers make no difference. We could still load PipelineModel back and call `transform` API on it.\r\n\r\nThe only difference would be that Transformers may not support `predict` function as that requires a column named `prediction`. Transformers are not designed as predictors so it's reasonable, and people can always specify the output column name as `prediction` if they insist on using this feature.","67":"Hi, \r\n\r\nI'm working on OSX 11.6.1 with RStudio 2021.09.0 and R 4.1.2 installed through Homebew 3.3.9. I used the quickstart instructions to install mlflow and it seemed to work, as far as the single training and the UI go. But when I try to run \r\n\r\n`> mlflow_run(uri = \".\/\", entry_point = \"train.R\")`\r\n\r\nI get the following error:\r\n\r\n> 2022\/01\/03 15:49:15 INFO mlflow.projects.utils: === Created directory \/var\/folders\/lk\/yxcpm09j299_b_kcp0v7pcv00000gn\/T\/tmpfvs7pcgm for downloading remote URIs passed to arguments of type 'path' ===\r\n2022\/01\/03 15:49:15 INFO mlflow.projects.backend.local: === Running command 'source \/Users\/mitch\/Library\/r-miniconda\/bin\/..\/etc\/profile.d\/conda.sh && conda activate mlflow-da39a3ee5e6b4b0d3255bfef95601890afd80709 1>&2 && Rscript -e \"mlflow::mlflow_source('train.R')\" --args' in run with ID '51e04222838f46fcb38343afb7a34d8c' === \r\nbash: Rscript: command not found\r\n2022\/01\/03 15:49:16 ERROR mlflow.cli: === Run (ID '51e04222838f46fcb38343afb7a34d8c') failed ===\r\nError in run(mlflow_bin, args = unlist(args), echo = echo, echo_cmd = verbose,  : \r\n  System command 'mlflow' failed, exit status: 1, stdout & stderr were printed \r\n\r\nNote that it works fine when I try to run the following in the shell:\r\n\r\n`source \/Users\/mitch\/Library\/r-miniconda\/bin\/..\/etc\/profile.d\/conda.sh `\r\n`conda activate mlflow-da39a3ee5e6b4b0d3255bfef95601890afd80709`\r\n`Rscript -e \"mlflow::mlflow_source('train.R')\" --args`\r\n\r\nIt just seems that the CLI does not get the path to Rscript (which is in its standard location \/opt\/homebrew\/bin\/Rscript). \r\n\r\nThanks for your help!\r\nMichel\r\n\r\n\r\n\r\n\r\n","68":"I have created my Own API for Creating Experiments, it always requesting Get method instead of Post. where do i change this to Post Method? it's bit urgent someone help me to solve this\r\n","69":"## Willingness to contribute\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nThe requested feature will allow users of mlflow (directly or e.g. through [optuna](https:\/\/github.com\/optuna\/optuna\/tree\/master\/optuna)) to avoid using connection pools when relying on RDBMS. In this case, a connection is made for each transaction then closed afterwards.\r\n\r\n## Motivation\r\n\r\nTo control the connections to the database when the program is run by parallel processes (or nodes). Using `pool_size=1` and `max_overflow=1` can efficiently serve this purpose if the script is run by a single process, but doesn't prevent overwhelming the database server when the program is run by parallel processes.\r\n\r\nThe motivation arose when I deployed my program of model training and evaluation for hyperparameters search within an HPC environment. The program instances were aborted due to SQLAlchemy exception indicating that maximum connections to the database has been reached. I also received a report from the server admin conveying that this behavior has affected other users of the database server and limited their access.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [x] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nBy consulting the documentation of [sqlalchemy.create_engine](https:\/\/docs.sqlalchemy.org\/en\/14\/core\/engines.html#sqlalchemy.create_engine.params.poolclass), this turns out to be solved if we set `poolclass` to `pool.NullPool`.\r\n\r\nHere is a proposed solution for this request:\r\n\r\n[A-Alaa\/mlflow\/tree\/null_pool](https:\/\/github.com\/A-Alaa\/mlflow\/tree\/null_pool)\r\n","70":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nAPI calls should return `HTTP 400` when the parameters (e.g.) don't match expected data types instead of failing with a `500`. Creating a JSON schema -- using [jsonschema](https:\/\/github.com\/Julian\/jsonschema), for example -- for the MLFlow REST API to check requests against would fix these issues. This would result in far friendlier UX, easier debugging, more predictable responses, and a generally more RESTful API.\r\n\r\n## Motivation\r\n\r\nI keep getting `500` errors for things like supplying a parameter to an API call that's the wrong data type. See [this issue](https:\/\/github.com\/mlflow\/mlflow\/issues\/5199) for an example. This has also happened with calls to logging parameters (both individually and in batches) and all kinds of other functions.\r\n\r\nRight now, this means that an end user of a running MLFlow service get an error message like this back when something goes wrong:\r\n\r\n```\r\nResponse [https:\/\/<<host>>\/api\/2.0\/mlflow\/runs\/log-batch]\r\n  Date: 2021-12-29 20:15\r\n  Status: 500\r\n  Content-Type: text\/html; charset=utf-8\r\n  Size: 290 B\r\n<!DOCTYPE HTML PUBLIC \"-\/\/W3C\/\/DTD HTML 3.2 Final\/\/EN\">\r\n<title>500 Internal Server Error<\/title>\r\n<h1>Internal Server Error<\/h1>\r\n<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.<\/p>\r\n```\r\n\r\nThis error was caused by providing a `timestamp` value to `log-batch` that was a character string as opposed to a numeric timestamp.\r\n\r\nObviously, this error is unhelpful. There's no indication of what went wrong or how to fix the issue. More importantly, the `500` is a hint that the client actually _did not do anything wrong_, and that there was a legitimate issue on the server side. For bad parameters (e.g.), this is obviously not the case, and the client should be seeing an error message with information about the incorrect parameter type and what type was expected, not a cryptic `500` with `Unable to complete your request`.\r\n\r\nThe value prop here should be relatively obvious, so I won't write too much beyond just saying that validating requests against a JSON schema would let users of the MLFlow REST API (in other words, every MLFlow user) more easily and reliably use MLFlow, develop wrappers for the MLFlow API, debug their code when things go wrong, etc. etc. etc.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [x] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nI haven't written any JSON schema for Python, but in R I know it's easy to just set up a function to validate requests and then use that function to validate the JSON body of any requests that come in before doing any actual work. If a request fails the JSON validation checks, you can easily return an `HTTP 400 -- JSON validation failed with << some error >>`.\r\n\r\nLet me know if I can help with this improvement! I think it'd be a major step forward for everyone using MLFlow and for the project in general.\r\n","71":"**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ X ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nI am unsure if it is a feature request or a bug:\r\nA mlflow model loaded from the registry using `mlflow.pyfunc` that uses a model_signature based on pandas DataFrames does not accept None values for numeric data types (it works for strings). As pandas is supporting nullable numeric types these days, it would be very helpful if mlflow could also support these.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\n## code to show that this currently does not work:\r\n\r\n```\r\nimport mlflow\r\nmlflow.autolog(\r\n    log_model_signatures=True,\r\n    log_models=True\r\n)\r\n\r\nimport numpy as np\r\nfrom sklearn.ensemble import RandomForestClassifier\r\nfrom sklearn.impute import SimpleImputer\r\nfrom sklearn.pipeline import Pipeline \r\nimport pandas as pd\r\n\r\nX_train = pd.DataFrame([[0, 0, np.nan], [np.nan, 1, 1], [np.nan, 0, 0]], columns=[\"c1\", \"c2\", \"c3\"])\r\nY_train = pd.DataFrame([0, 1, 0], columns=[\"label\"])\r\nX_test = pd.DataFrame([[0, 0, np.nan], [0, np.nan, np.nan], [0, 1,0]], columns=[\"c1\", \"c2\", \"c3\"])\r\n\r\n# Create our imputer to replace missing values with the mean e.g.\r\nimp = SimpleImputer(missing_values=np.nan, strategy='mean')\r\nclf = RandomForestClassifier(n_estimators=10)\r\n\r\npipe = Pipeline(steps=[(\"prepare\",imp), (\"clr\",clf)])\r\npipe.fit(X_train, Y_train)\r\n\r\npipe.predict(X_test)\r\n# outputs: array([0, 0, 0])\r\n```\r\n\r\nThen go to the registry, register the model of the run and adapt the load_function below accordingly\r\n\r\n```\r\nfrom mlflow.pyfunc import load_model\r\nm = load_model(f\"models:\/nan_problem\/1\")\r\nprint(m.metadata.signature)\r\n# inputs: \r\n#   ['c1': double, 'c2': long, 'c3': double]\r\n# outputs: \r\n#   [Tensor('int64', (-1,))]\r\n\r\nm.predict(X_test)\r\n# >> MlflowException: Incompatible input types for column c1. Can not safely convert int64 to float64.\r\n\r\n```\r\n\r\n## Stacktrace:\r\n```\r\n\r\n---------------------------------------------------------------------------\r\nMlflowException                           Traceback (most recent call last)\r\n\/var\/folders\/ym\/_50l9__942705dh4x6gh9d9r0000gn\/T\/ipykernel_85093\/2409685277.py in <module>\r\n      2 m = load_model(f\"models:\/nan_problem\/3\")\r\n      3 print(m.metadata.signature)\r\n----> 4 m.predict(X_test)\r\n\r\n~\/.pyenv\/versions\/3.8.7\/lib\/python3.8\/site-packages\/mlflow\/pyfunc\/__init__.py in predict(self, data)\r\n    605         input_schema = self.metadata.get_input_schema()\r\n    606         if input_schema is not None:\r\n--> 607             data = _enforce_schema(data, input_schema)\r\n    608         return self._model_impl.predict(data)\r\n    609 \r\n\r\n~\/.pyenv\/versions\/3.8.7\/lib\/python3.8\/site-packages\/mlflow\/pyfunc\/__init__.py in _enforce_schema(pfInput, input_schema)\r\n    563         _enforce_tensor_schema(pfInput, input_schema)\r\n    564         if input_schema.is_tensor_spec()\r\n--> 565         else _enforce_col_schema(pfInput, input_schema)\r\n    566     )\r\n    567 \r\n\r\n~\/.pyenv\/versions\/3.8.7\/lib\/python3.8\/site-packages\/mlflow\/pyfunc\/__init__.py in _enforce_col_schema(pfInput, input_schema)\r\n    452     new_pfInput = pandas.DataFrame()\r\n    453     for i, x in enumerate(input_names):\r\n--> 454         new_pfInput[x] = _enforce_mlflow_datatype(x, pfInput[x], input_types[i])\r\n    455     return new_pfInput\r\n    456 \r\n\r\n~\/.pyenv\/versions\/3.8.7\/lib\/python3.8\/site-packages\/mlflow\/pyfunc\/__init__.py in _enforce_mlflow_datatype(name, values, t)\r\n    407             )\r\n    408 \r\n--> 409         raise MlflowException(\r\n    410             \"Incompatible input types for column {0}. \"\r\n    411             \"Can not safely convert {1} to {2}.{3}\".format(name, values.dtype, numpy_type, hint)\r\n\r\nMlflowException: Incompatible input types for column c1. Can not safely convert int64 to float64.\r\n```\r\n\r\n","72":"### Willingness to contribute\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: docker `continuumio\/miniconda3` on Azure's Compute Instance\r\n- **MLflow installed from (source or binary)**: R's `install_mlflow()`\r\n- **MLflow version (run ``mlflow --version``)**: 1.22.0\r\n- **Python version**: 3.9\r\n\r\n### Describe the problem\r\nI am trying to use MLFlow on Azure's ML Compute Instances to track my experiments in R. The tracking URI set by the compute instance has the scheme `azureml:\/\/...` which is not supported by MLFlow. Azure has a [package](https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-mlflow\/?view=azure-ml-py) to enable support on Python, but as my code is in R, I found that I need to manually change the URI to `https:\/\/...` to make logging work.\r\n\r\nChanging the Tracking URI works correctly (i.e. I can log params and metrics) when setting the `MLFLOW_ARTIFACT_URI` environment variable or when calling `mlflow_set_tracking_uri()`, but it doesn't seem to have any effect on the artifact URI (related to #3469) as it is still using the old scheme (the one starting with `azureml:\/\/`), so I am not able to log artifacts.\r\n\r\nI see no method on [MLFlow's R API](https:\/\/www.mlflow.org\/docs\/latest\/R-api.html#mlflow-server) to change the artifact's URI scheme (and #2577 seems to be related, but I created a different issue as I don't want to re-define the whole URI, but just the scheme) and workarounds are possible at least while Microsoft implements an R API (I hope it happens someday), but I was wondering if MLFlow has any suggestion on this or if a new feature that could help this use-case is in the plan.\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nLanguage \r\n- [x] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [x] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","73":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nIn the experiment comparison, \"compare data on hover\" shows the metric. I feel it might be more useful if the parameters can be shown. \r\n![newplot](https:\/\/user-images.githubusercontent.com\/46158005\/147480978-34621901-7d81-48e9-b909-71ab16c6dd62.png)\r\n\r\n## Motivation\r\n- What is the use case for this feature? Comparison of different experimental runs; when the experiments are grouped by parameters. It is currently to convenient (at least for me to track the parameters from graphs).\r\n- Why is this use case valuable to support for MLflow users in general? Pls. see above and the graphs.\r\n- Why is this use case valuable to support for your project(s) or organization? Pls see above and graphs.\r\n- Why is it currently difficult to achieve this use case? Currently, the comparison is not convenient when the experiment management is based on experiments. Eg, if the project name is \"CatsDogsClassification\", the experiment might involve trying out a couple of models. Those would be the experiment name: eg \"DenseNet121\", \"SENet154\".  There would be multiple runs of each of these networks. Now, if we want to compare key parameters, this is not possible unless we start encoding the parameter name in the experiment Run Name. This makes it unnaturally long. Therefore, along with the key metric, if there is some way of displaying the parameters; i think it will be useful.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ x] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","74":"## What changes are proposed in this pull request?\r\n\r\nAdding Scikit-learn Example to get the better understanding of the following :\r\n\r\n- How to log a pre-trained model (all the existing examples have added the training code with it)\r\n- How to add signature in your model\r\n- How to register your model through code\r\n- How to shift your model into production through code\r\n\r\n## How is this patch tested?\r\n\r\nThis code is tested locally using mlflow CLI\r\n\r\n## Does this PR change the documentation?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Make sure the changed pages \/ sections render correctly by following the steps below.\r\n\r\n1. Check the status of the `ci\/circleci: build_doc` check. If it's successful, proceed to the\r\n   next step, otherwise fix it.\r\n2. Click `Details` on the right to open the job page of CircleCI.\r\n3. Click the `Artifacts` tab.\r\n4. Click `docs\/build\/html\/index.html`.\r\n5. Find the changed pages \/ sections and make sure they render correctly.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [x] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","75":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Monterrey (MLFlow hosted on Linux -- Docker + Heroku)\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**:\r\n- **Python version**:\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n\r\nTrying to run `mlflow::mlflow_transition_model_version_stage` as follows:\r\n\r\n```r\r\nmlflow_transition_model_version_stage(\r\n    name = \"foo\",\r\n    version = 1,\r\n    stage = \"Staging\"\r\n)\r\n```\r\n\r\ngives me the following errors. In R, I see this:\r\n\r\n```r\r\nError: API request to endpoint 'model-versions\/transition-stage' failed with error code 500. Reponse body: '<!DOCTYPE HTML PUBLIC \"-\/\/W3C\/\/DTD HTML 3.2 Final\/\/EN\">\r\n<title>500 Internal Server Error<\/title>\r\n<h1>Internal Server Error<\/h1>\r\n<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.<\/p>\r\n'\r\n```\r\n\r\nand in my Heroku logs, I see this:\r\n\r\n```bash\r\n2021-12-25T04:55:31.636699+00:00 heroku[router]: at=info method=POST path=\"\/api\/2.0\/mlflow\/model-versions\/transition-stage\" host=<<my host>> request_id=<<rid>> fwd=... dyno=web.1 connect=0ms service=2ms status=500 bytes=463 protocol=https\r\n2021-12-25T04:55:31.635410+00:00 app[web.1]: 2021\/12\/25 04:55:31 ERROR mlflow.server: Exception on \/api\/2.0\/mlflow\/model-versions\/transition-stage [POST]\r\n2021-12-25T04:55:31.635418+00:00 app[web.1]: Traceback (most recent call last):\r\n2021-12-25T04:55:31.635419+00:00 app[web.1]:   File \"\/opt\/conda\/lib\/python3.9\/site-packages\/google\/protobuf\/json_format.py\", line 585, in _ConvertFieldValuePair\r\n2021-12-25T04:55:31.635420+00:00 app[web.1]:     setattr(message, field.name, _ConvertScalarFieldValue(value, field))\r\n2021-12-25T04:55:31.635420+00:00 app[web.1]:   File \"\/opt\/conda\/lib\/python3.9\/site-packages\/google\/protobuf\/json_format.py\", line 720, in _ConvertScalarFieldValue\r\n2021-12-25T04:55:31.635421+00:00 app[web.1]:     return _ConvertBool(value, require_str)\r\n2021-12-25T04:55:31.635421+00:00 app[web.1]:   File \"\/opt\/conda\/lib\/python3.9\/site-packages\/google\/protobuf\/json_format.py\", line 838, in _ConvertBool\r\n2021-12-25T04:55:31.635422+00:00 app[web.1]:     raise ParseError('Expected true or false without quotes.')\r\n2021-12-25T04:55:31.635423+00:00 app[web.1]: google.protobuf.json_format.ParseError: Expected true or false without quotes.\r\n2021-12-25T04:55:31.635423+00:00 app[web.1]: \r\n2021-12-25T04:55:31.635424+00:00 app[web.1]: During handling of the above exception, another exception occurred:\r\n2021-12-25T04:55:31.635424+00:00 app[web.1]: \r\n2021-12-25T04:55:31.635424+00:00 app[web.1]: Traceback (most recent call last):\r\n2021-12-25T04:55:31.635425+00:00 app[web.1]:   File \"\/opt\/conda\/lib\/python3.9\/site-packages\/flask\/app.py\", line 2073, in wsgi_app\r\n2021-12-25T04:55:31.635425+00:00 app[web.1]:     response = self.full_dispatch_request()\r\n2021-12-25T04:55:31.635426+00:00 app[web.1]:   File \"\/opt\/conda\/lib\/python3.9\/site-packages\/flask\/app.py\", line 1518, in full_dispatch_request\r\n2021-12-25T04:55:31.635426+00:00 app[web.1]:     rv = self.handle_user_exception(e)\r\n2021-12-25T04:55:31.635426+00:00 app[web.1]:   File \"\/opt\/conda\/lib\/python3.9\/site-packages\/flask\/app.py\", line 1516, in full_dispatch_request\r\n2021-12-25T04:55:31.635427+00:00 app[web.1]:     rv = self.dispatch_request()\r\n2021-12-25T04:55:31.635427+00:00 app[web.1]:   File \"\/opt\/conda\/lib\/python3.9\/site-packages\/flask\/app.py\", line 1502, in dispatch_request\r\n2021-12-25T04:55:31.635427+00:00 app[web.1]:     return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\r\n2021-12-25T04:55:31.635428+00:00 app[web.1]:   File \"\/opt\/conda\/lib\/python3.9\/site-packages\/mlflow\/server\/handlers.py\", line 238, in wrapper\r\n2021-12-25T04:55:31.635428+00:00 app[web.1]:     return func(*args, **kwargs)\r\n2021-12-25T04:55:31.635428+00:00 app[web.1]:   File \"\/opt\/conda\/lib\/python3.9\/site-packages\/mlflow\/server\/handlers.py\", line 767, in _transition_stage\r\n2021-12-25T04:55:31.635429+00:00 app[web.1]:     request_message = _get_request_message(TransitionModelVersionStage())\r\n2021-12-25T04:55:31.635429+00:00 app[web.1]:   File \"\/opt\/conda\/lib\/python3.9\/site-packages\/mlflow\/server\/handlers.py\", line 219, in _get_request_message\r\n2021-12-25T04:55:31.635429+00:00 app[web.1]:     parse_dict(request_json, request_message)\r\n2021-12-25T04:55:31.635430+00:00 app[web.1]:   File \"\/opt\/conda\/lib\/python3.9\/site-packages\/mlflow\/utils\/proto_json_utils.py\", line 153, in parse_dict\r\n2021-12-25T04:55:31.635430+00:00 app[web.1]:     ParseDict(js_dict=js_dict, message=message, ignore_unknown_fields=True)\r\n2021-12-25T04:55:31.635430+00:00 app[web.1]:   File \"\/opt\/conda\/lib\/python3.9\/site-packages\/google\/protobuf\/json_format.py\", line 445, in ParseDict\r\n2021-12-25T04:55:31.635431+00:00 app[web.1]:     parser.ConvertMessage(js_dict, message)\r\n2021-12-25T04:55:31.635431+00:00 app[web.1]:   File \"\/opt\/conda\/lib\/python3.9\/site-packages\/google\/protobuf\/json_format.py\", line 476, in ConvertMessage\r\n2021-12-25T04:55:31.635431+00:00 app[web.1]:     self._ConvertFieldValuePair(value, message)\r\n2021-12-25T04:55:31.635432+00:00 app[web.1]:   File \"\/opt\/conda\/lib\/python3.9\/site-packages\/google\/protobuf\/json_format.py\", line 588, in _ConvertFieldValuePair\r\n2021-12-25T04:55:31.635432+00:00 app[web.1]:     raise ParseError('Failed to parse {0} field: {1}.'.format(name, e))\r\n2021-12-25T04:55:31.635433+00:00 app[web.1]: google.protobuf.json_format.ParseError: Failed to parse archive_existing_versions field: Expected true or false without quotes..\r\n```\r\n\r\nI'm not sure how to repro this more cleanly, but it seems like a bug. I tried explicitly setting the `archive_existing_versions` argument to a bunch of different things (i.e. `TRUE`, `FALSE`, `\"true\"`, `\"false\"`, etc.) to no avail.\r\n\r\nAnd while we're at I also noticed a small typo in the R package documentation under `?mlflow_transition_model_version_stage`: `Transition 'model_version' to this tage.` --> `Transition 'model_version' to this stage.`. It'd also be helpful to list out what the allowed stages are in the docs and to use something like `match.arg()` [at this point in the code](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/R\/mlflow\/R\/model-registry.R#L302-L306) to match against the allowed stages (I'd be happy to PR this change -- it'd be easy). \r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [x] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","76":"I am trying to launch mlflow ui in iframe but it gives DOM exception ...Blocked a frame with origin from accessing a cross origin frame error. I am working in python DASH app. Inside DASH app I want to launch mlflow ui but I am not able to do so with iframe .\r\n\r\nCan anyone suggest how to solve this issue.","77":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**:\r\n- **Python version**:\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\nI was serving a model using MLFlow model serve, the model won't serve until I put the source code in the same directory of the MLModel file so that I serve it. I want to serve the MLModel file without the need of the source code.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nCan't reproduce.\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nI thought the method load_context() in a wrapper class would help me to avoid this but I couldn't make it didn't have the result I was hoping for either. I implemented it like this:\r\n\r\n```\r\nclass Wrapper(PythonModel):\r\n    def __init__(self):\r\n        self.logger = get_logger(name='model')\r\n        self.model = None\r\n\r\n    def predict(self, context, model_input):\r\n        self.logger.warning(model_input)\r\n        return self.model.predict(model_input.values)\r\n\r\n    def load_context(self, context):\r\n        self.model = mlflow.pyfunc.load_model(path_to_model)\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","78":"how to fix this error ?\r\nmlflow.exceptions.MlflowException : la demande d'API \u00e0 http:\/\/0.0.0.0:5000\/api\/2.0\/mlflow\/runs\/create a \u00e9chou\u00e9 avec l'exception HTTPConnectionPool(host='0.0.0.0', port=5000) : nombre maximal de tentatives d\u00e9pass\u00e9 avec URL : \/api\/2.0\/mlflow\/runs\/create (caus\u00e9 par ResponseError('trop de 500 r\u00e9ponses d'erreur'))","79":"Signed-off-by: bramrodenburg <14278376+bramrodenburg@users.noreply.github.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nFixed issue #2804 in which users cannot specify the `run_name` when running an MLproject. \r\n\r\n## How is this patch tested?\r\n\r\n\r\n\r\n## Does this PR change the documentation?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Make sure the changed pages \/ sections render correctly by following the steps below.\r\n\r\n1. Check the status of the `ci\/circleci: build_doc` check. If it's successful, proceed to the\r\n   next step, otherwise fix it.\r\n2. Click `Details` on the right to open the job page of CircleCI.\r\n3. Click the `Artifacts` tab.\r\n4. Click `docs\/build\/html\/index.html`.\r\n5. Find the changed pages \/ sections and make sure they render correctly.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nUser can now specify the run_name when running an MLflow Project.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [x] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","80":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code: Yes\r\n- **OS Platform and Distribution:  Linux Ubuntu 18.04\r\n- **MLflow installed from: binary\r\n- **MLflow version: 1.22.0\r\n- **Python version: 3.8\r\n\r\n### Describe the problem\r\nThe metrics visualization of all runs in an experiment becomes broken\/are just plotted as a single constant value. Instead of showing the actual metric curve just a rectangular big blue box is plotted. Before everything is logged and visualized fine and at some point the metric visualization gets broken. This is then also the case for all metric values and also for previous runs under the same experiment name that were vsualized correctly before. It looks like in the database something is messed up and only the most recent metric value is stored without the past values which results in a overall constant metric. The broken curve looks like this (same for all other metric curves in the same experiment):\r\n![grafik](https:\/\/user-images.githubusercontent.com\/16177860\/146753090-9a971e69-5fbe-47cf-b834-eae1be66d685.png)\r\n\r\nI still could not find out when this happens. The only thing I know is that this happens after some time after multiple experiment runs then suddenly all metrics are broken. I should also add that I mostly stopp runs with Ctrl+C and not let them properly finish. \r\n\r\nMinimal code for logging that reproduces this behaviour is: \r\n   ```\r\n mlflow.set_experiment(\"my-example-experiment\")\r\n with mlflow.start_run():\r\n        mlflow.log_param(\"a\", 1)\r\n        mlflow.log_metric(\"b\", 2, step=0)\r\n        mlflow.log_metric(\"b\", 3, step=1)\r\n```\r\n\r\nRunning this many times after some time the metric visualization of \"b\" looks rectangualr\/broken instead of a line going from 2 to 3. Did anyone also experience this issue?\r\n\r\nIntegrations\r\n- [ x] `integrations\/azure`: MLFlow tracking server deployed in Azure App Service where the backend store is a managed PostgreSQL database.\r\n","81":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nThe mlflow R package has dropped support for `{mleap}` (https:\/\/github.com\/mlflow\/mlflow\/pull\/5166) which will become problematic as people who've depended on this have no alternative flavor to use. `{carrier}` package will not work for these cases.\r\n\r\nPropose that we either add `{mleap}` support back and help maintain `{mleap}` as it will continue to be the method used via python.\r\n\r\nAlternatively we can add a flavour specific to `{sparklyr}` but it will break more supporting functions (I've got a half-working prototype).\r\n\r\n\r\n\r\n## Motivation\r\nCurrently there is no supported flavor for models trained via `{sparklyr}` and it will become a barrier for existing users as they upgrade.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [x] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [x] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nCode that could be basis of an alternative to `{mleap}`, I don't think we should pursue this but just incase I tested it.\r\n\r\n```\r\nmlflow_save_model.ml_pipeline_model <- function(model,\r\n                                       path,\r\n                                       model_spec = list(),\r\n                                       conda_env = NULL,\r\n                                       ...) {\r\n  \r\n  mlflow:::assert_pkg_installed(\"sparklyr\")\r\n  if (dir.exists(path)) unlink(path, recursive = TRUE)\r\n  dir.create(path)\r\n  \r\n  model_data_subpath <- \"sparklyr\"\r\n  dir.create(file.path(path, model_data_subpath))\r\n  \r\n  # sparklyr::ml_save uses `invoke(\"save\", path)` so we add `file:\/` to path (avoid writing to DBFS on Databricks)\r\n  destination <- sparklyr::ml_save(model, path = file.path(\"file:\/\/\/\", path, model_data_subpath), overwrite = TRUE)\r\n  \r\n  conda_env <- mlflow:::create_default_conda_env_if_absent(\r\n    path, conda_env, default_pip_deps = list(\"mlflow\", paste0(\"sparklyr==\", as.character(utils::packageVersion(\"sparklyr\"))))\r\n  )\r\n  \r\n  sparklyr_conf <- list(\r\n    ml_pipeline_model = list(sparklyr_version = version, model_data = model_data_subpath)\r\n  )\r\n  \r\n  pyfunc_conf <- mlflow:::create_pyfunc_conf(\r\n    loader_module = \"mlflow.ml_pipeline_model\",\r\n    data = model_data_subpath,\r\n    env = conda_env\r\n  )\r\n  \r\n  model_spec$flavors <- c(model_spec$flavors, sparklyr_conf, pyfunc_conf)\r\n  mlflow:::mlflow_write_model_spec(path, model_spec)\r\n}\r\n\r\n\r\nmlflow_load_flavor.mlflow_flavor_ml_pipeline_model <- function(flavor, model_path) {\r\n  mlflow:::assert_pkg_installed(\"sparklyr\")\r\n  # `mlflow::mlflow_load_model()` does not have `...` we return a function that can be used with sparkContext \r\n  fn <- rlang::new_function(\r\n    args = rlang::exprs(sc =),\r\n    rlang::expr(sparklyr::ml_load(sc, file.path(\"file:\/\/\/\", !!model_path, \"sparklyr\")))\r\n   )\r\n  return(fn)\r\n}\r\n\r\nmlflow_predict.ml_pipeline_model <- function(sc, model, data, ...) {\r\n  mlflow:::assert_pkg_installed(\"sparklyr\")\r\n  sparklyr::ml_transform(model, data)\r\n}\r\n\r\n# ----------------------------------------\r\n# override mlflow function\r\nR.utils::reassignInPackage(\r\n  \"mlflow_save_model.ml_pipeline_model\",\r\n  pkgName = \"mlflow\",\r\n  value = mlflow_save_model.ml_pipeline_model\r\n)\r\n\r\n```\r\n\r\n","82":"I've seen usage of `threading.lock()` api -\r\n1. https:\/\/github.com\/mlflow\/mlflow\/blob\/0fa849ad75e5733bf76cc14a4455657c5c32f107\/mlflow\/store\/tracking\/sqlalchemy_store.py#L89\r\n2. https:\/\/github.com\/mlflow\/mlflow\/blob\/4195541c7f6a79fba4ccad2295534f16eaa8db39\/mlflow\/_spark_autologging.py#L28\r\n\r\nOn searching for threading use cases - https:\/\/github.com\/mlflow\/mlflow\/search?p=1&q=threading , it seems to be used in a few tests, some Kubernetes usage - https:\/\/github.com\/mlflow\/mlflow\/blob\/7a2e079b546644defba5bed35b5a8baa97693050\/mlflow\/projects\/kubernetes.py#L109 and a threadpool usage in code related to TensorFlow - https:\/\/github.com\/mlflow\/mlflow\/blob\/0fa849ad75e5733bf76cc14a4455657c5c32f107\/mlflow\/tensorflow\/__init__.py#L73\r\n\r\nNow coming back to my queries, would it be safe to assume -\r\n1. MLFlow uses multi-threading?\r\n2. If we're contributing to or using MLFlow OSS code, which parts should we be cautious of concurrency-related issues? Maybe Database? Logging? Flask-server?\r\n3. Multi-processing wasn't used for certain specific reasons?","83":"### Willingness to contribute\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: -\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 Home 21H2\r\n- **MLflow installed from (source or binary)**: Source\r\n- **MLflow version (run ``mlflow --version``)**: 1.22.0\r\n- **Python version**: 3.9\r\n- **npm version, if running the dev UI**: -\r\n\r\n### Describe the problem\r\nI use mlflow autologging for my sklearn pipeline and after exporting model to a different project, whenever I try to load the model, I get an error that modules are missing.\r\n\r\n### Code to reproduce issue\r\nI created an easily reproducible example.\r\n\r\nStep 1: Create a module to import in train.py\r\n\r\n    # custom_transformer.py\r\n\r\n    from sklearn.base import BaseEstimator, TransformerMixin\r\n\r\n    class ColumnSelector(BaseEstimator, TransformerMixin):\r\n\r\n        def fit(self, X, y=None):\r\n            return self\r\n\r\n        def transform(self, X):\r\n            return X\r\n\r\nStep 2: Create and log sklearn model\r\n\r\n    # train.py\r\n\r\n    import mlflow.sklearn\r\n    from sklearn.datasets import load_breast_cancer\r\n    from sklearn.naive_bayes import GaussianNB\r\n    from sklearn.pipeline import Pipeline, make_pipeline\r\n    from custom_transformer import ColumnSelector\r\n\r\n    mlflow.autolog()\r\n    \r\n    pipe = Pipeline([(\"selector\", ColumnSelector())])\r\n\r\n    data = load_breast_cancer()\r\n    labels = data[\"target\"]\r\n    features = data[\"data\"]\r\n\r\n    model = make_pipeline(pipe, GaussianNB())\r\n    model.fit(features, labels)\r\n\r\n\r\nStep 3: Copy model folder to a different project and try to load\r\n\r\n    # load.py\r\n\r\n    import mlflow.sklearn\r\n\r\n    mlflow.sklearn.load_model(\"model\")\r\n\r\n\r\n### Other info \/ logs\r\n    Traceback (most recent call last):\r\n      File \"C:\\Users\\issue_test\\load.py\", line 6, in load\r\n        mlflow.sklearn.load_model(\"model\")\r\n      File \"C:\\Users\\issue_example\\venv\\lib\\site-packages\\mlflow\\sklearn\\__init__.py\", line 549, in load_model\r\n        return _load_model_from_local_file(\r\n      File \"C:\\Users\\issue_example\\venv\\lib\\site-packages\\mlflow\\sklearn\\__init__.py\", line 417, in _load_model_from_local_file\r\n        return cloudpickle.load(f)\r\n    ModuleNotFoundError: No module named 'custom_transformer'\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [x] `area\/windows`: Windows support\r\n","84":"## Willingness to contribute\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nCreate a new mlflow function in order provide a way to rename the run name. This function could be the `mlflow.set_run_name`\r\n\r\n## Motivation\r\n\r\nThis feature will allow the user to rename the run name using the Python API. A use-case that makes this feature valuable is the following: Many tools implements their own mlflow integration without allowing the user to specify the flow run name, in that case it's useful to provide a high-level API for this purpose. This renaming functionality is currently supported by setting the `mlflow.runName` tag but this approach is not friendly for a new user. \r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [x] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nThis new function could look like:\r\n\r\n```python\r\ndef set_run_name(run_id: str, name: str):\r\n    pass  # use the given run_id in order to `mlflow.set_tag('mlflow.runName', name)\r\n```\r\n","85":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: SUSE Linux Enterprise Server 12 SP2\r\n- **MLflow installed from (source or binary)**: Binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.22 for the **client**, 1.11.0 for the **server**\r\n- **Python version**: 3.6.12\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: `MlflowClient().get_latest_versions(\"SOME_REGISTERED_MODEL\")`\r\n\r\n### Describe the problem\r\nWe have MlFlow 1.11.0 installed on a server, and version 1.22 on the client. When the client is connected to the server, and executing the `get_latest_version` command, the following message is shown:\r\n\r\n```python\r\nMlflowException: API request to endpoint \/api\/2.0\/mlflow\/registered-models\/get-latest-versions failed with error code 404 != 200. Response body: '<!DOCTYPE HTML PUBLIC \"-\/\/W3C\/\/DTD HTML 3.2 Final\/\/EN\">\r\n\r\n<title>404 Not Found<\/title>\r\n\r\n<h1>Not Found<\/h1>\r\n\r\n<p>The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.<\/p>\r\n```\r\nThe expected result would have been the latest version information of the model.\r\n\r\n\r\n### Code to reproduce issue\r\n\r\nPrerequisites:\r\n\r\n1. Run mlflow version 1.11.0 on a server in a conda environment\r\n2. Connect a client to the mlflow server using `mlflow.set_tracking_uri()`\r\n3. Create an experiment on the server using `MlflowClient.create_experiment`\r\n\r\nNow run:\r\n\r\n```python\r\nimport mlflow\r\nfrom mlflow.tracking import MlflowClient\r\n\r\nmlflow.set_tracking_uri(\"TRACKING_URI\")\r\n\r\nclient = MlflowClient()\r\nclient.get_latest_versions(\"EXPERIMENT_NAME\")\r\n```\r\n\r\n\r\n### Other info \/ logs\r\n\r\nThis problem seems to have been introduced with #4999. In that PR, support for POST-calls on get-latest-version was added. \r\nThis by itself is not a problem, since the author of the PR checks that if the POST-call is not available on the server, it catches the `ENDPOINT_NOT_FOUND` exception and tries to use a GET-call. \r\n\r\nThe problem is created however, because it calls `\/mlflow\/registered-models\/get-latest-version` instead of the usual `\/preview\/mlflow\/registered-models\/get-latest-versions`. This means  that not an `ENDPONT_NOT_FOUND` exception is thrown, but a 404 Not Found. This exception is not caught, meaning that the program will not continue to try the GET-call and crashes instead.\r\n\r\nIt seems to me that the omission of `preview` in the URL is the root cause of the bug (see: https:\/\/github.com\/stevenchen-db\/mlflow\/blob\/9bbbb0c28d285476e0f3e2a81ecfbf577d1b03ca\/mlflow\/protos\/model_registry.proto#L133), but I'm not sure if that is on purpose or not. If the omission of `preview` is on purpose, some other way of exception handling could be implemented to avoid getting 404-errors when working with older servers that do not support POST-calls.\r\n\r\nSince the reason behind the missing `preview` part is not entirely clear to me, I did not want to provide a bug fix immediately. If the maintainers could provide some guidance on which approach to fix this bug would be best for this project, I'd be happy to help implement the change.\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","86":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nWhen serving a model in a production environment, which is what we would like to use MLflow for, descriptive logs are crucial for being able to do that reliably. \r\nWe serve the model in a docker image built with `mlflow models build-docker` and currently to our best knowledge there are no logs whatsoever (with the exception of the information about starting gunicorn processes). Currently we would appreciate literally any additional pieces of information during runtime - after startup there is no information about whether the service is doing something.\r\nUseful logs could include: Endpoint access, some information about received data (size, structure, ...), output - model prediction, response time, ...\r\nAs building the image is automated and `mlflow models build-docker` currently does not seem to have any possibility to configure logging, achieving this currently seems impossible. \r\n\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n\r\n","87":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 20.04\r\n- **MLflow installed from (source or binary)**: from binary (pip install)\r\n- **MLflow version (run ``mlflow --version``)**: 1.18.0 (also tried with 1.22.0)\r\n- **Python version**: Python 3.8.10\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: \r\n\r\n### Describe the problem\r\nUsing .autolog (mlflow.keras.autolog() or mlflow.tensorflow.autolog()) on a Keras model is submitting empty runs (no params and no metrics)\r\n![mlflow_issue](https:\/\/user-images.githubusercontent.com\/10974651\/146200426-30940698-7cdf-495f-9720-362dbd3307b2.jpg)\r\n\r\n ### Code to reproduce issue\r\n```\r\nepoch = self.load_checkpoint(network=self.training_model, directory_helper=self.directory_helper)\r\nself._save_model_description()\r\ncheckpoint_path = os.path.join(self.directory_helper.checkpoint_dir(), CHECKPOINT_PATH_PATTERN)\r\nsave_callback = ModelCheckpoint(\r\n            filepath=checkpoint_path, save_weights_only=True, save_freq=\"epoch\", monitor=\"loss\"\r\n        )\r\nMLFLOW_TRACKING_SERVER_INSTANCE = \"http:\/\/localhost:5000\"\r\nmlflow.set_tracking_uri(MLFLOW_TRACKING_SERVER_INSTANCE)\r\nmlflow.set_experiment(\"my-test\")\r\nmlflow.tensorflow.autolog()\r\n# mlflow.keras.autolog() # tried also this\r\nwith mlflow.start_run() as run:\r\n    print(\"Active run_id: {}\".format(run.info.run_id)) # giving me a valid id\r\n    self.training_model.fit(\r\n        sample_iterator.framework_iterable(),\r\n        epochs=self.epochs,\r\n        steps_per_epoch=self.steps_per_epoch,\r\n        callbacks=self.callbacks + [save_callback],\r\n        initial_epoch=epoch,\r\n    )\r\n    self.training_model.evaluate(sample_iterator.framework_iterable(), steps=1)\r\n    self.training_model.save(\"\/tmp\/model\")\r\n```\r\nThe code runs successfully (train, evaluate and a model is saved)\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nTesting started at 14:48 ...\r\n\/<somedir>\/bin\/python \/home\/<somedir>\/pycharm-2020.2.2\/plugins\/python\/helpers\/pycharm\/_jb_pytest_runner.py --target network_integration_test.py::test_training_integration\r\nLaunching pytest with arguments network_integration_test.py::test_training_integration in <script>\r\n\r\n============================= test session starts ==============================\r\nplatform linux -- Python 3.8.10, pytest-6.2.5, py-1.11.0, pluggy-1.0.0 -- \/<somedir>\/bin\/python\r\ncachedir: .pytest_cache\r\nrootdir: <script_dir>\r\ncollecting ... collected 1 item\r\n\r\nnetwork_integration_test.py::test_training_integration PASSED            [100%]Using data set train and preprocessor mode train_steps.\r\nActive run_id: 27da2a3697764209b64851b9b3f95c1f\r\n1\/1 [==============================] - 0s 19ms\/step - batch: 0.0000e+00 - size: 1.0000 - loss: 4113.8296\r\nTraining is done.\r\nwaiting 2s---------------------------\r\nUsing data set validation and preprocessor mode validation_steps.\r\ninferred output:\r\n {'image_extractor': {'output': array([[[0.0000000e+00, 6.8138964e-03, 0.0000000e+00],\r\n        [0.0000000e+00, 1.1089750e-01, 0.0000000e+00],\r\n        [0.0000000e+00, 1.4115120e-01, 0.0000000e+00],\r\n        ...,\r\n        [0.0000000e+00, 4.0602821e+01, 0.0000000e+00],\r\n        [0.0000000e+00, 7.1283195e+01, 0.0000000e+00],\r\n        [0.0000000e+00, 7.4124146e+01, 0.0000000e+00]],\r\n\r\n       [[0.0000000e+00, 2.6389563e-01, 0.0000000e+00],\r\n        [0.0000000e+00, 6.3583678e-01, 0.0000000e+00],\r\n        [0.0000000e+00, 9.5497471e-01, 0.0000000e+00],\r\n        ...,\r\n        [0.0000000e+00, 8.9535469e+01, 0.0000000e+00],\r\n        [0.0000000e+00, 8.9088066e+01, 0.0000000e+00],\r\n        [0.0000000e+00, 8.9849754e+01, 0.0000000e+00]],\r\n\r\n       [[0.0000000e+00, 2.4204983e-01, 0.0000000e+00],\r\n        [0.0000000e+00, 4.7542697e-01, 0.0000000e+00],\r\n        [0.0000000e+00, 7.0950073e-01, 0.0000000e+00],\r\n        ...,\r\n        [0.0000000e+00, 5.1282654e+01, 0.0000000e+00],\r\n        [7.3204637e+00, 4.3331047e+01, 0.0000000e+00],\r\n        [0.0000000e+00, 5.6928738e+01, 0.0000000e+00]],\r\n\r\n       ...,\r\n\r\n       [[0.0000000e+00, 1.8032816e-01, 0.0000000e+00],\r\n        [0.0000000e+00, 3.6331969e-01, 0.0000000e+00],\r\n        [0.0000000e+00, 5.4345101e-01, 0.0000000e+00],\r\n        ...,\r\n        [0.0000000e+00, 1.9824995e+01, 0.0000000e+00],\r\n        [0.0000000e+00, 1.1003504e+01, 0.0000000e+00],\r\n        [0.0000000e+00, 3.6498924e+01, 0.0000000e+00]],\r\n\r\n       [[0.0000000e+00, 7.8257382e-02, 0.0000000e+00],\r\n        [0.0000000e+00, 1.9469540e-01, 0.0000000e+00],\r\n        [0.0000000e+00, 2.3878448e-01, 0.0000000e+00],\r\n        ...,\r\n        [0.0000000e+00, 2.6312938e+00, 0.0000000e+00],\r\n        [9.3650808e+00, 0.0000000e+00, 0.0000000e+00],\r\n        [1.0873189e+01, 8.4439039e+00, 0.0000000e+00]],\r\n\r\n       [[0.0000000e+00, 2.2829400e-02, 0.0000000e+00],\r\n        [0.0000000e+00, 8.9347780e-02, 0.0000000e+00],\r\n        [0.0000000e+00, 1.3833980e-01, 0.0000000e+00],\r\n        ...,\r\n        [5.5682340e+00, 6.9527259e+00, 0.0000000e+00],\r\n        [1.1677513e+01, 0.0000000e+00, 0.0000000e+00],\r\n        [5.9880052e+00, 0.0000000e+00, 0.0000000e+00]]], dtype=float32)}}\r\n2021-12-15 14:48:59.091233: I tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\r\n2021-12-15 14:48:59.112495: E tensorflow\/stream_executor\/cuda\/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\r\n2021-12-15 14:48:59.112559: I tensorflow\/stream_executor\/cuda\/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: cmucl855212\r\n2021-12-15 14:48:59.112570: I tensorflow\/stream_executor\/cuda\/cuda_diagnostics.cc:176] hostname: cmucl855212\r\n2021-12-15 14:48:59.112671: I tensorflow\/stream_executor\/cuda\/cuda_diagnostics.cc:200] libcuda reported version is: 470.57.2\r\n2021-12-15 14:48:59.112713: I tensorflow\/stream_executor\/cuda\/cuda_diagnostics.cc:204] kernel reported version is: 470.57.2\r\n2021-12-15 14:48:59.112720: I tensorflow\/stream_executor\/cuda\/cuda_diagnostics.cc:310] kernel version seems to match DSO: 470.57.2\r\n2021-12-15 14:48:59.112968: I tensorflow\/core\/platform\/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-12-15 14:48:59.136761: I tensorflow\/core\/platform\/profile_utils\/cpu_utils.cc:104] CPU Frequency: 2599990000 Hz\r\n2021-12-15 14:48:59.138434: I tensorflow\/compiler\/xla\/service\/service.cc:168] XLA service 0x2302b70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2021-12-15 14:48:59.138455: I tensorflow\/compiler\/xla\/service\/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2021-12-15 14:48:59.961617: W tensorflow\/python\/util\/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\r\n\r\n\r\n=============================== warnings summary ===============================\r\n..\/..\/..\/..\/..\/..\/..\/..\/..\/venv\/lib\/python3.8\/site-packages\/tensorflow\/python\/autograph\/utils\/testing.py:21\r\n  \/<somedir>\/lib\/python3.8\/site-packages\/tensorflow\/python\/autograph\/utils\/testing.py:21: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n    import imp\r\n\r\nnetwork_integration_test.py::test_training_integration\r\n  \/<somedir>\/lib\/python3.8\/site-packages\/pkg_resources\/__init__.py:1144: DeprecationWarning: Use of .. or absolute path in a resource path is not allowed and will raise exceptions in a future release.\r\n    return get_provider(package_or_requirement).get_resource_filename(\r\n\r\n-- Docs: https:\/\/docs.pytest.org\/en\/stable\/warnings.html\r\n======================== 1 passed, 2 warnings in 5.24s =========================\r\n\r\nProcess finished with exit code 0\r\n\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [x] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n\r\n","88":"Hi,\r\n\r\nThis is more of a question than a bug or a feature.\r\n\r\nOn browsing through the model \"flavour\" modules (e.g. pytorch, paddlepaddle etc.), I note that a majority of the code base is contained within the `__init__.py` file of each flavour module and I feel this is slightly unconventional.\r\n\r\n**Is there a reason for this being implemented this way?**\r\n\r\nIf shortening imports is the reason, then bringing all functions to the module level can be achieved by setting `__all__` attribute in the `__init__.py` file. For example, the pytorch model flavour `mlflow.pytorch` could be done this way, with all functions moved to a `pytorch.py` file in the `mflow\/pytorch` folder, the `__init__.py` would look as follows:\r\n\r\n```python\r\nfrom .python import log_model, save_model, get_default_conda_env, get_default_pip_requirements\r\n\r\n__all__ = [log_model, save_model, get_default_conda_env, get_default_pip_requirements]\r\n```\r\n\r\nThis would result in the above functions being accessible through the import:\r\n\r\n`from mlflow.pytorch import log_model`\r\n\r\nJust as though the functions themselves were contained within the `__init__.py` as they currently are.\r\n\r\nFurthermore, breaking the functions out into even more files is possible, as the imports can be collected into the `__init__.py` namespace. If the functions were saved into two separate python file, `model.py` and `env.py`, then they can be called from the pytorch module with the following `__init__.py` structure:\r\n\r\n```python\r\nfrom .model import log_model, save_model\r\nfrom .env import get_default_conda_env, get_default_pip_requirements\r\n\r\n__all__ = [log_model, save_model, get_default_conda_env, get_default_pip_requirements]\r\n```","89":"In order to demonstrate the use of a custom transformer we will create a new feature based upon the ratio of the resting blood pressure to the maximum blood pressure. This feature will be created as a new class and saved into a separate file so it can be output to the MLflow tracking server to be used during deployment in combination with the saved model.\r\n\r\n## What changes are proposed in this pull request?\r\n\r\n(Please fill in changes proposed in this fix)\r\n\r\n## How is this patch tested?\r\n\r\n(Details)\r\n\r\n## Does this PR change the documentation?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Make sure the changed pages \/ sections render correctly by following the steps below.\r\n\r\n1. Check the status of the `ci\/circleci: build_doc` check. If it's successful, proceed to the\r\n   next step, otherwise fix it.\r\n2. Click `Details` on the right to open the job page of CircleCI.\r\n3. Click the `Artifacts` tab.\r\n4. Click `docs\/build\/html\/index.html`.\r\n5. Find the changed pages \/ sections and make sure they render correctly.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","90":"Signed-off-by: dbczumar <corey.zumar@databricks.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\n(Please fill in changes proposed in this fix)\r\n\r\n## How is this patch tested?\r\n\r\n(Details)\r\n\r\n## Does this PR change the documentation?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Make sure the changed pages \/ sections render correctly by following the steps below.\r\n\r\n1. Check the status of the `ci\/circleci: build_doc` check. If it's successful, proceed to the\r\n   next step, otherwise fix it.\r\n2. Click `Details` on the right to open the job page of CircleCI.\r\n3. Click the `Artifacts` tab.\r\n4. Click `docs\/build\/html\/index.html`.\r\n5. Find the changed pages \/ sections and make sure they render correctly.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [x] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","91":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [X] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**:\r\n- **Python version**:\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\ninfer_signature fails when a pandas series is of dtype 'category' and a null value is present. Lightgbm and some other packages require categorical columns to be of this dtype.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nCode Ex 1:\r\n```\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom mlflow.models.signature import infer_signature\r\n\r\ndata = pd.DataFrame({\"a\": [\"foo\", np.nan]})\r\ndata[\"a\"] = data[\"a\"].fillna('').astype('category')\r\ninfer_signature(data)\r\n```\r\n\r\nCode Ex 2:\r\n```\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom mlflow.models.signature import infer_signature\r\n\r\ndata = pd.DataFrame({\"a\": [\"foo\", \"\"]})\r\ndata[\"a\"] = data[\"a\"].astype('category')\r\ninfer_signature(data)\r\n```\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nMlflowException                           Traceback (most recent call last)\r\n<command-905257552727287> in <module>\r\n      7 data[\"a\"] = data[\"a\"].fillna('').astype('category')\r\n      8 print(data[\"a\"].dtype)\r\n----> 9 infer_signature(data)\r\n\r\n\/databricks\/python\/lib\/python3.8\/site-packages\/mlflow\/models\/signature.py in infer_signature(model_input, model_output)\r\n    127     :return: ModelSignature\r\n    128     \"\"\"\r\n--> 129     inputs = _infer_schema(model_input)\r\n    130     outputs = _infer_schema(model_output) if model_output is not None else None\r\n    131     return ModelSignature(inputs, outputs)\r\n\r\n\/databricks\/python\/lib\/python3.8\/site-packages\/mlflow\/types\/utils.py in _infer_schema(data)\r\n    117     elif isinstance(data, pd.DataFrame):\r\n    118         schema = Schema(\r\n--> 119             [ColSpec(type=_infer_pandas_column(data[col]), name=col) for col in data.columns]\r\n    120         )\r\n    121     elif isinstance(data, np.ndarray):\r\n\r\n\/databricks\/python\/lib\/python3.8\/site-packages\/mlflow\/types\/utils.py in <listcomp>(.0)\r\n    117     elif isinstance(data, pd.DataFrame):\r\n    118         schema = Schema(\r\n--> 119             [ColSpec(type=_infer_pandas_column(data[col]), name=col) for col in data.columns]\r\n    120         )\r\n    121     elif isinstance(data, np.ndarray):\r\n\r\n\/databricks\/python\/lib\/python3.8\/site-packages\/mlflow\/types\/utils.py in _infer_pandas_column(col)\r\n    229             return DataType.string\r\n    230         else:\r\n--> 231             raise MlflowException(\r\n    232                 \"Unable to map 'np.object' type to MLflow DataType. np.object can\"\r\n    233                 \"be mapped iff all values have identical data type which is one \"\r\n\r\nMlflowException: Unable to map 'np.object' type to MLflow DataType. np.object canbe mapped iff all values have identical data type which is one of (string, (bytes or byterray),  int, float).\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","92":"**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (Occurs both in Windows 11 and Ubuntu 20.04)**:\r\n- **MLflow installed ffrom (pip)**:\r\n- **MLflow version (1.22.0)**:\r\n- **Python version (3.9.6)**:\r\n- **Exact command to reproduce (MLFLOW_TRACKING_URI = os.environ.get('MLFLOW_TRACKING_URI'))**:\r\n\r\n### Describe the problem\r\nLet's suppose that we work inside a python virtual environment with mlflow installed. A remote MLflow server for tracking is defined inside a .venv file as follows:\r\n```\r\nos.environ[\"MLFLOW_TRACKING_URI\"]= <my_remote_ip>\r\n```\r\nFor some reason, during runtime the command will fail to update the MLFLOW_TRACKING_URI environment variable command contrary to the rest of environment variables. Therefore, the tracking server will be arbitrarily set to the default value, namely localhost:5000.\r\n\r\n### Code to reproduce issue\r\nWith the above .env file present in the current directory and MLflow and python-dotenv installed in the python virtual environment, run the following code:\r\n```\r\nfrom dotenv import load_dotenv\r\nload_dotenv()\r\nMLFLOW_TRACKING_URI = os.environ.get('MLFLOW_TRACKING_URI')\r\nprint(MLFLOW_TRACKING_URI)\r\n```\r\n\r\n### Other info \/ logs\r\nNope\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","93":"### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Docker 20.10.10; `docker-compose` 2.1.1; `Linux 5.13.19-2-MANJARO`\r\n- **MLflow installed from (source or binary)**: pip\r\n- **MLflow version (run ``mlflow --version``)**: 1.21.0\r\n- **Python version**: 3.10.0\r\n- **Exact command to reproduce** (in effect):\r\n```bash\r\nmlflow server --host 0.0.0.0 -p 5000 --default-artifact-root \/home\/mlflow \\\r\n--backend-store-uri postgresql+asyncpg:\/\/postgres:${MLFLOW_DB_PASSWORD}@mlflow-db:5432\/${MLFLOW_DB_NAME}\r\n```\r\n\r\n### Description\r\n\r\nI am trying to make mlflow run as a service in docker-compose engine. And I succeeded, provided I only run the sync driver for postgres (`postgresql`). However, using the async driver `asyncpg` makes it so that MLFlow makes SQLAlchemy not be able to create the engine. The relevant files are in [this public gist](https:\/\/gist.github.com\/bgalvao\/49706a5eb30aef2288c6687993ed9879).\r\n\r\n### Steps to reproduce\r\n\r\n1. Download the [Dockerfile](https:\/\/gist.github.com\/bgalvao\/49706a5eb30aef2288c6687993ed9879#file-dockerfile) and place it in `.\/mlflow` so that it follows the build context specified at the docker compose file.\r\n2. Download [.env](https:\/\/gist.github.com\/bgalvao\/49706a5eb30aef2288c6687993ed9879#file-env) and [docker-compose.yml](https:\/\/gist.github.com\/bgalvao\/49706a5eb30aef2288c6687993ed9879#file-docker-compose-yml), and place them in `.\/`.\r\n3. From `.\/`, run `docker-compose up`.\r\n\r\n\r\n### Other info \/ logs\r\n\r\nTLDR from interpreting the gist is that in effect, the mlflow command that is invoked is\r\n\r\n```bash\r\nmlflow server --host 0.0.0.0 -p 5000 --default-artifact-root \/home\/mlflow \\\r\n--backend-store-uri postgresql+asyncpg:\/\/postgres:${MLFLOW_DB_PASSWORD}@mlflow-db:5432\/${MLFLOW_DB_NAME}\r\n```\r\n\r\nI've tried this procedure with and without `+asyncpg` in the SQLAlchemy URI. In the latter case, everything worked:\r\n![image](https:\/\/user-images.githubusercontent.com\/17158288\/145032834-30074deb-ef37-4d77-9127-f2b64ba3795e.png)\r\n\r\nIn the former case (with the `+asyncpg` driver), the GUI does not even start, and this is what the log from `docker-compose up mlflow` has to say:\r\n```\r\n \u283f Network docker_mlflow         Created                                                             0.0s\r\n \u283f Container docker-mlflow-db-1  Created                                                             0.0s\r\n \u283f Container docker-mlflow-1     Created                                                             0.0s\r\nAttaching to docker-mlflow-1\r\ndocker-mlflow-1  | 2021\/12\/07 12:12:34 WARNING mlflow.store.db.utils: SQLAlchemy engine could not be created. The following exception is caught.\r\ndocker-mlflow-1  | greenlet_spawn has not been called; can't call await_() here. Was IO attempted in an unexpected place? (Background on this error at: https:\/\/sqlalche.me\/e\/14\/xd2s)\r\ndocker-mlflow-1  | Operation will be retried in 0.1 seconds\r\n```\r\n\r\n","94":"I am trying to configure MSSQL db as the backend uri\r\n\r\n Dockerfile is as below:-\r\n\r\nFROM python:3.7-slim-buster\r\nARG BUCKET=bucketname\r\nARG ACCESS_KEY=key\r\nARG SECRET_ACCESS_KEY=key\r\nARG MSSQL_DATABASE=mlflowtest1\r\n\r\n\r\n\r\nRUN apt-get update \\\r\n   && apt-get install gcc -y \\\r\n && apt-get install unixodbc -y \\\r\n && apt-get install unixodbc-dev -y \\\r\n && apt-get install --reinstall build-essential -y\r\n\r\n \r\nRUN mkdir -p \/mlflow\/ \\\r\n  && pip install  mlflow \\\r\n    boto3 \\\r\n    mlflow[sqlserver] \\\r\n    pyodbc \r\n\r\n\r\n\r\n\r\nRUN chmod -R 777 \/mlflow\/\r\n\r\nEXPOSE 5000\r\n\r\nENV BACKEND_URI mssql+pyodbc:\/\/usr:pass@ip:port\/DBMLFlow\r\nENV ARTIFACT_ROOT s3:\/\/bucket\r\nENV MLFLOW_S3_ENDPOINT_URL https:\/\/endpointurl\r\nENV AWS_ACCESS_KEY_ID $ACCESS_KEY\r\nENV AWS_SECRET_ACCESS_KEY $SECRET_ACCESS_KEY\r\nENV AWS_CA_BUNDLE \/mlflow\/cacert.pem\r\n\r\n\r\nCMD mlflow server \\\r\n  --backend-store-uri \"${BACKEND_URI}\" \\\r\n  --default-artifact-root \"${ARTIFACT_ROOT}\" \\\r\n  --host 0.0.0.0\r\n\r\n### Describe the problem\r\nError in connecting to db\r\n2021\/12\/06 09:38:37 WARNING mlflow.store.db.utils: SQLAlchemy engine could not be created. The following exception is caught.\r\n(pyodbc.InterfaceError) ('IM002', '[IM002] [unixODBC][Driver Manager]Data source name not found, and no default driver specified (0) (SQLDriverConnect)')\r\n(Background on this error at: https:\/\/sqlalche.me\/e\/14\/rvf5)\r\n\r\ncould you please help me to figure out the issue\r\n","95":"Hi,\r\n\r\nI'm working on a Mac with M1 chip, which brings compatibility issues with some python packages.\r\nThere does exist a way of specifying the platform when creating a Conda environment (e.g. with an extra env variable `CONDA_SUBDIR=osx-64 conda create -n rosetta python` https:\/\/github.com\/conda-forge\/miniforge\/issues\/165#issuecomment-860233092). However the creation of Conda env while running a mlflow project seems automatic, I'm wondering how can I incorporate this trick during this process.\r\n\r\nThanks\r\n\r\n","96":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ X] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nI want to be able to define the signature of my model using mlflow and then at inference time do input format validation based on the signature metadata from the artifact. I know loading as `pyfunc` and then calling `predict` does this automatically, as does packaging the project for deployment with mlflow (which I'm not doing because I need more flexibility in the API), but then I lose access to other methods on my underlying model (such as predict_proba for an sklearn model). \r\n\r\nIt looks like I might be able to work around the issue by using `_model_impl` on the pyfunc object to still have access to predict_proba, but that interface may be subject to change:\r\n\r\n```\r\nmodel = mlflow.pyfunc.load_model(MODEL_URI)\r\nmodel._model_impl.predict_proba(df)\r\n```\r\n\r\nI can then do manual validation in a predict_proba endpoint with something like this perhaps (while still having it automatically done when calling predict() otherwise):\r\n\r\n```\r\nfrom mlflow.pyfunc import _enforce_schema\r\ninput_schema = model.metadata.get_input_schema()\r\ndf = _enforce_schema(df, input_schema)\r\n```\r\n\r\nIt would be nice if there was a built in option to have non-pyfunc models do signature-based validation, or otherwise an officially supported way to load metadata with a loaded model and verify some input based on the signature of that model.\r\n\r\n## Motivation\r\n\r\n- What is the use case for this feature? See above.\r\n- Why is this use case valuable to support for MLflow users in general? Input validation is important, so giving users ways to utilize it outside of the mlflow-specific deployment cases seems like a good idea.\r\n- Why is this use case valuable to support for your project(s) or organization? It would be great to keep the artifact as the source of truth for the input signature so my model serving can leverage that instead of having it externally defined.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient) I had to dig through the code just to find the workaround above, which may be prone to breaking as mlflow evolves. \r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [X] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n","97":"Hello, we are currently using the following products:\r\n\r\nmlflow-1.21.0\r\nmysql-server:8.0.27  (backend-store)\r\nminio\/minio:RELEASE.2020-10-09T22-55-05Z (artifact store)\r\n\r\nAll of these products are deployed to docker.\r\n\r\nIn mlflow we have a test experiment:\r\n![screen-1](https:\/\/user-images.githubusercontent.com\/49237188\/144577636-211c60a2-8c70-43de-a1d8-a798247b4b2f.png)\r\n\r\nThe artifacts of this experiment are stored in minio:\r\n![screen-2](https:\/\/user-images.githubusercontent.com\/49237188\/144577688-7cb29029-f38d-48a1-bb0e-21ef686364be.png)\r\n\r\nWe are removing this experiment from the mlflow GUI:\r\n![screen-3](https:\/\/user-images.githubusercontent.com\/49237188\/144577743-f27f3ffd-ac73-4740-99be-17dcfaf3e64a.png)\r\n\r\nAs you can see in the graphical interface, there is no more experiment with this name:\r\n![screen-4](https:\/\/user-images.githubusercontent.com\/49237188\/144577761-6104982e-d9c9-4c36-b599-fdc2c205ba38.png)\r\n\r\nWe are trying to create an experiment with the same name and we get the following error:\r\nMlflowException: Cannot set a deleted experiment 'test' as the active experiment. You can restore the experiment, or permanently delete the  experiment to create a new one.\r\n![screen-5](https:\/\/user-images.githubusercontent.com\/49237188\/144577795-5d897e77-477f-45c5-8a30-81f46315328c.png)\r\n\r\nThat is, information about the experiment named test remained in the mysql database.\r\n\r\nIf you check the artifacts related to this experiment in minio, then they also did not disappear:\r\n![screen-6](https:\/\/user-images.githubusercontent.com\/49237188\/144577844-de0a0fee-4489-4b4e-8aa5-690e55b225b6.png)\r\n\r\nPlease clarify why this is happening? Why deleting an experiment is just about removing metadata from the GUI?\r\n\r\nPlease clarify how you can automate the cleaning of records in mysql about a remote experiment, as well as cleaning up artifacts associated with a remote experiment in minio?\r\n","98":"Hi,\r\n\r\nI'm new to mlflow and cannot seem to get the installation for R correct in the Windows 10 environment.  \r\n**Below is the output of mlflow::install_mlflow()**\r\nI've tried everything even mlflow::install_mlflow(\"3.9\") or python_version = 3.9.\r\nIn Rstudio I've changed my Global Option for Python to :  C:\/Users\/grayh\/AppData\/Local\/Programs\/Python\/Python39\/python.exe\r\nthis seemed to resolve some issues but not the below issue\r\nI also ensured the default on the **Computer\\HKEY_CURRENT_USER\\SOFTWARE\\Python\\PythonCore\\3.9** is set to C:\\Users\\...\\Python\\Python39\\python.exe\r\n\r\n_I've pretty much ensured (imo) that I don't have python3.6 anywhere on my machine???_\r\n\r\n**Output**\r\nCollecting package metadata (current_repodata.json): ...working... done\r\nSolving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\r\nCollecting package metadata (repodata.json): ...working... done\r\nSolving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\r\n                                                                           0:00,  6.47it\/s]        \r\nFound conflicts! Looking for incompatible packages.\r\nThis can take several minutes.  Press CTRL-C to abort.\r\nfailed\r\n\r\nUnsatisfiableError: The following specifications were found\r\nto be incompatible with the existing python installation in your environment:\r\n\r\nSpecifications:\r\n\r\n  - mlflow==1.21.0 -> python[version='>=3.7,<3.8.0a0|>=3.8,<3.9.0a0|>=3.9,<3.10.0a0']\r\n\r\nYour python: python=3.6\r\n\r\nIf python is on the left-most side of the chain, that's the version you've asked for.\r\nWhen python appears to the right, that indicates that the thing on the left is somehow\r\nnot available for the python version you are constrained to. Note that conda will not\r\nchange your python version to a different minor version unless you explicitly specify\r\nthat.\r\n","99":"**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\n\r\nN\/A -- looking for a clarification on how this is supposed to work, or perhaps a doc update. Apologies if this is misclassified, the other options didn't seem appropriate either.\r\n\r\n### System information\r\n\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Linux \/ Debian-based\r\n- **MLflow installed from (source or binary)**: Binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.21.0\r\n- **Python version**: 3.8.7\r\n\r\n### Describe the problem\r\n\r\nI trained a model with auto-sklearn and used log_model. It successfully saves the artifact to S3, and the S3 conda and pip requirements files both show the proper dependencies. Conda env for example:\r\n\r\n```\r\nchannels:\r\n- conda-forge\r\ndependencies:\r\n- python=3.8.7\r\n- pip\r\n- pip:\r\n  - mlflow\r\n  - auto-sklearn==0.14.1\r\n  - cloudpickle==2.0.0\r\n  - scikit-learn==0.24.2\r\nname: mlflow-env\r\n```\r\n\r\nWhen I later try to call `load_model` I expected it would \"just work\", but I instead get an error since autosklearn doesn't exist in the python environment:\r\n\r\n```\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/sklearn\/__init__.py\", line 549, in load_model\r\n    return _load_model_from_local_file(\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/sklearn\/__init__.py\", line 417, in _load_model_from_local_file\r\n    return cloudpickle.load(f)\r\nModuleNotFoundError: No module named 'autosklearn'\r\n```\r\n\r\nSo it appears my assumption that the requirements would automatically be bundled with the model are wrong. But I also don't see any options on `log_model` or `load_model` that would either package the requirements with the model artifact or attempt an install before the load. Perhaps my issue here is that my workflow is off target, but after a lot of searching the docs \/ github \/ stackoverflow I'm not finding a clear answer on the proper workflow to handle a case like this. \r\n\r\nIs there an existing example that shows programmatically using the conda env or requirements.txt info from the artifact to create an environment prior to a `load_model` call? Or am I just expected to be handling inference environment creation separately? Of course the latter is doable, but I was hoping there would be some way to have the artifact be the source of truth for the environment...otherwise one needs to coordinate the training environment with the inference environment by other means. Again, doable, but I think I misunderstood that this was supposed to be a thing MLFlow somehow took care of for you.\r\n\r\nNote, I'm going to be using BentoML for model containerization and deployment. Roughly following [this](https:\/\/github.com\/bentoml\/gallery\/blob\/pre-v1.0\/bentomlflow\/mlflow-to-bentoml-example.ipynb) example. Not expecting anyone here to comment on the Bento side of things, just adding this as a data point as I was hoping to keep the model serving code independent of the training code as much as possible. The training environments are all containerized but have more requirements than I'd really need for inference, so just using that same image isn't ideal. \r\n\r\nThanks for your help.\r\n\r\n\r\nEDIT: I've come across `mlflow models prepare-env` which I may be able to utilize in a build step to create the env from the artifact definition. Will give that a shot.\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [X] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\n\r\n\r\n\r\n","100":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 20.04\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: 1.20.2\r\n- **Python version**: 3.8.10\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:  mlflow server \\\r\n    --backend-store-uri postgresql:\/\/user:pass*@db_server\\\r\n    --default-artifact-root s3:\/\/artifact-root \\\r\n    --host 0.0.0.0 -p 8000\r\n\r\n\r\n### Describe the problem\r\nWhen running the mlflow server using Postgres, one COMMIT and one ROLLBACK queries can be seen in the running queries in the Postgres log. However, these queries never finish running, gradually increasing the CPU load, and eventually causing a DB server crash.\r\n\r\n\r\n### Code to reproduce issue\r\n1. Run mlflow server using PostgreSQL as the backend-store-ui. \r\n2. Check PostgreSQL logs \r\n\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nImage of the queries in DigitalOcean query log:\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/27902909\/144143865-f415529e-4d9b-490e-b6a7-e12ad492f557.png)\r\n\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [x] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","101":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: docker python:3.10-slim-buster\r\n- **MLflow installed from (source or binary)**: binary, `pip install mlflow`\r\n- **MLflow version (run ``mlflow --version``)**: 1.22.0\r\n- **Python version**: 3.10\r\n- **npm version, if running the dev UI**: -\r\n- **Exact command to reproduce**: -\r\n\r\n### Describe the problem\r\nToo many scrollbars - see picture. \r\n\r\n![image (2)](https:\/\/user-images.githubusercontent.com\/432235\/144043532-4ba68106-13b0-46f7-8b16-0eab612864b8.png)\r\n\r\nI believe this line to blame: https:\/\/github.com\/mlflow\/mlflow\/blob\/d79a81671f50bf2b4d3105160912fbbee742cdec\/mlflow\/server\/js\/src\/experiment-tracking\/components\/ExperimentView.css#L332\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [x] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","102":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nMany tutorials suggests a set of best practices to follow when designing REST APIs:\r\n- https:\/\/stackoverflow.blog\/2020\/03\/02\/best-practices-for-rest-api-design\/\r\n- https:\/\/docs.microsoft.com\/en-us\/azure\/architecture\/best-practices\/api-design\r\n- https:\/\/www.freecodecamp.org\/news\/rest-api-best-practices-rest-endpoint-design-examples\/\r\n- https:\/\/restfulapi.net\/rest-api-design-tutorial-with-example\/#model-uris\r\n\r\nThey have common practices:\r\n- Use plural nouns and avoid verbs in endpoints\r\n- Conform to HTTP semantics\r\n- Use Nesting on Endpoints to Show Relationships\r\n- Allow filtering, sorting, and pagination\r\n\r\nMLFlow REST API violates most theses practices:\r\n- it uses nouns in endpoint like `2.0\/mlflow\/runs\/get`\r\n- it  uses the HTTP request data to send resource id like `experiment_id` for [`UpdateExeperiment`](https:\/\/www.mlflow.org\/docs\/latest\/rest-api.html#update-experiment)\r\n- it uses `POST` to delete resources\r\n\r\nThis issue is about making the MLFlow REST API more standard by following the best practices.\r\n\r\nIf we do that, we'll have endpoints like:\r\n- `\/api\/experiments`, `GET` to list the experiments `POST` to create a new experiment\r\n- `\/api\/experiments\/:id`, `GET` to get the experiment metadata, `PUT`\/`PATCH` to update it, `DELETE` to delete it\r\n- `\/api\/experiments\/:id\/runs`,  `GET` to list the runs of the experiment, `POST` to create a new run \r\n- `\/api\/runs\/:id`, `GET` to get the run metadata, `PUT`\/`PATCH` to update it, `DELETE` to delete it\r\n- `\/api\/runs\/:id\/parameters`,  `GET` to get the parameters logged during that run, `POST` to log a new parameter\r\n- `\/api\/runs\/:id\/parameters\/:name`, `GET` to get the value of the parameter, `DELETE` to delete it\r\n- `\/api\/runs\/:id\/metrics`, `GET` to get the metrics logged during that run, `POST` to log a new metric\r\n- `\/api\/runs\/:id\/metric\/:name`, `GET` to get the value of the metric, `DELETE` to delete it\r\n- `\/api\/runs\/:id\/tags`, `GET` to get the tags logged during that run, `POST` to log new tag\r\n\r\n## Motivation\r\n- This will make working with the REST API intuitive and easy to understand\r\n- It'll make it possible to use Nginx's `request_auth` feature to implement authorization over MLFlow requests, it's not possible right now becuase Nginx `auth_request` erases the data before sending `\/authorize` requests and MLFlow sends the `experiment_id\/run_id` in the data of `POST` and `UPDATE` requests instead of the URL (POST \/tracking\/experiments\/1), this makes it impossible to authorize such requests, see this comment: https:\/\/github.com\/mlflow\/mlflow\/issues\/761#issuecomment-981738147\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [x] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","103":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [X] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: YES\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.21.0\r\n- **databricks-connect version**: 9.1.4\r\n- **Python version**: 3.8.8\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: run the code below from pycharm using databricks-connect\r\n\r\n### Describe the problem\r\nIn pycharm, when I call log_model with a Spark model on a Databricks cluster where mlflow works perfectly with databricks-connect and non-Spark models, I get the following error:\r\n\r\n```\r\nERROR mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: c:\\temp\\tmpi32ow6na, flavor: spark)\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\utils\\environment.py\", line 196, in infer_pip_requirements\r\n    return _infer_requirements(model_uri, flavor)\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\utils\\requirements_utils.py\", line 299, in _infer_requirements\r\n    modules = _capture_imported_modules(model_uri, flavor)\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\utils\\requirements_utils.py\", line 235, in _capture_imported_modules\r\n    _run_command(\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\utils\\requirements_utils.py\", line 187, in _run_command\r\n    raise MlflowException(msg)\r\nmlflow.exceptions.MlflowException: Encountered an unexpected error while running ['C:\\\\Users\\\\myself\\\\PycharmProjects\\\\paa-datascience-nbra-model\\\\venv\\\\Scripts\\\\python.exe', 'C:\\\\Users\\\\myself\\\\PycharmProjects\\\\paa-datascience-nbra-model\\\\venv\\\\lib\\\\site-packages\\\\mlflow\\\\utils\\\\_capture_modules.py', '--model-path', 'C:\\\\temp\\\\tmpi32ow6na', '--flavor', 'spark', '--output-file', 'c:\\\\temp\\\\tmpy4sudk9v\\\\imported_modules.txt', '--sys-path', '[\"C:\\\\\\\\Users\\\\\\\\myself\\\\\\\\PycharmProjects\\\\\\\\paa-datascience-nbra-model\\\\\\\\project\", \"C:\\\\\\\\Users\\\\\\\\myself\\\\\\\\PycharmProjects\\\\\\\\paa-datascience-nbra-model\\\\\\\\venv\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\git\\\\\\\\ext\\\\\\\\gitdb\", \"C:\\\\\\\\temp\\\\\\\\spark-11c431d6-347c-4131-8a72-563a2d4ee3f8\\\\\\\\userFiles-cd3f3711-efb4-4fbe-a446-80315c673113\", \"C:\\\\\\\\Users\\\\\\\\myself\\\\\\\\PycharmProjects\\\\\\\\paa-datascience-nbra-model\", \"C:\\\\\\\\Users\\\\\\\\myself\\\\\\\\PycharmProjects\\\\\\\\paa-datascience-nbra-model\\\\\\\\venv\\\\\\\\Scripts\\\\\\\\python38.zip\", \"C:\\\\\\\\Users\\\\\\\\myself\\\\\\\\Anaconda3\\\\\\\\DLLs\", \"C:\\\\\\\\Users\\\\\\\\myself\\\\\\\\Anaconda3\\\\\\\\lib\", \"C:\\\\\\\\Users\\\\\\\\myself\\\\\\\\Anaconda3\", \"C:\\\\\\\\Users\\\\\\\\myself\\\\\\\\PycharmProjects\\\\\\\\paa-datascience-nbra-model\\\\\\\\venv\", \"C:\\\\\\\\Users\\\\\\\\myself\\\\\\\\PycharmProjects\\\\\\\\paa-datascience-nbra-model\\\\\\\\venv\\\\\\\\lib\\\\\\\\site-packages\", \"C:\\\\\\\\Users\\\\\\\\myself\\\\\\\\PycharmProjects\\\\\\\\paa-datascience-nbra-model\\\\\\\\venv\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\win32\", \"C:\\\\\\\\Users\\\\\\\\myself\\\\\\\\PycharmProjects\\\\\\\\paa-datascience-nbra-model\\\\\\\\venv\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\win32\\\\\\\\lib\", \"C:\\\\\\\\Users\\\\\\\\myself\\\\\\\\PycharmProjects\\\\\\\\paa-datascience-nbra-model\\\\\\\\venv\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\Pythonwin\", \"C:\\\\\\\\Users\\\\\\\\myself\\\\\\\\PycharmProjects\\\\\\\\paa-datascience-nbra-model\\\\\\\\venv\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\gitdb\\\\\\\\ext\\\\\\\\smmap\"]']\r\nexit status: 1\r\n```\r\nand a few seconds later:\r\n\r\n```\r\nINFO mlflow.spark: File 'C:\\temp\\tmpi32ow6na\\sparkml' not found on DFS. Will attempt to upload the file.\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\utils\\_capture_modules.py\", line 134, in <module>\r\n    main()\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\utils\\_capture_modules.py\", line 109, in main\r\n    mlflow.pyfunc.load_model(model_path)\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\pyfunc\\__init__.py\", line 667, in load_model\r\n    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\utils\\_capture_modules.py\", line 106, in _load_pyfunc_patch\r\n    return original(*args, **kwargs)\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\spark.py\", line 710, in _load_pyfunc\r\n    return _PyFuncModelWrapper(spark, _load_model(model_uri=path))\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\spark.py\", line 631, in _load_model\r\n    model_uri = _HadoopFileSystem.maybe_copy_from_uri(model_uri, dfs_tmpdir)\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\spark.py\", line 373, in maybe_copy_from_uri\r\n    return cls.maybe_copy_from_local_file(_download_artifact_from_uri(src_uri), dst_path)\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\tracking\\artifact_utils.py\", line 95, in _download_artifact_from_uri\r\n    return get_artifact_repository(artifact_uri=root_uri).download_artifacts(\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\store\\artifact\\artifact_repository_registry.py\", line 102, in get_artifact_repository\r\n    return _artifact_repository_registry.get_artifact_repository(artifact_uri)\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\store\\artifact\\artifact_repository_registry.py\", line 65, in get_artifact_repository\r\n    raise MlflowException(\r\nmlflow.exceptions.MlflowException: Could not find a registered artifact repository for: c:. Currently registered schemes are: ['', 'file', 's3', 'gs', 'wasbs', 'ftp', 'sftp', 'dbfs', 'hdfs', 'viewfs', 'runs', 'models']\r\n```\r\n\r\nI have configured mlflow tracking uri to \"databricks\", as well as the databricks-cli and enverything. In fact, this works fine for non-Spark models.\r\n\r\n### Code to reproduce issue\r\n```\r\nimport os\r\nimport mlflow\r\nfrom pyspark.sql import SparkSession\r\nfrom mlflow.tracking import MlflowClient\r\nfrom pyspark.ml.classification import RandomForestClassifier\r\nfrom pyspark.ml.feature import VectorAssembler\r\nfrom pyspark.ml.pipeline import Pipeline\r\n\r\nif __name__ == '__main__':\r\n    \r\n    def dummy_model(data):\r\n        vec_assmblr = VectorAssembler(inputCols=['col2', 'col3'], outputCol='features_norm')\r\n        alg = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features_norm\", maxDepth=3)\r\n        pipeline = Pipeline(stages=[vec_assmblr, alg])\r\n        model = pipeline.fit(data)\r\n        return model\r\n\r\n    os.environ[\"MLFLOW_TRACKING_INSECURE_TLS\"] = \"true\"\r\n    mlflow.set_tracking_uri(\"databricks\")\r\n\r\n    spark = SparkSession.builder \\\r\n        .appName(\"test\") \\\r\n        .getOrCreate()\r\n\r\n    mlflow.set_tracking_uri(\"databricks\")\r\n    client = MlflowClient()\r\n    experiment_path = \"\/Users\/myDatabricksUser\/mlops\/ExperimentBug\"  # existing path in Workspace\r\n    artifact_root = '\/user\/existingfolder\/mlops\/'   # existing DBFS folder\r\n    model_name = 'trial_1'\r\n\r\n    experiment = mlflow.get_experiment_by_name(name=experiment_path)\r\n    if experiment is None:\r\n        experiment_id = mlflow.create_experiment(name=experiment_path)\r\n    else:\r\n        experiment_id = experiment.experiment_id\r\n\r\n    os.environ[\"MLFLOW_TRACKING_INSECURE_TLS\"] = \"true\"\r\n    mlflow.set_tracking_uri('databricks')\r\n    client = MlflowClient()\r\n\r\n    tst = spark.createDataFrame(\r\n        [('a', 7, 2, 0.0),\r\n         ('b', 3, 4, 1.0),\r\n         ('c', 5, 6, 0.0),\r\n         ('d', 7, 8, 1.0),\r\n         ('a', 9, 10, 0.0),\r\n         ('a', 11, 12, 1.0),\r\n         ('g', 13, 14, 0.0)],\r\n        schema=['col1', 'col2', 'col3', 'label'])\r\n\r\n    model = dummy_model(tst)\r\n    with mlflow.start_run(experiment_id=experiment_id) as run:\r\n        mlflow.spark.log_model(spark_model=model,\r\n                               registered_model_name=model_name,\r\n                               artifact_path=artifact_root + model_name)\r\n\r\n    versions = client.search_model_versions(\"name=\\'\" + model_name + \"\\'\")\r\n    version = versions[0].version  # latest version\r\n\r\n    print('Loading version ' + version + ' from model ' + model_name)\r\n    model_fetched = mlflow.spark.load_model(model_uri='models:\/' + model_name + '\/' + version)\r\n\r\n    model_fetched.transform(tst).show()\r\n```\r\n\r\nJust FYI, if I change the artifact root variable to start with \"**dbfs:\/**\" so that \r\n`artifact_root = 'dbfs:\/user\/existingfolder\/mlops\/'` then I get a completely different error: \r\n\r\n```\r\nWARN ProtoSerializer: Failed to deserialize remote exception\r\njava.io.InvalidClassException: failed to read class descriptor\r\n    at java.io.ObjectInputStream.readNonProxyDesc(Unknown Source)\r\n...\r\nCaused by: java.lang.ClassNotFoundException: com.databricks.backend.daemon.data.common.InvalidMountException\r\n...\r\nERROR Instrumentation: com.databricks.service.SparkServiceRemoteException: com.databricks.backend.daemon.data.common.InvalidMountException: Error while using path \/databricks\/mlflow-tracking\/867383642994223\/7e16b7270b4940bdaa99e62be008f729\/artifacts\\dbfs:\/user\/existingfolder\/mlops\/trial_1\/sparkml for resolving path '\/867383642994223\/7e16b7270b4940bdaa99e62be008f729\/artifacts\\dbfs:\/user\/existingfolder\/mlops\/trial_1\/sparkml' within mount at '\/databricks\/mlflow-tracking'.\r\n```\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [X] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [X] `integrations\/databricks`: Databricks integrations\r\n","104":null,"105":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 11\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.21.0\r\n- **Python version**: 3.9\r\n- **npm version, if running the dev UI**: N\/A\r\n- **Exact command to reproduce**: see problem description\r\n\r\n### Describe the problem\r\n\r\nInvestigating https:\/\/github.com\/mlflow\/mlflow\/issues\/5100, I am trying to run MLflow with local sqlite backend store and local file artifact store but the stores do not seem to get properly initialized and `mlflow ui` fails to list the experiments. It looks like store initialization should have created `.\\mlruns\\0\\meta.yaml` but did not.\r\n\r\nCommands:\r\n```\r\nconda env create -f conda.yaml\r\nconda activate MLflowTracking\r\nmkdir mlruns\r\nset MLFLOW_TRACKING_URI=sqlite:\/\/\/.\/mlruns\/sqlite.db\r\npython train.py\r\nmlflow ui\r\n```\r\n\r\nError:\r\n```\r\nINFO:waitress:Serving on http:\/\/127.0.0.1:5000\r\nWARNING:waitress.queue:Task queue depth is 1\r\nWARNING:root:Malformed experiment '0'. Detailed error Yaml file '.\\mlruns\\0\\meta.yaml' does not exist.\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\mmaitre\\Miniconda3\\envs\\MLflowTracking\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 257, in list_experiments\r\n    experiment = self._get_experiment(exp_id, view_type)\r\n  File \"C:\\Users\\mmaitre\\Miniconda3\\envs\\MLflowTracking\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 340, in _get_experiment\r\n    meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\r\n  File \"C:\\Users\\mmaitre\\Miniconda3\\envs\\MLflowTracking\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 175, in read_yaml\r\n    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\r\nmlflow.exceptions.MissingConfigException: Yaml file '.\\mlruns\\0\\meta.yaml' does not exist.\r\n```\r\n\r\n### Code to reproduce issue\r\n\r\nMiniconda environment `conda.yaml`:\r\n```\r\nname: MLflowTracking\r\nchannels:\r\n- nodefaults\r\ndependencies:\r\n- python=3.9\r\n- pip\r\n- pip:\r\n  - matplotlib==3.4.3\r\n  - scikit-learn==0.24.2\r\n  - mlflow==1.21.0\r\n```\r\n\r\nTraining script `train.py`:\r\n```\r\nimport mlflow\r\nimport sklearn\r\nimport logging\r\n\r\nmlflow.autolog(log_input_examples=True)\r\n\r\niris = sklearn.datasets.load_iris()\r\n\r\nwith mlflow.start_run() as run:\r\n    print(f'MLflow run ID: {run.info.run_id}')\r\n    model = sklearn.svm.SVC()\r\n    model.fit(iris.data, iris.target)\r\n\r\ntry:\r\n    mlflow.register_model(f'runs:\/{run.info.run_id}\/model', 'sklearn_svm_iris')\r\nexcept mlflow.exceptions.MlflowException:\r\n    logging.warning('Model registration skipped')\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [x] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [x] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","106":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nAt my company we make use of object versioning in S3 buckets to avoid accidental overwrites of model objects. By using a specific object version we can be sure that we're using the correct model in our serving container but in the same time give the flexibility to data scientists to have read\/write (but not delete) access to the S3 bucket where we store model objects. I propose a new feature to support downloading object versions from S3 buckets in `S3ArtifactRepository`.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n\r\nMany companies make use of S3 bucket versioning to avoid accidental overwrites of objects. `S3ArtifactRepository` could conform to this best practice by accepting an optional version id when downloading objects from S3 buckets.\r\n\r\n```python\r\ndef _download_file(self, remote_file_path, local_path, version_id=None):\r\n        \"\"\"\r\n        Download a version of an object from S3. If version_id is not specified,\r\n        it downloads the latest version.\r\n        \"\"\"\r\n        (bucket, s3_root_path) = data.parse_s3_uri(self.artifact_uri)\r\n        s3_full_path = posixpath.join(s3_root_path, remote_file_path)\r\n        s3_client = self._get_s3_client()\r\n\r\n        extra_args = {}\r\n        if version_id:\r\n            extra_args = {'VersionId': version_id}\r\n\r\n        s3_client.download_file(bucket, s3_full_path, local_path, ExtraArgs=extra_args)\r\n```\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\n\r\nThis feature could help teams operating MLflow repositories on S3 buckets by allowing them to make use of bucket versioning.\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n\r\nAt my company we rely on bucket versioning to guarantee availability of models and in the same time give the flexibility to users to read\/write in buckets where the models are stored. By using this feature we wouldn't have to worry about accidental overwriting of objects.\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nAs of now MLflow doesn't support downloading object versions from S3 buckets in `S3ArtifactRepository`. We currently achieve this by using an MLflow plugin that subclasses `S3ArtifactRepository` and adds the functionality for object versions. If object versions are not supported by `S3ArtifactRepository` then a bucket (or bucket prefix) where model objects are stored has to be read only for data scientist users to avoid accidental overwrites. We believe that read only permission is not flexible enough and support for object versions can improve the user experience.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n\r\nI propose updating the following functions\/classes:\r\n* `mlflow.<model>.load_model`: Accept version id when using S3 to download model artefacts\r\n* `mlflow.tracking.artifact_utils._download_artifact_from_uri`: Accept version id when using S3 to download model artefacts\r\n* `mlflow.store.artifact.artifact_repo.ArtifactRepository.download_artifacts`: Accept version id when using S3 to download model artefacts\r\n* `mlflow.store.artifact.s3_artifact_repo.S3ArtifactRepository._download_file`:  Use optional version id to download file from S3\r\n\r\n### Considerations\r\n\r\nVersioning S3 \"folders\"\/prefixes can be hideous since version id is assigned to objects, not prefixes. We solve this by compressing MLflow model folders to ZIP files and storing those on S3 buckets. This makes object versioning much easier. We could add this functionality too to `S3ArtifactRepository`.\r\n","107":"Hello,\r\n\r\nDoes anyone have a step by step tutorial on how to setup Mlflow with SQLite and Azure Blob Storage ?\r\n\r\nI have posted a related [question ](https:\/\/stackoverflow.com\/questions\/70084661\/setup-mlflow-backend-sqlite-and-artifact-azure-blob-storage-stores) on Stackoverflow to show what I tried so far.\r\n\r\nThank you in advance for your help.\r\n\r\n","108":"![image](https:\/\/user-images.githubusercontent.com\/48846150\/143200210-816182dd-aca4-45cd-9355-204f6a030c95.png)\r\n\r\nas the pic above, when log_metrics or whatever log with mlflow, it will output this in my terminal. \r\nhow to get rid of it?","109":"\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Azure Distributed cluster\r\n- **MLflow installed from (source or binary)**:  source\r\n- **MLflow version (run ``mlflow --version``)**: 1.12.0\r\n- **Python version**: 3.7.3\r\n\r\n### Describe the problem\r\nI am trying to deploy Prophet Model.\r\nModel is logged as mlflow.prophet flavour.\r\nWhen I am creating image from Model Artifact this error came :\r\nWebserviceException: WebserviceException:\r\n        \"error\": {\r\n            \"message\": \"Image creation polling reached non-successful terminal state, current state: Failed\\nError response from server:\\nStatusCode: 400\\nMessage: Docker image build failed.\"\r\n        }\r\n    }\r\n\r\n### Code to reproduce issue\r\n    import azureml\r\n    import mlflow.azureml\r\n    from azureml.core import Workspace\r\n    from azureml.core.authentication import ServicePrincipalAuthentication\r\n    from azureml.core.webservice import AciWebservice, Webservice\r\n    \r\n    principal_auth = ServicePrincipalAuthentication(tenant_id, principal_id, app_secret)\r\n    workspace = Workspace.get(name=workspace_name, subscription_id=subscription_id, auth=principal_auth, resource_group=workspace_rg)\r\n    model_image, azureml_model = mlflow.azureml.build_image(model_uri='runs:\/016fc3f2d5c34c8eadbeb20ad16d3\/082358timeseriesforecasting', workspace=workspace)\r\n    model_image.wait_for_creation(show_output=True)\r\n\r\n### Other info \/ logs\r\nIn Container logs error is shown below:\r\n\r\n [0mThe command '\/bin\/sh -c CONDA_ROOT_DIR=$(conda info --root) && if [ -n \"$AZUREML_CONDA_ENVIRONMENT_PATH\" ]; then conda env update -p \"$AZUREML_CONDA_ENVIRONMENT_PATH\" -f '\/var\/azureml-app\/conda.yaml'; else conda env update -n base -f '\/var\/azureml-app\/conda.yaml'; fi && conda clean -aqy && rm -rf \/root\/.cache\/pip && rm -rf \"$CONDA_ROOT_DIR\/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} +' returned a non-zero code: 137\r\n2021\/11\/23 12:21:39 Container failed during run: acb_step_0. No retries remaining.\r\nfailed to run step ID: acb_step_0: exit status 137\r\n\r\nRun ID: cj58 failed after 6m19s. Error: failed during run, err: exit status 1\r\n\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [x ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\nPython\r\n\r\nIntegrations\r\n- [ x] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ x] `integrations\/databricks`: Databricks integrations\r\n","110":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**:\r\n- **Python version**:\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\nWhen i run the command, i get the error shown in the log (see below). Can someone tell me how to fix it? \r\nSeems to db is wrongly configured in the auto create of the sqldb.\r\n\r\n### Code to reproduce issue\r\n\r\nweb: mlflow server --host 0.0.0.0 --port 8080 --backend-store-uri mysql:\/\/URI --default-artifact-root .\/mlflowruns\r\n\r\n### Other info \/ logs\r\n```\r\n2021-11-22T19:44:59.784+01:00 [APP\/PROC\/WEB\/0] [ERR] 2021\/11\/22 18:44:59 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\r\n2021-11-22T19:44:59.801+01:00 [APP\/PROC\/WEB\/0] [ERR] 2021\/11\/22 18:44:59 ERROR mlflow.cli: Error initializing backend store\r\n2021-11-22T19:44:59.805+01:00 [APP\/PROC\/WEB\/0] [ERR] 2021\/11\/22 18:44:59 ERROR mlflow.cli: (MySQLdb._exceptions.OperationalError) (1709, 'Index column size too large. The maximum column size is 767 bytes')\r\n2021-11-22T19:44:59.805+01:00 [APP\/PROC\/WEB\/0] [ERR] [SQL:\r\n``` \r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [x ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","111":"Signed-off-by: harupy <hkawamura0130@gmail.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nAdd a python script to list failed cross version tests. This script will be called by our internal Jenkins job that automatically files ES tickets.\r\n\r\n## How is this patch tested?\r\n\r\nUnit tests\r\n\r\n## Does this PR change the documentation?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Make sure the changed pages \/ sections render correctly by following the steps below.\r\n\r\n1. Check the status of the `ci\/circleci: build_doc` check. If it's successful, proceed to the\r\n   next step, otherwise fix it.\r\n2. Click `Details` on the right to open the job page of CircleCI.\r\n3. Click the `Artifacts` tab.\r\n4. Click `docs\/build\/html\/index.html`.\r\n5. Find the changed pages \/ sections and make sure they render correctly.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","112":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Centos7\r\n- **MLflow installed from (source or binary)**: conda install -c conda-forge \r\n- **MLflow version (run ``mlflow --version``)**: version 1.21.0\r\n- **Python version**:  Python 3.7.11\r\n- **npm version, if running the dev UI**: No\r\n- **Exact command to reproduce**:\r\n\r\n\r\n### Describe the problem\r\nI was trying to use a remote HDFS to store my models, as a backend-artifact-root. Unfortunately, I got this error that said cannot find Hadoop. I did not install Hadoop on my local machine since the data engineer insist that there is no way that I can only figure it out by installing a Hadoop locally and a Hadoop installed on the server should be enough. I spent a few days still cannot save my models to HDFS, so I hope anyone here could help me. Thanks a lot!\r\n \r\nHere's my process:\r\n1. First I start a mlflow server on the remote AWS EC2 like that\r\n```\r\nmlflow server \\\r\n         --backend-store-uri mysql+pymysql:\/\/root:pwd@localhost\/mlflow_tracking_database \\\r\n         --default-artifact-root hdfs:\/\/localhost:14000\/webhdfs\/v1\/models_artifacts?op=LISTSTATUS \\\r\n         --host 0.0.0.0\r\n```\r\n\r\n2. Then I run the example sklearn_logistic_regression on my local machine as shown below.\r\n### Code to reproduce issue\r\n```\r\nimport numpy as np\r\nfrom sklearn.linear_model import LogisticRegression\r\n\r\nimport mlflow\r\nimport mlflow.sklearn\r\n\r\nif __name__ == \"__main__\":\r\n    mlflow.set_tracking_uri(\"http:\/\/ec2host:5000\")\r\n    mlflow.set_experiment(\"test-experiment\")\r\n    X = np.array([-2, -1, 0, 1, 2, 1]).reshape(-1, 1)\r\n    y = np.array([0, 0, 1, 1, 1, 0])\r\n    lr = LogisticRegression()\r\n    lr.fit(X, y)\r\n    score = lr.score(X, y)\r\n    print(\"Score: %s\" % score)\r\n    mlflow.log_metric(\"score\", score)\r\n    mlflow.sklearn.log_model(lr, \"model\")\r\n    print(\"Model saved in run %s\" % mlflow.active_run().info.run_uuid)\r\n```\r\n\r\n### Other info \/ logs\r\n```\r\nScore: 0.6666666666666666\r\n\/root\/anaconda3\/envs\/ueba_env\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact\/hdfs_artifact_repo.py:183: FutureWarning: pyarrow.hdfs.connect is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\r\n  extra_conf=extra_conf,\r\nTraceback (most recent call last):\r\n  File \"\/CF-AI\/mlflow-demo-master\/sklearn_logistic_regression\/train.py\", line 17, in <module>\r\n    mlflow.sklearn.log_model(lr, \"model\")\r\n  File \"\/root\/anaconda3\/envs\/ueba_env\/lib\/python3.7\/site-packages\/mlflow\/sklearn\/__init__.py\", line 380, in log_model\r\n    extra_pip_requirements=extra_pip_requirements,\r\n  File \"\/root\/anaconda3\/envs\/ueba_env\/lib\/python3.7\/site-packages\/mlflow\/models\/model.py\", line 188, in log\r\n    mlflow.tracking.fluent.log_artifacts(local_path, artifact_path)\r\n  File \"\/root\/anaconda3\/envs\/ueba_env\/lib\/python3.7\/site-packages\/mlflow\/tracking\/fluent.py\", line 584, in log_artifacts\r\n    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)\r\n  File \"\/root\/anaconda3\/envs\/ueba_env\/lib\/python3.7\/site-packages\/mlflow\/tracking\/client.py\", line 985, in log_artifacts\r\n    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)\r\n  File \"\/root\/anaconda3\/envs\/ueba_env\/lib\/python3.7\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 341, in log_artifacts\r\n    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)\r\n  File \"\/root\/anaconda3\/envs\/ueba_env\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact\/hdfs_artifact_repo.py\", line 48, in log_artifacts\r\n    with hdfs_system(scheme=self.scheme, host=self.host, port=self.port) as hdfs:\r\n  File \"\/root\/anaconda3\/envs\/ueba_env\/lib\/python3.7\/contextlib.py\", line 112, in __enter__\r\n    return next(self.gen)\r\n  File \"\/root\/anaconda3\/envs\/ueba_env\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact\/hdfs_artifact_repo.py\", line 183, in hdfs_system\r\n    extra_conf=extra_conf,\r\n  File \"\/root\/anaconda3\/envs\/ueba_env\/lib\/python3.7\/site-packages\/pyarrow\/hdfs.py\", line 229, in connect\r\n    extra_conf=extra_conf\r\n  File \"\/root\/anaconda3\/envs\/ueba_env\/lib\/python3.7\/site-packages\/pyarrow\/hdfs.py\", line 239, in _connect\r\n    extra_conf=extra_conf)\r\n  File \"\/root\/anaconda3\/envs\/ueba_env\/lib\/python3.7\/site-packages\/pyarrow\/hdfs.py\", line 47, in __init__\r\n    _maybe_set_hadoop_classpath()\r\n  File \"\/root\/anaconda3\/envs\/ueba_env\/lib\/python3.7\/site-packages\/pyarrow\/hdfs.py\", line 147, in _maybe_set_hadoop_classpath\r\n    classpath = _hadoop_classpath_glob('hadoop')\r\n  File \"\/root\/anaconda3\/envs\/ueba_env\/lib\/python3.7\/site-packages\/pyarrow\/hdfs.py\", line 172, in _hadoop_classpath_glob\r\n    return subprocess.check_output(hadoop_classpath_args)\r\n  File \"\/root\/anaconda3\/envs\/ueba_env\/lib\/python3.7\/subprocess.py\", line 411, in check_output\r\n    **kwargs).stdout\r\n  File \"\/root\/anaconda3\/envs\/ueba_env\/lib\/python3.7\/subprocess.py\", line 488, in run\r\n    with Popen(*popenargs, **kwargs) as process:\r\n  File \"\/root\/anaconda3\/envs\/ueba_env\/lib\/python3.7\/subprocess.py\", line 800, in __init__\r\n    restore_signals, start_new_session)\r\n  File \"\/root\/anaconda3\/envs\/ueba_env\/lib\/python3.7\/subprocess.py\", line 1551, in _execute_child\r\n    raise child_exception_type(errno_num, err_msg, err_filename)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'hadoop': 'hadoop'\r\n\r\nProcess finished with exit code 1\r\n```\r\n\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\n","113":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [X] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nThe Deployment Plugin `predict` CLI currently only accepts tabular data in the form of serialized Pandas DataFrames. However, the pyfunc MLflow Model format now supports evaluation of tensors, in addition to tabular data. This CLI should be updated to support all of the data types that are supported by `mlflow.pyfunc.PyFuncModel.predict()` (https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.pyfunc.html#mlflow.pyfunc.PyFuncModel).\r\n\r\nOn a related note, the `mlflow.models.predict()` interface and CLI has the same limitation.\r\n\r\n## Motivation\r\n- What is the use case for this feature? Support inference of deployed tensor-based models through a unified API.\r\n- Why is this use case valuable to support for MLflow users in general? Many MLflow users deploy tensor-based models.\r\n- Why is this use case valuable to support for your project(s) or organization? ^\r\n- Why is it currently difficult to achieve this use case? See above.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [X] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations","114":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS 11.6\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: mlflow, version 1.20.2\r\n- **Python version**: 3.8.8\r\n- **npm version, if running the dev UI**: --\r\n- **Exact command to reproduce**: --\r\n\r\n### Describe the problem\r\nIf you try to log_model or log_artifact bigger than 5 GB it fails with \r\n```\r\nmlflow.exceptions.MlflowException: API request failed with exception 400 Client Error\r\n```\r\nIt doesn't happen for files that are smaller than 5 GB (even slightly like 4.9 GB file).\r\n\r\nThis probably happens due to use of \"upload_file\" method from boto3 in \r\n```\r\nmlflow.store.artifact.artifact_repo.S3ArtifactRepository._upload_file \r\n```\r\nmethod, which seems to upload the file with single PUT method.\r\n\r\nThe size of the file uploaded in the single put method is limited to 5GB.\r\nA solution would be to use multipart upload for bigger files: https:\/\/stackoverflow.com\/questions\/43021266\/aws-s3-max-file-and-upload-sizes\r\n\r\nUploading files bigger than 5GB is required for speech recognition models for example.\r\n\r\n\r\n### Code to reproduce issue\r\nmlflow.log_artifact(\"\/file\/bigger\/than\/5\/GB.txt\", \"model\")\r\n\r\n### Other info \/ logs\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","115":"### Describe the problem\r\n[Review Python issue](https:\/\/bugs.python.org\/msg403410) \r\nDue to this issue running [docker example](https:\/\/github.com\/mlflow\/mlflow\/blob\/422c1c90bd7efde857fc55a134289d661da4c9bf\/examples\/docker\/Dockerfile) is failing.\r\nIt is throwing the same exception as in above python issue.\r\n[Mini conda version being used in docker image](https:\/\/hub.docker.com\/r\/continuumio\/miniconda3\/tags)\r\n\r\n### Other info \/ logs\r\n![image](https:\/\/user-images.githubusercontent.com\/23078472\/142166637-c9bab1dc-8cf3-4bc4-8c39-1de67bfee9d8.png)\r\nand it seems the fixes for above issues only committed for [main, 3.9 and 3.10 branches](https:\/\/bugs.python.org\/issue45406)\r\n","116":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\nEnable `mlflow.log_params` to log parameters with length over 250 characters.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nWe use `mlflow.log_params` to log parameters in the training pipeline.\r\nThe parameters could be hyperparameters or which text columns to used for the model. Some of the parameters have long names which may come from another platform like ETL which causes the following error:\r\n```\r\nmlflow.exceptions.MlflowException: Param value '[...' had length 376, which exceeded length limit of 250\r\n```\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\n    1. It would be easier for pytorch lightning users to log parameters with length over 250 characters. Please find the below issue and the PR accordingly.\r\n    https:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/issues\/5892\r\n    https:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/pull\/5893\r\n    2. We also found the same feature requests in the past:\r\n    https:\/\/github.com\/mlflow\/mlflow\/issues\/1976\r\n    https:\/\/github.com\/mlflow\/mlflow\/issues\/3931\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nIf it is possible for `mlflow.log_params` to expand the length limit, it would be easier for us to manage logs across platforms.\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nTo achieve this use case, we need to build another logger to maintain the logs.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/7b4ab0e4cac5d4c2d2cbfcd3d12aa55b2ee83efe\/mlflow\/utils\/validation.py#L29","117":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this installation issue template to ensure a timely and thorough response.**\r\n\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Monterey (MBA M1)\r\n- **MLflow installed from (source or binary)**:  source\r\n- **MLflow version (run ``mlflow --version``)**:  1.21.0\r\n- **Python version**: 3.8 (but also tried with 3.6)\r\n- **Exact command to reproduce**: `npm install`\r\n- **NPM version**: `npm 8.1.3`\r\n\r\n### Describe the problem\r\nI've been trying to follow the instructions provided in [Section 11](https:\/\/github.com\/mlflow\/mlflow\/blob\/a35ee7a5a3167ce05d6e9faf9169bbd4d819b750\/CONTRIBUTING.rst#id11) with no success.  There are some incompatibilities with python packages (because of the M1) but I managed to get them working. The Javascript and UI on the other hand, no matter what I've tried doesn't seem to work. Running the `npm install` results in the errors in attachment.\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached\r\n[2021-11-16T12_59_45_764Z-debug.log](https:\/\/github.com\/mlflow\/mlflow\/files\/7546444\/2021-11-16T12_59_45_764Z-debug.log)\r\n\r\n\r\n","118":"Signed-off-by: M Hemendra Kumar <mhemendrakumar@gmail.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nThis PR fixes the https:\/\/github.com\/mlflow\/mlflow\/issues\/5067 by removing the _validate_param_name and _validate_tag_name from the _valid_param and _valid_tag respectively. This ensure the name is being validated only once for file_store and sqlalchemy_store.\r\n\r\n## How is this patch tested?\r\n\r\nManually tested the changes to ensure the param_name and tag_name are still being validated.\r\n\r\n## Does this PR change the documentation?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Make sure the changed pages \/ sections render correctly by following the steps below.\r\n\r\n1. Check the status of the `ci\/circleci: build_doc` check. If it's successful, proceed to the\r\n   next step, otherwise fix it.\r\n2. Click `Details` on the right to open the job page of CircleCI.\r\n3. Click the `Artifacts` tab.\r\n4. Click `docs\/build\/html\/index.html`.\r\n5. Find the changed pages \/ sections and make sure they render correctly.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [x] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","119":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\n\r\nThe _validate_param_name and _validate_tag_name methods are being called twice during the log_batch call, once in the _tracking_service\\client.py and again inside the _validate_batch_log_data function call in both sqlalchemy_store and the file_store. The _validate_batch_log_data in turn calls the _validate_param and _validate_tag methods. \r\n\r\nThere are two ways of fixing the redundant call for _validate_param_name and _validate_tag_name\r\n1. Remove from log_batch in _tracking_service\\client.py\r\n2. Remove from the _validate_param and _validate_tag methods\r\n\r\nI think option 2 works because if we use option 1 there wont be a call to _validate_param_name and _validate_tag_name in case of rest_store.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [x] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","120":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\n\r\nI would appreciate it if we could have integration to keras tuner (e.g. https:\/\/www.tensorflow.org\/tutorials\/keras\/keras_tuner#instantiate_the_tuner_and_perform_hypertuning).\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","121":"Hello,\r\n\r\nI posted this question on stackoverflow two weeks ago but couldn't get an answer. Could you please help me with this issue, as I still can't figure out how to solve it ?\r\n\r\nHere's the link to the [question on stackoverflow](https:\/\/stackoverflow.com\/questions\/69738859\/multiple-values-for-a-single-parameter-in-the-mlflow-run-command).\r\n\r\nThank you in advance !","122":"the traceback : \r\n\r\n```python\r\n      1 import mlflow.pyfunc\r\n      2 import mlflow\r\n----> 3 model = mlflow.pyfunc.load_model(\r\n      4     model_uri=f\"models:\/LGBModel\/6\"\r\n      5 )\r\n\r\n\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/pyfunc\/__init__.py in load_model(model_uri, suppress_warnings)\r\n    649                               messages will be emitted.\r\n    650     \"\"\"\r\n--> 651     local_path = _download_artifact_from_uri(artifact_uri=model_uri)\r\n    652     model_meta = Model.load(os.path.join(local_path, MLMODEL_FILE_NAME))\r\n    653 \r\n\r\n\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/tracking\/artifact_utils.py in _download_artifact_from_uri(artifact_uri, output_path)\r\n     93         root_uri = prefix + urllib.parse.urlunparse(parsed_uri)\r\n     94 \r\n---> 95     return get_artifact_repository(artifact_uri=root_uri).download_artifacts(\r\n     96         artifact_path=artifact_path, dst_path=output_path\r\n     97     )\r\n\r\n\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/store\/artifact\/models_artifact_repo.py in download_artifacts(self, artifact_path, dst_path)\r\n    108         :return: Absolute path of the local filesystem location containing the desired artifacts.\r\n    109         \"\"\"\r\n--> 110         return self.repo.download_artifacts(artifact_path, dst_path)\r\n    111 \r\n    112     def _download_file(self, remote_file_path, local_path):\r\n\r\n\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/store\/artifact\/hdfs_artifact_repo.py in download_artifacts(self, artifact_path, dst_path)\r\n    132             if not hdfs.isdir(hdfs_base_path):\r\n    133                 local_path = os.path.join(local_dir, os.path.normpath(artifact_path))\r\n--> 134                 _download_hdfs_file(hdfs, hdfs_base_path, local_path)\r\n    135                 return local_path\r\n    136 \r\n\r\n\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/store\/artifact\/hdfs_artifact_repo.py in _download_hdfs_file(hdfs, remote_file_path, local_file_path)\r\n    224     if not os.path.exists(dirs):\r\n    225         os.makedirs(dirs)\r\n--> 226     with open(local_file_path, \"wb\") as f:\r\n    227         f.write(hdfs.open(remote_file_path, \"rb\").read())\r\n    228 \r\n\r\nIsADirectoryError: [Errno 21] Is a directory: '\/tmp\/tmpsos7uut3\/.'\r\n```\r\n\r\nIf I call the function: \r\n```python\r\nmlflow.pyfunc.load_model(\"models:\/xxx\/xxx\")\r\n```\r\nIt will call into : `_download_artifact_from_uri(\"models:\/xxx\/xxx\")`, as the uri is a models uri,  the `artifact_path` will be set to empty string [at here](https:\/\/github.com\/mlflow\/mlflow\/blob\/d6ae84164987e2881cdffdce07f7dcf0e3d94aaa\/mlflow\/tracking\/artifact_utils.py#L89)\r\n```python\r\n    if ModelsArtifactRepository.is_models_uri(artifact_uri):\r\n        root_uri = artifact_uri\r\n        artifact_path = \"\"  # set empty here\r\n    else:\r\n        artifact_path = posixpath.basename(parsed_uri.path)\r\n        parsed_uri = parsed_uri._replace(path=posixpath.dirname(parsed_uri.path))\r\n        root_uri = prefix + urllib.parse.urlunparse(parsed_uri)\r\n\r\n    return get_artifact_repository(artifact_uri=root_uri).download_artifacts(\r\n        artifact_path=artifact_path, dst_path=output_path\r\n    )\r\n```\r\n\r\nand then the `artifact_path` will be used to `download_artifacts` by `HdfsArtifactRepository`,  it should generate a `local_path` for download, but the empty `artifact_path` will generate a directory: \r\n```python\r\ndef download_artifacts(self, artifact_path, dst_path=None):\r\n        # aritfact_path is empty\r\n        hdfs_base_path = _resolve_base_path(self.path, artifact_path)\r\n        local_dir = _tmp_dir(dst_path)\r\n       \r\n        with hdfs_system(scheme=self.scheme, host=self.host, port=self.port) as hdfs:\r\n            # of couse is not dir\r\n            if not hdfs.isdir(hdfs_base_path):\r\n                # `os.path.normpath` return \".\" because aritifact_path is empty; \r\n                local_path = os.path.join(local_dir, os.path.normpath(artifact_path))\r\n                _download_hdfs_file(hdfs, hdfs_base_path, local_path)\r\n                return local_path\r\n       ...\r\n```\r\n\r\nthen open file on a directory will cause an error: \r\n\r\n```\r\n\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/store\/artifact\/hdfs_artifact_repo.py in _download_hdfs_file(hdfs, remote_file_path, local_file_path)\r\n    224     if not os.path.exists(dirs):\r\n    225         os.makedirs(dirs)\r\n--> 226     with open(local_file_path, \"wb\") as f:\r\n    227         f.write(hdfs.open(remote_file_path, \"rb\").read())\r\n```\r\n\r\n","123":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [x] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu18.04, Windows 10\r\n- **MLflow installed from (source or binary)**: MLflow R SDK from https:\/\/cloud.r-project.org\/\r\n- **MLflow version (run ``mlflow --version``)**: 1.20.2\r\n- **Python version**: NA\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nIn R MLflow SDK as a part of mlflow_log_model api call [timestamp](https:\/\/github.com\/mlflow\/mlflow\/blob\/d6ae84164987e2881cdffdce07f7dcf0e3d94aaa\/mlflow\/R\/mlflow\/R\/model.R#L57) generated to capture model creation time, is an invalid timestamp string.\r\n \r\nA sample timestamp string generated is **21-11-11T21:49:25.25.46**. This string cannot be parsed by C# [DateTime.Parse](https:\/\/docs.microsoft.com\/en-us\/dotnet\/api\/system.datetime.parse?view=net-5.0#System_DateTime_Parse_System_String_) and throws following error **[System.FormatException: String was not recognized as a valid DateTime**\r\n\r\n### Code to reproduce issue\r\n1. Run following R code in R Studio to generate a timestamp as generated to [mlflow_log_model ](https:\/\/github.com\/mlflow\/mlflow\/blob\/d6ae84164987e2881cdffdce07f7dcf0e3d94aaa\/mlflow\/R\/mlflow\/R\/model.R#L30)API\r\n```R\r\nmlflow_timestamp <- function() {\r\n  withr::with_options(\r\n    c(digits.secs = 2),\r\n    format(\r\n      as.POSIXlt(Sys.time(), tz = \"GMT\"),\r\n      \"%y-%m-%dT%H:%M:%S.%OS\"\r\n    )\r\n  )\r\n}\r\n\r\nmlflow_timestamp ()\r\n```\r\n2. Copy the timestamp string generated in step 1 and run following C# code\r\n```csharp\r\nusing System;\r\n\t\t\t\t\t\r\npublic class Program\r\n{\r\n\tpublic static void Main()\r\n\t{\r\n\t\t\t\t\/\/Corrected Date Format in string\r\n\t\t \t\tstring test = \"21-11-11T21:49:25.25.46\";\r\n\t\t\t\t\/\/Convert the string date value to datetime \r\n                DateTime DT = DateTime.Parse(test);\r\n\t\t\r\n\t\t\t \tConsole.WriteLine(\"Value in datetime format : \" + DT);\r\n\t\t\r\n\t}\r\n}\r\n```\r\n\r\nIt will result in following error: \r\n```csharp\r\nStack Trace:\r\n\r\n[System.FormatException: String was not recognized as a valid DateTime.]\r\n   at System.DateTimeParse.Parse(String s, DateTimeFormatInfo dtfi, DateTimeStyles styles)\r\n   at System.DateTime.Parse(String s)\r\n   at Program.Main() :line 10\r\n```\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [X] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","124":"Signed-off-by: Mohamad Arabi <mohamad.arabi@databricks.com>\r\n\r\n## What changes are proposed in this pull request?\r\nWe are proposing that the paginating feature of the `search_runs()` fluent api request runs in batches of 1k instead of 10k from `MlflowClient().search_runs`. This doesn't change the functionality of fetching runs for mlflow client.\r\n\r\n## How is this patch tested?\r\nNo test added, can\r\n\r\n## Does this PR change the documentation?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Make sure the changed pages \/ sections render correctly by following the steps below.\r\n\r\n1. Check the status of the `ci\/circleci: build_doc` check. If it's successful, proceed to the\r\n   next step, otherwise fix it.\r\n2. Click `Details` on the right to open the job page of CircleCI.\r\n3. Click the `Artifacts` tab.\r\n4. Click `docs\/build\/html\/index.html`.\r\n5. Find the changed pages \/ sections and make sure they render correctly.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","125":"In machine learning projects which have multi steps such as preprocessing, feature engineering and model training, it's easy to train with MLFlowProject, but after that how to automatically serving the whole pipline in production?","126":"## Willingness to contribute\r\n- [x] Yes. I can contribute this feature independently.\r\n\r\n## Proposal Summary\r\nI want to add a separate TensorFlow Lite flavor (tflite) to the list of supported MLFlow flavors. \r\n\r\n## Motivation\r\n- ***What is the use case for this feature?*** - To use mlflow functionality for the TensorFlow Lite models for logging runs and storing artefacts in a format, suitable to be propagated to the embedded devices without any extra change required. \r\n- ***Why is this use case valuable to support for MLflow users in general?*** - it gives MLflow users ability to build end-to-end integration between environments when models are defined and trained and target embedded environments that support TensorFlow Lite runtime for inference. \r\n- ***Why is this use case valuable to support for your project(s) or organization?*** - I serve as a consultant for US based client with 1M+ consumer IoT devices running ML models. We are currently using Databricks for the model development and training. When there is time for the model to be propagated to the embedded device, we use custom enhancement  over mlfow.models.Model to specify log, save, load and pyfunc load logic for integration of TensorFlow Lite with MLFlow. It works as expected, but having this workaround is increasing complexity (we either need to reference custom class in each notebook by running notebook with class declaration code, or create a separate module with this class and install on cluster).  \r\n- ***Why is it currently difficult to achieve this use case?***  - as specified above, it is achievable through custom class declaration using inheritance from mlflow, however, it doesn't provide proper integration and should be considered as a bed pattern. \r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [X] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n\r\n\r\n## Details\r\nIf approved I can link my pull request as a proposal for implementation. \r\nI used existing implementations of the flavors as reference during development. \r\n","127":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:  - No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: - Windows 10 \r\n- **MLflow installed from (source or binary)**: - binary (pip install mlflow)\r\n- **MLflow version (run ``mlflow --version``)**: - mlflow, version 1.21.0\r\n- **Python version**: - 3.9.5\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:  - Launch mlflow ui\r\n\r\n### Describe the problem\r\nWhen I launch the `mlflow ui` I get an error `500 Internal Server Error Internal Server Error The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.` \r\n\r\n### Code to reproduce issue\r\n1. Start the Tracking Server and point it to MS-SQL Server. \r\n2. Run the Training using train.py (I used the one from examples\\sklearn_elasticnet_wine\r\n3. Start the MLFlow UI using `mlflow ui` command and pointing `--backend-store-uri` to the MS-SQL Server \r\n4. Open the web page and go to `localhost:5000` \r\n\r\nFollowing error appears - \r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/4989127\/140950877-75d4ab43-6e32-4b28-a15d-12a3b91b9592.png)\r\n\r\n\r\n### My Analysis\r\n\r\nThis is the problematic query - \r\n\r\n```\r\ndeclare @p1 int\r\nset @p1=NULL\r\nexec sp_prepexec @p1 output,N'@P1 int,@P2 int,@P3 nvarchar(2),@P4 nvarchar(12),@P5 int,@P6 int,@P7 int,@P8 int',\r\nN'SELECT DISTINCT runs.run_uuid AS runs_run_uuid, runs.name AS runs_name, runs.source_type AS runs_source_type, \r\nruns.source_name AS runs_source_name, runs.entry_point_name AS runs_entry_point_name, runs.user_id AS runs_user_id, \r\nruns.status AS runs_status, runs.start_time AS runs_start_time, runs.end_time AS runs_end_time, runs.source_version \r\nAS runs_source_version, runs.lifecycle_stage AS runs_lifecycle_stage, runs.artifact_uri AS runs_artifact_uri, \r\nruns.experiment_id AS runs_experiment_id, CASE WHEN (runs.start_time IS NULL) THEN @P1 ELSE @P2 END AS anon_1 \r\nFROM runs \r\nWHERE runs.experiment_id IN (@P3) AND runs.lifecycle_stage IN (@P4) ORDER BY CASE WHEN (runs.start_time IS NULL) THEN @P5 ELSE @P6 END, runs.start_time DESC, runs.run_uuid\r\n OFFSET @P7 ROWS\r\n FETCH FIRST @P8 ROWS ONLY',1,0,N'0',N'active',1,0,0,100\r\nselect @p1\r\n```\r\n\r\n\r\n### Other info \/ logs\r\n```\r\n2021\/11\/09 20:34:45 ERROR mlflow.server: Exception on \/ajax-api\/2.0\/preview\/mlflow\/runs\/search [POST]\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1799, in _execute_context\r\n    self.dialect.do_execute(\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\site-packages\\sqlalchemy\\engine\\default.py\", line 717, in do_execute\r\n    cursor.execute(statement, parameters)\r\npyodbc.ProgrammingError: ('42000', '[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]ORDER BY items must appear in the select list if SELECT DISTINCT is specified. (145) (SQLExecDirectW); [42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Statement(s) could not be prepared. (8180)')\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\site-packages\\mlflow\\store\\db\\utils.py\", line 79, in make_managed_session\r\n    yield session\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\site-packages\\mlflow\\store\\tracking\\sqlalchemy_store.py\", line 785, in _search_runs\r\n    query.distinct()\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\site-packages\\sqlalchemy\\orm\\query.py\", line 2711, in all\r\n    return self._iter().all()\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\site-packages\\sqlalchemy\\orm\\query.py\", line 2846, in _iter\r\n    result = self.session.execute(\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\site-packages\\sqlalchemy\\orm\\session.py\", line 1689, in execute\r\n    result = conn._execute_20(statement, params or {}, execution_options)\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1611, in _execute_20\r\n    return meth(self, args_10style, kwargs_10style, execution_options)\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\site-packages\\sqlalchemy\\sql\\elements.py\", line 325, in _execute_on_connection\r\n    return connection._execute_clauseelement(\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1478, in _execute_clauseelement\r\n    ret = self._execute_context(\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1842, in _execute_context\r\n    self._handle_dbapi_exception(\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 2023, in _handle_dbapi_exception\r\n    util.raise_(\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\site-packages\\sqlalchemy\\util\\compat.py\", line 207, in raise_\r\n    raise exception\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1799, in _execute_context\r\n    self.dialect.do_execute(\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\site-packages\\sqlalchemy\\engine\\default.py\", line 717, in do_execute\r\n    cursor.execute(statement, parameters)\r\nsqlalchemy.exc.ProgrammingError: (pyodbc.ProgrammingError) ('42000', '[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]ORDER BY items must appear in the select list if SELECT DISTINCT is specified. (145) (SQLExecDirectW); [42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Statement(s) could not be prepared. (8180)')\r\n[SQL: SELECT DISTINCT runs.run_uuid AS runs_run_uuid, runs.name AS runs_name, runs.source_type AS runs_source_type, runs.source_name AS runs_source_name, runs.entry_point_name AS runs_entry_point_name, runs.user_id AS runs_user_id, runs.status AS runs_status, runs.start_time AS runs_start_time, runs.end_time AS runs_end_time, runs.source_version AS runs_source_version, runs.lifecycle_stage AS runs_lifecycle_stage, runs.artifact_uri AS runs_artifact_uri, runs.experiment_id AS runs_experiment_id, CASE WHEN (runs.start_time IS NULL) THEN ? ELSE ? END AS anon_1\r\nFROM runs\r\nWHERE runs.experiment_id IN (?) AND runs.lifecycle_stage IN (?) ORDER BY CASE WHEN (runs.start_time IS NULL) THEN ? ELSE ? END, runs.start_time DESC, runs.run_uuid\r\n OFFSET ? ROWS\r\n FETCH FIRST ? ROWS ONLY]\r\n[parameters: (1, 0, '0', 'active', 1, 0, 0, 100)]\r\n(Background on this error at: https:\/\/sqlalche.me\/e\/14\/f405)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\site-packages\\mlflow\\server\\handlers.py\", line 214, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\site-packages\\mlflow\\server\\handlers.py\", line 467, in _search_runs\r\n    run_entities = _get_tracking_store().search_runs(\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\site-packages\\mlflow\\store\\tracking\\abstract_store.py\", line 242, in search_runs\r\n    runs, token = self._search_runs(\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\site-packages\\mlflow\\store\\tracking\\sqlalchemy_store.py\", line 799, in _search_runs\r\n    next_page_token = compute_next_token(len(runs))\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\contextlib.py\", line 135, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\site-packages\\mlflow\\store\\db\\utils.py\", line 86, in make_managed_session\r\n    raise MlflowException(message=e, error_code=INTERNAL_ERROR)\r\nmlflow.exceptions.MlflowException: (pyodbc.ProgrammingError) ('42000', '[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]ORDER BY items must appear in the select list if SELECT DISTINCT is specified. (145) (SQLExecDirectW); [42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Statement(s) could not be prepared. (8180)')\r\n[SQL: SELECT DISTINCT runs.run_uuid AS runs_run_uuid, runs.name AS runs_name, runs.source_type AS runs_source_type, runs.source_name AS runs_source_name, runs.entry_point_name AS runs_entry_point_name, runs.user_id AS runs_user_id, runs.status AS runs_status, runs.start_time AS runs_start_time, runs.end_time AS runs_end_time, runs.source_version AS runs_source_version, runs.lifecycle_stage AS runs_lifecycle_stage, runs.artifact_uri AS runs_artifact_uri, runs.experiment_id AS runs_experiment_id, CASE WHEN (runs.start_time IS NULL) THEN ? ELSE ? END AS anon_1\r\nFROM runs\r\nWHERE runs.experiment_id IN (?) AND runs.lifecycle_stage IN (?) ORDER BY CASE WHEN (runs.start_time IS NULL) THEN ? ELSE ? END, runs.start_time DESC, runs.run_uuid\r\n OFFSET ? ROWS\r\n FETCH FIRST ? ROWS ONLY]\r\n[parameters: (1, 0, '0', 'active', 1, 0, 0, 100)]\r\n(Background on this error at: https:\/\/sqlalche.me\/e\/14\/f405)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\site-packages\\flask\\app.py\", line 2073, in wsgi_app\r\n    response = self.full_dispatch_request()\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\site-packages\\flask\\app.py\", line 1518, in full_dispatch_request\r\n    rv = self.handle_user_exception(e)\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\site-packages\\flask\\app.py\", line 1516, in full_dispatch_request\r\n    rv = self.dispatch_request()\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\site-packages\\flask\\app.py\", line 1502, in dispatch_request\r\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\site-packages\\mlflow\\server\\handlers.py\", line 217, in wrapper\r\n    response.set_data(e.serialize_as_json())\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\site-packages\\mlflow\\exceptions.py\", line 60, in serialize_as_json\r\n    return json.dumps(exception_dict)\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\json\\__init__.py\", line 231, in dumps\r\n    return _default_encoder.encode(obj)\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\json\\encoder.py\", line 199, in encode\r\n    chunks = self.iterencode(o, _one_shot=True)\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\json\\encoder.py\", line 257, in iterencode\r\n    return _iterencode(o, 0)\r\n  File \"c:\\users\\dhiraj.suvarna\\anaconda3\\envs\\learnenv\\lib\\json\\encoder.py\", line 179, in default\r\n    raise TypeError(f'Object of type {o.__class__.__name__} '\r\n```\r\n\r\n\r\n","128":"Dear Team from MLFlow,\r\n\r\nI am part of the PyTorch Lightning Team. Currently, PyTorch Lightning integrates multiple platforms, and some of them as WanDB and Neptune.ai made Lightning a first-class citizen within their ecosystem.\r\n\r\nRecently, we noticed an increase in bugs related to MLFlow usage with Lightning but our expertise in MLFlow is quite limited.\r\n\r\nWe wondered if the MLFlow Team would be willing to improve MLFlow support within Lightning and become at term its code-owner.\r\n\r\nFind me on Lightning Slack under the username tchaton.\r\n\r\nBest,\r\nT.C ","129":"## What changes are proposed in this pull request?\r\n\r\nAs per spaCy v3, the recommended way to train your spaCy pipelines is via the [`spacy train` command](https:\/\/spacy.io\/usage\/training). This pull request adds a callback logger, which can be an entry point that can later be registered to the spaCy `config.cfg`. This can efficiently report spaCy training metrics, params and models into MLFlow without having separate training scripts in many use cases in my organisation. There is already an [issue](https:\/\/github.com\/mlflow\/mlflow\/issues\/4953) which reflects this, though it's regarding the documentation.\r\n\r\nAs per a discussion on a [pull request](https:\/\/github.com\/explosion\/spaCy\/pull\/7961) for registering an MLFlow logger into spaCy logger registry concluded on adding a logger here, that will be maintained by MLFlow community, which can be added as an [entry point](https:\/\/spacy.io\/usage\/saving-loading#entry-points) in `spacy_loggers` [registry](https:\/\/spacy.io\/api\/top-level#registry).\r\n\r\n## How is this patch tested?\r\nPerformed integration tests with spaCy CLI trainers\r\n\r\n## Release Notes\r\nAdding in callback logger for logging spaCy training metrics, parameters and models into MLflow that can be used in spaCy \r\nby specifying MLflow as the logger in spaCy training config.\r\nE.g.:\r\n```properties\r\n[training.logger]\r\n@loggers = \"spacy.MLFlow.v1\"\r\nrun_name = \"monitor_spacy_training\"\r\nremove_config_values = [\"paths.train\", \"paths.dev\", \"corpora.train.path\", \"corpora.dev.path\"]\r\nlog_interval = 100\r\nlog_dataset_dir = \"corpus\"\r\nlog_best_model = true\r\n```\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nAdding in callback logger for logging spaCy training metrics, parameters and models into MLflow that can be used in spaCy \r\nby specifying MLflow as the logger in spaCy training config.\r\nE.g.:\r\n```properties\r\n[training.logger]\r\n@loggers = \"spacy.MLFlow.v1\"\r\nrun_name = \"monitor_spacy_training\"\r\nremove_config_values = [\"paths.train\", \"paths.dev\", \"corpora.train.path\", \"corpora.dev.path\"]\r\nlog_interval = 100\r\nlog_dataset_dir = \"corpus\"\r\nlog_best_model = true\r\n```\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","130":"## What changes are proposed in this pull request?\r\nThis PR adds the possibility to generate the gRPC grammar of an MLflow Model.\r\nIt addresses the Feature Request #4911 \r\n\r\n## How is this patch tested?\r\nUnit-tests.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nPossibility to generate the gRPC grammar of an MLflow Model\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<a name=\"grpc-grammar-for-mlflow-model\"><\/a>\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","131":"\r\n### System information\r\n- **image: python:3.8-slim**:\r\n- **MLflow installed from (source or binary)**:\r\n- **mlflow==1.20.2**:\r\n- **Python version: 3.8**:\r\n- **Exact command to reproduce**:\r\n```\r\npip3 install mlflow==1.20.2\r\nmlflow sagemaker build-and-push-container --build -c mlflow-pyfunc:1.20.2\r\n```\r\n\r\n### Describe the problem\r\nWe are trying to build and push mlflow sagemaker docker image to AWS ECR, in our CI\/CD pipeline using image: python:3.8-slim. However, once we installed mlflow and run `mlflow sagemaker build-and-push-container` , we got the following error: (Check Logs section).\r\nWe are wondering if running `mlflow sagemaker build-and-push-container` require docker cmd installed? If so, does the community have any suggestion on what base image to use so that we can easily install mlflow, and docker, in order to run this cmd `mlflow sagemaker build-and-push-container`?\r\n\r\nThanks, \r\n\r\n\r\n\r\n### Other info \/ logs\r\n```\r\n\/tmp\/tmpyoqzwmvf\/\r\n\/tmp\/tmpyoqzwmvf\/Dockerfile\r\nTraceback (most recent call last):\r\n  File \"\/usr\/local\/bin\/mlflow\", line 8, in <module>\r\n    sys.exit(cli())\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/click\/core.py\", line 1128, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/click\/core.py\", line 1053, in main\r\n    rv = self.invoke(ctx)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/click\/core.py\", line 1659, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/click\/core.py\", line 1659, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/click\/core.py\", line 1395, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/click\/core.py\", line 754, in invoke\r\n    return __callback(*args, **kwargs)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/sagemaker\/cli.py\", line 534, in build_and_push_container\r\n    mlflow.models.docker_utils._build_image(\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/models\/docker_utils.py\", line 127, in _build_image\r\n    proc = Popen(commands, cwd=cwd, stdout=PIPE, stderr=STDOUT, universal_newlines=True,)\r\n  File \"\/usr\/local\/lib\/python3.8\/subprocess.py\", line 858, in __init__\r\n    self._execute_child(args, executable, preexec_fn, close_fds,\r\n  File \"\/usr\/local\/lib\/python3.8\/subprocess.py\", line 1704, in _execute_child\r\n    raise child_exception_type(errno_num, err_msg, err_filename)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'docker'\r\n```","132":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [X ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu 20.04\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**:1.21.0\r\n- **Python version**: 3.8\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: mlflow run prophet\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\nWhen I run the prophet from examples folder as\r\n\r\nmlflow run prophet\r\n\r\nit hangs at\r\n\r\nInstalling pip dependencies:\r\n\r\nnot sure whether it is due to issue  with  prophet package on conda as outlined in:\r\n\r\nhttps:\/\/github.com\/facebook\/prophet\/issues\/1868\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\non ubuntu 20.04 run\r\n\r\nmlflow run prophet\r\n\r\nfrom mlflow\/examples folder\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ X] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","133":"**Steps to reproduce:**\r\n\r\n1) Turn on autologging.\r\n2) Produce a Pandas DataFrame with X input columns and y predictor column which is of data type string.\r\n3) Instantiate an XGBoostClassifier (or any other sklearn model) and fit on X and y.\r\n\r\n**Expected behavior:**\r\n\r\ninfer_signature(X, y) is equal to the model signature logged in MLFlow.\r\n\r\n**Actual behavior:**\r\n\r\ninfer_signature(X,y) produces .... \"outputs: [string]\" \r\n\r\nMLFlow model signature produces .... \"outputs: [Tensor('object', (-1,))]\"\r\n\r\n**Root cause**\r\n\r\n1) autolog calls infer_signature(X, estimator.predict(X)) instead of infer_signature(X,y)\r\n2) estimator.predict(X) returns a numpy.ndarray\r\n3) Pandas dataFrame strings are dtype('O'), i.e. objects\r\n4) infer_signature calls _infer_schema\r\n5) _infer_schema on a Pandas series of strings returns \"string\"; _infer_schema on a numpy.ndarray returns a Tensor, and sets the dtype as object\r\n\r\nSee also this test, which should be extended to assert that the two signatures above are not equal\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/9c934f5a57cc8701475eb7ed0b6b072600b66bed\/tests\/xgboost\/test_xgboost_model_export.py#L83\r\n\r\n**Recommended fix**\r\n\r\nInfer output in the model signature from the predictor column, not the estimator's predict type.","134":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this documentation issue template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages documentation fix contributions. Would you or another member of your organization be willing to contribute a fix for this documentation issue to the MLflow code base?\r\n\r\n- [X] Yes. I can contribute a documentation fix independently.\r\n- [ ] Yes. I would be willing to contribute a document fix with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a documentation fix at this time.\r\n\r\n### URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry in question: https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.log_param\r\n\r\n### Description of proposal (what needs changing):\r\n\r\nHi folks, ran into the 250 character limit of `log_param` when I passed the command used to call my script in `sys.argv` to MLflow. For context, MLflow gave me this error:\r\n\r\n```\r\nmlflow.exceptions.MlflowException: Param value '<my-super-long-string>' had length 260, which exceeded length limit of 250\r\n```\r\n\r\nHaven't had the time to trace the source of the character limit, but have a hunch that it depends on the tracking server being used. I ran into this error when using a `sqlite` backend.\r\n\r\nThought it would be worth mentioning in the docs, since exceeding the char limit throws an exception and can interrupt training jobs w\/o the user being aware up front. Would like to suggest adding a warning similar to how [log_image](https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.log_image) warns users for values out of range.\r\n","135":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this installation issue template to ensure a timely and thorough response.**\r\n\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 11\r\n- **MLflow installed from (source or binary)**: NA\r\n- **MLflow version (run ``mlflow --version``)**: NA\r\n- **Python version**: 3.6.13\r\n- **Exact command to reproduce**:\r\n- \r\nconda create --name mlflow-dev-env python=3.6\r\nconda activate mlflow-dev-env\r\npip install -r dev-requirements.txt\r\npip install -r test-requirements.txt\r\n\r\n### Describe the problem\r\nProvide the exact sequence of commands \/ steps that you executed before running into the problem.\r\n\r\nThe setup step ran fine till dev-requirements.txt, but when i ran for test-requirements.txt, pip setup runs for hours but never finishes, it was downloading all the versions of almost all libraries. I could see lots of messages like \"pip is looking at multiple versions of <library_name>\" for many libraries.\r\nWhen i tried to use pip-compile test-requirements.txt as suggested in https:\/\/stackoverflow.com\/questions\/65122957\/resolving-new-pip-backtracking-runtime-issue, I'm getting the below error\r\n\r\nCould not find a version that matches gast==0.3.3,==0.4.0 (from tensorflow==2.6.1->-r dev\/extra-ml-requirements.txt (line 18))\r\nTried: 0.1, 0.1.1, 0.1.2, 0.1.3, 0.1.4, 0.1.5, 0.2.0, 0.2.1, 0.2.1.post0, 0.2.1.post1, 0.2.2, 0.3.0, 0.3.1, 0.3.2, 0.3.3, 0.3.3, 0.4.0, 0.4.0, 0.5.0, 0.5.0, 0.5.1, 0.5.1, 0.5.2, 0.5.2\r\nThere are incompatible versions in the resolved dependencies:\r\n  gast==0.4.0 (from tensorflow==2.6.1->-r dev\/extra-ml-requirements.txt (line 18))\r\n  gast==0.3.3 (from paddlepaddle==2.1.3->-r dev\/extra-ml-requirements.txt (line 44))\r\n\r\nPlease let me know how to resolve this issue.\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n","136":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows Server 2019\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: 1.20.3\r\n- **Python version**: 3.6.13\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: mlflow_transition_model_version_stage(name, version, stage = \"Production\", archive_existing_versions = TRUE)\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\nmlflow_rest function fails in requests with boolean variables. This is caused by the use of rapply(data, as.character, how = \"replace\"), which quotes the boolean variables, replacing them as characters. \r\n\r\nThis can easily be fixed by adding the argument 'classes = c(\"numeric\", \"character\")' to the rapply statement. This excludes boolean variables from being converted.\r\n\r\nAn example is when using the mlflow_transition_model_version_stage() function with the archive_existing_versions argument. \r\nThis function throws the error:\r\n \"Error: API request to endpoint 'model-versions\/transition-stage' failed with error code 500. Reponse body: '<!DOCTYPE HTML PUBLIC \"-\/\/W3C\/\/DTD HTML 3.2 Final\/\/EN\">\r\n<title>500 Internal Server Error<\/title>\r\n<h1>Internal Server Error<\/h1>\r\n<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.<\/p>\r\n' \"\r\n\r\nFor now it can be circumvented in R by calling the REST API directly without the 'rapply' wrapper.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nmlflow_transition_model_version_stage(name, version, stage = \"Production\", archive_existing_versions = TRUE)\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n Error: API request to endpoint 'model-versions\/transition-stage' failed with error code 500. Reponse body: '<!DOCTYPE HTML PUBLIC \"-\/\/W3C\/\/DTD HTML 3.2 Final\/\/EN\">\r\n<title>500 Internal Server Error<\/title>\r\n<h1>Internal Server Error<\/h1>\r\n<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.<\/p>\r\n' \r\n3. stop(msg, call. = FALSE) at tracking-rest.R#123\r\n2. mlflow_rest(\"model-versions\", \"transition-stage\", client = client, \r\n    verb = \"POST\", version = \"2.0\", data = list(name = name, \r\n        version = version, stage = stage, archive_existing_versions = archive_existing_versions)) at model-registry.R#307\r\n1. mlflow_transition_model_version_stage(name = name, version = version, stage = \"Production\", archive_existing_versions = TRUE) \r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [x ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","137":"Sometimes I would like to add a custom plot to a run, and ideally view these plots within MLflow. As far as I know, this cannot be done at the moment. \r\n\r\n## Willingness to contribute\r\n\r\nI cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nHave a syntax that allows you to upload local images to the MLflow server, and allow you to inspect them in the MLflow interface. \r\n\r\n`mlflow.add_image(\"image-name\", \"some-image.png\")`\r\n\r\nFor example\r\n\r\n`mlflow.add_image(\"embedding visualisation\", \"epoch-11.png\")`\r\n\r\nAt the moment I am uploading custom files to S3 and analysing them there, but it's a lot of switching between tabs.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\n- [ X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n","138":"I have a pmml file which contains a lightgbm model. So when I am trying to log artifacts it is showing an error\r\n'Model' object has no attribute 'save_model'\r\n\r\nSo, is it possible to generate artifacts for pmml model.","139":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 20.04\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: 1.20.2\r\n- **Python version**: 3.8.10\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nWhen I log Spark model with `mlflow.spark.log_model()` in my Spark Cluster. I found that Mlflow will run sub-process after logged model and It will call [this function]( https:\/\/github.com\/mlflow\/mlflow\/blob\/d7a26a7db9b3170b516ebe0f6773e0b4d7357dc2\/mlflow\/spark.py#L683).\r\nIt will create a new SparkSession and I got this error: ` Only one SparkContext should be running in this JVM`. I am sure I created SparkSession before I call `mlflow.spark.log_model`. So I really do not know why It created a new Spark session. Please help me to explain it. I also provide my code below.\r\n### Code to reproduce the issue\r\n```\r\nspark = SparkSession.builder\\\r\n    .config(key=\"spark_session.python.worker.reuse\", value=True)\\\r\n    .master(\"spark:\/\/spark-master:7077\")\\\r\n    .getOrCreate()\r\n......\r\ndata = spark.createDataFrame(df)\r\n.....\r\nmodel= pipeline.fit(data)\r\n\r\nmlflow.set_tracking_uri('http:\/\/127.0.0.1:5000')\r\nwith mlflow.start_run():\r\n    mlflow.spark.log_model(spark_model=model, artifact_path=\"spark-model\")\r\n```\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","140":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Red Hat Enterprise Linux 8.4 (Ootpa)\r\n- **MLflow installed from (source or binary)**: Binary (I think? \ud83d\ude42 Installed through `pip` via `poetry`)\r\n- **MLflow version (run ``mlflow --version``)**: mlflow, version 1.21.0\r\n- **Python version**: Python 3.8.6\r\n- **npm version, if running the dev UI**: NA\r\n- **Exact command to reproduce**: See code for reproducing\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\nExpected behavior is for `client.get_metric_history` to return an empty list when the given metric has not been logged before. Actual behavior is a raised exception with the message:\r\n```\r\nmlflow.exceptions.MlflowException: Metric 'accuracy' not found under run '4e18eced00654b2db9165ceda272c592'\r\n```\r\n\r\nCalling `get_metric_history` for a `MlflowClient` raises an exception when the given metric has not been logged before. In the documentation it says that the return value is: \"A list of :py:class:`mlflow.entities.Metric` entities if logged, else empty list\".\r\n\r\nEither the documentation is incorrect or the code (atleast for file store) is. See `mlflow.store.tracking.file_store.FileStore::_get_metric_history` for root cause of exception.\r\n\r\nI have only tested this using the file store.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\nimport mlflow\r\n\r\nwith mlflow.start_run() as run:\r\n    run_id = run.info.run_id\r\n\r\n    # Call client.get_metric_history\r\n    client = mlflow.tracking.MlflowClient()\r\n    metric_history = client.get_metric_history(run_id, \"accuracy\")\r\n\r\n    # Should be an empty list, as per the documentation\r\n    # Instead it raises an `mlflow.exceptions.MlflowException`\r\n    assert metric_history == []\r\n```\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"~\/contrib\/mlflow\/getmetrichistory.py\", line 9, in <module>\r\n    metric_history = client.get_metric_history(active_run_id, \"accuracy\")\r\n  File \"~\/.cache\/pypoetry\/virtualenvs\/getmetrichistory-gdY77lq0-py3.8\/lib\/python3.8\/site-packages\/mlflow\/tracking\/client.py\", line 217, in get_metric_history\r\n    return self._tracking_client.get_metric_history(run_id, key)\r\n  File \"~\/.cache\/pypoetry\/virtualenvs\/getmetrichistory-gdY77lq0-py3.8\/lib\/python3.8\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 76, in get_metric_history\r\n    return self.store.get_metric_history(run_id=run_id, metric_key=key)\r\n  File \"~\/.cache\/pypoetry\/virtualenvs\/getmetrichistory-gdY77lq0-py3.8\/lib\/python3.8\/site-packages\/mlflow\/store\/tracking\/file_store.py\", line 644, in get_metric_history\r\n    return self._get_metric_history(run_info, metric_key)\r\n  File \"~\/.cache\/pypoetry\/virtualenvs\/getmetrichistory-gdY77lq0-py3.8\/lib\/python3.8\/site-packages\/mlflow\/store\/tracking\/file_store.py\", line 650, in _get_metric_history\r\n    raise MlflowException(\r\nmlflow.exceptions.MlflowException: Metric 'accuracy' not found under run '4e18eced00654b2db9165ceda272c592'\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","141":"Signed-off-by: harupy <hkawamura0130@gmail.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nDrop support for old ML package versions:\r\n\r\n- To save the number of CI runs\r\n- Decrease the maintenance burden\r\n\r\n## How is this patch tested?\r\n\r\nUnit tests\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","142":"Signed-off-by: Xuan Hu <i@huxuan.org>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nReduce redundant parsing.\r\n\r\n## How is this patch tested?\r\n\r\nWhole test.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","143":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**:\r\n- **Python version**:\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n when i am trying to load lightgbm pmml model and log it I am getting error: Could not find an \"MLmodel\" configuration file at location .....\r\n\r\n### Code to reproduce issue\r\nlr = mlflow.lightgbm.load_model('iris.pmml')\r\nmlflow.lightgbm.log_model(lr,\"model\")\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [Yes ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","144":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**: `1.20.2` (skinny)\r\n- **Python version**: 3.8.8\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\nin an airflow DAG\/python file\r\n```\r\nimport mlflow\r\n```\r\n\r\n### Describe the problem\r\nWe are using Airflow to orchestrate some operations against our MLFlow deployment. All DAGs that import MLFlow fail to\r\n\r\n### Code to reproduce issue\r\npython dag file:\r\n```\r\nimport mlflow\r\n\r\ndef train_model():\r\n  # ...\r\n  pass\r\n\r\nwith DAG(\"my_dag\",\r\n  start_date=datetime(2021, 1 ,1),\r\n  schedule_interval='@daily',\r\n) as dag:\r\n  PythonOperator(\r\n    task_id=f\"training_model\",\r\n    python_callable=train_model,\r\n  )\r\n```\r\n\r\nThe tasks in this dag will execute but it appears to overwrite the existing logging handlers and prevent all tasks within the DAG from sending the logs to s3 on `close`\r\n\r\n### Other info \/ logs\r\nAn issue was opened in the airflow project but airflow maintainers think that it is an issue with the MLFlow logging code.\r\nhttps:\/\/github.com\/apache\/airflow\/issues\/12236\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","145":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this documentation issue template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages documentation fix contributions. Would you or another member of your organization be willing to contribute a fix for this documentation issue to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a documentation fix independently.\r\n- [ ] Yes. I would be willing to contribute a document fix with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a documentation fix at this time.\r\n\r\n### URL(s) with the issue:\r\n\r\nhttps:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/spacy\r\n\r\n### Description of proposal (what needs changing):\r\nThe example code above is for the previous spacy version 2. Spacy did an update to version 3 and it changes most of its infrastructure and also how it trains. Spacy now trains its models in the CLW and I could not find any documentation to store metrics\/parameters of a model trained in the CLW like how spacy does. \r\nIt would be nice to have it written down as I am having this problem at the moment.\r\n","146":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nIt would be really helpful to have `dotenv` file support to specify environment variables (e.g. tracking uri) in a project-specific way so that it can be shared across teams. MLFlow could read the local dotenv file and set its tracking\/artifact uri (both the command line and the library)\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nThe tracking URI can be committed into version control and be will be ready-to-go when the repo is cloned. It also makes mlflow easier to use by implicitly transferring the responsibility of setting the tracking\/artifact uri to the library itself. \r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\nSetting tracking\/artifact uri is an infrastructural concern which can be off-loaded to a dedicated file that is read implicitly. It will make running mlflow for new users even simpler since they can focus on the ml code and not the infrastructure. Additionally, setting environment variables is not simple for new users, especially across platforms (windows for example requires a multi-step process unless using powershell and `$Env:...`). \r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nMakes it simpler to get started with mlflow, can share code templates across projects without worrying about setting the tracking\/artifact uri.\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nThis is more of a convenience feature, the current mlflow features and components are sufficient however this feature would further help move the focus from experiment management to the experiment itself. Especially for newer users in a project who just want to get something running.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [x] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [x] `language\/r`: R APIs and clients\r\n- [x] `language\/java`: Java APIs and clients\r\n- [x] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nThis feature should be quite simple to implement given the abundance of `dotenv` loader libraries across most language ecosystems. The file should be loaded when mlflow initialises and reads environment variables.","147":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nWe are trying to use MLFlow model REST serving to run image inference. Images are typically sent with content types like `application\/octet-stream`, `multipart\/form-data`, `image\/jpeg`, etc. Going through the MLFlow docs it does not look like those content types are supported and instead images need to be base64-encoded as part of a JSON payload:\r\nhttps:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/flower_classifier#how-to-train-and-deploy-image-classifier-with-mlflow-and-keras\r\nAdding support for binary HTTP payload would be more client friendly and increase performance.\r\n\r\n## Motivation\r\n- What is the use case for this feature? Realtime image inference\r\n- Why is this use case valuable to support for MLflow users in general? It would bring MLFlow serving on par with production-level services like Azure Cognitive Services [[API doc](https:\/\/southcentralus.dev.cognitive.microsoft.com\/docs\/services\/Custom_Vision_Prediction_3.1\/operations\/5eb37d24548b571998fde5f3)]\r\n- Why is this use case valuable to support for your project(s) or organization? It would provide a uniform way to manage models and endpoints, whether they deal with JSON, images, audio, etc.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient) Base64-encoding-in-JSON of images is an unusual way for REST APIs to handle images.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n\r\nOne option could be for the server to expand its supported content types and use Pillow to convert images to Pandas. Ideally this would integrate with transform pipelines in PyTorch, Tensforflow, etc. to avoid drift between training and inference (ex: scaling color channels by 1\/255, etc.).\r\n","148":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 21.04\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: 1.20.2\r\n- **Python version**: 3.7\r\n- **npm version, if running the dev UI**: n\/a\r\n\r\n### Describe the problem\r\n\r\nThe Model Registry web UI allows me to create a model with an apostrophe in the name (i.e. `Cariad's Model`), but the model cannot be opened. An error is shown, reading:\r\n\r\n> Something went wrong\r\n> If this error persists, please report an issue [here](https:\/\/github.com\/mlflow\/mlflow\/issues).\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/5700041\/138704907-a775ffb1-5ae0-47ea-a597-4cac648c7d6a.png)\r\n\r\nI don't have any business case for supporting apostrophes, but it would be nice if the UI prevented me creating a model that can't be opened later.\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [x] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","149":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ x ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\nOS Platform and Distribution: Windows 10\r\nMLflow installed: using pip\r\nMLflow version: version 1.20.2\r\n**Python version: Python 3.9.7 **\r\n\r\n### Describe the problem\r\nI have saved an .h5 keras model, and when i tryed to execute mlflow.keras.load_model(\"run:\/id_run\/model\") i have been waiting almost an hour but it doesn't finish. So i stopped the execution and I got the next error:\r\n\r\n```\r\nERROR:root:Internal Python error in the inspect module.\r\nBelow is the traceback from this internal error.\r\n\r\nERROR:root:Internal Python error in the inspect module.\r\nBelow is the traceback from this internal error.\r\n\r\nTraceback (most recent call last):\r\n  File \"~\\anaconda3\\envs\\python_38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-3-277d37cc6084>\", line 1, in <module>\r\n    keras_model = mlflow.keras.load_model(\"runs:\/483745e28a864eceb738c852cf062774\/model\")\r\n  File \"~\\AppData\\Roaming\\Python\\Python38\\site-packages\\mlflow\\keras.py\", line 585, in load_model\r\n    local_model_path = _download_artifact_from_uri(artifact_uri=model_uri)\r\n  File \"~\\AppData\\Roaming\\Python\\Python38\\site-packages\\mlflow\\tracking\\artifact_utils.py\", line 83, in _download_artifact_from_uri\r\n    return get_artifact_repository(artifact_uri=root_uri).download_artifacts(\r\n  File \"~\\AppData\\Roaming\\Python\\Python38\\site-packages\\mlflow\\store\\artifact\\runs_artifact_repo.py\", line 125, in download_artifacts\r\n    return self.repo.download_artifacts(artifact_path, dst_path)\r\n  File \"~\\AppData\\Roaming\\Python\\Python38\\site-packages\\mlflow\\store\\artifact\\artifact_repo.py\", line 180, in download_artifacts\r\n    return download_artifact_dir(\r\n  File \"~\\AppData\\Roaming\\Python\\Python38\\site-packages\\mlflow\\store\\artifact\\artifact_repo.py\", line 147, in download_artifact_dir\r\n    download_artifact_dir(\r\n  File \"~\\AppData\\Roaming\\Python\\Python38\\site-packages\\mlflow\\store\\artifact\\artifact_repo.py\", line 152, in download_artifact_dir\r\n    download_artifact(\r\n  File \"~\\AppData\\Roaming\\Python\\Python38\\site-packages\\mlflow\\store\\artifact\\artifact_repo.py\", line 129, in download_artifact\r\n    self._download_file(\r\n  File \"~\\AppData\\Roaming\\Python\\Python38\\site-packages\\mlflow\\store\\artifact\\azure_blob_artifact_repo.py\", line 136, in _download_file\r\n    container_client.download_blob(remote_full_path).readinto(file)\r\n  File \"~\\anaconda3\\envs\\python_38\\lib\\site-packages\\azure\\storage\\blob\\_download.py\", line 617, in readinto\r\n    downloader.process_chunk(chunk)\r\n  File \"~\\anaconda3\\envs\\python_38\\lib\\site-packages\\azure\\storage\\blob\\_download.py\", line 129, in process_chunk\r\n    chunk_data = self._download_chunk(chunk_start, chunk_end - 1)\r\n  File \"~\\anaconda3\\envs\\python_38\\lib\\site-packages\\azure\\storage\\blob\\_download.py\", line 211, in _download_chunk\r\n    chunk_data = process_content(response, offset[0], offset[1], self.encryption_options)\r\n  File \"~\\anaconda3\\envs\\python_38\\lib\\site-packages\\azure\\storage\\blob\\_download.py\", line 52, in process_content\r\n    content = b\"\".join(list(data))\r\n  File \"~\\anaconda3\\envs\\python_38\\lib\\site-packages\\azure\\core\\pipeline\\transport\\_requests_basic.py\", line 158, in __next__\r\n    chunk = next(self.iter_content_func)\r\n  File \"~\\anaconda3\\envs\\python_38\\lib\\site-packages\\requests\\models.py\", line 758, in generate\r\n    for chunk in self.raw.stream(chunk_size, decode_content=True):\r\n  File \"~\\anaconda3\\envs\\python_38\\lib\\site-packages\\urllib3\\response.py\", line 576, in stream\r\n    data = self.read(amt=amt, decode_content=decode_content)\r\n  File \"~\\anaconda3\\envs\\python_38\\lib\\site-packages\\urllib3\\response.py\", line 519, in read\r\n    data = self._fp.read(amt) if not fp_closed else b\"\"\r\n  File \"~\\anaconda3\\envs\\python_38\\lib\\http\\client.py\", line 459, in read\r\n    n = self.readinto(b)\r\n  File \"~\\anaconda3\\envs\\python_38\\lib\\http\\client.py\", line 503, in readinto\r\n    n = self.fp.readinto(b)\r\n  File \"~\\anaconda3\\envs\\python_38\\lib\\socket.py\", line 669, in readinto\r\n    return self._sock.recv_into(b)\r\n  File \"~\\anaconda3\\envs\\python_38\\lib\\ssl.py\", line 1241, in recv_into\r\n    return self.read(nbytes, buffer)\r\n  File \"~\\anaconda3\\envs\\python_38\\lib\\ssl.py\", line 1099, in read\r\n    return self._sslobj.read(len, buffer)\r\nKeyboardInterrupt\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"~\\anaconda3\\envs\\python_38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"~\\anaconda3\\envs\\python_38\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\r\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\r\n  File \"~\\anaconda3\\envs\\python_38\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\r\n    return f(*args, **kwargs)\r\n  File \"~\\anaconda3\\envs\\python_38\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\r\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\r\n  File \"~\\anaconda3\\envs\\python_38\\lib\\inspect.py\", line 1515, in getinnerframes\r\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\r\n  File \"~\\anaconda3\\envs\\python_38\\lib\\inspect.py\", line 1473, in getframeinfo\r\n    filename = getsourcefile(frame) or getfile(frame)\r\n  File \"~\\anaconda3\\envs\\python_38\\lib\\inspect.py\", line 708, in getsourcefile\r\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\r\n  File \"~\\anaconda3\\envs\\python_38\\lib\\inspect.py\", line 754, in getmodule\r\n    os.path.realpath(f)] = module.__name__\r\n  File \"~\\anaconda3\\envs\\python_38\\lib\\ntpath.py\", line 647, in realpath\r\n    path = _getfinalpathname(path)\r\nKeyboardInterrupt\r\n```\r\n\r\nMy artifact sotrage is an Azure Blob Storage and my MLflow Server is running in axeternal server \r\n\r\nI checked the model in the UI and it was there o i tryed to dowload it from there. But the download stops as you can see in the images and then restart over and over again. I noticed that it weight 355MB, soy i logged the model dicrectory compressed as an artifact with more or less the same weight and it gives the same problem when you try to download it. \r\n\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/82539263\/138273641-654ebddc-fd65-4926-91c5-655d978b034a.png)\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/82539263\/138273521-f80575c7-c7d6-4a52-a5ba-3a771d82fd53.png)\r\n\r\n### Code to reproduce issue\r\nJust log a file with the same weight and try to recover it\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ x ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ x ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ x ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ x ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","150":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n-  No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.04\r\n- **MLflow installed from (source or binary)**: pip\r\n- **MLflow version (run ``mlflow --version``)**: mlflow, version 1.20.2\r\n- **Python version**: Python 3.9.1\r\n- **npm version, if running the dev UI**: NA\r\n- **Exact command to reproduce**: NA\r\n\r\n### Describe the problem\r\nI'm using a spark training method to train the model and store the model as pyspark flavour inside a container environment. However, for prediction, I'm using another container with python base image and trying to do prediction using pyfunc flavour. However, this tells me to install pyspark in the prediction cluster. Is there any way I could make the pyspark model interoperable  across various flavour without actually using pyspark in my prediction\/model-serving container?\r\n\r\n### Code to reproduce issue\r\nTraining code:\r\n----------------------\r\n```\r\nfrom pyspark.ml.classification import LogisticRegression\r\nfrom pyspark.ml.feature import VectorAssembler, StandardScaler\r\nfrom pyspark.ml import Pipeline\r\nfrom pyspark.sql import SparkSession\r\nfrom sklearn.datasets import load_iris\r\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\r\n\r\nimport mlflow\r\n\r\nmlflow.set_registry_uri(\"mysql+pymysql:\/\/root:root@127.0.0.1:3306\/mlflow_tracking_database\")\r\nmlflow.set_tracking_uri(\"http:\/\/127.0.0.1:5000\")\r\nmr_uri = mlflow.get_registry_uri()\r\nprint(\"Current registry uri: {}\".format(mr_uri))\r\ntracking_uri = mlflow.get_tracking_uri()\r\nprint(\"Current tracking uri: {}\".format(tracking_uri))\r\n\r\n\r\nexpr_name = \"Sample_spark_aws_exp\"  # create a new experiment (do not replace)\r\nmlflow.set_experiment(expr_name)\r\nexpr = mlflow.get_experiment_by_name(expr_name)\r\nexpr_id = expr.experiment_id\r\nexpr_id, expr\r\n\r\nprint(\"===================Starting Spark session====================\")\r\nspark = SparkSession.builder \\\r\n.appName('ML Flow test') \\\r\n.config(\"spark.hadoop.fs.s3a.endpoint\", \"s3.us-east-1.amazonaws.com\") \\\r\n.config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\r\n.config(\"spark.hadoop.fs.s3a.access.key\", \"AKIA4A2VACX6BAG7W35Q\") \\\r\n.config(\"spark.hadoop.fs.s3a.secret.key\", \"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\") \\\r\n.getOrCreate()\r\n\r\nprint(\"=====================Loading Data===========================\")\r\ndf = load_iris(as_frame=True).frame.rename(columns={\"target\": \"label\"})\r\ndf = spark.createDataFrame(df)\r\ntrain, test = df.randomSplit([0.8, 0.2],)\r\nprint(\"=====================Data load completed======================\")\r\n\r\n\r\nassembler = VectorAssembler(inputCols=df.columns[:-1], outputCol=\"features\")\r\nscaler = StandardScaler(inputCol=assembler.getOutputCol(), outputCol=\"scaledFeatures\")\r\nlor = LogisticRegression(maxIter=5, featuresCol=scaler.getOutputCol())\r\n\r\n\r\ntags = {\"Dataset\": \"IRIS data\",\r\n        \"Platform\": \"Sample Examples\",\r\n        \"Framework\": \"Pyspark\"}\r\n\r\nprint(\"=====================Starting Mlflow run===================\")\r\npipeline = Pipeline(stages=[assembler, scaler, lor])\r\nwith mlflow.start_run(experiment_id=expr_id):\r\n    print(\"Current artifact uri: {}\".format(mlflow.get_artifact_uri()))\r\n    print(\"Training in progress...\")\r\n    pipeline_model = pipeline.fit(train)\r\n    print(\"======================Training Completed!================\")\r\n\r\n    print(\"======================Logging Model======================\")\r\n    mlflow.spark.log_model(pipeline_model,\"spark_model_dir\")\r\n    \r\n    columns = [\"label\",\"features\", \"prediction\",\"rawPrediction\", \"probability\"]\r\n    predictions = pipeline_model.transform(test)\r\n\r\n    predictions.select(columns).show(10, False)\r\n    \r\n    evaluator = MulticlassClassificationEvaluator()\r\n    \r\n    f1_score = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\r\n    accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\r\n    truePositiveRateByLabel = evaluator.evaluate(predictions, {evaluator.metricName: \"truePositiveRateByLabel\"})\r\n    hammingLoss = evaluator.evaluate(predictions, {evaluator.metricName: \"hammingLoss\"})\r\n    recallByLabel = evaluator.evaluate(predictions, {evaluator.metricName: \"recallByLabel\"})\r\n    \r\n    metrics = { \r\n    'F1 score': f1_score,\r\n    'Accuracy': accuracy,\r\n    'truePositiveRateByLabel': truePositiveRateByLabel,\r\n    'hammingLoss': hammingLoss,\r\n    'recallByLabel': recallByLabel,\r\n    }\r\n    \r\n    print(\"================================Evaluation Metrics: =====================================\")\r\n    print(metrics)\r\n    \r\n    mlflow.log_metrics(metrics)\r\n    mlflow.set_tags(tags)\r\n    \r\n    with open(\"test_file.txt\", \"w\") as f:\r\n        f.write(\"test Atrifacts \\n\")\r\n\r\n    mlflow.log_artifact(\"test_file.txt\")\r\n```\r\n----------------------\r\n**Model serving code:**\r\n---------------------\r\n```\r\nfrom flask import Flask, request, redirect, url_for, flash, jsonify\r\nimport numpy as np\r\nimport pandas as pd\r\nimport json\r\nimport mlflow\r\n\r\napp = Flask(__name__)\r\nmlflow.set_registry_uri(\"mysql+pymysql:\/\/root:root@mysql-server:3306\/mlflow_tracking_database\")\r\nmlflow.set_tracking_uri(\"http:\/\/mlflow-server2:5000\")\r\nmr_uri = mlflow.get_registry_uri()\r\n\r\nprint(\"Current registry uri: {}\".format(mr_uri))\r\ntracking_uri = mlflow.get_tracking_uri()\r\nprint(\"Current tracking uri: {}\".format(tracking_uri))\r\n\r\n#logged_model = \"models:\/IRIS_data_model_spark\/4\"\r\n#loaded_model = mlflow.pyfunc.load_model(logged_model)\r\n\r\n\r\n@app.route('\/predict', methods=['POST'])\r\ndef makecalc():\r\n    logged_model = \"models:\/IRIS_data_model_spark\/4\"\r\n    loaded_model = mlflow.pyfunc.load_model(logged_model)\r\n    data = request.get_json()\r\n    df = pd.DataFrame(data=data[\"data\"],columns=data[\"columns\"])\r\n    return jsonify(loaded_model.predict(df))\r\n#    return data\r\n\r\nif __name__ == '__main__':\r\n    app.run(debug=True, host='0.0.0.0',port=4321)\r\n```\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","151":"Signed-off-by: Bipin Krishnan <bipinkrishna.p@gmail.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nLog model signature and input example in tensorflow autologging\r\n\r\n## How is this patch tested?\r\n\r\nUnit tests\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","152":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n \r\n- [x] Yes. We can contribute this feature independently within the @AmadeusITGroup\/mlflow-contributors team.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n \r\n## Proposal Summary\r\n \r\nAs of today, MLflow enables serving an ML model as a REST API endpoint for inference.\r\nThere are cases where a REST API is not suitable, and a gRPC API would be preferable instead.\r\nAs a building block for providing a gRPC inference server, the gRPC grammar corresponding to a given MLflow model is needed.\r\nThe grammar would easily allow the generation of both client and server code.\r\n \r\n## Motivation\r\n- What is the use case for this feature?\r\nServing and consuming an MLflow model through a gRPC channel.\r\n- Why is this use case valuable to support for MLflow users in general?\r\nBecause of the advantages of the gRPC protocol related to performance (e.g., smaller binary payload) and to the native code generation.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nTo leverage gRPC performance in the context of serving a model within an Amadeus Fast Data microservice architecture.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nCurrently, to have a gRPC inference server\/client, the grammar has to be generated manually or with custom tooling.\r\n \r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents\r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n \r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n \r\nLanguages\r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n \r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n \r\n## Details\r\n \r\nThe gRPC grammar seems to be tightly related to the model signature. Therefore a first proposal would be to add a new `grpc` module, within the `models` package, handling the generation of the grammar. It would be then possible to leverage the existing `mlflow.log_text()` API to materialize the gRPC grammar as an experiment run artifact.\r\n \r\nExample of usage:\r\n \r\n```\r\nimport mlflow.models.signature as signature\r\nimport mlflow.models.grpc as grpc\r\n \r\n...\r\n\r\nmodel_signature = signature.infer_signature(...)\r\ngrpc_grammar = grpc.generate_grammar(model_signature)\r\nmlflow.log_text(grpc_grammar, \"grpc_grammar.proto\")\r\n \r\n...\r\n```","153":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this installation issue template to ensure a timely and thorough response.**\r\n\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Centos 7\r\n- **MLflow installed from (source or binary)**: Binary\r\n- **MLflow version (run ``mlflow --version``)**:  1.20.1\r\n- **Python version**: Python 3.8.5\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nProvide the exact sequence of commands \/ steps that you executed before running into the problem.\r\nI am planning to perform an mlflow server upgrade from  1.20.1 to 1.20.2 and unable to  find any document or steps to perform and upgrade. I am using mysql 8.0.23  as database.\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nWhile performing the upgrade I am getting his message.\r\n\r\n .\/pip install mlflow\r\nRequirement already satisfied: mlflow in \/mlflow\/lib\/python3.8\/site-packages (1.20.1)\r\n","154":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux RHEL 7\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.7.2, also in current version\r\n- **Python version**: 3.7\r\n- **npm version, if running the dev UI**: -\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\nThe following code blocks:\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/a46bb1f3f69940768e1f6b5e583f99703bd4dfeb\/mlflow\/store\/artifact\/hdfs_artifact_repo.py#L22-L24\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/a46bb1f3f69940768e1f6b5e583f99703bd4dfeb\/mlflow\/store\/artifact\/hdfs_artifact_repo.py#L157-L184\r\nwill encounter: `ArrowIOError: HDFS list directory failed, errno: 255 (Unknown error 255) Please check that you are connecting to the correct HDFS RPC port`\r\nwith java backend error: `UnknownHostException: java.net.UnknownHostException: Invalid host name: local host is: (unknown); destination host is: \"myhdfs-ns\":8020; java.net.UnknownHostException; For more details see:  http:\/\/wiki.apache.org\/hadoop\/UnknownHost`\r\nwhen we use `--default-artifact-root hdfs:\/\/MyHDFS-ns\/mlflow_artifacts`.\r\nIn our hadoop dfs.nameservices set to MyHDFS-ns in $HADOOP_CONF_DIR\/hdfs-site.xml. Urllib converts name service (from --default-artifact-root) to lowercase (myhdfs-ns). After it pyarrow can't connect to hdfs correctly.\r\n\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nYou need hadoop with dfs.nameservices with Uppercase as in our case.\r\nStart mlflow server with  key `--default-artifact-root hdfs:\/\/{dfs.nameservices}\/mlflow_artifacts` and try to read, write or list artifacts.\r\n\r\n### Other info \/ logs\r\nWe found 2 WA for this bug.\r\n1) With our hadoop and pyarrow==0.15.1 we comment host, port, user and driver variables: \r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/a46bb1f3f69940768e1f6b5e583f99703bd4dfeb\/mlflow\/store\/artifact\/hdfs_artifact_repo.py#L172-L175\r\n\r\n2) We corrupt our $HADOOP_CONF_DIR\/hdfs-site.xml with lowercase dfs.nameservices.\r\n\r\nBoth wa is wrong way to fix this bug.\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","155":"\r\n### Willingness to contribute\r\nThe MLflow Community encourages documentation fix contributions. Would you or another member of your organization be willing to contribute a fix for this documentation issue to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a documentation fix independently.\r\n- [x] Yes. I would be willing to contribute a document fix with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a documentation fix at this time.\r\n\r\n### URL(s) with the issue:\r\n\r\nFor some reason\r\n\r\n`https:\/\/mlflow.org\/docs\/latest\/tracking.html#storage`\r\n\r\ndoes not exist anymore and is present as:\r\n\r\nhttps:\/\/mlflow.org\/docs\/latest\/tracking.html#id12\r\n\r\n![strorage](https:\/\/user-images.githubusercontent.com\/17945\/137368657-10acbb50-278f-4b2a-8373-0498b683e409.png)\r\n\r\nThis makes the link from the MLflow `Model` section wrong:\r\n\r\n![mlfow_popup](https:\/\/user-images.githubusercontent.com\/17945\/137368639-1ed10b5f-78d4-4845-a3f6-82658f9d29a9.png)\r\n\r\n\r\n### Description of proposal (what needs changing):\r\n\r\nProperly render `https:\/\/mlflow.org\/docs\/latest\/tracking.html#id12` as `https:\/\/mlflow.org\/docs\/latest\/tracking.html#storage`\r\n\r\nNote: I tried adding a `.. _storage:` and rebuilding the docs but the issue is still there. Not sure where\/why it is conflicting.","156":"## Willingness to contribute\r\n- [ x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nThe images are currently shown relatively small. I am plotting many things and it would be great if I could see the artifacts in a higher resolution. It would be optimal to use all available width of the window.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n","157":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: windows 10\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.20.2\r\n- **Python version**: 3.8\r\n- **npm version, if running the dev UI**: N\/A\r\n- **Exact command to reproduce**: \r\n  - Start server: `mlflow models serve -m runs:\/5f8aee52fcb442388368af4da658b398\/model --no-conda`\r\n  -  Submit an inference request: `curl -i -X POST -d \"{\\\"data\\\":0.0199132142]}\" -H \"Content-Type: application\/json\" http:\/\/localhost:5000\/invocations`\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\nSubmitting an inference requests to the MLFlow model server with invalid content returns HTTP error 500 'Internal Server Error' instead of HTTP error 400 'Bad Request'. This prevents proper error handling on the client side and blocks REST API fuzzing.\r\n\r\nEx:\r\n```\r\ncurl -i -X POST -d \"{\\\"data\\\":0.0199132142]}\" -H \"Content-Type: application\/json\" http:\/\/localhost:5000\/invocations\r\nHTTP\/1.1 500 INTERNAL SERVER ERROR\r\nContent-Length: 901\r\nContent-Type: application\/json\r\nDate: Wed, 13 Oct 2021 22:16:44 GMT\r\nServer: mlflow\r\n\r\n{\"error_code\": \"MALFORMED_REQUEST\", \"message\": \"Failed to parse input from JSON. Ensure that input is a valid JSON formatted string.\", \"stack_trace\": \"Traceback (most recent call last):\\n  File \\\"C:\\\\Source\\\\local_training_mlflow_project\\\\.venv\\\\lib\\\\site-packages\\\\mlflow\\\\pyfunc\\\\scoring_server\\\\__init__.py\\\", line 81, in infer_and_parse_json_input\\n    decoded_input = json.loads(json_input)\\n  File \\\"C:\\\\Users\\\\mmaitre\\\\Anaconda3\\\\lib\\\\json\\\\__init__.py\\\", line 357, in loads\\n    return _default_decoder.decode(s)\\n  File \\\"C:\\\\Users\\\\mmaitre\\\\Anaconda3\\\\lib\\\\json\\\\decoder.py\\\", line 337, in decode\\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\\n  File \\\"C:\\\\Users\\\\mmaitre\\\\Anaconda3\\\\lib\\\\json\\\\decoder.py\\\", line 353, in raw_decode\\n    obj, end = self.scan_once(s, idx)\\njson.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 21 (char 20)\\n\"}\r\n```\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.'\r\n\r\n```\r\ncurl -i -X POST -d \"{\\\"data\\\":0.0199132142]}\" -H \"Content-Type: application\/json\" http:\/\/localhost:5000\/invocations\r\n```\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","158":"the current default is records, which is highly inefficient for reasonable sized datasets.\r\n\r\nSigned-off-by: Gerben Oostra <gerben.oostra@gmail.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nGives callers to the pyfunc rest api (\/invocations) the possibility to pass a header 'Orientation', that can be valued 'columns', 'records' or 'split'. This will change the json serialization of the returned pandas dataframe.\r\n\r\nCurrently only 'records' is used, which adds a lot of content to the json. This can cause errors for reasonably sized datasets (already with 5000 rows).\r\n\r\n## How is this patch tested?\r\n\r\n(Details)\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [X] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\nAllow header 'Orientation' on pyfunc server, changing the orientation of returned pandas DataFrame's.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [X] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n\r\nAssociated Issue: FR-4889 :  https:\/\/github.com\/mlflow\/mlflow\/issues\/4889 ","159":"It would be useful to have an API defined to add user defined ML packages to be integrated with _mlflow_ auto logging. Either it can be defined as a public API accessible to user for registering their packages and its corresponding _autolog_ function or support can be provided inside _[mlflow.tracking.fluent](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/tracking\/fluent.py)_ for exposing LIBRARY_TO_AUTOLOG_FN as a configurable .\r\nExample usage (Python syntax) :-\r\n```\r\n    import mlflow\r\n    mlflow.register_autolog_library(user_ml_package, autolog_function)\r\n    mlflow.autolog()\r\n    import user_ml_package\r\n```\r\nwhere,\r\n _user_ml_package_ :- User created ML package name as String\r\n _autolog_function_ :- User defined function with same syntax as that of _[mlflow.tracking.fluent.autolog](https:\/\/github.com\/mlflow\/mlflow\/blob\/20610102e5d35181fbb7cffda1a1c3700a3e35fc\/mlflow\/tracking\/fluent.py#L1270)_\r\n","160":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: `python:3.7` official image\r\n- **MLflow installed from (source or binary)**: \r\n- **MLflow version (run ``mlflow --version``)**: 1.20.2\r\n- **Python version**: `python:3.7` official image\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: `mlflow models serve`\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\nThe feature request here: https:\/\/github.com\/mlflow\/mlflow\/pull\/2725 does not appear to affect `mlflow model serve` servers.  \r\nExpected that server launched by `mlflow model serve` would answer to `\/health` calls, specifically responding with a `200 OK`\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n`mlflow model serve`  \r\n`curl <model_url>\/health`\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n`[2021-10-13 02:33:35 +0000] [51] [DEBUG] GET \/health\r\n-- ip -- \"GET \/health HTTP\/1.1\" 404 232 5207 \"curl\/7.54.0\" -`\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","161":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [X] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Big Sur 11.6\r\n- **MLflow installed from (source or binary)**: pip installed\r\n- **MLflow version (run ``mlflow --version``)**: version 1.20.2\r\n- **Python version**: 3.8.3\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nThe documentation show https:\/\/www.mlflow.org\/docs\/latest\/models.html#built-in-deployment-tools how to pass pandas DataFrames to the model scoring API. The 'split' layout seems to be recommended & the default.\r\n\r\nHowever, it itself responds in the 'records' layout, inflating the returned json (because the column names are repeated for every row).\r\nWith 3.4 million rows, and 6 columns with each more than 15 characters, this causes the following error:\r\n```\r\n[error] 18#18: *21 client intended to send too large body: 7446039352 bytes, client: 172.17.0.1, server: , request: \"POST \/invocations HTTP\/1.1\", host: \"127.0.0.1:5001\"\r\n```\r\n\r\nThe line defining this behavior is the following:\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/537158f82b9981b5d440ed81dc5c4c92f2c77edc\/mlflow\/pyfunc\/scoring_server\/__init__.py#L175\r\n\r\n\r\nThe docker throwing this was created based on a custom python func flavor, returning a pandas.DataFrame as follows:\r\n```\r\npoetry run mlflow models build-docker --install-mlflow -n my_name -m file:\/\/\/FullPath\/To\/my\/model\r\ndocker run -p 5001:8080 my_name\r\n```\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nSending a dataframe similar to, but with 3.4 million rows, where the response is a dataframe with 6 columns each more than 15 characters\r\n```\r\ncurl http:\/\/127.0.0.1:5000\/invocations -H 'Content-Type: application\/json' -d '{\r\n    \"columns\": [\"a\", \"b\", \"c\"],\r\n    \"data\": [[1, 2, 3], [4, 5, 6]]\r\n}'\r\n```\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [X] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [X] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","162":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **MLflow version (run ``mlflow --version``)**: mlflow, version 1.20.2\r\n- **Python version**: Python 3.7.10\r\n\r\n### Describe the problem\r\nThe problem I encountered is that `Run Command` showed on frontend when I run experiment on databricks shows different command than command that was actually used for running the experiment and therefore the experiment is not reproducible.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nFor example if I run locally:\r\n\r\n```\r\nmlflow run . -e main -P parameter=ab -b databricks --backend-config meta\/training_cluster.json --experiment-name \/some\/path\/experiment-1 --no-conda\r\n```\r\n\r\nI end up on databricks mlflow frontend with following command being shown as `Run Command`:\r\n```\r\nmlflow run file:\/\/\/Users\/xxx\/projects\/project -v xxxxxxxxxxxxxxxxxxxxxxxxxxx -e main -b databricks -P parameter=ab\r\n```\r\n\r\nWhere some of the parameters I used are missing (`backend-config`, `no-conda`, `experiment-name`) and therefore the run is not reproducible.\r\n\r\n\r\nSimilar issue happens if I use mlflow run from python:\r\n\r\n```\r\n        mlflow.projects.run(\r\n            uri='.', \r\n            entry_point='main',\r\n            backend='databricks',\r\n            backend_config='meta\/training_cluster.json',\r\n            synchronous=True,\r\n            experiment_name='\/some\/path\/experiment-1',\r\n        )\r\n```\r\n\r\nIn that case the `Run Command` shown of frontend is:\r\n\r\n```\r\nmlflow run file:\/\/\/Users\/xxx\/projects\/project -v xxxxxxxxxxxxxxxxxxxxxxxxxxx -e main -b local\r\n```\r\n\r\nWhere the `Run Command` says it was run locally and not on databricks and therefore it is misleading and not reproducible.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [x] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [x] `integrations\/databricks`: Databricks integrations\r\n","163":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**:1.20.2\r\n- **Python version**:3.8\r\n- **npm version, if running the dev UI**:N\/A\r\n- **Exact command to reproduce**:mlflow models serve -m runs:\/5f8aee52fcb442388368af4da658b398\/model\r\n\r\n### Describe the problem\r\n\r\nWe run `pip install` in [hash-checking mode](https:\/\/pip.pypa.io\/en\/stable\/cli\/pip_install\/#hash-checking-mode) to prevent package tampering. MLFlow does not support this by default so I provided the `requirements.txt` file explicitly:\r\n```\r\n    mlflow.sklearn.log_model(\r\n        model,\r\n        artifact_path = \"model\",\r\n        signature = mlflow.models.infer_signature(X_train[:10], y_train[:10]),\r\n        input_example = X_train[:10],\r\n        pip_requirements = \"requirements.txt\")\r\n```\r\nInstead of using the `requirements.txt` file as-is, MLFlow added an extra `mlflow` entry in the list of PIP requirements. This `mlflow` entry has no version or hash, which breaks `pip install` when trying to serve the model. The fix is likely not to add that extra entry when the `mlflow` package is already present in the requirement list.\r\n\r\nconda.yaml logged in model artifacts:\r\n```\r\nchannels:\r\n- conda-forge\r\ndependencies:\r\n- python=3.8.8\r\n- pip\r\n- pip:\r\n  - mlflow\r\n  - adal==1.2.7 --hash=sha256:2a7451ed7441ddbc57703042204a3e30ef747478eea022c70f789fc7f084bc3d\r\n    --hash=sha256:d74f45b81317454d96e982fd1c50e6fb5c99ac2223728aea8764433a39f566f1\r\n  - alembic==1.4.1 --hash=sha256:791a5686953c4b366d3228c5377196db2f534475bb38d26f70eb69668efd9028\r\n  - azure-common==1.1.27 --hash=sha256:426673962740dbe9aab052a4b52df39c07767decd3f25fdc87c9d4c566a04934\r\n    --hash=sha256:9f3f5d991023acbd93050cf53c4e863c6973ded7e236c69e99c8ff5c7bad41ef\r\n<snip>\r\n  - werkzeug==2.0.2 --hash=sha256:63d3dc1cf60e7b7e35e97fa9861f7397283b75d765afcaefd993d6046899de8f\r\n    --hash=sha256:aa2bb6fc8dee8d6c504c0ac1e7f5f7dc5810a9903e793b6f715a9f015bdadb9a\r\n  - zipp==3.6.0 --hash=sha256:71c644c5369f4a6e07636f0aa966270449561fcea2e3d6747b8d23efaa9d7832\r\n    --hash=sha256:9fe5ea21568a0a70e50f273397638d39b03353731e6cbbb3fd8502a33fec40bc\r\nname: mlflow-env\r\n```\r\n\r\nCommand error:\r\n```\r\n(.venv) (base) C:\\Source\\local_training_mlflow_project>mlflow models serve -m runs:\/5f8aee52fcb442388368af4da658b398\/model\r\n2021\/10\/11 23:28:11 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\r\n2021\/10\/11 23:28:15 INFO mlflow.utils.conda: === Creating conda environment mlflow-895112428d2cf8da9ab88b552b55b1ea2f22dc1c ===\r\nCollecting package metadata (repodata.json): done\r\nSolving environment: done\r\n\r\n\r\n==> WARNING: A newer version of conda exists. <==\r\n  current version: 4.10.1\r\n  latest version: 4.10.3\r\n\r\nPlease update conda by running\r\n\r\n    $ conda update -n base -c defaults conda\r\n\r\n\r\n\r\nDownloading and Extracting Packages\r\nopenssl-1.1.1l       | 5.7 MB    | ############################################################################################################################### | 100%\r\npython-3.8.8         | 19.2 MB   | ############################################################################################################################### | 100%\r\nPreparing transaction: done\r\nVerifying transaction: done\r\nExecuting transaction: done\r\nInstalling pip dependencies: | Ran pip subprocess with arguments:\r\n['C:\\\\Users\\\\mmaitre\\\\Anaconda3\\\\envs\\\\mlflow-895112428d2cf8da9ab88b552b55b1ea2f22dc1c\\\\python.exe', '-m', 'pip', 'install', '-U', '-r', 'C:\\\\Source\\\\local_training_mlflow_project\\\\mlruns\\\\0\\\\5f8aee52fcb442388368af4da658b398\\\\artifacts\\\\model\\\\condaenv.4kpb_18z.requirements.txt']\r\nPip subprocess output:\r\nCollecting mlflow\r\n\r\nPip subprocess error:\r\nERROR: In --require-hashes mode, all requirements must have their versions pinned with ==. These do not:\r\n    mlflow from https:\/\/files.pythonhosted.org\/packages\/ac\/60\/cc5ad7b761f31854d3158dc420e62d5adaa283e5d65efebf029ae2c400c2\/mlflow-1.20.2-py3-none-any.whl#sha256=963c22532e82a93450674ab97d62f9e528ed0906b580fadb7c003e696197557c (from -r C:\\Source\\local_training_mlflow_project\\mlruns\\0\\5f8aee52fcb442388368af4da658b398\\artifacts\\model\\condaenv.4kpb_18z.requirements.txt (line 1))\r\n\r\nfailed\r\n\r\nCondaEnvException: Pip failed\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\mmaitre\\Anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"C:\\Users\\mmaitre\\Anaconda3\\lib\\runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Source\\local_training_mlflow_project\\.venv\\Scripts\\mlflow.exe\\__main__.py\", line 7, in <module>\r\n  File \"C:\\Source\\local_training_mlflow_project\\.venv\\lib\\site-packages\\click\\core.py\", line 1128, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"C:\\Source\\local_training_mlflow_project\\.venv\\lib\\site-packages\\click\\core.py\", line 1053, in main\r\n    rv = self.invoke(ctx)\r\n  File \"C:\\Source\\local_training_mlflow_project\\.venv\\lib\\site-packages\\click\\core.py\", line 1659, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"C:\\Source\\local_training_mlflow_project\\.venv\\lib\\site-packages\\click\\core.py\", line 1659, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"C:\\Source\\local_training_mlflow_project\\.venv\\lib\\site-packages\\click\\core.py\", line 1395, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"C:\\Source\\local_training_mlflow_project\\.venv\\lib\\site-packages\\click\\core.py\", line 754, in invoke\r\n    return __callback(*args, **kwargs)\r\n  File \"C:\\Source\\local_training_mlflow_project\\.venv\\lib\\site-packages\\mlflow\\models\\cli.py\", line 54, in serve\r\n    return _get_flavor_backend(\r\n  File \"C:\\Source\\local_training_mlflow_project\\.venv\\lib\\site-packages\\mlflow\\pyfunc\\backend.py\", line 91, in serve\r\n    return _execute_in_conda_env(\r\n  File \"C:\\Source\\local_training_mlflow_project\\.venv\\lib\\site-packages\\mlflow\\pyfunc\\backend.py\", line 149, in _execute_in_conda_env\r\n    conda_env_name = get_or_create_conda_env(conda_env_path, env_id=env_id)\r\n  File \"C:\\Source\\local_training_mlflow_project\\.venv\\lib\\site-packages\\mlflow\\utils\\conda.py\", line 93, in get_or_create_conda_env\r\n    process.exec_cmd(\r\n  File \"C:\\Source\\local_training_mlflow_project\\.venv\\lib\\site-packages\\mlflow\\utils\\process.py\", line 40, in exec_cmd\r\n    raise ShellCommandException(\"Non-zero exitcode: %s\" % (exit_code))\r\nmlflow.utils.process.ShellCommandException: Non-zero exitcode: 1\r\n```\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n- train.py:\r\n```\r\nimport mlflow\r\nimport sklearn\r\n\r\nmlflow.sklearn.autolog(log_models=False) # Use explicit model logging to control pip requirements\r\n\r\n# Load data\r\nX, y = sklearn.datasets.load_diabetes(return_X_y = True)\r\nX_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2, random_state=0)\r\n\r\n# Train model\r\nwith mlflow.start_run() as run:\r\n    print(f\"MLFlow run ID: {run.info.run_id}\")\r\n\r\n    model = sklearn.linear_model.Ridge(alpha=0.03)\r\n    model.fit(X_train, y_train)\r\n\r\n    mlflow.sklearn.log_model(\r\n        model,\r\n        artifact_path = \"model\",\r\n        signature = mlflow.models.infer_signature(X_train[:10], y_train[:10]),\r\n        input_example = X_train[:10],\r\n        pip_requirements = \"requirements.txt\")\r\n```\r\n\r\n- requirements.in:\r\n```\r\npandas==1.3.2\r\nscikit-learn==0.24.2\r\nmlflow==1.20.2\r\nazureml-mlflow==1.34.0\r\n```\r\n\r\nRequirement pinning:\r\n```\r\npip install pip-tools\r\npip-compile --generate-hashes --output-file=requirements.txt requirements.in\r\n```\r\n\r\n### Other info \/ logs\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations","164":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nThe server's home page shows the default experiment which means hitting `\/` sends `GET \/experiments\/get?experiment_id=0` to the server, in a multi-user access controlled environment where a user only have access to his experiments (the ownership information and access control mechanics are delegated to a separated application) this means all users accessing MLFlow will try to get the default experiment which they don't have access to.\r\n\r\nWhy does MLFlow do that? Why don't the home page just shows the experiments list or general information not related to any experiment?\r\n\r\n## Motivation\r\nWe're having this problem as part of our MLOps platform https:\/\/iko.ai particularly when implementing access control mechanics for MLFlow resources\r\n\r\nAccess control is important for privacy, users should not be allowed to see others' experiments and tracking data\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations","165":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nSupport running of a MLproject on an existing Databricks cluster. Right now, the mlflow api only accepts a new cluster configuration when running a project on Databricks. We would like it to accept the `existing_cluster_id` as described in the [Databricks API](https:\/\/docs.microsoft.com\/en-us\/azure\/databricks\/dev-tools\/api\/latest\/jobs#--request-structure-6) as well.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nUsers can more quickly run a mlflow project on an existing cluster that is already started up instead of waiting for the new cluster to be created (around 5 min), and the conda environment to be created (again a couple of minutes). \r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\nMore flexibility in choosing how to run a project on Databricks via the API or CLI.\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nUsers of our ML platform (using mlflow & databricks) have been asking for the ability to use an existing cluster to test out their runs with a quicker feedback loop.\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nIt's not especially difficult, just more time-consuming to have to wait for the cluster and conda environment to be created before being able to see if the run will start or be successful. \r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [x] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","166":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: docker image `python:3.8.11-slim-buster`\r\n- **MLflow installed from (source or binary)**: pypi.or via `pip install mlflow[extras,sqlserver,aliyun_oss]==1.20.2`\r\n- **MLflow version (run ``mlflow --version``)**: `mlflow, version 1.20.2`\r\n- **Python version**: 3.8.11\r\n- **npm version, if running the dev UI**: -\r\n- **Exact command to reproduce**: `mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri=postgresql:\/\/postgres:password@host:5432 --default-artifact-root=\/usr\/local\/share\/mlflow`\r\n\r\n### Describe the problem\r\nCrash happens with the following traceback:\r\n<details>\r\n<summary> traceback <\/summary>\r\n\r\n```\r\n2021\/10\/08 13:40:00 ERROR mlflow.cli: Error initializing backend store\r\n2021\/10\/08 13:40:00 ERROR mlflow.cli: No module named 'psycopg2'\r\nTraceback (most recent call last):\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/cli.py\", line 383, in server\r\n    initialize_backend_stores(backend_store_uri, default_artifact_root)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/server\/handlers.py\", line 145, in initialize_backend_stores\r\n    _get_tracking_store(backend_store_uri, default_artifact_root)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/server\/handlers.py\", line 130, in _get_tracking_store\r\n    _tracking_store = _tracking_store_registry.get_store(store_uri, artifact_root)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/tracking\/_tracking_service\/registry.py\", line 39, in get_store\r\n    return self._get_store_with_resolved_uri(resolved_store_uri, artifact_uri)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/tracking\/_tracking_service\/registry.py\", line 49, in _get_store_with_resolved_uri\r\n    return builder(store_uri=resolved_store_uri, artifact_uri=artifact_uri)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/server\/handlers.py\", line 101, in _get_sqlalchemy_store\r\n    return SqlAlchemyStore(store_uri, artifact_uri)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/store\/tracking\/sqlalchemy_store.py\", line 118, in __init__\r\n    ] = mlflow.store.db.utils.create_sqlalchemy_engine_with_retry(db_uri)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/store\/db\/utils.py\", line 158, in create_sqlalchemy_engine_with_retry\r\n    engine = create_sqlalchemy_engine(db_uri)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/store\/db\/utils.py\", line 188, in create_sqlalchemy_engine\r\n    return sqlalchemy.create_engine(db_uri, pool_pre_ping=True, **pool_kwargs)\r\n  File \"<string>\", line 2, in create_engine\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/util\/deprecations.py\", line 298, in warned\r\n    return fn(*args, **kwargs)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/create.py\", line 560, in create_engine\r\n    dbapi = dialect_cls.dbapi(**dbapi_args)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/dialects\/postgresql\/psycopg2.py\", line 793, in dbapi\r\n    import psycopg2\r\nModuleNotFoundError: No module named 'psycopg2'\r\n```\r\n\r\n<\/details>\r\n\r\nIt would be great if:\r\n1. `psycopg2-binary` included in the `sqlserver` extras.\r\n2. you have `all` extras, which combine all other extras.\r\n\r\n### Code to reproduce the issue\r\n1. `docker run -it mlflow[extras,sqlserver,aliyun_oss]==1.20.2 bash`\r\n2. Being in container: `pip install mlflow[extras,sqlserver,aliyun_oss]==1.20.2`\r\n3. Being in container: `mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri=postgresql:\/\/postgres:password@host:5432 --default-artifact-root=\/usr\/local\/share\/mlflow`\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [x] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [x] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","167":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this installation issue template to ensure a timely and thorough response.**\r\n\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: 1.20.3.dev0\r\n- **Python version**: 3.6.13\r\n- **Exact command to reproduce**: [install node modules](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#install-node-modules) failed\r\n\r\n### Describe the problem\r\nThe error message asks to contact `npm` directly. I think it might be better to first present the error here to see if it is a configuration error.\r\n\r\n```\r\n(mlflow-dev-env) usr_name@usr_name-ubuntu:~\/github\/mlflow\/mlflow\/server\/js$ npm install\r\nnpm WARN deprecated react-dom@16.3.2: This version of react-dom\/server contains a minor vulnerability. Please update react-dom to 16.3.3 or 16.4.2+. Learn more: https:\/\/fb.me\/cve-2018-6341\r\nnpm WARN deprecated core-js@2.6.12: core-js@<3.3 is no longer maintained and not recommended for usage due to the number of issues. Because of the V8 engine whims, feature detection in old core-js versions could cause a slowdown up to 100x even if nothing is polyfilled. Please, upgrade your dependencies to the actual version of core-js.\r\nnpm WARN deprecated core-js@1.2.7: core-js@<3.3 is no longer maintained and not recommended for usage due to the number of issues. Because of the V8 engine whims, feature detection in old core-js versions could cause a slowdown up to 100x even if nothing is polyfilled. Please, upgrade your dependencies to the actual version of core-js.\r\nnpm ERR! Linux 5.4.0-87-generic\r\nnpm ERR! argv \"\/usr\/bin\/node\" \"\/usr\/bin\/npm\" \"install\"\r\nnpm ERR! node v8.10.0\r\nnpm ERR! npm  v3.5.2\r\nnpm ERR! code EMISSINGARG\r\n\r\nnpm ERR! typeerror Error: Missing required argument #1\r\nnpm ERR! typeerror     at andLogAndFinish (\/usr\/share\/npm\/lib\/fetch-package-metadata.js:31:3)\r\nnpm ERR! typeerror     at fetchPackageMetadata (\/usr\/share\/npm\/lib\/fetch-package-metadata.js:51:22)\r\nnpm ERR! typeerror     at resolveWithNewModule (\/usr\/share\/npm\/lib\/install\/deps.js:456:12)\r\nnpm ERR! typeerror     at \/usr\/share\/npm\/lib\/install\/deps.js:457:7\r\nnpm ERR! typeerror     at \/usr\/share\/npm\/node_modules\/iferr\/index.js:13:50\r\nnpm ERR! typeerror     at \/usr\/share\/npm\/lib\/fetch-package-metadata.js:37:12\r\nnpm ERR! typeerror     at addRequestedAndFinish (\/usr\/share\/npm\/lib\/fetch-package-metadata.js:82:5)\r\nnpm ERR! typeerror     at returnAndAddMetadata (\/usr\/share\/npm\/lib\/fetch-package-metadata.js:117:7)\r\nnpm ERR! typeerror     at pickVersionFromRegistryDocument (\/usr\/share\/npm\/lib\/fetch-package-metadata.js:134:20)\r\nnpm ERR! typeerror     at \/usr\/share\/npm\/node_modules\/iferr\/index.js:13:50\r\nnpm ERR! typeerror This is an error with npm itself. Please report this error at:\r\nnpm ERR! typeerror     <http:\/\/github.com\/npm\/npm\/issues>\r\n\r\nnpm ERR! Please include the following file with any support request:\r\nnpm ERR!     \/home\/usr_name\/github\/mlflow\/mlflow\/server\/js\/npm-debug.log\r\n\r\n```\r\n\r\n### Other info \/ logs\r\nnpm log file : [npm-debug.log](https:\/\/github.com\/mlflow\/mlflow\/files\/7305059\/npm-debug.log)\r\n\r\n","168":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n-  No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)No:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)Linux:\r\n- **MLflow installed from (source or binary)pip:\r\n- **MLflow version (run ``mlflow --version``)1.19.0:\r\n- **Python version3.6:\r\n\r\n### Describe the problem\r\nI build a model in tensorflow 1.15.4 and log it in the mlflow. After loading it back in tensorflow it shows that it does not have a predict function. If I load it back in the default pyfunc then it is also not predicting the dataframe\/numpy\/dict. \r\n\r\n### Code to reproduce issue\r\nPredicting using tensorflow model\r\n```\r\ntf_graph = tf.Graph()\r\ntf_sess = tf.Session(graph=tf_graph)\r\ntensor_model = mlflow.tensorflow.load_model(model_uri=\"runs:\/519a3786726249e0ad8a6dd26b0531cd\/widedeep\", tf_sess=tf_sess)\r\ntensor_model.predict(test)\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-46-28b1b402562c> in <module>\r\n----> 1 tensor_model.predict(test)\r\n\r\nAttributeError: predict\r\n```\r\nPredicting using default pyfunc model\r\n```\r\nmodel = mlflow.pyfunc.load_model(model_uri= \"runs:\/519a3786726249e0ad8a6dd26b0531cd\/widedeep\", suppress_warnings= True)\r\nmodel.predict(test)\r\n---------------------------------------------------------------------------\r\nKeyError                                  Traceback (most recent call last)\r\nD:\\Anaconda\\envs\\reco_base\\lib\\site-packages\\pandas\\core\\indexes\\base.py in get_loc(self, key, method, tolerance)\r\n   2897             try:\r\n-> 2898                 return self._engine.get_loc(casted_key)\r\n   2899             except KeyError as err:\r\n\r\npandas\\_libs\\index.pyx in pandas._libs.index.IndexEngine.get_loc()\r\n\r\npandas\\_libs\\index.pyx in pandas._libs.index.IndexEngine.get_loc()\r\n\r\npandas\\_libs\\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()\r\n\r\npandas\\_libs\\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()\r\n\r\nKeyError: 'examples'\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nKeyError                                  Traceback (most recent call last)\r\n<ipython-input-45-c0ac8462bce6> in <module>\r\n----> 1 model.predict(test)\r\n\r\nD:\\Anaconda\\envs\\reco_base\\lib\\site-packages\\mlflow\\pyfunc\\__init__.py in predict(self, data)\r\n    594         if input_schema is not None:\r\n    595             data = _enforce_schema(data, input_schema)\r\n--> 596         return self._model_impl.predict(data)\r\n    597 \r\n    598     @property\r\n\r\nD:\\Anaconda\\envs\\reco_base\\lib\\site-packages\\mlflow\\tensorflow.py in predict(self, data)\r\n    535                 feed_dict = {\r\n    536                     self.input_tensor_mapping[tensor_column_name]: data[tensor_column_name].values\r\n--> 537                     for tensor_column_name in self.input_tensor_mapping.keys()\r\n    538                 }\r\n    539             else:\r\n\r\nD:\\Anaconda\\envs\\reco_base\\lib\\site-packages\\mlflow\\tensorflow.py in <dictcomp>(.0)\r\n    535                 feed_dict = {\r\n    536                     self.input_tensor_mapping[tensor_column_name]: data[tensor_column_name].values\r\n--> 537                     for tensor_column_name in self.input_tensor_mapping.keys()\r\n    538                 }\r\n    539             else:\r\n\r\nD:\\Anaconda\\envs\\reco_base\\lib\\site-packages\\pandas\\core\\frame.py in __getitem__(self, key)\r\n   2904             if self.columns.nlevels > 1:\r\n   2905                 return self._getitem_multilevel(key)\r\n-> 2906             indexer = self.columns.get_loc(key)\r\n   2907             if is_integer(indexer):\r\n   2908                 indexer = [indexer]\r\n\r\nD:\\Anaconda\\envs\\reco_base\\lib\\site-packages\\pandas\\core\\indexes\\base.py in get_loc(self, key, method, tolerance)\r\n   2898                 return self._engine.get_loc(casted_key)\r\n   2899             except KeyError as err:\r\n-> 2900                 raise KeyError(key) from err\r\n   2901 \r\n   2902         if tolerance is not None:\r\n\r\nKeyError: 'examples'\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\n","169":"I have seen lot of article where they used smaller model to deploy them with mlflow and kubernetes.Is there any sources for BERT models?\r\n","170":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No custom code\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Big Sur v 11.6\r\n- **MLflow installed from (source or binary)**: source (github)\r\n- **MLflow version (run ``mlflow --version``)**: mlflow, version 1.20.3.dev0\r\n- **Python version**: Python 3.8.5\r\n- **npm version, if running the dev UI**:  7.21.0\r\n- **Exact command to reproduce**: npm install from within mlflow\/server\/js\r\n\r\n### Describe the problem\r\nFollowing the instructions [here](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#javascript-and-ui) after installing `brew install pixman cairo pango jpeg` npm install fails with the following error;\r\n\r\n```\r\nnpm ERR! ..\/src\/backend\/..\/closure.h:6:10: fatal error: 'jpeglib.h' file not found\r\nnpm ERR! #include <jpeglib.h>\r\nnpm ERR!          ^~~~~~~~~~~\r\nnpm ERR! 1 error generated.\r\nnpm ERR! make: *** [Release\/obj.target\/canvas\/src\/backend\/PdfBackend.o] Error 1\r\nnpm ERR! gyp ERR! build error\r\nnpm ERR! gyp ERR! stack Error: make failed with exit code: 2\r\nnpm ERR! gyp ERR! stack     at ChildProcess.onExit (\/opt\/brew\/lib\/node_modules\/npm\/node_modules\/node-gyp\/lib\/build.js:194:23)\r\nnpm ERR! gyp ERR! stack     at ChildProcess.emit (node:events:394:28)\r\nnpm ERR! gyp ERR! stack     at Process.ChildProcess._handle.onexit (node:internal\/child_process:290:12)\r\nnpm ERR! gyp ERR! System Darwin 20.6.0\r\nnpm ERR! gyp ERR! command \"\/opt\/brew\/Cellar\/node\/16.8.0\/bin\/node\" \"\/opt\/brew\/lib\/node_modules\/npm\/node_modules\/node-gyp\/bin\/node-gyp.js\" \"build\" \"--fallback-to-build\" \"--module=\/Users\/systemuser\/mlflow\/mlflow\/server\/js\/node_modules\/canvas\/build\/Release\/canvas.node\" \"--module_name=canvas\" \"--module_path=\/Users\/systemuser\/mlflow\/mlflow\/server\/js\/node_modules\/canvas\/build\/Release\" \"--napi_version=8\" \"--node_abi_napi=napi\" \"--napi_build_version=0\" \"--node_napi_label=node-v93\"\r\nnpm ERR! gyp ERR! cwd \/Users\/systemuser\/mlflow\/mlflow\/server\/js\/node_modules\/canvas\r\nnpm ERR! gyp ERR! node -v v16.8.0\r\nnpm ERR! gyp ERR! node-gyp -v v7.1.2\r\nnpm ERR! gyp ERR! not ok\r\nnpm ERR! node-pre-gyp ERR! build error\r\nnpm ERR! node-pre-gyp ERR! stack Error: Failed to execute '\/opt\/brew\/Cellar\/node\/16.8.0\/bin\/node \/opt\/brew\/lib\/node_modules\/npm\/node_modules\/node-gyp\/bin\/node-gyp.js build --fallback-to-build --module=\/Users\/systemuser\/mlflow\/mlflow\/server\/js\/node_modules\/canvas\/build\/Release\/canvas.node --module_name=canvas --module_path=\/Users\/systemuser\/mlflow\/mlflow\/server\/js\/node_modules\/canvas\/build\/Release --napi_version=8 --node_abi_napi=napi --napi_build_version=0 --node_napi_label=node-v93' (1)\r\nnpm ERR! node-pre-gyp ERR! stack     at ChildProcess.<anonymous> (\/Users\/systemuser\/mlflow\/mlflow\/server\/js\/node_modules\/node-pre-gyp\/lib\/util\/compile.js:83:29)\r\nnpm ERR! node-pre-gyp ERR! stack     at ChildProcess.emit (node:events:394:28)\r\nnpm ERR! node-pre-gyp ERR! stack     at maybeClose (node:internal\/child_process:1064:16)\r\nnpm ERR! node-pre-gyp ERR! stack     at Process.ChildProcess._handle.onexit (node:internal\/child_process:301:5)\r\nnpm ERR! node-pre-gyp ERR! System Darwin 20.6.0\r\nnpm ERR! node-pre-gyp ERR! command \"\/opt\/brew\/Cellar\/node\/16.8.0\/bin\/node\" \"\/Users\/systemuser\/mlflow\/mlflow\/server\/js\/node_modules\/.bin\/node-pre-gyp\" \"install\" \"--fallback-to-build\"\r\nnpm ERR! node-pre-gyp ERR! cwd \/Users\/systemuser\/mlflow\/mlflow\/server\/js\/node_modules\/canvas\r\nnpm ERR! node-pre-gyp ERR! node -v v16.8.0\r\nnpm ERR! node-pre-gyp ERR! node-pre-gyp -v v0.11.0\r\nnpm ERR! node-pre-gyp ERR! not ok\r\n```\r\nI am not sure what's going on here since jpeg is already installed. Also I do have xcode installed if it matters. Any pointers would be appreciated.\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [x] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [x] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\n","171":"Started using MLflow and when you click models in the menubar, I got an error INVALID_PARAMETER_VALUE: Model registry functionality is unavailable; got unsupported URI '.\/mlruns' for model registry data storage. Supported URI schemes are: ['postgresql', 'mysql', 'sqlite', 'mssql']. See https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#storage for how to run an MLflow server against one of the supported backend storage locations.","172":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nWe are running the MLflow server on K8s using S3 and RDS. Successfully logging an artifact which is a 2MB JSON file, however when trying to view this file within the UI it takes a long time to load (minutes) and Firefox even complains it is slowing the browser down. \r\n\r\nThen if a user clicks off and tries to view once again the loading restarts. This is not a great UX, so the enhancements I would suggest:\r\n\r\n* Try to load these larger files a different \/ faster way\r\n* If that's not entirely possible change the UI to tell the user to wait a little longer or a loading bar on first load and then ... \r\n* Implement some form of caching to enable faster second load\r\n\r\n## Motivation\r\n- What is the use case for this feature? Large file viewing in the artifact screens\r\n- Why is this use case valuable to support for MLflow users in general? Some artifacts are not necessarily small and would be useful for debugging experiments and their runs\r\n- Why is this use case valuable to support for your project(s) or organization? We use various pieces of metadata and extra artifacts in our ensemble or pipelines which are useful to been seen alongside our metrics\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient) as explained above it's mostly around latency and UX not quite being there for this use case\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\nI am no frontend developer but imagine it's a UI update for the loading bar and then leveraging in browser caches potentially. \r\n","173":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: -\r\n- **MLflow installed from (source or binary)**: via pip\r\n- **MLflow version (run ``mlflow --version``)**: 1.20.0\r\n- **Python version**: 3.9.6\r\n\r\n### Describe the problem\r\nI run log_batch with non string values for Param values. Typeerror during to_proto ensures.\r\n\r\n\r\n### Code to reproduce issue\r\n```\r\nfrom mlflow.tracking import MlflowClient\r\nfrom mlflow.entities import Param\r\n\r\n# Create MLflow entities and a run under the default experiment (whose id is '0').\r\nparams = [Param(\"p\", 1)]\r\nexperiment_id = \"0\"\r\nclient = MlflowClient()\r\nrun = client.create_run(experiment_id)\r\nclient.log_batch(run.info.run_id, params=params)\r\nclient.set_terminated(run.info.run_id)\r\n\r\n```","174":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10, WSL2\r\n- **MLflow installed from (source or binary)**: PyPI\r\n- **MLflow version (run ``mlflow --version``)**: 1.20.2\r\n- **Python version**: 3.8.10\r\n- **npm version, if running the dev UI**: n\/a\r\n- **Exact command to reproduce**: mlflow run .\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\nUsing a Win10\/WSL2\/docker setup, the container mount path to the artifact store is incorrect. From the logs:\r\n\r\n2021\/09\/29 10:41:52 INFO mlflow.projects.backend.local: === Running command 'docker run --rm -v C:\\Users\\jacobss\\gitlab\\test-mlflow-project\\mlruns:\/mlflow\/tmp\/mlruns -v C:\\Users\\jacobss\\gitlab\\test-mlflow-project\\mlruns\\0\\2084a026daf8461fad6474e83532b9ce\\artifacts:C:\\Users\\jacobss\\gitlab\\test-mlflow-project\\mlruns\\0\\2084a026daf8461fad6474e83532b9ce\\artifacts -e MLFLOW_RUN_ID=2084a026daf8461fad6474e83532b9ce -e MLFLOW_TRACKING_URI=file:\/\/\/mlflow\/tmp\/mlruns -e MLFLOW_EXPERIMENT_ID=0 mlflow-experiments:6432e77 bash .\/main.sh' in run with ID '2084a026daf8461fad6474e83532b9ce' ===\r\n\r\nSo the first volume mount (of mlruns) is fine, but the second one has windows paths for both the source path (correct) and the destination path (incorrect).\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [x] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","175":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute to this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nWhile using `load_model()` in python, I noticed it leads to creating a folder present in the temp folder. I am working on a project which loads 4 MLModels whose size is 2.5GB each, and this results in filling up disk space very quickly. A suggestion would be deleting this folder as soon as the program stops running or providing an `argument` for changing the folder's directory where MLModels are loaded.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nI discovered this issue while debugging my project and noticed this is a problem if I deploy it somewhere. \r\n- Why is this use case valuable to support for MLflow users in general?\r\nI feel many MLflow users will come with this issue if they are taking their projects to production.\r\n- Why is this use case valuable to support your project(s) or organization?\r\nOur organization is moving towards MLOps very quickly as it is a skill required for every software engineer interested in data science\/AI-related work. MLFlow is an integral part of automating our ML projects; hence, we think this feature would benefit us and ML Engineers in general.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [x] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [x] `language\/new`: Proposals for new client languages (Python)\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [x] `integrations\/sagemaker`: SageMaker integrations\r\n- [x] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","176":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nPaddlePaddle framework users can use MLFlow for PaddlePaddle training experiment visualization.\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\nMLFlow users can use PaddlePaddle framework natively.\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nPaddlePaddle framework users can use MLFlow for PaddlePaddle training experiment visualization.\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nWe need to figure out MLFlow capability to support distributed training currently.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n- [x] `integrations\/paddlepaddle`: PaddlePaddle integrations\r\n\r\n## Details\r\n\r\nPaddlePaddle team has implemented the deep learning training visualization through PaddlePaddle high-level API integration. For this project, visualization capability of Paddle distributed training based on MLFlow should be implemented.\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","177":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ X] Yes. I can contribute a fix for this bug independently.\r\n\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: linux\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**:   1.19.0\r\n- **Python version**: 3.8\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n```\r\ndocker build -t mlflow-docker-example -f Dockerfile .\r\nmlflow run examples\/docker -P alpha=0.5\r\n```\r\n\r\n### Describe the problem\r\n\r\nThe example in `examples\/docker` has become out of date and no longer runs. The base image (`miniconda:4.5.4`) in the dockerfile is pinned to Python 2.7, and several of the other python packages are also broken.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\n$ docker build -t mlflow-docker-example -f Dockerfile .\r\nSending build context to Docker daemon  278.5kB\r\nStep 1\/2 : FROM continuumio\/miniconda:4.5.4\r\n4.5.4: Pulling from continuumio\/miniconda\r\ncc1a78bfd46b: Pull complete\r\n420ea9ce27d9: Pull complete\r\n1b219c050547: Pull complete\r\n1c177edca126: Pull complete\r\nDigest: sha256:19d3eedab8b6301a0e1819476cfc50d53399881612183cf65208d7d43db99cd9\r\nStatus: Downloaded newer image for continuumio\/miniconda:4.5.4\r\n ---> 16e4fbac86ce\r\n...\r\nRemoving intermediate container 977134a62fa9\r\n ---> 683df65a5751\r\nSuccessfully built 683df65a5751\r\nSuccessfully tagged mlflow-docker-example:latest\r\n\r\n$ mlflow run examples\/docker -P alpha=0.5\r\n2021\/09\/20 21:30:59 INFO mlflow.projects.docker: === Building docker image docker-example:94891da ===\r\n2021\/09\/20 21:31:02 INFO mlflow.projects.utils: === Created directory \/tmp\/tmpnk6qb3_7 for downloading remote URIs passed to arguments of type 'path' ===\r\n2021\/09\/20 21:31:02 INFO mlflow.projects.backend.local: === Running command 'docker run --rm -v \/home\/osdi-eval\/mlflow\/mlruns:\/mlflow\/tmp\/mlruns -v \/home\/osdi-eval\/mlflow\/mlruns\/0\/1db9353955c74803bbe8f9f2245070b3\/artifacts:\/home\/osdi-eval\/mlflow\/mlruns\/0\/1db9353955c74803bbe8f9f2245070b3\/artifacts -e MLFLOW_RUN_ID=1db9353955c74803bbe8f9f2245070b3 -e MLFLOW_TRACKING_URI=file:\/\/\/mlflow\/tmp\/mlruns -e MLFLOW_EXPERIMENT_ID=0 docker-example:94891da python train.py --alpha 0.5 --l1-ratio 0.1' in run with ID '1db9353955c74803bbe8f9f2245070b3' ===\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 16, in <module>\r\n    import mlflow\r\n  File \"\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/__init__.py\", line 31, in <module>\r\n    import mlflow.tracking._model_registry.fluent\r\n  File \"\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/tracking\/__init__.py\", line 8, in <module>\r\n    from mlflow.tracking.client import MlflowClient\r\n  File \"\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/tracking\/client.py\", line 8, in <module>\r\n    from mlflow.entities import ViewType\r\n  File \"\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/entities\/__init__.py\", line 6, in <module>\r\n    from mlflow.entities.experiment import Experiment\r\n  File \"\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/entities\/experiment.py\", line 2, in <module>\r\n    from mlflow.entities.experiment_tag import ExperimentTag\r\n  File \"\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/entities\/experiment_tag.py\", line 2, in <module>\r\n    from mlflow.protos.service_pb2 import ExperimentTag as ProtoExperimentTag\r\n  File \"\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/protos\/service_pb2.py\", line 7, in <module>\r\n    from google.protobuf import descriptor as _descriptor\r\n  File \"\/opt\/conda\/lib\/python2.7\/site-packages\/google\/protobuf\/descriptor.py\", line 113\r\n    class DescriptorBase(metaclass=DescriptorMetaclass):\r\n                                  ^\r\nSyntaxError: invalid syntax\r\n2021\/09\/20 21:31:03 ERROR mlflow.cli: === Run (ID '1db9353955c74803bbe8f9f2245070b3') failed ===\r\n```\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ X ] `area\/examples`: Example code\r\n\r\nInterface \r\n\r\n- [ X] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n\r\n","178":"Dear All,\r\n\r\nmlflow.models not contain prophet, also there's an issue when you import fbprophet\r\nfrom fbprophet import Prophet ,serialize\r\n\r\nThis method doesn't exist, I can't save the model inside the folder because of this.\r\nmlflow.prophet\r\n\r\nMany thanks\r\nBest regards\r\n\r\n\r\nThank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**:\r\n- **Python version**:\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","179":"## What changes are proposed in this pull request?\r\n\r\nArtifacts from remote locations are not properly copied to the DFS when loading a model.\r\nThis is problematic when using spark in a non-local mode since the artifacts will not be distributed to the executors.\r\n\r\nThis PR adds a check to see in which mode spark it running and will copy the artifacts to the specified DFS if in a non-local mode.\r\n\r\n## How is this patch tested?\r\n\r\nTest on a local session to ensure the current behaviour is unchanged, as well as on a cluster with executors on k8s + zeppelin to ensure that the artifacts were copied properly to the DFS.\r\nEFS volumes mounted to \/tmp\/mlflow were used as a shared volume.\r\nS3 was used as the remote artifact store.\r\n\r\nPreviously when loading the model, the user will be presented with an error similar to the following:\r\n\r\n```python\r\nloaded_model = mlflow.spark.load_model(\"models:\/my_model\/Production\")\r\nloaded_model.transform(test).show()\r\n```\r\n```sh\r\n2021\/09\/18 21:49:08 INFO mlflow.spark: URI 's3:\/\/bucket\/mlflow\/mlflow\/13\/622fe7993ab1449d84fcca5c3e1fe7e6\/artifacts\/model\/sparkml' does not point to the current DFS.\r\n2021\/09\/18 21:49:08 INFO mlflow.spark: File 's3:\/\/bucket\/mlflow\/mlflow\/13\/622fe7993ab1449d84fcca5c3e1fe7e6\/artifacts\/model\/sparkml' not found on DFS. Will attempt to upload the file.\r\n---------------------------------------------------------------------------\r\nPy4JJavaError                             Traceback (most recent call last)\r\n\/tmp\/ipykernel_195\/2212746676.py in <module>\r\n      1 # Load the model\r\n----> 2 loaded_model = mlflow.spark.load_model(\"models:\/my_model\/Production\")\r\n      3 loaded_model.transform(test).show()\r\n ...\r\n ...\r\n\r\nCaused by: java.io.FileNotFoundException: File file:\/tmp\/tmpx2exbpfw\/sparkml\/metadata\/part-00000 does not exist\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:668)\r\n```\r\n\r\nAfter the change, the model can be loaded and used properly\r\n\r\n```python\r\nloaded_model = mlflow.spark.load_model(\"models:\/my_model\/Production\")\r\nloaded_model.transform(test).show()\r\n```\r\n```sh\r\n2021\/09\/19 18:21:41 INFO mlflow.spark: URI 's3:\/\/bucket\/mlflow\/mlflow\/13\/e7897a24158d4f15893de4b6845c5690\/artifacts\/model\/sparkml' does not point to the current DFS.\r\n2021\/09\/19 18:21:41 INFO mlflow.spark: File 's3:\/\/bucket\/mlflow\/mlflow\/13\/e7897a24158d4f15893de4b6845c5690\/artifacts\/model\/sparkml' not found on DFS. Will attempt to upload the file.\r\n2021\/09\/19 18:21:45 INFO mlflow.spark: Copied SparkML model to \/tmp\/mlflow\/6d9d9e7f-6f2e-41ca-8504-ea5511cee1e2\r\n\r\n+---+---------------+-----+------------------+--------------------+--------------------+--------------------+----------+\r\n| id|           text|label|             words|            features|       rawPrediction|         probability|prediction|\r\n+---+---------------+-----+------------------+--------------------+--------------------+--------------------+----------+\r\n|  4|    spark i j k|  1.0|  [spark, i, j, k]|(262144,[19036,68...|[-4.1623768837849...|[0.01533178105401...|       1.0|\r\n|  5|          l m n|  0.0|         [l, m, n]|(262144,[1303,526...|[8.74372896527203...|[0.99984056725892...|       0.0|\r\n|  6|mapreduce spark|  1.0|[mapreduce, spark]|(262144,[132966,1...|[-1.7585831706284...|[0.14696787648797...|       1.0|\r\n|  7|  apache hadoop|  0.0|  [apache, hadoop]|(262144,[68303,19...|[4.03791379488062...|[0.98267135451941...|       0.0|\r\n+---+---------------+-----+------------------+--------------------+--------------------+--------------------+----------+\r\n```\r\n\r\n## Release Notes\r\n\r\nChange spark artifact copy behaviour to copy file to specified DFS when in a non-local mode and using a remote artifact store.\r\n\r\n### Is this a user-facing change?\r\n\r\n- [X] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [X] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [X] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [X] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","180":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [X] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04 - **AWS EC2**\r\n- **MLflow installed from (source or binary)**: conda\r\n- **MLflow version (run ``mlflow --version``)**: mlflow, version 1.20.2\r\n- **Python version**: 3.6.9\r\n- **npm version, if running the dev UI**: \r\n- **Exact command to reproduce**: mlflow.start_run()\r\n\r\n### Describe the problem\r\nI have remote tracking server (the access policies for EC2 to server are setted correct, but I'm not sure at 100%).\r\nI have a main run (parent), and under that parent I also have a few child runs. The issue is related to first start_run() (parent run). When the script calls `with mlflow.start_run()`, script crashes.\r\n\r\nThe resposne from server calls: `RESOURCE_DOES_NOT_EXIST` when looking for run_id\r\n\r\n\r\n\r\n### Code to reproduce issue\r\n```\r\nremote_server_uri = \"http:\/\/x.x.x.x:xxxx\" # set to your server URI\r\n    mlflow.set_tracking_uri(remote_server_uri)\r\n    mlflow.set_experiment('\/cargo_movement')\r\n    # You can get the path at the root of the MLflow project with this:\r\n    root_path = os.path.abspath('.')\r\n\r\n    # Check which steps we need to execute\r\n    if isinstance(config[\"main\"][\"execute_steps\"], str):\r\n        # This was passed on the command line as a comma-separated list of steps\r\n        steps_to_execute = config[\"main\"][\"execute_steps\"].split(\",\")\r\n    else:\r\n\r\n        steps_to_execute = list(config[\"main\"][\"execute_steps\"])\r\n    \r\n    with mlflow.start_run() as parent_run:\r\n        # Download step\r\n        if \"1_download\" in steps_to_execute:\r\n\r\n            _ = mlflow.run(\r\n                os.path.join(root_path, \"1_download\"),\r\n                \"main\",\r\n                parameters={\r\n                    \"parent_run_id\": parent_run.info.run_id,\r\n                }\r\n            )\r\n        ...\r\n```\r\n\r\n### Other info \/ logs\r\n```\r\n$ mlflow run .\r\n2021\/09\/18 13:30:47 INFO mlflow.projects.utils: === Created directory \/tmp\/tmpy661fhzb for downloading remote URIs passed to arguments of type 'path' ===\r\n2021\/09\/18 13:30:47 INFO mlflow.projects.backend.local: === Running command 'source \/home\/ubuntu\/anaconda3\/bin\/..\/etc\/profile.d\/conda.sh && conda activate mlflow-167823303a9c0913bc4240ea63b3cb92329b0538 1>&2 && python main.py' in run with ID 'f7b8bafb58404dcb8e27ae1b901b2524' === \r\nENV VAR: f7b8bafb58404dcb8e27ae1b901b2524\r\nTraceback (most recent call last):\r\n  File \"\/home\/ubuntu\/fchardnet\/main.py\", line 109, in <module>\r\n    go(config)\r\n  File \"\/home\/ubuntu\/fchardnet\/main.py\", line 25, in go\r\n    with mlflow.start_run() as parent_run:\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/mlflow-167823303a9c0913bc4240ea63b3cb92329b0538\/lib\/python3.9\/site-packages\/mlflow\/tracking\/fluent.py\", line 204, in start_run\r\n    active_run_obj = client.get_run(existing_run_id)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/mlflow-167823303a9c0913bc4240ea63b3cb92329b0538\/lib\/python3.9\/site-packages\/mlflow\/tracking\/client.py\", line 150, in get_run\r\n    return self._tracking_client.get_run(run_id)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/mlflow-167823303a9c0913bc4240ea63b3cb92329b0538\/lib\/python3.9\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 65, in get_run\r\n    return self.store.get_run(run_id)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/mlflow-167823303a9c0913bc4240ea63b3cb92329b0538\/lib\/python3.9\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 132, in get_run\r\n    response_proto = self._call_endpoint(GetRun, req_body)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/mlflow-167823303a9c0913bc4240ea63b3cb92329b0538\/lib\/python3.9\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 56, in _call_endpoint\r\n    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/mlflow-167823303a9c0913bc4240ea63b3cb92329b0538\/lib\/python3.9\/site-packages\/mlflow\/utils\/rest_utils.py\", line 217, in call_endpoint\r\n    response = verify_rest_response(response, endpoint)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/mlflow-167823303a9c0913bc4240ea63b3cb92329b0538\/lib\/python3.9\/site-packages\/mlflow\/utils\/rest_utils.py\", line 169, in verify_rest_response\r\n    raise RestException(json.loads(response.text))\r\nmlflow.exceptions.RestException: RESOURCE_DOES_NOT_EXIST: Run with id=f7b8bafb58404dcb8e27ae1b901b2524 not found\r\n2021\/09\/18 13:30:48 ERROR mlflow.cli: === Run (ID 'f7b8bafb58404dcb8e27ae1b901b2524') failed ===\r\n```\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [X] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [X] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","181":"## MLflow Roadmap Item\r\n\r\nThis is an MLflow Roadmap item that has been prioritized by the MLflow maintainers. We're seeking help with the implementation of roadmap items tagged with the `help wanted` label.\r\n\r\nFor requirements clarifications and implementation questions, or to request a PR review, please tag @BenWilson2 in your communications related to this issue.\r\n\r\n## Proposal Summary\r\n\r\nInclude model signature and input example information with MLflow Models that are logged during autologging. This functionality is currently only present in a few autologging integrations: [mlflow.xgboost.autolog()](https:\/\/github.com\/mlflow\/mlflow\/blob\/94891da1c272038ac506f5d091c8c6b19e009b2d\/mlflow\/xgboost.py#L662-L664), [mlflow.lightgbm.autolog()](https:\/\/github.com\/mlflow\/mlflow\/blob\/94891da1c272038ac506f5d091c8c6b19e009b2d\/mlflow\/lightgbm.py#L553-L555), and [mlflow.sklearn.autolog()](https:\/\/github.com\/mlflow\/mlflow\/blob\/94891da1c272038ac506f5d091c8c6b19e009b2d\/mlflow\/sklearn\/__init__.py#L1227-L1229), but there are many other integrations listed here - https:\/\/mlflow.org\/docs\/latest\/tracking.html#automatic-logging - that do not have this functionality.\r\n\r\n## Motivation\r\n- What is the use case for this feature? Model signatures and input examples make it easier to incorporate ML models into inference workflows.\r\n- Why is this use case valuable to support for MLflow users in general? ^\r\n- Why is this use case valuable to support for your project(s) or organization? ^\r\n- Why is it currently difficult to achieve this use case? Users must currently compute signatures \/ input examples manually and invoke `mlflow.*.log_model()` to record this information with a persisted MLflow Model. This complicates the autologging experience.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations","182":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [X] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OSX\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: version 1.20.3.dev0\r\n- **Python version**: 3.8.12\r\n- **npm version, if running the dev UI**: N\/A\r\n- **Exact command to reproduce**: pytest\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\nBy refering to the [CONTRIBUTING.rst](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst), I try to make pytest passed but failed. Though there is a merged change #1223, but I think it should be included in `large-requirements.txt` or `extra-ml-requirements.txt`.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```shell\r\npip install -r dev-requirements.txt\r\npip install -r test-requirements.txt\r\npip install -e .[extras]\r\npip install -e tests\/resources\/mlflow-test-plugin\r\npytest\r\n```\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n```\r\n=========================================================================================================================================================================== test session starts ============================================================================================================================================================================\r\nplatform linux -- Python 3.8.12, pytest-3.2.1, py-1.10.0, pluggy-0.4.0 -- \/home\/xuan.hu\/.local\/share\/virtualenvs\/mlflow-RhJSDBvS\/bin\/python\r\ncachedir: .cache\r\nrootdir: \/home\/xuan.hu\/Code\/mlflow, inifile: pytest.ini\r\nplugins: localserver-0.5.0, cov-2.6.0\r\ncollected 3724 items \/ 1 errors\r\n\r\n================================================================================================================================================================================== ERRORS ==================================================================================================================================================================================\r\n_________________________________________________________________________________________________________________________________________________________ ERROR collecting tests\/mleap\/test_mleap_model_export.py __________________________________________________________________________________________________________________________________________________________\r\nImportError while importing test module '\/home\/xuan.hu\/Code\/mlflow\/tests\/mleap\/test_mleap_model_export.py'.\r\nHint: make sure your test modules\/packages have valid Python names.\r\nTraceback:\r\ntests\/mleap\/test_mleap_model_export.py:10: in <module>\r\n    import mleap.version\r\nE   ModuleNotFoundError: No module named 'mleap'\r\n============================================================================================================================================================================= warnings summary =============================================================================================================================================================================\r\ntests\/utils\/test_logging_utils.py::TestStream\r\n  cannot collect test class 'TestStream' because it has a __init__ constructor\r\n\r\n-- Docs: http:\/\/doc.pytest.org\/en\/latest\/warnings.html\r\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 errors during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\r\n========================================================================================================================================================================== 2035 tests deselected ===========================================================================================================================================================================\r\n========================================================================================================================================================== 2035 deselected, 1 warnings, 1 error in 129.49 seconds ==========================================================================================================================================================\r\n```\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [X] `area\/build`: Build and test infrastructure for MLflow\r\n- [X] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","183":"## MLflow Roadmap Item\r\n\r\nThis is an MLflow Roadmap item that has been prioritized by the MLflow maintainers. We're seeking help with the implementation of roadmap items tagged with the `help wanted` label.\r\n\r\nFor requirements clarifications and implementation questions, or to request a PR review, please tag @sunishsheth2009 in your communications related to this issue.\r\n\r\n## Proposal Summary\r\n\r\nIntroduce support for sorting the Runs table in the MLflow Experiment UI by multiple columns at once. Users should be able to select and deselect columns for sorting and sorting them in both ascending and descending order.\r\n\r\n## Motivation\r\n- What is the use case for this feature? Multiple metrics and parameters are often important to determining a model's configuration and performance characteristics. It can be difficult to identify optimal run(s) via the experiment UI when runs table sorting is only allowed on a single column.\r\n- Why is this use case valuable to support for MLflow users in general? Many MLflow users leverage the experiment UI \/ runs table to identify good candidate runs.\r\n- Why is this use case valuable to support for your project(s) or organization? Many Databricks users leverage the experiment UI \/ runs table to identify good candidate runs.\r\n- Why is it currently difficult to achieve this use case? Users must currently use the MLflow API to sort runs on multiple metrics, parameters, etc simultaneously; this is not offered in the UI.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [X] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","184":"## MLflow Roadmap Item\r\n\r\nThis is an MLflow Roadmap item that has been prioritized by the MLflow maintainers. \r\n\r\n## Proposal Summary\r\n\r\nThe Keras framework is now embedded in the TensorFlow namespace; i.e. it is recommended that users refer to `tf.keras` when building Keras models. Currently, the `mlflow.tensorflow` model flavor does not provide a friendly interface for saving `tf.keras` models in MLflow format, and the inference input \/ output format for pyfunc representations of `tf.keras` models is also difficult to use. Finally, users often experience confusion about which module to use with Keras models in MLflow: `mlflow.keras` or `mlflow.tensorflow`. \r\n\r\nWe propose that:\r\n\r\n1. Users should be able to save tf.keras models in SavedModel format via the `mlflow.tensorflow.log_model` and `mlflow.tensorflow.save_model` APIs.\r\n\r\n2. The pyfunc representation of a tf.keras model should use the same input \/ output interface that is currently in place for models saved from the `mlflow.keras` module.\r\n\r\n3. The `mlflow.keras` module should be deprecated in favor of the `mlflow.tensorflow` module.\r\n\r\n## Motivation\r\n- What is the use case for this feature? Unifying the tf.Keras model experience in MLflow and removing model persistence and inference format pitfalls will improve the usability of this part of the platform.\r\n- Why is this use case valuable to support for MLflow users in general? Many MLflow users leverage tf.keras for model development.\r\n- Why is this use case valuable to support for your project(s) or organization? Many Databricks users leverage tf.keras for model development.\r\n- Why is it currently difficult to achieve this use case? There is no clear guidance for which module to use when saving \/ deploying tf.keras models in MLflow. `mlflow.keras` and `mlflow.tensorflow` behave differently.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [X] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","185":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [X] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Linux, Ubuntu \r\n- **MLflow installed from (source or binary)**: pip [python] and install.packages(\"mlflow\") [R]\r\n- **MLflow version (run ``mlflow --version``)**: mlflow, version 1.20.2\r\n- **Python version**:  Python 3.6.13 , R 3.6\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nUsing R API for mlflow with the above mentioned information. Not able to set tracking URI to sqlite. Getting the following error\r\n ```\r\nError in new_mlflow_client.default(tracking_uri) : \r\n  Unsupported scheme: 'sqlite'\r\n```\r\n\r\n### Code to reproduce issue\r\n```\r\nlibrary(mlflow)\r\nmlflow_client(tracking_uri=\"sqlite:\/\/\/mlflow.db\")\r\n```\r\n\r\n### Other info \/ logs\r\nWe have installed mlflow R API via `install.packages('mlflow')`. Not just sqlite but we also have a custom\r\ntracking server plugin which was working with python but was never able to  get it working  with R.\r\nFailing with the same error mentioned above `Unsupported scheme:`. \r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [X] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","186":"Hi All, \r\nI am unable to load pytorch pretrained model of object detection.\r\ncould you please help me with code , I try ml file is only creating default library.\r\n\r\nThanks in Advance","187":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [X] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**:\r\n- **Python version**:\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\nThe expected behavior is that `mlflow.sklearn.eval_and_log_metrics` returns binary evaluation metrics for binary data when using default `pos_label` of 1.  This would be consistent with sklearn.metrics and align with the normal expectation when using binary data.  The actual behavior is that multi-class evaluation metrics are returned.  This is due to using `method='weighted'` instead of `method='binary'` in mlflow.utils._get_classifier_metrics, even when performing binary classification.  \r\n\r\nThis leads to misleading output, especially for imbalanced data.  If the positive class is a small fraction of the total, a naive predictor that classifies to the negative class will have precision, recall and F1 score near 1.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\nimport mlflow\r\nimport numpy as np\r\nimport pandas as pd\r\nimport sklearn\r\n\r\nmodel = sklearn.linear_model.LogisticRegression()\r\nX = pd.DataFrame({'x': [0] * 100})\r\ny = [0] * 99 + [1]\r\n\r\n# Model can't predict the single 1 so binary classifiers are all 0.\r\n# This is reasonable as this classifier can't detect the positive class at all.\r\nmodel.fit(X, y)\r\nprint(sklearn.metrics.precision_score(y, model.predict(X)))\r\n# 0.0\r\nprint(sklearn.metrics.recall_score(y, model.predict(X)))\r\n# 0.0\r\nprint(sklearn.metrics.f1_score(y, model.predict(X)))\r\n# 0.0\r\n\r\n# But mlflow  precision, recall, and F1 score are all near 1.\r\nmlflow.sklearn.eval_and_log_metrics(model, X, y, prefix='train_')\r\n# {'train_precision_score': 0.9801000000000001,\r\n# 'train_recall_score': 0.99,\r\n# 'train_f1_score': 0.9850251256281406,\r\n# 'train_accuracy_score': 0.99,\r\n# 'train_log_loss': 0.04641982852065066,\r\n# 'train_roc_auc_score': 1.0}\r\n```\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ X]`area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","188":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [* ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nCurrently pytorch model serving works for single input and single output model. To make it generic and flexible, it would be great if it supports multi input and multi output serving.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nThis has many use cases. In fact most of the real world models output multiple features.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ *] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ *] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [* ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nI am using a single input - multiple output model in this example using Pytorch lightning:\r\n\r\n`model = CustomModel(args)'\r\n'model_dict = {'input1': np.zeros((1, 256, 256, 3))}'\r\n'input_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, 256,256,3)),])'\r\n'output_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, 2), name='out1'), TensorSpec(np.dtype(np.float32), (-1, 3), name='out2')])'\r\n'signature = ModelSignature(inputs=input_schema, outputs=output_schema)'\r\n'mlflow.pytorch.log_model(model,\"Models\", input_example=model_dict['input1'], signature=signature)`\r\n\r\nWhen this model is served, it throws this error:\r\n\r\n**\"xxxxxxx in predict\\n    \\\"but got output of type '{}'\\\".format(type(preds))\\nTypeError: Expected PyTorch model to output a single output tensor, but got output of type '<class 'dict'>'\\n\"**\r\n\r\n","189":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: yes, custom code\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.20.2\r\n- **Python version**: 3.6.9\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n\r\nI am running unit tests for mlflow for different cases, and I need to reset the sqlite database and mlruns for each test case. Therefore I use setUp and tearDown to initialize the database and remote it later. I had no problem with this while using version 1.19. After I switched to version 1.20.2, I started having this problem.\r\n\r\nThe problem is, after tearDown removes the sqlite db after first case which have been, and setUp re-creates the database, following error occurs:\r\n\r\n```\r\nMyTests::test_case_3 Failed: [undefined]mlflow.exceptions.MlflowException: (sqlite3.OperationalError) no such table: experiments\r\n[SQL: SELECT experiments.experiment_id AS experiments_experiment_id, experiments.name AS experiments_name, experiments.artifact_location AS experiments_artifact_location, experiments.lifecycle_stage AS experiments_lifecycle_stage \r\nFROM experiments \r\nWHERE experiments.name = ? AND experiments.lifecycle_stage IN (?, ?)]\r\n[parameters: ('foo', 'active', 'deleted')]\r\n```\r\n\r\nIt seems like new test cases are not able to create missing tables.\r\nThanks in advance.\r\n\r\n### Code to reproduce issue\r\n\r\nCode below works well on 1.19, but fails on 1.20.2.\r\n\r\nRun with pytest as `pytest tests\/test_dummy.py`\r\n\r\n```\r\nimport unittest\r\nimport os\r\nimport sqlite3\r\nimport shutil\r\nimport stat\r\n\r\nimport pytest\r\nimport pandas as pd\r\nimport lightgbm as lgb\r\nimport mlflow\r\nfrom mlflow.models.signature import infer_signature\r\n\r\n\r\nDB_NAME = \"mock.db\"\r\nos.environ[\"MLFLOW_TRACKING_URI\"] = \"sqlite:\/\/\/\" + DB_NAME\r\n\r\n\r\nclass MyTests(unittest.TestCase):\r\n\r\n    @classmethod\r\n    def setUp(cls):\r\n        con = sqlite3.connect(DB_NAME)\r\n        con.close()\r\n\r\n    @classmethod\r\n    def tearDown(cls):\r\n        os.remove(DB_NAME)\r\n        if os.path.isdir(\"mlruns\"):\r\n            def _remove_readonly(func, path, excinfo):\r\n                os.chmod(path, stat.S_IWRITE)\r\n                func(path)\r\n\r\n            shutil.rmtree(\"mlruns\", onerror=_remove_readonly)\r\n\r\n    @property\r\n    def train_data(self):\r\n        return pd.DataFrame([\r\n            (1, 2, 3),\r\n            (2, 3, 5),\r\n            (3, 4, 7),\r\n            (4, 5, 9),\r\n            (5, 6, 11),\r\n        ], columns=[\"a\", \"b\", \"y\"])\r\n\r\n    @property\r\n    def test_data(self):\r\n        return pd.DataFrame([\r\n            (6, 7, 13)\r\n        ], columns=[\"a\", \"b\", \"y\"])\r\n\r\n    def test_case_1(self):\r\n        mlflow.set_experiment(\"foo\")\r\n        model_name = \"lgbm_model\"\r\n        parent_run = mlflow.start_run(run_name=\"parent_\" + model_name)\r\n        mlflow.start_run(nested=True, run_name=model_name)\r\n\r\n        train_data = self.train_data\r\n        x_train = train_data[[\"a\", \"b\"]]\r\n        y_train = train_data[\"y\"]\r\n        signature = infer_signature(x_train)\r\n\r\n        model = lgb.LGBMRegressor(n_estimators=10, num_leaves=5)\r\n        model.fit(x_train, y_train)\r\n        mlflow.sklearn.log_model(\r\n            model, \"model\", signature=signature,\r\n            registered_model_name=model_name)\r\n\r\n        mlflow.end_run()\r\n        mlflow.end_run()\r\n\r\n        # prediction\r\n        mlflow.start_run(run_id=parent_run.info.run_id)\r\n        mlflow.start_run(nested=True, run_name=\"prediction_\" + model_name)\r\n\r\n        test_data = self.test_data\r\n        x_test = test_data[[\"a\", \"b\"]]\r\n\r\n        loaded_model = mlflow.sklearn.load_model(\r\n            f\"models:\/{model_name}\/1\")\r\n        predictions = loaded_model.predict(x_test)\r\n        self.assertEqual(len(predictions), 1)\r\n\r\n        mlflow.end_run()\r\n        mlflow.end_run()\r\n\r\n    def test_case_2(self):\r\n        mlflow.set_experiment(\"foo\")\r\n        model_name = \"lgbm_model\"\r\n        parent_run = mlflow.start_run(run_name=\"parent_\" + model_name)\r\n        mlflow.start_run(nested=True, run_name=model_name)\r\n\r\n        train_data = self.train_data\r\n        x_train = train_data[[\"a\", \"b\"]]\r\n        y_train = train_data[\"y\"]\r\n        signature = infer_signature(x_train)\r\n\r\n        model = lgb.LGBMRegressor(n_estimators=10, num_leaves=5)\r\n        model.fit(x_train, y_train)\r\n        mlflow.sklearn.log_model(\r\n            model, \"model\", signature=signature,\r\n            registered_model_name=model_name)\r\n\r\n        mlflow.end_run()\r\n        mlflow.end_run()\r\n\r\n        # prediction\r\n        mlflow.start_run(run_id=parent_run.info.run_id)\r\n        mlflow.start_run(nested=True, run_name=\"prediction_\" + model_name)\r\n\r\n        test_data = self.test_data\r\n        x_test = test_data[[\"a\", \"b\"]]\r\n\r\n        loaded_model = mlflow.sklearn.load_model(\r\n            f\"models:\/{model_name}\/1\")\r\n        predictions = loaded_model.predict(x_test)\r\n        self.assertEqual(len(predictions), 1)\r\n\r\n        mlflow.end_run()\r\n        mlflow.end_run()\r\n\r\n    def test_case_3(self):\r\n        mlflow.set_experiment(\"foo\")\r\n        model_name = \"lgbm_model\"\r\n        parent_run = mlflow.start_run(run_name=\"parent_\" + model_name)\r\n        mlflow.start_run(nested=True, run_name=model_name)\r\n\r\n        train_data = self.train_data\r\n        x_train = train_data[[\"a\", \"b\"]]\r\n        y_train = train_data[\"y\"]\r\n        signature = infer_signature(x_train)\r\n\r\n        model = lgb.LGBMRegressor(n_estimators=10, num_leaves=5)\r\n        model.fit(x_train, y_train)\r\n        mlflow.sklearn.log_model(\r\n            model, \"model\", signature=signature,\r\n            registered_model_name=model_name)\r\n\r\n        mlflow.end_run()\r\n        mlflow.end_run()\r\n\r\n        # prediction\r\n        mlflow.start_run(run_id=parent_run.info.run_id)\r\n        mlflow.start_run(nested=True, run_name=\"prediction_\" + model_name)\r\n\r\n        test_data = self.test_data\r\n        x_test = test_data[[\"a\", \"b\"]]\r\n\r\n        loaded_model = mlflow.sklearn.load_model(\r\n            f\"models:\/{model_name}\/1\")\r\n        predictions = loaded_model.predict(x_test)\r\n        self.assertEqual(len(predictions), 1)\r\n\r\n        mlflow.end_run()\r\n        mlflow.end_run()\r\n\r\n```\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","190":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nThe current view for comparing model versions shows parameters and metrics, but doesn't have a section to compare tags. Could we add a section which shows tags from the training run?\r\n\r\n## Motivation\r\n\r\nWe're currently storing some information in tags that would be useful to have as context when comparing across model versions. Given that the UI already allows you to compare metrics and parameters, it seems like we should also support comparing tags. We like to keep parameters more focused on data like hyperparameters, but there's additional run metadata that we log as tags. I imagine other teams similarly find it useful to add extra context to model runs through tags, and we should allow visibility of this context from the compare view.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nWe'd have to extend `CompareModelVersionsView.js` to include a component which compares tags across model versions. It looks like [we're already grabbing the run tags](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/server\/js\/src\/model-registry\/components\/CompareModelVersionsView.js#L637) (in order to read the run name), we just need to add a table which displays the information.\r\n","191":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\nI'm comfortable making the backend changes but may need assistance for UI updates.\r\n\r\n## Proposal Summary\r\n\r\nThe model registry currently offers a \"compare\" view across registered versions which is very helpful. However, it is most helpful if we only want to have a detailed comparison for the few latest registered model versions. I would like the ability to **view the evolution of a metric (e.g. model accuracy) over the lineage of a registered model**. Ideally, we can select a single metric of interest and plot this metric value on the y axis with the model version on the x-axis.\r\n\r\n## Motivation\r\nFor a given registered model, I want to have visibility on how the model behavior is changing over time as we ship and deploy new versions. Do we see a dip in accuracy for the latest stage model that should be reviewed before promoting the model stage to production? Is there a long term trend for a given metric of interest? It's hard to have this sort of visibility from the UI currently.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n- The compare view becomes awkward to use when we've selected 10+ model versions. It may be useful to add a new component to the `\/models\/registered_model_name` page which is focused on plotting metrics over all versions.\r\n- The user should be able to select a metric and plot using either (1) model version or (2) training run timestamp for the x axis.\r\n- Model versions which don't have a value for the selected metric should be transparently excluded from the plot.\r\n- [optional] It would be nice to color (and toggle visibility for) model versions based on their stage.","192":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nLinking directly to an artifact view in the mlflow client ui. \r\n\r\n## Motivation\r\n\r\nWhen creating custom html views, it would be nice to share links directly to these artifacts or even better, having the ability to see the artifact as a page on its own. An example would be a GAN that generates art, a html view that showed some examples of the art.\r\n\r\nAt the moment you have to scroll and potentially search for the artifact you want. ","193":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nSometimes, it would be handy to deactivate the autologging functionality temporarily. Like this\r\n```python\r\nimport mlflow\r\n\r\nmlflow.sklearn.autolog() \r\n# do stuff\r\n\r\nwith mlflow.sklearn.autolog(disable = True):\r\n    # fit a null model or \r\n    # do a sklearn transformation not related to the main model\r\n    # ect.\r\n```\r\nUnfortunately, this gives an error. Of course, the workaround is to manually manage the context, but it's brittle and requires more boilerplate code.\r\n```python\r\nimport mlflow\r\n\r\nmlflow.sklearn.autolog() \r\n# do stuff\r\n\r\nmlflow.sklearn.autolog(disable = True)\r\n# fit a null model or \r\n# do a sklearn transformation not related to the main model\r\n# ect.\r\n\r\nmlflow.sklearn.autolog() \r\n```\r\n\r\n\r\n## Motivation\r\n- What is the use case for this feature? Boiler plate reduction and cognitive burden reduction.\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? More code, remember parameters set before etc.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","194":"### Details \r\n\r\nI have the following code: \r\n\r\n\r\nI cannot log a pipeline object using mlflow and i am unsure why. Hyperclassifier search is a package which is just a wrapper around gridsearchcv\r\n\r\n```\r\nfrom HyperclassifierSearch import HyperclassifierSearch\r\nimport mlflow\r\nimport mlflow.sklearn\r\nimport mlflow.tracking\r\nfrom mlflow.tracking import MlflowClient\r\n\r\nmodels = {  'xgb': Pipeline(steps=[('preprocessor', preprocessor),('clf', OneVsRestClassifier(XGBClassifier(objective='binary:logistic',n_jobs=-1,random_state = 42)))])\r\n                     \r\n                         }\r\n\r\n\r\nmlflow.sklearn.autolog()\r\nwith mlflow.start_run():\r\n            \r\n            search = HyperclassifierSearch(models, params)\r\n            best_grid = search.train_model(X_train, y_train, cv=3, scoring='accuracy')\r\n            results = search.evaluate_model()\r\n            fitted_model = best_grid.best_estimator_\r\n            mlflow.sklearn.log_model(fitted_model, \"tester\")\r\n```\r\nWhen i look at 'tester' it tells me how to read the model : `loaded_model = mlflow.pyfunc.load_model(logged_model)`\r\n\r\nhowever i do not get the gridserch object back which is what i want. How can i save gridsearch object using mlflow? I am unsure how i can do this","195":"I am using mlflow version 1.20.2 and docker version 20.10.7. I am able to serve my mlflow model\r\n\r\n`mlflow models serve -m models:\/my_model\/Staging\r\n`\r\n\r\nhowever when I run\r\n\r\n`mlflow models build-docker -m models:\/my_model\/Staging -n \"model_name\" --install-mlflow\r\n`\r\n\r\nI get the following error\r\n\r\n```\r\n#17 51.50 Installing pip dependencies: ...working... Traceback (most recent call last):\r\n#17 197.4   File \"<string>\", line 1, in <module>\r\n#17 197.4   File \"\/miniconda\/lib\/python3.9\/site-packages\/mlflow\/models\/container\/__init__.py\", line 101, in _install_pyfunc_deps\r\n#17 197.4     raise Exception(\"Failed to create model environment.\")\r\n#17 197.4 Exception: Failed to create model environment.\r\n#17 197.5 creating and activating custom environment\r\n#17 ERROR: executor failed running [\/bin\/sh -c python -c                 'from mlflow.models.container import _install_pyfunc_deps;                _install_pyfunc_deps(\"\/opt\/ml\/model\", install_mlflow=True)']: exit code: 1\r\n------\r\n > [12\/12] RUN python -c                 'from mlflow.models.container import _install_pyfunc_deps;                _install_pyfunc_deps(\"\/opt\/ml\/model\", install_mlflow=True)':\r\n------\r\nexecutor failed running [\/bin\/sh -c python -c                 'from mlflow.models.container import _install_pyfunc_deps;                _install_pyfunc_deps(\"\/opt\/ml\/model\", install_mlflow=True)']: exit code: 1\r\nTraceback (most recent call last):\r\n  File \"\/Users\/flavio.lisdero\/Desktop\/MPRNet_lightning\/.venv\/bin\/mlflow\", line 8, in <module>\r\n    sys.exit(cli())\r\n  File \"\/Users\/flavio.lisdero\/Desktop\/MPRNet_lightning\/.venv\/lib\/python3.8\/site-packages\/click\/core.py\", line 1137, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\/Users\/flavio.lisdero\/Desktop\/MPRNet_lightning\/.venv\/lib\/python3.8\/site-packages\/click\/core.py\", line 1062, in main\r\n    rv = self.invoke(ctx)\r\n  File \"\/Users\/flavio.lisdero\/Desktop\/MPRNet_lightning\/.venv\/lib\/python3.8\/site-packages\/click\/core.py\", line 1668, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/Users\/flavio.lisdero\/Desktop\/MPRNet_lightning\/.venv\/lib\/python3.8\/site-packages\/click\/core.py\", line 1668, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/Users\/flavio.lisdero\/Desktop\/MPRNet_lightning\/.venv\/lib\/python3.8\/site-packages\/click\/core.py\", line 1404, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\/Users\/flavio.lisdero\/Desktop\/MPRNet_lightning\/.venv\/lib\/python3.8\/site-packages\/click\/core.py\", line 763, in invoke\r\n    return __callback(*args, **kwargs)\r\n  File \"\/Users\/flavio.lisdero\/Desktop\/MPRNet_lightning\/.venv\/lib\/python3.8\/site-packages\/mlflow\/models\/cli.py\", line 159, in build_docker\r\n    _get_flavor_backend(model_uri, docker_build=True).build_image(\r\n  File \"\/Users\/flavio.lisdero\/Desktop\/MPRNet_lightning\/.venv\/lib\/python3.8\/site-packages\/mlflow\/pyfunc\/backend.py\", line 137, in build_image\r\n    _build_image(\r\n  File \"\/Users\/flavio.lisdero\/Desktop\/MPRNet_lightning\/.venv\/lib\/python3.8\/site-packages\/mlflow\/models\/docker_utils.py\", line 132, in _build_image\r\n    raise RuntimeError(\"Docker build failed.\")\r\n```\r\n\r\nThe main problem is that is almost impossible to debug this error","196":"- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n I propose to add the functionality for specifying the environment variables in the `sagemaker.deploy_transform_job` method.\r\n\r\n## Motivation\r\nThe AWS SageMaker's `create_transform_job` API supports specifying the environment variables to be passed to the docker container executing the job. Using the environment variables is convenient to control the behavior of the job.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [x] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations","197":"## What changes are proposed in this pull request?\r\nEnabling _local_destination_path_ argument in load_model() calls to enable users to be able to download the artifacts from the artifact store in their chosen location in the local filesystem. Internally, this _local_destination_path_ argument passes the value to _ output_path_ argument in _download_artifact_from_uri().\r\n\r\n## How is this patch tested?\r\n\r\n- Lint test\r\n- Partial Unit test (Have been facing issues while running unit tests. Any kind of help will be highly appreciated.)\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [X] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nUpdates in load_model() references for all model flavours.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [X] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [X] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [X] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [X] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","198":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this documentation issue template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages documentation fix contributions. Would you or another member of your organization be willing to contribute a fix for this documentation issue to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a documentation fix independently.\r\n- [x] Yes. I would be willing to contribute a document fix with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a documentation fix at this time.\r\n\r\n### URL(s) with the issue:\r\n\r\nhttps:\/\/www.mlflow.org\/docs\/latest\/tracking.html\r\n\r\n### Description of proposal (what needs changing):\r\n\r\nScenario 4 has a syntax error that can cause many issues with Artifact logging. \r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/27409084\/133038582-2b66ca28-8d62-4387-934f-b3520971d0c7.png)\r\n\r\nthe `--default-artifact-root` value should start with `s3:\/\/...` instead of `S3:\/...` . The documentation for scenario 3 and scenario 4 would heavily benefit from example commands that the user can modify rather than having the command written in the image.\r\n\r\nAn example that can be added to the doc would be:\r\n\r\n```bash\r\n mlflow server \\\r\n--backend-store-uri mysql+pymysql:\/\/${MYSQL_USER}:${MYSQL_PASSWORD}@mysql_db:3306\/${MYSQL_DATABASE} \\\r\n--default-artifact-root s3:\/\/<bucket-name> \\\r\n--host 0.0.0.0\r\n``` \r\n","199":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\nDear MLFlow Team,\r\n\r\nUsers are being confused between Lightning MLFlowLogger and th\u00e9 one provided there: https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/pytorch\/_pytorch_autolog.py.\r\n\r\nI wondered if the MLFlow team would be willing to upate and maintain the MLFlowLogger within Lightning directly, to make sure to always provide the best experience for the end user ?\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","200":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Big Sur\r\n- **MLflow installed from (source or binary)**: Source\r\n- **MLflow version (run ``mlflow --version``)**: 1.20.2.dev0\r\n- **Python version**: 3.9.4\r\n- **npm version, if running the dev UI**: Not applicable\r\n- **Exact command to reproduce**: \r\n\r\n```python\r\nmodel_loaded = mlflow.tensorflow.load_model(output_path)   \r\n\r\n# Code block here to produce an example_tensor tf.train.Example which is fed to the model.\r\n\r\nmodel_loaded(example_tensor)\r\n``` \r\n\r\n### Describe the problem\r\nWhen attempting to run the loaded model for inference it raises the following stack trace pasted below. The model is unable to find variables in the model, and the same issue has been tracked in a couple of Tensorflow issues, see [#33060](https:\/\/github.com\/tensorflow\/tensorflow\/issues\/33060) and [#37615](https:\/\/github.com\/tensorflow\/tensorflow\/issues\/37615). \r\n\r\nIn short, the problem seems to be that when a model is loaded inside of a function's scope, the variables are garbage collected when exiting that scope. It is possible to force the interpreter to track the variables by modifying the `_load_tensorflow_saved_model` function to add them as an attribute to the model signature, like this:\r\n\r\n```python\r\ndef _load_tensorflow_saved_model(\r\n    tf_saved_model_dir, tf_meta_graph_tags, tf_signature_def_key, tf_sess=None\r\n):\r\n    if Version(tensorflow.__version__) < Version(\"2.0.0\"):\r\n        loaded = tensorflow.saved_model.loader.load(\r\n            sess=tf_sess, tags=tf_meta_graph_tags, export_dir=tf_saved_model_dir\r\n        )\r\n        loaded_sig = loaded.signature_def\r\n    else:\r\n        print(\"Loading Tensorflow2 version...\")\r\n        loaded = tensorflow.saved_model.load(  # pylint: disable=no-value-for-parameter\r\n            tags=tf_meta_graph_tags, export_dir=tf_saved_model_dir\r\n        )\r\n        loaded_sig = loaded.signatures\r\n    if tf_signature_def_key not in loaded_sig:\r\n        raise MlflowException(\r\n            \"Could not find signature def key %s. Available keys are: %s\"\r\n            % (tf_signature_def_key, list(loaded_sig.keys()))\r\n        )\r\n\r\n    model_sig = loaded_sig[tf_signature_def_key]\r\n    model_sig._backref_to_saved_model = loaded\r\n    return model_sig\r\n```\r\n\r\n\r\n### Code to reproduce issue\r\n```python\r\n\r\noutput_path = \"output\/path\/for\/model\"\r\n\r\n# Schema for MNIST classification with tf.train.Example serialized input\r\ninput_schema = Schema(\r\n    [\r\n        TensorSpec(np.dtype(\"bytes\"), (-1, 1)),\r\n    ]\r\n)\r\noutput_schema = Schema(\r\n    [\r\n        TensorSpec(np.dtype(np.float32), (-1, 10))\r\n    ]\r\n)\r\n\r\nsignature = ModelSignature(inputs=input_schema, outputs=output_schema)\r\n\r\nmlflow.tensorflow.save_model(\r\n    tf_saved_model_dir=\"path\/to\/savedModel\",\r\n    tf_meta_graph_tags=[\"serve\"],\r\n    tf_signature_def_key=\"serve_example\",\r\n    path=output_path,\r\n    signature=signature\r\n)\r\n\r\n\r\nmodel_loaded = mlflow.tensorflow.load_model(output_path)   \r\n\r\n# Code block here to produce an example_tensor tf.train.Example which is fed to the model.\r\n\r\nmodel_loaded(example_tensor)\r\n``` \r\n\r\n### Other info \/ logs\r\nStack trace\r\n\r\n```\r\n2021-09-07 10:37:51.076618: W tensorflow\/core\/framework\/op_kernel.cc:1767] OP_REQUIRES failed at resource_variable_ops.cc:657 : Not found: Resource localhost\/_AnonymousVar24\/N10tensorflow3VarE does not exist.\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n~\/.virtualenvs\/tf-testing\/lib\/python3.9\/site-packages\/tensorflow\/python\/eager\/function.py in _call_impl(self, args, kwargs, cancellation_manager)\r\n   1719         try:\r\n-> 1720           return self._call_with_structured_signature(args, kwargs,\r\n   1721                                                       cancellation_manager)\r\n\r\n~\/.virtualenvs\/tf-testing\/lib\/python3.9\/site-packages\/tensorflow\/python\/eager\/function.py in _call_with_structured_signature(self, args, kwargs, cancellation_manager)\r\n   1797         self._function_spec.canonicalize_function_inputs(*args, **kwargs)\r\n-> 1798     self._structured_signature_check_missing_args(args, kwargs)\r\n   1799     self._structured_signature_check_unexpected_args(args, kwargs)\r\n\r\n~\/.virtualenvs\/tf-testing\/lib\/python3.9\/site-packages\/tensorflow\/python\/eager\/function.py in _structured_signature_check_missing_args(self, args, kwargs)\r\n   1816     if missing_arguments:\r\n-> 1817       raise TypeError(\"{} missing required arguments: {}\".format(\r\n   1818           self._structured_signature_summary(),\r\n\r\nTypeError: signature_wrapper(*, examples) missing required arguments: examples\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nFailedPreconditionError                   Traceback (most recent call last)\r\n\/var\/folders\/81\/j6spqkp903s_7nvwgc24v69m0000gn\/T\/ipykernel_7022\/4032791860.py in <module>\r\n----> 1 model_loaded(example_tensor)[\"output_0\"]\r\n\r\n~\/.virtualenvs\/tf-testing\/lib\/python3.9\/site-packages\/tensorflow\/python\/eager\/function.py in __call__(self, *args, **kwargs)\r\n   1709       TypeError: If the arguments do not match the function's signature.\r\n   1710     \"\"\"\r\n-> 1711     return self._call_impl(args, kwargs)\r\n   1712 \r\n   1713   def _call_impl(self, args, kwargs, cancellation_manager=None):\r\n\r\n~\/.virtualenvs\/tf-testing\/lib\/python3.9\/site-packages\/tensorflow\/python\/eager\/function.py in _call_impl(self, args, kwargs, cancellation_manager)\r\n   1722         except TypeError as structured_err:\r\n   1723           try:\r\n-> 1724             return self._call_with_flat_signature(args, kwargs,\r\n   1725                                                   cancellation_manager)\r\n   1726           except TypeError:\r\n\r\n~\/.virtualenvs\/tf-testing\/lib\/python3.9\/site-packages\/tensorflow\/python\/eager\/function.py in _call_with_flat_signature(self, args, kwargs, cancellation_manager)\r\n   1776                         \"got {} ({})\".format(self._flat_signature_summary(), i,\r\n   1777                                              type(arg).__name__, str(arg)))\r\n-> 1778     return self._call_flat(args, self.captured_inputs, cancellation_manager)\r\n   1779 \r\n   1780   def _call_with_structured_signature(self, args, kwargs, cancellation_manager):\r\n\r\n~\/.virtualenvs\/tf-testing\/lib\/python3.9\/site-packages\/tensorflow\/python\/saved_model\/load.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n    115     else:  # cross-replica context\r\n    116       captured_inputs = list(map(get_unused_handle, captured_inputs))\r\n--> 117     return super(_WrapperFunction, self)._call_flat(args, captured_inputs,\r\n    118                                                     cancellation_manager)\r\n    119 \r\n\r\n~\/.virtualenvs\/tf-testing\/lib\/python3.9\/site-packages\/tensorflow\/python\/eager\/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n   1958         and executing_eagerly):\r\n   1959       # No tape is watching; skip to running the function.\r\n-> 1960       return self._build_call_outputs(self._inference_function.call(\r\n   1961           ctx, args, cancellation_manager=cancellation_manager))\r\n   1962     forward_backward = self._select_forward_and_backward_functions(\r\n\r\n~\/.virtualenvs\/tf-testing\/lib\/python3.9\/site-packages\/tensorflow\/python\/eager\/function.py in call(self, ctx, args, cancellation_manager)\r\n    589       with _InterpolateFunctionError(self):\r\n    590         if cancellation_manager is None:\r\n--> 591           outputs = execute.execute(\r\n    592               str(self.signature.name),\r\n    593               num_outputs=self._num_outputs,\r\n\r\n~\/.virtualenvs\/tf-testing\/lib\/python3.9\/site-packages\/tensorflow\/python\/eager\/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     57   try:\r\n     58     ctx.ensure_initialized()\r\n---> 59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n     60                                         inputs, attrs, num_outputs)\r\n     61   except core._NotOkStatusException as e:\r\n\r\nFailedPreconditionError:  Could not find variable _AnonymousVar28. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status=Not found: Resource localhost\/_AnonymousVar28\/N10tensorflow3VarE does not exist.\r\n\t [[{{node StatefulPartitionedCall\/mnist_model\/dense_2\/MatMul\/ReadVariableOp}}]] [Op:__inference_signature_wrapper_1775]\r\n\r\nFunction call stack:\r\nsignature_wrapper\r\n```\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","201":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Custom code\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.04 LTS\r\n- **MLflow installed from (source or binary)**: used pip install mlflow\r\n- **MLflow version (run ``mlflow --version``)**: 1.19.0\r\n- **Python version**:  3.8.5\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n\r\n\r\n\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\nWhile using ray tune in the script and ran the script through an MLproject file instead of spawning multiple run's mlflow records a single run and the run id is picked by MLproject file instead of raytune sepcified one.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","202":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ -] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**:\r\n- **Python version**:\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ -] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [- ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n\r\nI am using a custom pytorch lightning trainer with  mlflow logger\r\n_**MLFlowLogger(experiment_name=\"Experiment\", tracking_uri=tracking_uri)**_\r\n\r\n**_I use both mlflow.pytorch.autolog()_**\r\n\r\nand the logger - which saves the parameters in default run and metrics in the run in \"Experiment\". However it does not log the model which i want to use for serving, it gives the following error:\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/57705684\/131857341-2cc063c2-e9bb-4f16-930d-ae8c47205915.png)\r\n\r\nIs it that pltrainer models are not supported? My model has  single inputs and multiple outputs.\r\n","203":"## Willingness to contribute\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal\r\nHave the ability to track the source code that was used while running the experiment and then, in the UI, select 2 experiments and see the diff:\r\n\r\nExample:\r\n![experiment_diff_code](https:\/\/user-images.githubusercontent.com\/111569\/131687003-509397e6-3a36-4e8a-a420-fe4d62102d2e.png)\r\n","204":"## Proposal Summary\r\n\r\nAdd a run ID columns to runs table in experiment page UI\r\n\r\n## Motivation\r\n- In order to uniquely identify runs.\r\n- CSV export has a run ID column, which is impossible to correlate to the UI runs tables since the latter lacks a run ID.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ x] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n\r\n","205":"## Proposal Summary\r\n\r\n[FR] Display actual timestamp (e.g. 2021-08-30 23:12:34) instead of \"1 days ago\" for the \"Start Time\" column in runs table of experiment page UI\r\n\r\n## Motivation\r\n- It is very difficult to distinguish multiple runs of one day when the \"Start Time\" is always \"1 days ago\".\r\n- There is no unique identifier (primary key) for runs in this page since the run ID is not displayed in the table.\r\n- In the absence of a run ID, \"Start Time\" is the best proxy for a unique identifier.\r\n- Therefore the actual timestamp should be displayed instead of vague \"1 days ago\".\r\n- Actual timestamp is also needed for model governance and regulatory environments.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n\r\n<img width=\"682\" alt=\"runs_ui\" src=\"https:\/\/user-images.githubusercontent.com\/1721873\/131450154-d581b6e9-2bee-461d-aeaa-ddc0b6eee30a.png\">\r\n\r\n","206":"## Willingness to contribute\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal\r\nAs a ML Engineer, I need the ML tracking solution to be integrated into GH and GitHub Enterprise so that I:\r\n1. Can see a link to the experiment results upon every git commit in a pull request.\r\n1. Can see a GitHub comment text with the most relevant comparison results against the baseline at the master\/main or GH protected branch and a link to a more detail comparison in the tool specialized UI.\r\n1. Can see a new Experiments tab within the GH web UI, similar to what [DAGsHub](https:\/\/dagshub.com\/docs\/reference\/discovering_experiments\/) provides\r\n![image](https:\/\/user-images.githubusercontent.com\/111569\/131334235-7d9f1aa1-d796-4fba-b579-dc9aa68b8af2.png)\r\n\r\nIntegrations\r\n- [x] `integrations\/github`: GitHub.com and GitHub Enterprise integrations\r\n","207":"I'm facing some model publish problems:\r\n\r\n1. how to set downgrade strategy when online model failed?\r\n    when we create a AI system, we always update our model, but some problems always be happen.\r\n    so, I want know, if the newest model error or failed, how can I use mlflow to return preview good model result?\r\n\r\n2. how to set fusion result strategy when use multiple models?\r\n    this problem is similar with 1, out model is not always best everytime, everwhere\u2026\u2026\r\n    so, I'm eager to know, if mlflow has those functions or modules, that can help me to create some strategies control output results?\r\n\r\nthat's all,  hope your answer!","208":"I get many deprecation warnings when running tests:\r\nmlflow\/protos\/databricks_pb2.py:218: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get\/find descriptors from generated code or query the descriptor_pool.\r\n\r\nPerhaps we should upgrade databricks_pb2.py using a new protoc version.\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**:\r\n- **Python version**:\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","209":"## Proposal Summary\r\nAllow displaying the max\/min value of a metric for each run in the experiments UI. E.g. if logging a validation metric every epoch for NN training it would be useful to easily compare runs by the \"best\" value of the metric rather than the latest one.\r\n\r\n## Motivation\r\nLatest value of a metric for a specific run may not accurately represent how well the experiment run is doing. This would allow easily comparing experiment runs in the experiments UI when training NNs or boosted trees with early stopping.\r\n\r\nSimilar to: https:\/\/github.com\/mlflow\/mlflow\/issues\/1422","210":"Does Java API support MLflow run models?","211":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nA following up PR will implement the following proposed modifications:\r\n\r\n* allow for the use of a new environment variable, `MLFLOW_CONDA_CREATE_ENV_CMD`, that allows the user to specify an executable to be used for creating environments. If the user does not set it, `conda` will be used. If the user sets it, for example as `MLFLOW_CONDA_CREATE_ENV_CMD=mamba`, then `mamba` will be used (of course, the user will have to take care of installing `mamba` first).\r\n* only one minor change is required, in the file `utils\/conda.py`. Tests for this change will also be provided.\r\n\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n\r\n [`mamba`](https:\/\/github.com\/mamba-org\/mamba) is a package manager compatible with Conda, but many times faster than conda when creating environments and installing packages. When using MLflow, creating the environment can be very time consuming, sometimes dominating the total runtime of an MLflow project. This feature allows to use `mamba` instead of `conda` to create the environments. \r\n\r\nIt only requires the user to set the env variable `MLFLOW_CONDA_CREATE_ENV_CMD=mamba` (after having installed mamba, of course).\r\n\r\nIt also allows, for advanced users, to create a wrapper script or executable that runs only when creating environments. Just point `MLFLOW_CONDA_CREATE_ENV_CMD` to the wrapper.\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\n\r\nIt makes the execution of MLflow project and pipelines potentially much faster, by speeding up the environment creation step without requiring any change whatsoever to the MLflow project.\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n\r\nWe use MLflow extensively for pipelines, and sometimes the environment creation step is the most time-consuming part of executing a pipeline step. Using mamba speeds up some of our pipeline steps by up to a factor of 10x.\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nCurrently it is possible to specify a custom installation of conda, but it is impossible to use `conda` for environment management (listing, for example) and `mamba` for creating the environments. It is not possible to use `mamba` in place of `conda` for everything because commands like `mamba activate` are not available.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n","212":"Signed-off-by: harupy <hkawamura0130@gmail.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nReplace the `import` workflow with a pytest script to decrease the number of workflows.\r\n\r\n## How is this patch tested?\r\n\r\nAdded tests\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [x] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","213":"\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nCurrent API for SearchRuns return a lot of data - including RunInfo and RunData. This can cause serious slowdown to the UI. If this is used to populate list of experiments\r\non the UI (compact version), however, only a small subset, only some basic info is needed. \r\n\r\n## Motivation\r\n- What is the use case for this feature? - Speed up UI\r\n- Why is this use case valuable to support for MLflow users in general? - Faster Experience, Less data usage\r\n- Why is this use case valuable to support for your project(s) or organization? - Local MLFLOW server can be made speedier and data usage efficient in terms of traffic\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient) - With the current search API we are forced to use the full version.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [x ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nThe searchRuns API -\r\n```js\r\nstatic searchRuns({ data, success, error }) {\r\n    return $.ajax(Utils.getAjaxUrl('ajax-api\/2.0\/preview\/mlflow\/runs\/search'), {\r\n      type: 'POST',\r\n      contentType: 'application\/json; charset=utf-8',\r\n      dataType: 'json',\r\n      data: JSON.stringify(data),\r\n      jsonp: false,\r\n      success: success,\r\n      error: error,\r\n    });\r\n  }\r\n```\r\n\r\nreturns a very large amount of data, including runInfo, and runData (that contains params and metrics). Even if we want to load just top 100, this ends up taking a lot of traffic and slows down the UI considerably. \r\n\r\nIf one wants to load only basic information about runs in the main experiment page (only a few tags like run name, etc.), the full search results are not needed. If there was a minimal search API, or if the current search API had control for what should be returned, the loading of search results can be very optimized.\r\n","214":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nIs it possible to set default set of columns being displayed in MLflow ui? I only need few of them and I don't want to manually hide them by unchecking in options each time I open a dashboard. I can't see that option right now.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","215":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [\u2714] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n add a feature that would get the entire data once the signature is diaplayed\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nthis would let all the people working on the mlflow to access the data once the model is published\r\n- Why is this use case valuable to support for MLflow users in general?\r\nfor a na\u00efve user can get the data in the entire work flow\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nthis would reduce the bulk data transvers and the data can be simply accessed at a time\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\ninput_example only gives the first row of the data set and has no other attributes \r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [\u2714 ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [\u2714 ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ \u2714] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","216":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04 \r\n- **MLflow installed from (source or binary)**: pip\r\n- **MLflow version (run ``mlflow --version``)**: 1.19.0\r\n- **Python version**: 3.8\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: Run the code snippet in a multi gpu node\r\n\r\n### Describe the problem\r\nWhen mlflow.pytorch.autolog() is used in multi gpu (ddp_spawn) context, it fails with the following error - AttributeError: Can't pickle local object '_create_patch_fit.<locals>.getPLCallback.<locals>.__MLflowPLCallback'\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nSample Code:\r\n```python\r\nimport mlflow\r\nimport os\r\nimport torch\r\nimport torch.nn as nn\r\nimport pytorch_lightning as pl\r\nfrom torch.nn import functional as F\r\nfrom torch.utils.data import DataLoader, random_split\r\nfrom torchvision import transforms\r\nfrom torchvision.datasets import MNIST\r\nfrom pytorch_lightning.metrics.functional import accuracy\r\nimport mlflow.pytorch\r\nfrom torchvision.datasets import MNIST\r\nfrom torchvision import datasets, transforms\r\nimport os\r\n\r\nclass LightningMNISTClassifier(pl.LightningModule):\r\n\r\n  def __init__(self):\r\n    super(LightningMNISTClassifier, self).__init__()\r\n\r\n    # mnist images are (1, 28, 28) (channels, width, height) \r\n    self.layer_1 = torch.nn.Linear(28 * 28, 128)\r\n    self.layer_2 = torch.nn.Linear(128, 256)\r\n    self.layer_3 = torch.nn.Linear(256, 10)\r\n\r\n  def forward(self, x):\r\n      batch_size, channels, width, height = x.size()\r\n\r\n      # (b, 1, 28, 28) -> (b, 1*28*28)\r\n      x = x.view(batch_size, -1)\r\n\r\n      # layer 1 (b, 1*28*28) -> (b, 128)\r\n      x = self.layer_1(x)\r\n      x = torch.relu(x)\r\n\r\n      # layer 2 (b, 128) -> (b, 256)\r\n      x = self.layer_2(x)\r\n      x = torch.relu(x)\r\n\r\n      # layer 3 (b, 256) -> (b, 10)\r\n      x = self.layer_3(x)\r\n\r\n      # probability distribution over labels\r\n      x = torch.log_softmax(x, dim=1)\r\n\r\n      return x\r\n\r\n  def cross_entropy_loss(self, logits, labels):\r\n    return F.nll_loss(logits, labels)\r\n\r\n  def training_step(self, train_batch, batch_idx):\r\n      x, y = train_batch\r\n      logits = self.forward(x)\r\n      loss = self.cross_entropy_loss(logits, y)\r\n\r\n      logs = {'train_loss': loss}\r\n      return {'loss': loss, 'log': logs}\r\n\r\n  def validation_step(self, val_batch, batch_idx):\r\n      x, y = val_batch\r\n      logits = self.forward(x)\r\n      loss = self.cross_entropy_loss(logits, y)\r\n      return {'val_loss': loss}\r\n\r\n  def validation_epoch_end(self, outputs):\r\n      # called at the end of the validation epoch\r\n      # outputs is an array with what you returned in validation_step for each batch\r\n      # outputs = [{'loss': batch_0_loss}, {'loss': batch_1_loss}, ..., {'loss': batch_n_loss}] \r\n      avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\r\n      tensorboard_logs = {'val_loss': avg_loss}\r\n      return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}\r\n\r\n  def prepare_data(self):\r\n    # transforms for images\r\n    transform=transforms.Compose([transforms.ToTensor(), \r\n                                  transforms.Normalize((0.1307,), (0.3081,))])\r\n      \r\n    # prepare transforms standard to MNIST\r\n    mnist_train = MNIST(train=True, download=True, transform=transform)\r\n    mnist_test = MNIST(train=False, download=True, transform=transform)\r\n    \r\n    self.mnist_train, self.mnist_val = random_split(mnist_train, [55000, 5000])\r\n\r\n  def train_dataloader(self):\r\n    return DataLoader(self.mnist_train, batch_size=64)\r\n\r\n  def val_dataloader(self):\r\n    return DataLoader(self.mnist_val, batch_size=64)\r\n\r\n  def test_dataloader(self):\r\n    return DataLoader(self,mnist_test, batch_size=64)\r\n\r\n  def configure_optimizers(self):\r\n    optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\r\n    return optimizer\r\n\r\n## Auto log all MLflow entities\r\nmlflow.pytorch.autolog()\r\nfrom mlflow.tracking import MlflowClient\r\n\r\nwith mlflow.start_run(run_name='mlflow_debug_run') as run:\r\n    from pytorch_lightning.loggers import MLFlowLogger\r\n    experiment_id = run.info.experiment_id\r\n    # get the experiment name\r\n    exp_name = mlflow.get_experiment(experiment_id).name\r\n    # get the mlflow tracking uri\r\n    mlflow_uri = mlflow.get_tracking_uri()\r\n\r\n    mlf_logger = MLFlowLogger(experiment_name=exp_name, tracking_uri=mlflow_uri)\r\n    # link the mlflowlogger run ID to the azureml run ID\r\n    mlf_logger._run_id = run.info.run_id\r\n    model = LightningMNISTClassifier()\r\n    trainer = pl.Trainer(gpus=2, max_epochs=10,accelerator = 'ddp_spawn', logger=mlf_logger)\r\n    trainer.fit(model)\r\n    \r\n```\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n<details>\r\n<summary>Full Traceback: <\/summary>\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<command-1606990188855480> in <module>\r\n     16     model = LightningMNISTClassifier()\r\n     17     trainer = pl.Trainer(gpus=2, max_epochs=10,accelerator = 'ddp_spawn', logger=mlf_logger)\r\n---> 18     trainer.fit(model)\r\n     19 \r\n\r\n\/databricks\/python\/lib\/python3.8\/site-packages\/mlflow\/utils\/autologging_utils\/safety.py in safe_patch_function(*args, **kwargs)\r\n    490                         patch_function.call(call_original, *args, **kwargs)\r\n    491                     else:\r\n--> 492                         patch_function(call_original, *args, **kwargs)\r\n    493 \r\n    494                     session.state = \"succeeded\"\r\n\r\n\/databricks\/python\/lib\/python3.8\/site-packages\/mlflow\/utils\/autologging_utils\/safety.py in patch_with_managed_run(original, *args, **kwargs)\r\n    240 \r\n    241             try:\r\n--> 242                 result = patch_function(original, *args, **kwargs)\r\n    243             except (Exception, KeyboardInterrupt):\r\n    244                 # In addition to standard Python exceptions, handle keyboard interrupts to ensure\r\n\r\n\/databricks\/python\/lib\/python3.8\/site-packages\/mlflow\/pytorch\/_pytorch_autolog.py in fit(original, self, *args, **kwargs)\r\n    314         Patching trainer.fit method to add autolog class into callback\r\n    315         \"\"\"\r\n--> 316         return _run_and_log_function(self, original, args, kwargs)\r\n    317 \r\n    318     return fit\r\n\r\n\/databricks\/python\/lib\/python3.8\/site-packages\/mlflow\/pytorch\/_pytorch_autolog.py in _run_and_log_function(self, original, args, kwargs)\r\n    306         if not any(isinstance(callbacks, __MLflowPLCallback) for callbacks in self.callbacks):\r\n    307             self.callbacks += [__MLflowPLCallback()]\r\n--> 308         result = original(self, *args, **kwargs)\r\n    309 \r\n    310         return result\r\n\r\n\/databricks\/python\/lib\/python3.8\/site-packages\/mlflow\/utils\/autologging_utils\/safety.py in call_original(*og_args, **og_kwargs)\r\n    446                                 disable_warnings=False, reroute_warnings=False,\r\n    447                             ):\r\n--> 448                                 original_result = original(*og_args, **og_kwargs)\r\n    449 \r\n    450                             try_log_autologging_event(\r\n\r\n\/databricks\/python\/lib\/python3.8\/site-packages\/pytorch_lightning\/trainer\/trainer.py in fit(self, model, train_dataloader, val_dataloaders, datamodule)\r\n    458         )\r\n    459 \r\n--> 460         self._run(model)\r\n    461 \r\n    462         assert self.state.stopped\r\n\r\n\/databricks\/python\/lib\/python3.8\/site-packages\/pytorch_lightning\/trainer\/trainer.py in _run(self, model)\r\n    756 \r\n    757         # dispatch `start_training` or `start_evaluating` or `start_predicting`\r\n--> 758         self.dispatch()\r\n    759 \r\n    760         # plugin will finalized fitting (e.g. ddp_spawn will load trained model)\r\n\r\n\/databricks\/python\/lib\/python3.8\/site-packages\/pytorch_lightning\/trainer\/trainer.py in dispatch(self)\r\n    797             self.accelerator.start_predicting(self)\r\n    798         else:\r\n--> 799             self.accelerator.start_training(self)\r\n    800 \r\n    801     def run_stage(self):\r\n\r\n\/databricks\/python\/lib\/python3.8\/site-packages\/pytorch_lightning\/accelerators\/accelerator.py in start_training(self, trainer)\r\n     94 \r\n     95     def start_training(self, trainer: 'pl.Trainer') -> None:\r\n---> 96         self.training_type_plugin.start_training(trainer)\r\n     97 \r\n     98     def start_evaluating(self, trainer: 'pl.Trainer') -> None:\r\n\r\n\/databricks\/python\/lib\/python3.8\/site-packages\/pytorch_lightning\/plugins\/training_type\/ddp_spawn.py in start_training(self, trainer)\r\n    120 \r\n    121     def start_training(self, trainer):\r\n--> 122         mp.spawn(self.new_process, **self.mp_spawn_kwargs)\r\n    123         # reset optimizers, since main process is never used for training and thus does not have a valid optim state\r\n    124         trainer.optimizers = []\r\n\r\n\/databricks\/python\/lib\/python3.8\/site-packages\/torch\/multiprocessing\/spawn.py in spawn(fn, args, nprocs, join, daemon, start_method)\r\n    197                ' torch.multiprocessing.start_process(...)' % start_method)\r\n    198         warnings.warn(msg)\r\n--> 199     return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\r\n\r\n\/databricks\/python\/lib\/python3.8\/site-packages\/torch\/multiprocessing\/spawn.py in start_processes(fn, args, nprocs, join, daemon, start_method)\r\n    146             daemon=daemon,\r\n    147         )\r\n--> 148         process.start()\r\n    149         error_queues.append(error_queue)\r\n    150         processes.append(process)\r\n\r\n\/databricks\/python\/lib\/python3.8\/multiprocessing\/process.py in start(self)\r\n    119                'daemonic processes are not allowed to have children'\r\n    120         _cleanup()\r\n--> 121         self._popen = self._Popen(self)\r\n    122         self._sentinel = self._popen.sentinel\r\n    123         # Avoid a refcycle if the target function holds an indirect\r\n\r\n\/databricks\/python\/lib\/python3.8\/multiprocessing\/context.py in _Popen(process_obj)\r\n    282         def _Popen(process_obj):\r\n    283             from .popen_spawn_posix import Popen\r\n--> 284             return Popen(process_obj)\r\n    285 \r\n    286     class ForkServerProcess(process.BaseProcess):\r\n\r\n\/databricks\/python\/lib\/python3.8\/multiprocessing\/popen_spawn_posix.py in __init__(self, process_obj)\r\n     30     def __init__(self, process_obj):\r\n     31         self._fds = []\r\n---> 32         super().__init__(process_obj)\r\n     33 \r\n     34     def duplicate_for_child(self, fd):\r\n\r\n\/databricks\/python\/lib\/python3.8\/multiprocessing\/popen_fork.py in __init__(self, process_obj)\r\n     17         self.returncode = None\r\n     18         self.finalizer = None\r\n---> 19         self._launch(process_obj)\r\n     20 \r\n     21     def duplicate_for_child(self, fd):\r\n\r\n\/databricks\/python\/lib\/python3.8\/multiprocessing\/popen_spawn_posix.py in _launch(self, process_obj)\r\n     45         try:\r\n     46             reduction.dump(prep_data, fp)\r\n---> 47             reduction.dump(process_obj, fp)\r\n     48         finally:\r\n     49             set_spawning_popen(None)\r\n\r\n\/databricks\/python\/lib\/python3.8\/multiprocessing\/reduction.py in dump(obj, file, protocol)\r\n     58 def dump(obj, file, protocol=None):\r\n     59     '''Replacement for pickle.dump() using ForkingPickler.'''\r\n---> 60     ForkingPickler(file, protocol).dump(obj)\r\n     61 \r\n     62 #\r\n\r\nAttributeError: Can't pickle local object '_create_patch_fit.<locals>.getPLCallback.<locals>.__MLflowPLCallback'\r\n```\r\n<\/details>\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [x] `integrations\/databricks`: Databricks integrations\r\n","217":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:  Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 20.04.2 LTS\r\n- **MLflow installed from (source or binary)**: conda\r\n- **MLflow version (run ``mlflow --version``)**: 1.19.0\r\n- **Python version**: 3.7\r\n\r\n\r\n### Describe the problem\r\nI train a CNN (using pytorch) and try to log my metrics using Mlflow. For that, I ramped up a remote server in another linux machine, and in my current machine, I train the CNN.  In my remote server, I use sftp for the artifacts and postgresql for logging the metrics. \r\nThe CNN keeps training but in random epochs, the mlflow crashes the simulation with the attached error. \r\n\r\n### Code to reproduce issue\r\n\r\nremote_server_uri = <my other linux machine ip>  # set to your server URI\r\nmlflow.set_tracking_uri(remote_server_uri)\r\nex = \"tutorial2\"\r\n\r\nmlflow.create_experiment(ex, artifact_location=\"sftp:\/\/<my user>:<my pass>@<my other linux machine ip>\/media\/sftp\/mlflow\/artifacts\")\r\nmlflow.set_experiment(ex)\r\n\r\nand here comes my training code...\r\nThe command the crashes the simulation is \r\n\r\nmlflow.log_metric(\"train_loss\", loss.data.item())\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n```\r\n]\r\nEpoch 9: 100%|______________________________________________________________________________________________________________________________| 4315\/4315 [14:30<00:00,  4.96batch\/s, accuracy=84.6, loss=0.366]\r\n100%|________________________________________________________________________________________________________________________________________| 480\/480 [00:03<00:00, 140.20batch\/s, accuracy=71.4, loss=0.848]\r\nEpoch 10:  97%|_________________________________________________________________________________________________________________________    | 4166\/4315 [14:10<00:30,  4.90batch\/s, accuracy=68.8, loss=0.595]\r\nTraceback (most recent call last):\r\n  File \"\/home\/shlomi\/projects\/gesturedetection\/MouthCoverDetection\/scenarios\/cnn_mouth_classifier\/train.py\", line 95, in <module>\r\n    mlflow.log_metric(\"lr\", optimizer.param_groups[0][\"lr\"])\r\n  File \"\/home\/shlomi\/anaconda3\/envs\/pytorch17\/lib\/python3.7\/site-packages\/mlflow\/tracking\/fluent.py\", line 441, in log_metric\r\n    MlflowClient().log_metric(run_id, key, value, int(time.time() * 1000), step or 0)\r\n  File \"\/home\/shlomi\/anaconda3\/envs\/pytorch17\/lib\/python3.7\/site-packages\/mlflow\/tracking\/client.py\", line 678, in log_metric\r\n    self._tracking_client.log_metric(run_id, key, value, timestamp, step)\r\n  File \"\/home\/shlomi\/anaconda3\/envs\/pytorch17\/lib\/python3.7\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 209, in log_metric\r\n    self.store.log_metric(run_id, metric)\r\n  File \"\/home\/shlomi\/anaconda3\/envs\/pytorch17\/lib\/python3.7\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 184, in log_metric\r\n    self._call_endpoint(LogMetric, req_body)\r\n  File \"\/home\/shlomi\/anaconda3\/envs\/pytorch17\/lib\/python3.7\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 56, in _call_endpoint\r\n    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)\r\n  File \"\/home\/shlomi\/anaconda3\/envs\/pytorch17\/lib\/python3.7\/site-packages\/mlflow\/utils\/rest_utils.py\", line 170, in call_endpoint\r\n    response = verify_rest_response(response, endpoint)\r\n  File \"\/home\/shlomi\/anaconda3\/envs\/pytorch17\/lib\/python3.7\/site-packages\/mlflow\/utils\/rest_utils.py\", line 128, in verify_rest_response\r\n    raise MlflowException(\"%s. Response body: '%s'\" % (base_msg, response.text))\r\nmlflow.exceptions.MlflowException: API request to endpoint \/api\/2.0\/mlflow\/runs\/log-metric failed with error code 403 != 200. Response body: '<!doctype html>\r\n<html>\r\n<head>\r\n<meta http-equiv=\"refresh\" content=\"0;url=http:\/\/7rx80271.ibosscloud.com\/ibreports\/ibp\/bp.html?bu=http:\/\/10.189.***.***:8080\/api\/2.0\/mlflow\/runs\/log-metric&bc=The%20requested%20URL%20cannot%20be%20accessed.&ip=10.189.***.***&er=ERR_ACCESS_DENIED\"\/>\r\n<\/head>\r\n<body>\r\n<\/body>\r\n<\/html>\r\n'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"\/home\/shlomi\/projects\/gesturedetection\/MouthCoverDetection\/scenarios\/cnn_mouth_classifier\/train.py\", line 114, in <module>\r\n    writer.close()\r\n  File \"\/home\/shlomi\/anaconda3\/envs\/pytorch17\/lib\/python3.7\/site-packages\/mlflow\/tracking\/fluent.py\", line 110, in __exit__\r\n    end_run(RunStatus.to_string(status))\r\n  File \"\/home\/shlomi\/anaconda3\/envs\/pytorch17\/lib\/python3.7\/site-packages\/mlflow\/tracking\/fluent.py\", line 291, in end_run\r\n    MlflowClient().set_terminated(run.info.run_id, status)\r\n  File \"\/home\/shlomi\/anaconda3\/envs\/pytorch17\/lib\/python3.7\/site-packages\/mlflow\/tracking\/client.py\", line 1438, in set_terminated\r\n    self._tracking_client.set_terminated(run_id, status, end_time)\r\n  File \"\/home\/shlomi\/anaconda3\/envs\/pytorch17\/lib\/python3.7\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 364, in set_terminated\r\n    run_id, run_status=RunStatus.from_string(status), end_time=end_time\r\n  File \"\/home\/shlomi\/anaconda3\/envs\/pytorch17\/lib\/python3.7\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 140, in update_run_info\r\n    response_proto = self._call_endpoint(UpdateRun, req_body)\r\n  File \"\/home\/shlomi\/anaconda3\/envs\/pytorch17\/lib\/python3.7\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 56, in _call_endpoint\r\n    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)\r\n  File \"\/home\/shlomi\/anaconda3\/envs\/pytorch17\/lib\/python3.7\/site-packages\/mlflow\/utils\/rest_utils.py\", line 170, in call_endpoint\r\n    response = verify_rest_response(response, endpoint)\r\n  File \"\/home\/shlomi\/anaconda3\/envs\/pytorch17\/lib\/python3.7\/site-packages\/mlflow\/utils\/rest_utils.py\", line 128, in verify_rest_response\r\n    raise MlflowException(\"%s. Response body: '%s'\" % (base_msg, response.text))\r\nmlflow.exceptions.MlflowException: API request to endpoint \/api\/2.0\/mlflow\/runs\/update failed with error code 403 != 200. Response body: '<!doctype html>\r\n<html>\r\n<head>\r\n<meta http-equiv=\"refresh\" content=\"0;url=http:\/\/7rx80271.ibosscloud.com\/ibreports\/ibp\/bp.html?bu=http:\/\/10.189.***.***:8080\/api\/2.0\/mlflow\/runs\/update&bc=The%20requested%20URL%20cannot%20be%20accessed.&ip=10.189.***.***&er=ERR_ACCESS_DENIED\"\/>\r\n<\/head>\r\n<body>\r\n<\/body>\r\n<\/html>\r\n\r\n```\r\n\r\nand the logs from the server are :\r\n\r\n`\r\n\r\nAug 16 09:27:15 mlserv2 bash[52763]: \/home\/mlserv2\/anaconda3\/envs\/mlflow_env\/lib\/python3.6\/site-packages\/pysftp\/__init__.py:61: UserWarning: Failed to load HostKeys from \/media\/sftp\/mlflow\/artifacts\/.ssh\/known_hosts.  You will need to explicitly load HostKeys (cnopts.hostkeys.load(filename)) or disableHostKey checking (cnopts.hostkeys = None).\r\nAug 16 09:27:15 mlserv2 bash[52763]:   warnings.warn(wmsg, UserWarning)\r\nAug 16 09:27:15 mlserv2 bash[52763]: 2021\/08\/16 09:27:15 ERROR mlflow.server: Exception on \/ajax-api\/2.0\/preview\/mlflow\/artifacts\/list [GET]\r\nAug 16 09:27:15 mlserv2 bash[52763]: Traceback (most recent call last):\r\nAug 16 09:27:15 mlserv2 bash[52763]:   File \"\/home\/mlserv2\/anaconda3\/envs\/mlflow_env\/lib\/python3.6\/site-packages\/flask\/app.py\", line 2070, in wsgi_app\r\nAug 16 09:27:15 mlserv2 bash[52763]:     response = self.full_dispatch_request()\r\nAug 16 09:27:15 mlserv2 bash[52763]:   File \"\/home\/mlserv2\/anaconda3\/envs\/mlflow_env\/lib\/python3.6\/site-packages\/flask\/app.py\", line 1515, in full_dispatch_request\r\nAug 16 09:27:15 mlserv2 bash[52763]:     rv = self.handle_user_exception(e)\r\nAug 16 09:27:15 mlserv2 bash[52763]:   File \"\/home\/mlserv2\/anaconda3\/envs\/mlflow_env\/lib\/python3.6\/site-packages\/flask\/app.py\", line 1513, in full_dispatch_request\r\nAug 16 09:27:15 mlserv2 bash[52763]:     rv = self.dispatch_request()\r\nAug 16 09:27:15 mlserv2 bash[52763]:   File \"\/home\/mlserv2\/anaconda3\/envs\/mlflow_env\/lib\/python3.6\/site-packages\/flask\/app.py\", line 1499, in dispatch_request\r\nAug 16 09:27:15 mlserv2 bash[52763]:     return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\r\nAug 16 09:27:15 mlserv2 bash[52763]:   File \"\/home\/mlserv2\/anaconda3\/envs\/mlflow_env\/lib\/python3.6\/site-packages\/mlflow\/server\/handlers.py\", line 214, in wrapper\r\nAug 16 09:27:15 mlserv2 bash[52763]:     return func(*args, **kwargs)\r\nAug 16 09:27:15 mlserv2 bash[52763]:   File \"\/home\/mlserv2\/anaconda3\/envs\/mlflow_env\/lib\/python3.6\/site-packages\/mlflow\/server\/handlers.py\", line 487, in _list_artifacts\r\nAug 16 09:27:15 mlserv2 bash[52763]:     artifact_entities = _get_artifact_repo(run).list_artifacts(path)\r\nAug 16 09:27:15 mlserv2 bash[52763]:   File \"\/home\/mlserv2\/anaconda3\/envs\/mlflow_env\/lib\/python3.6\/site-packages\/mlflow\/server\/handlers.py\", line 214, in wrapper\r\nAug 16 09:27:15 mlserv2 bash[52763]:     return func(*args, **kwargs)\r\nAug 16 09:27:15 mlserv2 bash[52763]:   File \"\/home\/mlserv2\/anaconda3\/envs\/mlflow_env\/lib\/python3.6\/site-packages\/mlflow\/server\/handlers.py\", line 526, in _get_artifact_repo\r\nAug 16 09:27:15 mlserv2 bash[52763]:     return get_artifact_repository(run.info.artifact_uri)\r\nAug 16 09:27:15 mlserv2 bash[52763]:   File \"\/home\/mlserv2\/anaconda3\/envs\/mlflow_env\/lib\/python3.6\/site-packages\/mlflow\/store\/artifact\/artifact_repository_registry.py\", line 102, in get_artifact_repository\r\nAug 16 09:27:15 mlserv2 bash[52763]:     return _artifact_repository_registry.get_artifact_repository(artifact_uri)\r\nAug 16 09:27:15 mlserv2 bash[52763]:   File \"\/home\/mlserv2\/anaconda3\/envs\/mlflow_env\/lib\/python3.6\/site-packages\/mlflow\/store\/artifact\/artifact_repository_registry.py\", line 71, in get_artifact_repository\r\nAug 16 09:27:15 mlserv2 bash[52763]:     return repository(artifact_uri)\r\nAug 16 09:27:15 mlserv2 bash[52763]:   File \"\/home\/mlserv2\/anaconda3\/envs\/mlflow_env\/lib\/python3.6\/site-packages\/mlflow\/store\/artifact\/sftp_artifact_repo.py\", line 70, in __init__\r\nAug 16 09:27:15 mlserv2 bash[52763]:     self.sftp = pysftp.Connection(**self.config)\r\nAug 16 09:27:15 mlserv2 bash[52763]:   File \"\/home\/mlserv2\/anaconda3\/envs\/mlflow_env\/lib\/python3.6\/site-packages\/pysftp\/__init__.py\", line 132, in __init__\r\nAug 16 09:27:15 mlserv2 bash[52763]:     self._tconnect['hostkey'] = self._cnopts.get_hostkey(host)\r\nAug 16 09:27:15 mlserv2 bash[52763]:   File \"\/home\/mlserv2\/anaconda3\/envs\/mlflow_env\/lib\/python3.6\/site-packages\/pysftp\/__init__.py\", line 71, in get_hostkey\r\nAug 16 09:27:15 mlserv2 bash[52763]:     raise SSHException(\"No hostkey for host %s found.\" % host)\r\nAug 16 09:27:15 mlserv2 bash[52763]: paramiko.ssh_exception.SSHException: No hostkey for host 10.189.***.***found.\r\n\r\n\r\n`","218":"I logged a sentiment-analysis model in `Mlflow` with the custom signature, everything is working fine but as soon as I serve the model and hit it with the curl command, then for my multiple inputs it's returning a single output, please help if someone can point to the issue\r\n\r\nCurl command i am using :\r\n\r\n    curl http:\/\/127.0.0.1:2000\/invocations -H 'Content-Type: application\/json' -d '{\"columns\": [\"text\"],\"data\": [[\"Its a Bad day\"],[\"what are you\"]]}'\r\n\r\nOutput:\r\n\r\n    [\"negative\"]\r\n\r\nExpected Output:\r\n\r\n    [\"negative\",\"neutral\"]\r\n\r\nHere is the model signature :\r\n\r\n[![enter image description here][1]][1]\r\n\r\n\r\n  [1]: https:\/\/i.stack.imgur.com\/iNZHX.png\r\n\r\n\r\nI have tried two different models, both of them are giving the same issue and if I am trying a model which takes integer values then it's working as expected.","219":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this installation issue template to ensure a timely and thorough response.**\r\n\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  VM Linux Ubuntu 16.04 running mlflow remotely\r\n- **MLflow installed from (source or binary)**: Pip install mlflow\r\n- **MLflow version (run ``mlflow --version``)**: latest, 1.19.0\r\n- **Python version**: python 3.8.10\r\n- **Exact command to reproduce**:\r\n\r\nmssql+pyjdbc:\/\/user:password@<server_name>.database.windows.net:<port>\/<database_name>\r\n\r\n\r\n### Describe the problem\r\nI have created a virtual machine that stored mlflow backend component data locally, and artifact data in a blob storage. This works completely fine, however I wanted to change the backend component to a SQL Server as per clients request.\r\n\r\nI created a SQL Server and database in Microsoft Azure. I find it strange that the dialect shown in Azure sql is sqlserver not mssql, but tried it with both anyway.\r\n\r\nmssql+pyjdbc:\/\/user:password@<server_name>.database.windows.net:<port>\/<database_name>\r\n\r\nI followed the connection string (seen above) in the mlflow documentation and received the following error:\r\n\r\nmlflow server --backend-store-uri mssql+jdbc:\/\/user:password@backend-component-mlflow.database.windows.net:1433\/mlflow --default-artifact-root wasbs:\/\/hiding_this\/ --host 0.0.0.0\r\n2021\/08\/11 13:03:30 ERROR mlflow.cli: Error initializing backend store\r\n2021\/08\/11 13:03:30 ERROR mlflow.cli: Can't load plugin: sqlalchemy.dialects:mssql.jdbc\r\nTraceback (most recent call last):\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/mlflow\/cli.py\", line 383, in server\r\n    initialize_backend_stores(backend_store_uri, default_artifact_root)\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/mlflow\/server\/handlers.py\", line 145, in initialize_backend_stores\r\n    _get_tracking_store(backend_store_uri, default_artifact_root)\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/mlflow\/server\/handlers.py\", line 130, in _get_tracking_store\r\n    _tracking_store = _tracking_store_registry.get_store(store_uri, artifact_root)\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/mlflow\/tracking\/_tracking_service\/registry.py\", line 38, in get_store\r\n    return builder(store_uri=store_uri, artifact_uri=artifact_uri)\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/mlflow\/server\/handlers.py\", line 101, in _get_sqlalchemy_store\r\n    return SqlAlchemyStore(store_uri, artifact_uri)\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/mlflow\/store\/tracking\/sqlalchemy_store.py\", line 104, in __init__\r\n    self.engine = mlflow.store.db.utils.create_sqlalchemy_engine_with_retry(db_uri)\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/mlflow\/store\/db\/utils.py\", line 159, in create_sqlalchemy_engine_with_retry\r\n    engine = create_sqlalchemy_engine(db_uri)\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/mlflow\/store\/db\/utils.py\", line 189, in create_sqlalchemy_engine\r\n    return sqlalchemy.create_engine(db_uri, pool_pre_ping=True, **pool_kwargs)\r\n  File \"<string>\", line 2, in create_engine\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/sqlalchemy\/util\/deprecations.py\", line 298, in warned\r\n    return fn(*args, **kwargs)\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/create.py\", line 522, in create_engine\r\n    entrypoint = u._get_entrypoint()\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/url.py\", line 636, in _get_entrypoint\r\n    cls = registry.load(name)\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/sqlalchemy\/util\/langhelpers.py\", line 343, in load\r\n    raise exc.NoSuchModuleError(\r\nsqlalchemy.exc.NoSuchModuleError: Can't load plugin: sqlalchemy.dialects:mssql.jdbc\r\nWhen I tried the same with mssql + JDBC I receive the following error:\r\n\r\n2021\/08\/11 12:56:37 ERROR mlflow.cli: Error initializing backend store\r\n2021\/08\/11 12:56:37 ERROR mlflow.cli: Can't load plugin: sqlalchemy.dialects:mssql.jdbc\r\nTraceback (most recent call last):\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/mlflow\/cli.py\", line 383, in server\r\n    initialize_backend_stores(backend_store_uri, default_artifact_root)\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/mlflow\/server\/handlers.py\", line 145, in initialize_backend_stores\r\n    _get_tracking_store(backend_store_uri, default_artifact_root)\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/mlflow\/server\/handlers.py\", line 130, in _get_tracking_store\r\n    _tracking_store = _tracking_store_registry.get_store(store_uri, artifact_root)\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/mlflow\/tracking\/_tracking_service\/registry.py\", line 38, in get_store\r\n    return builder(store_uri=store_uri, artifact_uri=artifact_uri)\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/mlflow\/server\/handlers.py\", line 101, in _get_sqlalchemy_store\r\n    return SqlAlchemyStore(store_uri, artifact_uri)\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/mlflow\/store\/tracking\/sqlalchemy_store.py\", line 104, in __init__\r\n    self.engine = mlflow.store.db.utils.create_sqlalchemy_engine_with_retry(db_uri)\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/mlflow\/store\/db\/utils.py\", line 159, in create_sqlalchemy_engine_with_retry\r\n    engine = create_sqlalchemy_engine(db_uri)\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/mlflow\/store\/db\/utils.py\", line 189, in create_sqlalchemy_engine\r\n    return sqlalchemy.create_engine(db_uri, pool_pre_ping=True, **pool_kwargs)\r\n  File \"<string>\", line 2, in create_engine\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/sqlalchemy\/util\/deprecations.py\", line 298, in warned\r\n    return fn(*args, **kwargs)\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/create.py\", line 522, in create_engine\r\n    entrypoint = u._get_entrypoint()\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/url.py\", line 636, in _get_entrypoint\r\n    cls = registry.load(name)\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/sqlalchemy\/util\/langhelpers.py\", line 343, in load\r\n    raise exc.NoSuchModuleError(\r\nsqlalchemy.exc.NoSuchModuleError: Can't load plugin: sqlalchemy.dialects:mssql.jdbc\r\n\r\n\r\nFinally when trying it with sqlserver as dialect I get the expected error below:\r\n\r\nfor model registry data storage. Supported URI schemes are: ['', 'file', 'postgresql', 'mysql', 'sqlite', 'mssql']. See https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#storage for how to run an MLflow server against one of the supported backend storage locations.\r\nTraceback (most recent call last):\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/mlflow\/tracking\/registry.py\", line 76, in get_store_builder\r\n    store_builder = self._registry[scheme]\r\nKeyError: 'sqlserver+jdbc'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/mlflow\/cli.py\", line 383, in server\r\n    initialize_backend_stores(backend_store_uri, default_artifact_root)\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/mlflow\/server\/handlers.py\", line 145, in initialize_backend_stores\r\n    _get_tracking_store(backend_store_uri, default_artifact_root)\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/mlflow\/server\/handlers.py\", line 130, in _get_tracking_store\r\n    _tracking_store = _tracking_store_registry.get_store(store_uri, artifact_root)\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/mlflow\/tracking\/_tracking_service\/registry.py\", line 37, in get_store\r\n    builder = self.get_store_builder(store_uri)\r\n  File \"\/home\/viraj\/.local\/lib\/python3.8\/site-packages\/mlflow\/tracking\/registry.py\", line 78, in get_store_builder\r\n    raise UnsupportedModelRegistryStoreURIException(\r\nmlflow.tracking.registry.UnsupportedModelRegistryStoreURIException:  Model registry functionality is unavailable; got unsupported URI 'sqlserver+jdbc:\/\/user:password@backend-component-mlflow.database.windows.net:1433\/mlflow' for model registry data storage. Supported URI schemes are: ['', 'file', 'postgresql', 'mysql', 'sqlite', 'mssql']. See https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#storage for how to run an MLflow server against one of the supported backend storage locations. \r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n","220":"## Willingness to contribute\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nNeed for logging metrics, parameters, tags and artifacts for detectron2 project.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n","221":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Red Hat Enterprise Linux 7.6 \r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: 1.19\r\n- **Python version**: 3.6.8\r\n\r\n### Describe the problem\r\nI am trying to setup mlflow server using Hitachi Container Platform - Hitachi Vantara (S3-compatible storage) as artifact store. The mlflow tracking UI manage to run smoothly, I also managed to put in the params, models file in the bucket. However, there is a problem when i tried to view the model from the mlflow tracking UI. It displayed a notification as follows\r\n\r\n**Loading Artifacts Failed\r\nUnable to list artifacts stored under <code>{artifactUri}<\/code> for the current run. Please contact your tracking server administrator to notify them of this error, which can happen when the tracking server lacks permission to list artifacts under the current run's root artifact directory.**\r\n\r\n### Other info \/ logs\r\nbotocore.errorfactory.NoSuchKey: An error occurred (NoSuchKey) when calling the ListObjectsV2 operation: The specified key does not exist.\r\n\r\nIt seems like an issue related to\r\nhttps:\/\/stackoverflow.com\/questions\/44778448\/s3-giving-me-nosuchkey-error-even-when-the-key-exists\r\n\r\nbecause there is an encoding in the bucket file path\r\n\r\n%2F1%2F0c2e7c786b0c4585b27a1c9f0554cd61%2Fartifacts%2Fmodel%2F \r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [x] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [x] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","222":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nImplement the function `delete_artifacts` in 'mlflow\/store\/artifact\/gcs_artifact_repo.py'.\r\n\r\n## Motivation\r\nEnable `mlflow gc` to work with gcs artifact deletion.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nImplement the function `delete_artifacts` in analogous way to that of s3 version.\r\n","223":"**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug-fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [X] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **OS Platform and Distribution**: MLflow docker image based on 'python:3.9-slim-buster'. Deployed in k8s cluster.\r\n- **MLflow installed from**: official pip \\ pypi\r\n- **MLflow version**: 1.16.0\r\n- **MLflow backend store**: AWS RDS Postgres-SQL 12\r\n- **MLflow artifact root**: AWS S3 bucket\r\n- **Python version**: 3.9\r\n- **Command**: `mlflow server --host 0.0.0.0  --port 5000 --default-artifact-root ${BUCKET}  --backend-store-uri mysql+pymysql:\/\/${USERNAME}:${PASSWORD}@${HOST}:${PORT}\/${DATABASE}`\r\n\r\n### Describe the problem\r\nThis MLFlow tracking server is exposed with a AWS load balancer, and there are other services that load models using this ALB from mlflow. I have observed a significant increase in load time as compared to conventional method which involved model loading from the S3-locations.\r\nFor the service within the same VPC, the time for loading the model using mlflow's load_model() is slightly higher(~5 seconds) compared to the conventional way of loading directly from the bucket (~0.3 seconds); whereas in the other case where the VPC is different, the load time is significantly high (>200 seconds). (Note : The model size is in megabytes.)\r\n\r\nIssue raised in StackOverflow : [[link]](https:\/\/stackoverflow.com\/questions\/68679258\/loading-time-with-mlflow-load-model-is-very-high)\r\n\r\n### Code to reproduce issue\r\nlogged_model = \"models:\/\" + model_name + \"\/\" + registered_version_number\r\nmodel = mlflow.keras.load_model(logged_model)\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [X] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [X] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [X] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [X] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\nTags\r\n- [X] `help wanted`: Need help from community","224":"Hi guys,\r\n\r\nI have a doubt when I use client.delete_run why it doesn't remove files in the repository? Because I'd like remove the old runs and them files too.\r\n\r\nDo you think interesting it implement this?\r\n\r\nI've used Minio (protocol S3).\r\n\r\nTks","225":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows10\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: 1.14.1\r\n- **Python version**: 3.7\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\nD:\\Download\\model_automl\\model_Xgboost_qWLDn>mlflow models serve -m model -p 5000 -h 0.0.0.0 --no-conda\r\n2021\/08\/05 21:50:04 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\r\n2021\/08\/05 21:50:04 INFO mlflow.pyfunc.backend: === Running command 'waitress-serve --host=0.0.0.0 --port=5000 --ident=mlflow mlflow.pyfunc.scoring_server.wsgi:app'\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\linra\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"C:\\Users\\linra\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"D:\\virtualenv\\aipaas_automl_37\\Scripts\\waitress-serve.exe\\__main__.py\", line 7, in <module>\r\n  File \"d:\\virtualenv\\aipaas_automl_37\\lib\\site-packages\\waitress\\runner.py\", line 283, in run\r\n    app = resolve(module, obj_name)\r\n  File \"d:\\virtualenv\\aipaas_automl_37\\lib\\site-packages\\waitress\\runner.py\", line 218, in resolve\r\n    obj = __import__(module_name, fromlist=segments[:1])\r\n  File \"d:\\virtualenv\\aipaas_automl_37\\lib\\site-packages\\mlflow\\pyfunc\\scoring_server\\wsgi.py\", line 6, in <module>\r\n    app = scoring_server.init(load_model(os.environ[scoring_server._SERVER_MODEL_PATH]))\r\n  File \"d:\\virtualenv\\aipaas_automl_37\\lib\\site-packages\\mlflow\\pyfunc\\__init__.py\", line 655, in load_model\r\n    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\r\n  File \"d:\\virtualenv\\aipaas_automl_37\\lib\\site-packages\\mlflow\\pyfunc\\model.py\", line 237, in _load_pyfunc\r\n    python_model.load_context(context=context)\r\n  File \"\/tmp\/pyfunc_model.py\", line 26, in load_context\r\n  File \"d:\\virtualenv\\aipaas_automl_37\\lib\\site-packages\\mlflow\\sklearn\\__init__.py\", line 449, in load_model\r\n    local_model_path = _download_artifact_from_uri(artifact_uri=model_uri)\r\n  File \"d:\\virtualenv\\aipaas_automl_37\\lib\\site-packages\\mlflow\\tracking\\artifact_utils.py\", line 79, in _download_artifact_from_uri\r\n    return get_artifact_repository(artifact_uri=root_uri).download_artifacts(\r\n  File \"d:\\virtualenv\\aipaas_automl_37\\lib\\site-packages\\mlflow\\store\\artifact\\artifact_repository_registry.py\", line 102, in get_artifact_repository\r\n    return _artifact_repository_registry.get_artifact_repository(artifact_uri)\r\n  File \"d:\\virtualenv\\aipaas_automl_37\\lib\\site-packages\\mlflow\\store\\artifact\\artifact_repository_registry.py\", line 68, in get_artifact_repository\r\n    artifact_uri, list(self._registry.keys())\r\nmlflow.exceptions.MlflowException: Could not find a registered artifact repository for: d:\\Download\\model_automl\\model_Xgboost_qWLDn\\model\\artifacts. Currently registered schemes are: ['', 'file', 's3', 'gs', 'wasbs', 'ftp', 'sftp', 'dbfs', 'hdfs', 'viewfs', 'runs', 'models']\r\n\r\n### Describe the problem\r\n\r\nI use mlflow.pyfunc.save_model to generate a model that contains artifacts. I can successfully deploy on ubuntu, but there is a problem that artifacts cannot be found in windows.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [x] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","226":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 18.04.4\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**:1.19.0\r\n- **Python version**:3.7.0\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\nI want to access to artifacts from UI, but I'm getting these errors:\r\n21\/08\/05 05:48:31 ERROR mlflow.server: Exception on \/ajax-api\/2.0\/preview\/mlflow\/artifacts\/list [GET]\r\nTraceback (most recent call last):\r\n  File \"\/opt\/anaconda\/anaconda3\/envs\/mlflow_environ\/lib\/python3.7\/site-packages\/flask\/app.py\", line 2070, in wsgi_app\r\n    response = self.full_dispatch_request()\r\n  File \"\/opt\/anaconda\/anaconda3\/envs\/mlflow_environ\/lib\/python3.7\/site-packages\/flask\/app.py\", line 1515, in full_dispatch_request\r\n    rv = self.handle_user_exception(e)\r\n  File \"\/opt\/anaconda\/anaconda3\/envs\/mlflow_environ\/lib\/python3.7\/site-packages\/flask\/app.py\", line 1513, in full_dispatch_request\r\n    rv = self.dispatch_request()\r\n  File \"\/opt\/anaconda\/anaconda3\/envs\/mlflow_environ\/lib\/python3.7\/site-packages\/flask\/app.py\", line 1499, in dispatch_request\r\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\r\n  File \"\/opt\/anaconda\/anaconda3\/envs\/mlflow_environ\/lib\/python3.7\/site-packages\/mlflow\/server\/handlers.py\", line 214, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"\/opt\/anaconda\/anaconda3\/envs\/mlflow_environ\/lib\/python3.7\/site-packages\/mlflow\/server\/handlers.py\", line 487, in _list_artifacts\r\n    artifact_entities = _get_artifact_repo(run).list_artifacts(path)\r\n  File \"\/opt\/anaconda\/anaconda3\/envs\/mlflow_environ\/lib\/python3.7\/site-packages\/mlflow\/server\/handlers.py\", line 214, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"\/opt\/anaconda\/anaconda3\/envs\/mlflow_environ\/lib\/python3.7\/site-packages\/mlflow\/server\/handlers.py\", line 526, in _get_artifact_repo\r\n    return get_artifact_repository(run.info.artifact_uri)\r\n  File \"\/opt\/anaconda\/anaconda3\/envs\/mlflow_environ\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact\/artifact_repository_registry.py\", line 102, in get_artifact_repository\r\n    return _artifact_repository_registry.get_artifact_repository(artifact_uri)\r\n  File \"\/opt\/anaconda\/anaconda3\/envs\/mlflow_environ\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact\/artifact_repository_registry.py\", line 62, in get_artifact_repository\r\n    scheme = get_uri_scheme(artifact_uri)\r\n  File \"\/opt\/anaconda\/anaconda3\/envs\/mlflow_environ\/lib\/python3.7\/site-packages\/mlflow\/utils\/uri.py\", line 161, in get_uri_scheme\r\n    if any([scheme.lower().startswith(db) for db in DATABASE_ENGINES]):\r\n  File \"\/opt\/anaconda\/anaconda3\/envs\/mlflow_environ\/lib\/python3.7\/site-packages\/mlflow\/utils\/uri.py\", line 161, in <listcomp>\r\n    if any([scheme.lower().startswith(db) for db in DATABASE_ENGINES]):\r\nTypeError: startswith first arg must be bytes or a tuple of bytes, not str\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n","227":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nFigure logging is already possible with the Python client for figures [produced with matplotlib and plotly](https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.log_figure). I'd like to add support for [plotnine](https:\/\/plotnine.readthedocs.io\/en\/stable\/) figures, a port of the popular ggplot2 library in R to python. This reduces boilerplate code for the user, who currently has to save the figure into a temp directory before logging it as an artifact. This feature is backward compatible and small in scope.\r\n\r\n\r\n\r\n## Motivation\r\n- What is the use case for this feature? Logging plotnine figures as one can log figures created with other libraries.\r\n- Why is this use case valuable to support for MLflow users in general? Plotnine is a popular python visualization library.\r\n- Why is this use case valuable to support for your project(s) or organization? Reduce boilerplate code.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient) Because I have to use `log_artifact()`.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### Details\r\n\r\nNone","228":"## What changes are proposed in this pull request?\r\n\r\n(Please fill in changes proposed in this fix)\r\n\r\nCreate new `getBitbucketSelfhostedRegex` which recognize self-hosted bitbucket URL. Adding the case where is a match with `getBitbucketSelfhostedRegex` in `getGitRepoUrl` and `getGitCommitUrl` \r\n\r\n## How is this patch tested?\r\n\r\n(Details)\r\n\r\nAdded test cases to test `getBitbucketSelfhostedRegex` and to test `getGitRepoUrl` after adding `getBitbucketSelfhosted ` match \r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [x] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","229":"### Willingness to contribute\r\n- [x] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code**: Yes\r\n- **OS Platform and Distribution**: Linux Ubuntu 18.04\r\n- **MLflow installed from**: binary\r\n- **MLflow version**: 1.12.1\r\n- **Python version**: 3.8.5\r\n- **Tensorflow version**: 2.3.0\r\n\r\n### Describe the problem\r\nI cannot load tensorflow models from the `mlfow.tensorflow.load_model` call.\r\n\r\n**Expected behaviour**:\r\nLoad model and input data.\r\n**Actual behaviour**:\r\nModel variables are stored on the `loaded` model object and the `mlfow.tensorflow.load_model` call returns a concrete function which garbage collects the `loaded` model, causing the concrete function to fail with `Error while reading resource variable iris_model\/dense_1\/kernel_98 from Container: localhost.`\r\n\r\nThis behaviour is discussed in https:\/\/github.com\/tensorflow\/tensorflow\/issues\/34253, on the tensorflow github.\r\n\r\nSection in your codebase that causes the bug: \r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/b1c7ef3a7c60ad4df45041871c3fda40b68a47c6\/mlflow\/tensorflow.py#L468-L477\r\n\r\nA solution to this would be to return the `loaded` object from the `mlfow.tensorflow.load_model` call but this would change your API.\r\n\r\nThis solution below where a function binds the `loaded` variable from its outer scope could also work... feels very hacky though.\r\n```python\r\ndef _load_tensorflow_saved_model(\r\n    tf_saved_model_dir, tf_meta_graph_tags, tf_signature_def_key, tf_sess=None\r\n):\r\n    ...\r\n        loaded = tensorflow.saved_model.load(  # pylint: disable=no-value-for-parameter\r\n            tags=tf_meta_graph_tags, export_dir=tf_saved_model_dir\r\n        )\r\n        loaded_sig = loaded.signatures\r\n    if tf_signature_def_key not in loaded_sig:\r\n        raise MlflowException(\r\n            \"Could not find signature def key %s. Available keys are: %s\"\r\n            % (tf_signature_def_key, list(loaded_sig.keys()))\r\n        )\r\n\r\n    def call(*args, **kwargs):\r\n        return loaded.signatures[tf_signature_def_key](*args, **kwargs)\r\n\r\n    return call\r\n```\r\n\r\n\r\n### Code to reproduce issue\r\n\r\nWhole training and prediction code to reproduce:\r\nhttps:\/\/gist.github.com\/jchacks\/6ae685460c82e4b46ad9be2a90db2b47\r\n\r\n```python\r\n# Save a model using the tf api\r\ntf.saved_model.save(\r\n    model,\r\n    \"..\/model\/iris_model\",\r\n    signatures=model.predict\r\n)\r\n\r\nx = 'some dataset'\r\n\r\n# This works as it keeps the `loaded` variable\r\nloaded = tf.saved_model.load(\"..\/model\/iris_model\")\r\nloaded.predict(x)\r\n\r\nmodel = mlflow.tensorflow.load_model(\r\n    model_uri=f\"models:\/{model_name}\/{model_version}\"\r\n)\r\n# This should work as it returns the concrete function \r\n# but the loaded model in your API is being garbage \r\n# collected and deletes the model variables\r\nmodel(x)\r\n\r\n```\r\n\r\n### Other info \/ logs\r\nFull traceback of TF failure.\r\n```bash\r\nTraceback (most recent call last):\r\n  File \"predict.py\", line 17, in <module>\r\n    model(x=x)\r\n  File \"\/root\/opt\/conda\/lib\/python3.8\/site-packages\/tensorflow\/python\/eager\/function.py\", line 1655, in __call__\r\n    return self._call_impl(args, kwargs)\r\n  File \"\/root\/opt\/conda\/lib\/python3.8\/site-packages\/tensorflow\/python\/eager\/function.py\", line 1673, in _call_impl\r\n    return self._call_with_flat_signature(args, kwargs, cancellation_manager)\r\n  File \"\/root\/opt\/conda\/lib\/python3.8\/site-packages\/tensorflow\/python\/eager\/function.py\", line 1722, in _call_with_flat_signature\r\n    return self._call_flat(args, self.captured_inputs, cancellation_manager)\r\n  File \"\/root\/opt\/conda\/lib\/python3.8\/site-packages\/tensorflow\/python\/saved_model\/load.py\", line 105, in _call_flat\r\n    return super(_WrapperFunction, self)._call_flat(args, captured_inputs,\r\n  File \"\/root\/opt\/conda\/lib\/python3.8\/site-packages\/tensorflow\/python\/eager\/function.py\", line 1923, in _call_flat\r\n    return self._build_call_outputs(self._inference_function.call(\r\n  File \"\/root\/opt\/conda\/lib\/python3.8\/site-packages\/tensorflow\/python\/eager\/function.py\", line 545, in call\r\n    outputs = execute.execute(\r\n  File \"\/root\/opt\/conda\/lib\/python3.8\/site-packages\/tensorflow\/python\/eager\/execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.FailedPreconditionError:  Error while reading resource variable iris_model\/dense_1\/kernel_98 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost\/iris_model\/dense_1\/kernel_98\/N10tensorflow3VarE does not exist.\r\n         [[{{node StatefulPartitionedCall\/iris_model\/dense_1\/MatMul\/ReadVariableOp}}]] [Op:__inference_signature_wrapper_88]\r\n\r\nFunction call stack:\r\nsignature_wrapper\r\n```\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\n","230":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:-\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: docker image: nvidia\/cuda:11.0-cudnn8-devel-ubuntu18.04\r\n- **MLflow installed from (source or binary)**: pip\r\n- **MLflow version (run ``mlflow --version``)**:1.19.0\r\n- **Python version**: 3.6.9\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: `cd path\/that\/contain\/mlruns`  and `mlflow ui -h 0.0.0.0 -p 5000`\r\n\r\n\r\n### Describe the problem\r\n\r\nHi I am not sure what am i doing wrong, but everything seems to work except that artifacts are not seen by the UI although they are in the artifact directory. Parameters and metrics are correctly shown.\r\n\r\n### Code to reproduce issue\r\nBelow is the minimal code to reproduce my issue\r\n\r\n```python\r\nimport mlflow\r\nimport yaml\r\ndef main():\r\n    with open(config_file, 'r') as cfile:\r\n         yml = yaml.load(cfile, Loader=yaml.FullLoader)\r\n     # copy config files\r\n    mlflow.log_dict(yml, \"config.yaml\")\r\n    mlflow.log_artifact(yml['model-config-file'])\r\n\r\nif __name__ == '__main__':\r\n    mlflow.set_tracking_uri(\"\/out\/mlruns\")\r\n    mlflow.set_experiment(\"dummy-test\") \r\n    \r\n    with mlflow.start_run():\r\n        main()\r\n```\r\n\r\nThen, to launch the UI, I go to the parent directory of mlruns and run `mlflow ui -h 0.0.0.0 -p 5000`\r\n``` tree mlruns\/\r\nmlruns\/\r\n\u251c\u2500\u2500 ...\r\n\u2514\u2500\u2500 1\r\n    \u251c\u2500\u2500 3822fcba86334cf08754bf5baf37a36a\r\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 artifacts\r\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 config.yaml\r\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 model.yaml\r\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 meta.yaml\r\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 metrics\r\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 params\r\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 tags\r\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 mlflow.source.name\r\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 mlflow.source.type\r\n    \u2502\u00a0\u00a0     \u2514\u2500\u2500 mlflow.user\r\n    \u2514\u2500\u2500 meta.yaml\r\nmlflow ui -h 0.0.0.0 -p 5000\r\n```\r\n\r\n\r\n### Other info \/ logs\r\n\r\nIn my complete code I also log the model and tensorboard data into a directory with `mlflow.log_artifacts(log_path, artifact_path=\"tf_logs\")`. Data are correctly copied in the artifact directory but are not seen either.\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","231":"Standardize the official spelling: PyFunc or Pyfunc? I've seen both in the docs. For example:\r\n- All [PyFunc](https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.pyfunc.html#inference-api) models\r\n- Creating custom [Pyfunc](https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.pyfunc.html#filesystem-format) models.","232":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nI'd like to dump mlflow's `ui` into a static site with a few experiments, to be hosted at gh-pages or a similar service. These experiments are the accompanying material to a research paper. No new experiments will be added, and no changes will be done; so doing one \"dump\" of the ui interface into plain HTML\/CSS\/JS would solve this.\r\n\r\nI couldn't find any previous posts about this.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n\r\nI have a set of experiments accompanying an upcoming paper. There will be no more runs for this project, and I want to share all the results of the experiments I did. I find the `mlflow ui` very easy to use and, ideally, I'd just like to deploy the relevant experiments in a gh-pages or similar site.  \r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\n\r\nIt might be relevant for people who want to share the interactive visualization of their experiments without too much hazzle or reinventing a website from scratch.\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nIt is my impression that it shouldn't be that difficult to do, assuming I already have everything in my `mlruns` folder and that there will be no further experiments for this project. I essentially want to \"freeze\" these visualizations permanently as a supplementary material of my research paper.\r\n\r\nMaybe something like `Frozen-Flask` will do? But I'd be very grateful if I can get some help on this.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\n## Details\r\n\r\nAny guidance on how to achieve this would be greatly appreciated.\r\n\r\nI already tried scraping my `localhost:5000` but I keep getting error messages. Maybe `ajax` operations going on? I understand if it's unfeasible to do this, but I thought that what I want to store is really those HTML files with concluded experiments. Maybe doable?\r\n\r\nThanks.\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","233":"I have a user in a Linux machine and I run a mlflow server from this user. Artifacts are stored in local mlruns folder. Lets call this user as user A. Then I run another mlflow server from another Linux user and call this user as user B. I wanted to migrate older experiments and their artifacts that resides in mlruns directory of user A to mlflow that run in user B. I simply moved mlruns directory of user A to the home directory of user B and run mlflow from there again. When I accessed to mlflow UI by browser I saw that artifact location is configured correctly to mlruns folder of user B, but I couldn't see the experiments that moved from user A's mlruns directory. Is there any capability for uploading experiments and artifacts to another MLFlow server? How can I accomplish it?\r\n","234":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **MLflow installed from (source or binary)**: npm\r\n- **MLflow version (run ``mlflow --version``)**: 1.18.0\r\n- **Python version**: 3.8.8\r\n- **npm version, if running the dev UI**: 6.14.11\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\nExpected behavior:\r\nThere should be a hyperlink in the `source` attribute that directs to the repository where this run was logged from \r\n\r\nActual behavior:\r\nThe hyperlink in the `source` attribute is not working for self-hosted bitbucket. As you can see it in the following photo:\r\n![Git commit is not clickable](https:\/\/user-images.githubusercontent.com\/36420198\/127988631-700395d3-a1ac-4a94-aa41-53529a816d41.png)\r\n\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nTry to use MLflow projects to run from a repository on self-hosted bitbucket.\r\nfor example: `mlflow run https:\/\/bitbucket.XXXX.XXXX.com\/XXXX\/mlflow-docker.git -v kube_backend -P alpha=0.5`\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [x] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","235":"System Information:\r\n'pytorch-lightning==1.3.8\r\n'mlflow==1.19.0'\r\n\r\nDescription:\r\nI am using mlflow autologger with pytorch_lightning. The auto logging feature works fine with it is run on a single GPU. But it fails when I try it on multiple GPUs. From the stack trace I understand that it is trying to add the MLflow callback to the list of callbacks and then it fails when it is trying to spawn a new process\r\n\r\nError:\r\n\r\nAttributeError: Can't pickle local object '_create_patch_fit.<locals>.getPLCallback.<locals>.__MLflowPLCallback'\r\ndatabricks\/python\/lib\/python3.8\/site-packages\/mlflow\/utils\/autologging_utils\/safety.py in safe_patch_function(*args, **kwargs)\r\n    490                         patch_function.call(call_original, *args, **kwargs)\r\n    491                     else:\r\n--> 492                         patch_function(call_original, *args, **kwargs)\r\n    493 \r\n    494                     session.state = \"succeeded\"\r\n\r\n\/databricks\/python\/lib\/python3.8\/site-packages\/mlflow\/utils\/autologging_utils\/safety.py in patch_with_managed_run(original, *args, **kwargs)\r\n    240 \r\n    241             try:\r\n--> 242                 result = patch_function(original, *args, **kwargs)\r\n    243             except (Exception, KeyboardInterrupt):\r\n    244                 # In addition to standard Python exceptions, handle keyboard interrupts to ensure\r\n\r\n\/databricks\/python\/lib\/python3.8\/site-packages\/mlflow\/pytorch\/_pytorch_autolog.py in fit(original, self, *args, **kwargs)\r\n    314         Patching trainer.fit method to add autolog class into callback\r\n    315         \"\"\"\r\n--> 316         return _run_and_log_function(self, original, args, kwargs)\r\n    317 \r\n    318     return fit\r\n\r\n\/databricks\/python\/lib\/python3.8\/site-packages\/mlflow\/pytorch\/_pytorch_autolog.py in _run_and_log_function(self, original, args, kwargs)\r\n    306         if not any(isinstance(callbacks, __MLflowPLCallback) for callbacks in self.callbacks):\r\n    307             self.callbacks += [__MLflowPLCallback()]\r\n--> 308         result = original(self, *args, **kwargs)\r\n    309 \r\n    310         return result\r\n\r\n\/databricks\/python\/lib\/python3.8\/site-packages\/mlflow\/utils\/autologging_utils\/safety.py in call_original(*og_args, **og_kwargs)\r\n    446                                 disable_warnings=False, reroute_warnings=False,\r\n    447                             ):\r\n--> 448                                 original_result = original(*og_args, **og_kwargs)\r\n    449 \r\n    450                             try_log_autologging_event(\r\n\r\n\/databricks\/python\/lib\/python3.8\/site-packages\/pytorch_lightning\/trainer\/trainer.py in fit(self, model, train_dataloader, val_dataloaders, datamodule)\r\n    458         )\r\n    459 \r\n--> 460         self._run(model)\r\n    461 \r\n    462         assert self.state.stopped\r\n\r\n\/databricks\/python\/lib\/python3.8\/site-packages\/pytorch_lightning\/trainer\/trainer.py in _run(self, model)\r\n    756 \r\n    757         # dispatch `start_training` or `start_evaluating` or `start_predicting`\r\n--> 758         self.dispatch()\r\n    759 \r\n    760         # plugin will finalized fitting (e.g. ddp_spawn will load trained model)\r\n\r\n\/databricks\/python\/lib\/python3.8\/site-packages\/pytorch_lightning\/trainer\/trainer.py in dispatch(self)\r\n    797             self.accelerator.start_predicting(self)\r\n    798         else:\r\n--> 799             self.accelerator.start_training(self)\r\n    800 \r\n    801     def run_stage(self):\r\n\r\n\/databricks\/python\/lib\/python3.8\/site-packages\/pytorch_lightning\/accelerators\/accelerator.py in start_training(self, trainer)\r\n     94 \r\n     95     def start_training(self, trainer: 'pl.Trainer') -> None:\r\n---> 96         self.training_type_plugin.start_training(trainer)\r\n     97 \r\n     98     def start_evaluating(self, trainer: 'pl.Trainer') -> None:\r\n\r\n\/databricks\/python\/lib\/python3.8\/site-packages\/pytorch_lightning\/plugins\/training_type\/ddp_spawn.py in start_training(self, trainer)\r\n    120 \r\n    121     def start_training(self, trainer):\r\n--> 122         mp.spawn(self.new_process, **self.mp_spawn_kwargs)\r\n    123         # reset optimizers, since main process is never used for training and thus does not have a valid optim state\r\n    124         trainer.optimizers = []\r\n\r\n\/databricks\/python\/lib\/python3.8\/site-packages\/torch\/multiprocessing\/spawn.py in spawn(fn, args, nprocs, join, daemon, start_method)\r\n    197                ' torch.multiprocessing.start_process(...)' % start_method)\r\n    198         warnings.warn(msg)\r\n--> 199     return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\r\n\r\n\/databricks\/python\/lib\/python3.8\/site-packages\/torch\/multiprocessing\/spawn.py in start_processes(fn, args, nprocs, join, daemon, start_method)\r\n    146             daemon=daemon,\r\n    147         )\r\n--> 148         process.start()\r\n    149         error_queues.append(error_queue)\r\n    150         processes.append(process)\r\n\r\n\/databricks\/python\/lib\/python3.8\/multiprocessing\/process.py in start(self)\r\n    119                'daemonic processes are not allowed to have children'\r\n    120         _cleanup()\r\n--> 121         self._popen = self._Popen(self)\r\n    122         self._sentinel = self._popen.sentinel\r\n    123         # Avoid a refcycle if the target function holds an indirect\r\n\r\n\/databricks\/python\/lib\/python3.8\/multiprocessing\/context.py in _Popen(process_obj)\r\n    282         def _Popen(process_obj):\r\n    283             from .popen_spawn_posix import Popen\r\n--> 284             return Popen(process_obj)\r\n    285 \r\n    286     class ForkServerProcess(process.BaseProcess):\r\n\r\n\/databricks\/python\/lib\/python3.8\/multiprocessing\/popen_spawn_posix.py in __init__(self, process_obj)\r\n     30     def __init__(self, process_obj):\r\n     31         self._fds = []\r\n---> 32         super().__init__(process_obj)\r\n     33 \r\n     34     def duplicate_for_child(self, fd):\r\n\r\n\/databricks\/python\/lib\/python3.8\/multiprocessing\/popen_fork.py in __init__(self, process_obj)\r\n     17         self.returncode = None\r\n     18         self.finalizer = None\r\n---> 19         self._launch(process_obj)\r\n     20 \r\n     21     def duplicate_for_child(self, fd):\r\n\r\n\/databricks\/python\/lib\/python3.8\/multiprocessing\/popen_spawn_posix.py in _launch(self, process_obj)\r\n     45         try:\r\n     46             reduction.dump(prep_data, fp)\r\n---> 47             reduction.dump(process_obj, fp)\r\n     48         finally:\r\n     49             set_spawning_popen(None)\r\n\r\n\/databricks\/python\/lib\/python3.8\/multiprocessing\/reduction.py in dump(obj, file, protocol)\r\n     58 def dump(obj, file, protocol=None):\r\n     59     '''Replacement for pickle.dump() using ForkingPickler.'''\r\n---> 60     ForkingPickler(file, protocol).dump(obj)\r\n     61 \r\n     62 #\r\n\r\n\r\n","236":"### System information\r\n- **MLflow version: 1.19.0\r\n\r\n### Describe the problem\r\nOpen source version of MLflow allows a non-existent 'source' to be supplied to MLflowClient.create_model_version(). This allows a non-existent model to be registered, and the error is only caught when you try to fetch the model from the registry.\r\n\r\nHowever, when calling create_model_version() against the Databricks MLflow tracking server an error is reported. See error below.\r\n\r\n```\r\nFile \"\/Users\/andre\/venvs\/mlflow-export-import-env\/lib\/python3.7\/site-packages\/mlflow\/tracking\/_model_registry\/client.py\", line 221, in create_model_version\r\n    mv.name, mv.version, mv.status, mv.status_message\r\nmlflow.exceptions.MlflowException: Model version creation failed for model name: CDE_banner1000 version: 1 with status: FAILED_REGISTRATION                     and message: Failed registration. The given source path does not exist.\r\n```\r\n\r\n### Code to reproduce issue\r\nclient.create_model_version(\"my_model\", \"foo\", \"d36bf288007b4941a90d041c4e955557\")\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area\/server-infra`: MLflow Tracking server backend\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\n\r\n","237":"Hi there,\r\n\r\nI'm trying to use mlflow to run multiple experiments asynchronously using an MLproject file in a docker container which for now I'm running locally.\r\n\r\nMy MLproject file looks like this:\r\n\r\nname: active-learner\r\ndocker_env:\r\n  image: mlflow\/active-learning\r\n\r\nentry_points:\r\n  main:\r\n    parameters:\r\n      task_name: {type: str}\r\n      data_dir: path\r\n      test_size: {type: int}\r\n      train_sample_size: {type: int}\r\n      sampling_technique: {type: str}\r\n      estimator: {type: str}\r\n      query_strategy: {type: str}\r\n      n_queries: {type: int}\r\n      methods: {type: str}\r\n      output_dir: path\r\n      batch_size: {type: int, default: 3}\r\n    command: \"python train.py \\\r\n    --task_name {task_name} \\\r\n    --data_dir {data_dir} \\\r\n    --test_size {test_size} \\\r\n    --train_sample_size {train_sample_size} \\\r\n    --estimator {estimator} \\\r\n    --sampling_technique {sampling_technique} \\\r\n    --query_strategy {query_strategy} \\\r\n    --n_queries {n_queries} \\\r\n    --methods {methods} \\\r\n    --output_dir {output_dir} \\\r\n    --batch_size {batch_size}\"\r\n\r\nHere train.py contains the main function. However, I keep getting this issue while I'm running mlflow run on CLI or using another script file with mlflow.projects.run(github_URI) for multiple runs. I've looked up all possible fixes I can get but nothing seems to work on my end. Any help would be appreciated!!","238":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this documentation issue template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages documentation fix contributions. Would you or another member of your organization be willing to contribute a fix for this documentation issue to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a documentation fix independently.\r\n- [ x] Yes. I would be willing to contribute a document fix with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a documentation fix at this time.\r\n\r\n### URL(s) with the issue:\r\n\r\nhttps:\/\/www.mlflow.org\/docs\/latest\/models.html#custom-flavors\r\n\r\n### Description of proposal (what needs changing):\r\nIn order to be able to add support for our spark models that produce multidimensional output vectors I wanted to add a modified version of the mlflow.spark flavor without working on a fork of your project. I took the fact that this should be possible from the referenced url:\r\n\r\n`To create a new flavor to support a custom model, you define the set of flavor-specific attributes to include in the MLmodel configuration file, as well as the code that can interpret the contents of the model directory and the flavor\u2019s attributes.`\r\n\r\nSadly, I find it hard to understand how to do that given the documentation. \r\nDo I need to create a plugin for that?\r\nIf so, what endpoints do I need to implement?\r\n\r\nSimply adding a modified version of `mlflow\/spark.py ` where I adapted ...\r\n\r\n- the `predict` method\r\n- FLAVOR_NAME, DFS_TMP, _SPARK_MODEL_PATH_SUB\r\n- the default values of `flavor` params in several methods to point to this python file\r\n- the `loader_module` param in the `_save_model_metadata` function:\r\n```\r\npyfunc.add_to_model(\r\n        mlflow_model,\r\n        loader_module=\"flavors.custom_spark_flavor\",\r\n        data=_SPARK_MODEL_PATH_SUB,\r\n        env=conda_env_subpath,\r\n    )\r\n```\r\nto my project and calling this new `flavor`'s `log`  methods did not help, since the model still uses the original code of the predict method from  `mlflow\/spark.py `when being deployed with `mlflow serve`.\r\n\r\nAlso all attempts to create the respective scalar output using spark transformers did not succeed. I tried to use the SQLTransformer with udfs to extract classifier scores (in the `probability` output column of the model) values because I found no other transformer that takes a vector column as input and returns a scalar column. But those udfs like `vector_to_array` are not known when predictions are made with mlflow-logged and served models.\r\n\r\nIf someone could provide details or an example of how to add new flavors, I would love to contribute a document that explains the required steps to make it happen.","239":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\nI get this error when using mlflow with Pytorch llightning\r\n\r\n```\r\nFile \"\/usr\/local\/lib\/python3.7\/dist-packages\/pytorch_lightning\/loggers\/mlflow.py\", line 145, in experiment\r\n    expt = self._mlflow_client.get_experiment_by_name(self._experiment_name)\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/mlflow\/tracking\/client.py\", line 463, in get_experiment_by_name\r\n    return self._tracking_client.get_experiment_by_name(name)\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 155, in get_experiment_by_name\r\n    return self.store.get_experiment_by_name(name)\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/mlflow\/store\/tracking\/rest_store.py\", line 278, in get_experiment_by_name\r\n    response_proto = self._call_endpoint(GetExperimentByName, req_body)\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/mlflow\/store\/tracking\/rest_store.py\", line 56, in _call_endpoint\r\n    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/mlflow\/utils\/rest_utils.py\", line 164, in call_endpoint\r\n    host_creds=host_creds, endpoint=endpoint, method=method, params=json_body\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/mlflow\/utils\/rest_utils.py\", line 83, in http_request\r\n    max_rate_limit_interval, url=url, headers=headers, verify=verify, **kwargs\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/mlflow\/utils\/rest_utils.py\", line 62, in request_with_ratelimit_retries\r\n    response = requests.request(**kwargs)\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/requests\/api.py\", line 61, in request\r\n    return session.request(method=method, url=url, **kwargs)\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/requests\/sessions.py\", line 542, in request\r\n    resp = self.send(prep, **send_kwargs)\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/requests\/sessions.py\", line 697, in send\r\n    r.content\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/requests\/models.py\", line 836, in content\r\n    self._content = b''.join(self.iter_content(CONTENT_CHUNK_SIZE)) or b''\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/requests\/models.py\", line 761, in generate\r\n    raise ChunkedEncodingError(e)\r\nrequests.exceptions.ChunkedEncodingError: (\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))\r\n```\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [x] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Colab\r\n- **MLflow installed from (source or binary)**: Binary\r\n- **MLflow version (run ``mlflow --version``)**:\r\n- **Python version**:\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","240":"This makes it impossible to deploy the image in a Kubernetes Cluster without editing the MLFlow source directly by adding `-b 0.0.0.0:8000`  to `mlflow\/models\/docker_utils.py:36`. The standard serve CLI allows to set a host parameter, this should be possible with the build-docker CLI, too.","241":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux\r\n- **MLflow installed from (source or binary)**: source. master\r\n- **MLflow version (run ``mlflow --version``)**: 1.19.0.dev0\r\n- **Python version**: 3.9.2\r\n- **Exact command to reproduce**: `pytest`\r\n\r\n### Describe the problem\r\n\r\nI'm running the tests and some of them are failing, but I do not see any relevant logs since the whole log is overflown with deprecation warnings.\r\n\r\n### Code to reproduce issue\r\n`pytest`\r\n\r\n### Other info \/ logs\r\n```\r\ntests\/tracking\/fluent\/test_fluent.py::test_start_run_existing_run_from_environment\r\n  The Column.copy() method is deprecated and will be removed in a future release. (deprecated since: 1.4)\r\n  The ColumnCollectionConstraint.copy() method is deprecated and will be removed in a future release. (deprecated since: 1.4)\r\n  The ForeignKeyConstraint.copy() method is deprecated and will be removed in a future release. (deprecated since: 1.4)\r\n  The CheckConstraint.copy() method is deprecated and will be removed in a future release. (deprecated since: 1.4)\r\n\r\ntests\/tracking\/fluent\/test_fluent.py::test_start_run_existing_run_from_environment_with_set_environment\r\n  The Column.copy() method is deprecated and will be removed in a future release. (deprecated since: 1.4)\r\n  The ColumnCollectionConstraint.copy() method is deprecated and will be removed in a future release. (deprecated since: 1.4)\r\n  The ForeignKeyConstraint.copy() method is deprecated and will be removed in a future release. (deprecated since: 1.4)\r\n  The CheckConstraint.copy() method is deprecated and will be removed in a future release. (deprecated since: 1.4)\r\n...\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [x] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","242":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\nI propose somehow to give the user the ability to pass the `MLFLOW_TRACKING_URI`variable from the MLproject file instead of setting the environment variable. I think it is more controllable and easy to implement since you already take variables out of MLproject file \r\n\r\n## Motivation\r\n- What is the use case for this feature? \r\nIt is very useful whenever you want to set MLFLOW_TRACKING_URI \r\n- Why is this use case valuable to support for MLflow users in general? \r\nThis feature will solve a problem a lot of MLflow projects users has faced. Which is setting  `MLFLOW_TRACKING_URI` variable. If you set the `MLFLOW_TRACKING_URI` after running the `mlflow run` you will get a `RESOURCE NOT FOUND` error. This is because the run is create on one tracking URI and then you are trying to access it on another URI. This feature will help to avoid having this problem.\r\n- Why is this use case valuable to support for your project(s) or organization? \r\nAs most of organizations, we always try to log our output on a remote server so we always try to set MLFLOW_TRACKING_URI to a remote server instead logging locally \r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient) \r\nI don't think it is difficult to achieve\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [x] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","243":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [x] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: **1.19.0**\r\n- **Python version**: **3.6**\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n\r\nI have trained and logged a h2o model in mlflow. I'm getting **errors** when I try to use the model for predictions using `mlflow-sagemaker` functionality or plain prediction using `mlflow.pyfunc`\r\n\r\n### Code to reproduce issue\r\n\r\n   - Train Model (Used a Jupyter Notebook)\r\n   \r\n```python\r\n    # !pip install requests\r\n    # !pip install tabulate\r\n    # !pip install \"colorama>=0.3.8\"\r\n    # !pip install future\r\n    # !pip install -f http:\/\/h2o-release.s3.amazonaws.com\/h2o\/latest_stable_Py.html h2o\r\n    # !pip install mlflow\r\n    # !wget https:\/\/github.com\/mlflow\/mlflow-example\/blob\/master\/wine-quality.csv\r\n\r\n    import h2o\r\n    import random\r\n    import mlflow\r\n    import mlflow.h2o\r\n    from h2o.estimators.random_forest import H2ORandomForestEstimator\r\n    h2o.init()\r\n    wine = h2o.import_file(path=\"winequality.csv\")\r\n    r = wine['quality'].runif()\r\n    train = wine[r  < 0.7]\r\n    test  = wine[0.3 <= r]\r\n    mlflow.set_tracking_uri('https:\/\/mlflow.xxxxxxx.cloud\/')\r\n    mlflow.set_experiment(\"H2ORandomForestEstimator\")\r\n    \r\n    def train_random_forest(ntrees):\r\n        with mlflow.start_run():\r\n            rf = H2ORandomForestEstimator(ntrees=ntrees)\r\n            train_cols = [n for n in wine.col_names if n != \"quality\"]\r\n            rf.train(train_cols, \"quality\", training_frame=train, validation_frame=test)      \r\n            mlflow.log_param(\"ntrees\", ntrees)        \r\n            mlflow.log_metric(\"rmse\", rf.rmse())\r\n            mlflow.log_metric(\"r2\", rf.r2())\r\n            mlflow.log_metric(\"mae\", rf.mae())       \r\n            mlflow.h2o.log_model(rf, \"model\")        \r\n            h2o.save_model(rf)            \r\n            predict = rf.predict(test)        \r\n            print(predict.head())\r\n\r\n    for ntrees in [10, 20, 50, 100]:\r\n        train_random_forest(ntrees)\r\n```\r\n\r\n\r\n   - Build and Push SageMaker Container\r\n   \r\n```   \r\n    mlflow sagemaker build-and-push-container\r\n\r\n    mlflow sagemaker run-local --model-uri \"s3:\/\/mlflow-sagemaker\/1\/66f7c015fe8d4fb080940f3d31003f49\/artifacts\/model\"\r\n```    \r\n    \r\n\r\n   - Error when trying to invoke local endpoint\r\n\r\n```bash\r\n    curl -i -X POST -H \"Content-Type: application\/json; format=pandas-split\" -d '{\"fixed acidity\":\"8.1\", \"volatile acidity\":\"0.28\", \"citric acid\":\"0.4\", \"residual sugar\": \"6.9\", \"chlorides\": \"0.05\", \"free sulfur dioxide\": \"30\", \"total sulfur dioxide\": \"97\", \"density\": \"0.9951\", \"pH\": \"3.26\", \"sulphates\": \"0.44\",  \"alcohol\":\"10.1\"}' http:\/\/127.0.0.1:5000\/invocations\r\n\r\n    {\"error_code\": \"MALFORMED_REQUEST\", \"message\": \"Failed to parse input as a Pandas DataFrame. Ensure that the input is a valid JSON-formatted Pandas DataFrame with the `split` orient produced using the `pandas.DataFrame.to_json(..., orient='split')` method.\", \"stack_trace\": \"Traceback (most recent call last):\\n  File \\\"\/miniconda\/envs\/custom_env\/lib\/python3.6\/site-packages\/mlflow\/pyfunc\/scoring_server\/__init__.py\\\", line 117, in parse_json_input\\n    return _dataframe_from_json(json_input, pandas_orient=orient, schema=schema)\\n  File \\\"\/miniconda\/envs\/custom_env\/lib\/python3.6\/site-packages\/mlflow\/utils\/proto_json_utils.py\\\", line 130, in _dataframe_from_json\\n    path_or_str, orient=pandas_orient, dtype=False, precise_float=precise_float\\n  File \\\"\/miniconda\/envs\/custom_env\/lib\/python3.6\/site-packages\/pandas\/util\/_decorators.py\\\", line 199, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"\/miniconda\/envs\/custom_env\/lib\/python3.6\/site-packages\/pandas\/util\/_decorators.py\\\", line 296, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"\/miniconda\/envs\/custom_env\/lib\/python3.6\/site-packages\/pandas\/io\/json\/_json.py\\\", line 618, in read_json\\n    result = json_reader.read()\\n  File \\\"\/miniconda\/envs\/custom_env\/lib\/python3.6\/site-packages\/pandas\/io\/json\/_json.py\\\", line 755, in read\\n    obj = self._get_object_parser(self.data)\\n  File \\\"\/miniconda\/envs\/custom_env\/lib\/python3.6\/site-packages\/pandas\/io\/json\/_json.py\\\", line 777, in _get_object_parser\\n    obj = FrameParser(json, **kwargs).parse()\\n  File \\\"\/miniconda\/envs\/custom_env\/lib\/python3.6\/site-packages\/pandas\/io\/json\/_json.py\\\", line 886, in parse\\n    self._parse_no_numpy()\\n  File \\\"\/miniconda\/envs\/custom_env\/lib\/python3.6\/site-packages\/pandas\/io\/json\/_json.py\\\", line 1126, in _parse_no_numpy\\n    self.check_keys_split(decoded)\\n  File \\\"\/miniconda\/envs\/custom_env\/lib\/python3.6\/site-packages\/pandas\/io\/json\/_json.py\\\", line 876, in check_keys_split\\n    raise ValueError(f\\\"JSON data had unexpected key(s): {bad_keys}\\\")\\nValueError: JSON data had unexpected key(s): pH, free sulfur dioxide, volatile acidity, density, citric acid, chlorides, alcohol, fixed acidity, total sulfur dioxide, residual sugar, sulphates\\n\"}sh-4.2$ \r\n    \r\n```\r\n\r\n   - Also tried getting a prediction without using mlflow.pyfunc   \r\n```python   \r\n    import mlflow\r\n    logged_model = 's3:\/\/mlflow-sagemaker\/1\/66f7c015fe8d4fb080940f3d31003f49\/artifacts\/model'\r\n\r\n    # Load model as a PyFuncModel.\r\n    loaded_model = mlflow.pyfunc.load_model(logged_model)\r\n\r\n    # Predict on a Pandas DataFrame.\r\n    import pandas as pd\r\n    loaded_model.predict(pd.DataFrame(test))\r\n```\r\n```bash\r\n   Error\r\n   Job with key $03017f00000132d4ffffffff$_990da74b0db027b33cc49d1d90934149 failed with an exception: java.lang.IllegalArgumentException: Test\/Validation dataset has no columns in common with the training set  \r\n```\r\n\r\n   - Works fine when I load the model directly using h2o for prediction\r\n   \r\n```python   \r\n\r\n   model = h2o.load_model('DRF_model_python_1626812026003_6') \r\n\r\n   model.predict(test)\r\n   \r\n```\r\n```html\r\n   predict\r\n   --\r\n   5.82059\r\n   5.5\r\n   5.5\r\n   6\r\n   5.82059\r\n   5.9\r\n   5.88\r\n   5.1\r\n   5.3\r\n   5.3\r\n```\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [x] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations","244":"## What changes are proposed in this pull request?\r\n\r\n(Please fill in changes proposed in this fix)\r\nAs discussed a year ago in #2501, Running a MLflow project with docker_env fails to create the docker container whenever you try to log locally due to having the artifact cmd included in the docker cmd as you can see here https:\/\/github.com\/mlflow\/mlflow\/blob\/221fedc81679bd23fc68b2cb769b07ce5e8fe9f1\/mlflow\/projects\/backend\/local.py#L232\r\n\r\nI proposed that we remove the artifact cmd as it tries to include the artifact folder in the container which already included in tracking cmd. as you can see from the log here \r\n`2021\/07\/26 12:50:18 INFO mlflow.projects.backend.local: === Running command 'docker run --rm -v C:\\Users\\mlflow-docker\\mlruns:\/mlflow\/tmp\/mlruns -v C:\\Users\\mlflow-docker\\mlruns\\0\\c0447737c6d94573b93440ca3bcb1ab0\\artifacts:C:\\Users\\r\\mlflow-docker\\mlruns\\0\\c0447737c6d94573b93440ca3bcb1ab0\\artifacts -e MLFLOW_RUN_ID=c0447737c6d94573b93440ca3bcb1ab0 -e MLFLOW_TRACKING_URI=file:\/\/\/mlflow\/tmp\/mlruns -e MLFLOW_EXPERIMENT_ID=0 docker-example:b80c453 python train.py --alpha 0.5 --l1-ratio 0.1' in run with ID 'c0447737c6d94573b93440ca3bcb1ab0' ===`\r\n## How is this patch tested?\r\n\r\n(Details)\r\n\r\nFollowed the docker example and worked successfully\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","245":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nIt would be nice to have support to push images to private image\/container registry hosted on different cloud environments for the Kubernetes backend. Right now the images are not pushed to private repositories as they require `docker login` before pushing the image.\r\n\r\n## Motivation\r\n- What is the use case for this feature? Be able to store images in private registries instead of just public ones.\r\n- Why is this use case valuable to support for MLflow users in general? It is helpful in cases where users do not want to make their MLFlow project image publicly available. \r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient) There is no support of performing `docker login` before pushing the image to any private repository. \r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n\r\nI have performed a POC by pushing the image to a private repository on IBM Cloud Container registry with and without docker login. We essentially need to update `push_image_to_registry` method in the kubernetes.py file and perform a docker login before the image is pushed. For IBM Cloud Container registry, following worked for me:\r\n\r\n```\r\nclient = docker.from_env()\r\nclient.login(username=\"iamapikey\", password=\"<api_key>\", registry=\"us.icr.io\")\r\n```\r\n","246":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\nI have little experience in coding UI, though.\r\n\r\n## Proposal Summary\r\n\r\nIn the MLflow UI allow experiments to be grouped together in a folder structure, preferably multiple levels deep, which can be collapsed and expanded, so that experiments can be grouped together and sorted easily.\r\n\r\nPreferably, sort the experiments by name as well for clarity.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nWe have so many different experiments (with many training runs in each) that it becomes difficult to manage the list and keep an overview of the experiments. Being able to sort and group them would make it much simpler to manage them.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n\r\nI would like to be able to name my experiments\r\n```Project 1\/model 1.1\r\nProject 1\/model 1.2\r\nProject 1\/model 1.3\r\nProject 2\/model 2.1\r\nProject 2\/model 2.2\r\netc.\r\n```\r\n\r\nwhich would be rendered in the UI as collapsible and expandable folders:\r\n\r\n**Experiments**\r\n- Project 1\r\n    - model 1.1\r\n    - model 1.2\r\n    - model 1.3\r\n- Project 2\r\n    - model 2.1\r\n    - model 2.2\r\n- etc.\r\n\r\nMultiple levels of folders would be greatly appreciated, e.g. `Program X\/Project 3\/Component B\/model 1`","247":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nI'd like to be able to identify an MLflow Server's version as a client.\r\n- In the REST API\r\n- In the Python API\r\n- In the user interface\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nIn many companies the team responsible for maintaining the MLflow Server is a different team from the people using the server. As a data scientist I'm tracking and registering models to the server, but I'm not (always) informed when the server gets upgraded to a new version, and which version is being installed. I would like to make sure my client scripts\/programs use the correct MLflow version matching the server, so there are no problems in the client-server communication.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [?] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [?] `area\/examples`: Example code\r\n- [?] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [x] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nCan I add...?\r\n- [x] `language\/python`: Python APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n\r\n**REST API**:\r\n\r\nIt would be nice to have an endpoint\r\n```2.0\/mlflow\/server\/version```\r\nfor the HTTP method GET which would return a string with the server's version number.\r\n\r\n**Python API**:\r\n\r\nIn my scripts I'd like to be able to run:\r\n```import mlflow\r\nclient = mlflow.tracking.MlflowClient()\r\nserver_version = client.get_server_version()\r\n```\r\n\r\nor, perhaps better:\r\n\r\n```import mlflow\r\nclient = mlflow.tracking.MlflowClient()\r\nserver = client.get_server()\r\nserver_info = server.info\r\nserver_version = server_info.version\r\n```\r\n\r\nI think it would make sense to add `mlflow.entities.Server` and `mlflow.entities.ServerInfo` to the object model, which could in principle be expanded in the future with additional functionalities.\r\n\r\n**User interface**:\r\n\r\nWe could add an \"About\" section to the top menu bar, which can display a page with server information, including the version number. The link to the Docs could be changed to refer not to the latest documentation, but to the documentation corresponding to the current MLflow version number.","248":"The tutorials show how to load specific kinds of models (e.g. XGBoost model), but I see no way to easily log an existing saved MLFlow model.\r\nThis is confusing, since MLFlow tries to unify different model flavors.\r\n\r\nCould you make the following possible:\r\n```python\r\nModel.log(model_path=\"my_model.MLFlowModel\")\r\n# or (but I'm not sure it's a good idea since it will require specific packages to be installed)\r\nModel.load(model_path=\"my_model.MLFlowModel\").log()\r\n```","249":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nMake the width of experiments list sidebar in the tracking server UI adjustable (via a handle which shows when you hover the mouse on the right border)\r\n\r\n<img src=\"https:\/\/user-images.githubusercontent.com\/39926682\/126555363-a3cf45c3-ef30-48f7-9152-c71dd42fcf10.png\" width=\"40%\" height=\"40%\">\r\n\r\n## Motivation\r\n\r\n- What is the use case for this feature?\r\n\r\nThis would make it possible to view the full experiment names\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\n\r\nCurrently, longer names get truncated and there's no way to view the full names simultaneously for all experiments in the list. If you hover a given name, there is a tool tip that shows the full name, but that doesn't allow you to look at multiple at once. Requiring the user to hover their mouse over each one in the list is tedious\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n\r\nWe plan to use a naming schema to organize large numbers of experiments and make them easier to query programmatically. For example, `modeling_task\/architecture\/[feature,release]\/title`. As seen in the screenshot, most of these are too long to display at the current fixed width. I imagine a naming schema is common practice at many other organizations as well\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nThere is no drag-able handle to adjust the sidebar width, and zooming out in the browser doesn't help either\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","250":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\n- [x] Yes. I can contribute a fix for this bug independently.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.x\r\n- **MLflow installed from (source or binary)**: Source\r\n- **MLflow version (run ``mlflow --version``)**: mlflow, version 1.17.0\r\n- **Python version**: 3.8\r\n\r\n### Describe the problem\r\nWhen using `mlflow.keras.autolog()`, an error occurs: \r\n`ModuleNotFoundError: No module named 'keras'`\r\n\r\nSeems to be because the source imports `keras`, and not `tensorflow.keras`. Since Keras is now part of TensorFlow, should it be doing `import tensorflow.keras` instead, by default? \r\n\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/cfed457438f6a20b02557e25c0de66f488ec5a41\/mlflow\/keras.py#L631\r\n\r\n\r\n### Code to reproduce issue\r\n```\r\nimport mlflow\r\nmlflow.keras.autolog()\r\n```","251":"### Willingness to contribute\r\nThe MLflow Community encourages documentation fix contributions. Would you or another member of your organization be willing to contribute a fix for this documentation issue to the MLflow code base?\r\n\r\n- [x] Yes. I can contribute a documentation fix independently.\r\n- [ ] Yes. I would be willing to contribute a document fix with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a documentation fix at this time.\r\n\r\n### URL(s) with the issue:\r\n\r\nhttps:\/\/www.mlflow.org\/docs\/latest\/projects.html\r\n\r\n### Description of proposal (what needs changing):\r\n\r\nThe overall MLflow Projects page is confusing to some extent:\r\n- [ ]  Instead of using the sections titles \"Project Directories\" and \"MLproject File\" it would be easier to understand if they were called \"Without MLproject File\" and \"With MLproject File\" (only for example, maybe some other wording comes to mind).\r\n- [ ] The example MLproject file contains whitespaces in the project's name, this causes Docker to not accept the image URI. It is necessary to show at least a note that for Docker, the name must not contain any whitespaces.\r\n- [ ] There's no information that you need `-P` to provide parameters (except for one example run which runs a git repository and there's no real explanation accompanying it). It would be nice if that was explained where the parameters are introduced (https:\/\/www.mlflow.org\/docs\/latest\/projects.html#specifying-parameters).\r\n- [ ] There's no example command for a local run, only for the remote git repository. There's also no example how to specify different entrypoints instead of using `main` (for which you need the `-e` flag).\r\n- [ ] Although the documentation states that it creates a new Docker image, it doesn't mention that for both Conda and Docker, it uses the current commit hash appended to the name to create a new Conda environment and Docker image respectively.\r\n- [ ] Generally I feel like it would make sense to put the MLproject file in the center of attention of the documentation and provide an example config with some bold note underneath stating that you can also run projects without MLproject files. It might be that people use MLflow projects without an MLproject file but I suspect most people do and having an example file at the top makes everything pretty clear immediately and the project files are a central part. Having an example command how to run the project (remotely and locally) directly underneath would also be handy. After this short introduction, the more in-depth explanations could follow.\r\n\r\nI could contribute the smaller fixes, like adding missing information, and would like to collaborate for the larger restructurings (if any wanted at all).","252":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nIf I understand correctly, [MLflow Signature](https:\/\/www.mlflow.org\/docs\/latest\/models.html#model-signature) does not support optional columns or columns containing sequential data (columns containing lists etc...). For example following dataframe has column `list_column` inferred as `string` instead of something like `List[string]`.\r\n\r\n```\r\nfrom mlflow.models.signature import infer_signature\r\ninfer_signature(pd.DataFrame([{'list_column': [1, 2, 3]}]), None)\r\n```\r\n\r\nMy proposal is to add support for those use cases \/ for at least one of them.\r\n\r\n## Motivation\r\n\r\nRight now we have use cases where model to make a prediction requires a dataframe with some specific columns but also can use some additional ones if they are present. For example `modelA` requires dataframe only with column 'b' but if `c` is present it'll also be used. The missing support for this is stopping us from using MLflow Signature. In addition to, this we're a bit worried about no support for sequential data types (`list` etc..) in MLflow signature. I believe those two features could make MLFlow Signature more flexible.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","253":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\ndask-ml is a part of the larger dask ecosystem, and provides a few interfaces for running certain machine learning tasks at scale using dask. dask-ml provides scikit-learn interfaces for the implemented estimators. \r\n[dask-ml](https:\/\/ml.dask.org\/index.html)\r\n\r\nAn example would be [GridSearchCV](https:\/\/ml.dask.org\/modules\/generated\/dask_ml.model_selection.GridSearchCV.html#dask_ml.model_selection.GridSearchCV) which allows the user to train any scikit learn compatible model\/estimator over a hyperparameter grid in a parallel way (using dask).\r\n\r\n## Motivation\r\n- What is the use case for this feature? **support autolog for dask-ml estimators**\r\n- Why is this use case valuable to support for MLflow users in general? **autolog support for dask-ml would enable a one line integration for users of dask-ml by calling an equivalent to mlflow.sklearn.autolog(). There could also be some dask specific metrics or something that can be added if we find that useful**\r\n- Why is this use case valuable to support for your project(s) or organization? **ease of use** \r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient) **currently there is no integration with dask for autolog. We need to call the various tracking apis for log model, metrics, artifacts, etc.. after we do a run with dask. The sklearn implementation also has support for things like parameter search models in autolog that would be helpful in this context as well**\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nThere is a related github issue #3966 with slightly different use case. There is discussion there around potentially sharing code between distributed computing platforms. Another idea I had was to somehow make an autolog feature that accepts any estimator\/class with the sklearn API (can be done as some kind of registration thing or pass the class reference through for patching). But maybe making an autolog function specific to dask-ml might be better since it will have it's own idiosyncrasies.\r\n\r\nBy studying some of the code I was able to monkey patch in a few things into the existing sklearn autolog support (basically I tricked the mlflow code into patching the dask-ml code). Particularly `_get_meta_estimators_for_autologging` and `_is_parameter_search_estimator` in sklearn\/utils.py . This seems to work for GridSearchCV and RandomizedSearchCV in dask-ml since they are drop-in replacements for the sklearn equivalents. I had less luck for some of the other hyperparameter search functions.","254":"I have deployed my model into mlflow by using data bricks by using below code\r\n\r\nwith mlflow.start_run(): \r\n  mlflow.sklearn.log_model(\r\n        sk_model = sample_model,\r\n        artifact_path = \"samplefolder\",\r\n        registered_model_name = \"sample-mlmodel\",\r\n        serialization_format = mlflow.sklearn.SERIALIZATION_FORMAT_PICKLE,\r\n        conda_env = conda_env\r\n    )\r\n\r\nI go to verify Machine Learning models in Databricks and I see as below and I have observed python_function favlor is missing and it is causing issue when it is trying to deploy using ACI. Can you please help me how to resolve the issue,\r\n\r\nartifact_path: retailstores\r\ndatabricks_runtime: 8.2.x-scala2.12\r\nflavors:\r\n  sklearn:\r\n    pickled_model: model.pkl\r\n    serialization_format: pickle\r\n    sklearn_version: 0.23.2\r\nrun_id: 50fdab13993446aeb6c5ec854xxx1731\r\nutc_time_created: '2021-07-15 18:06:23.574932'\r\n","255":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time (sadly lacking the competence for front-end development).\r\n\r\n## Proposal Summary\r\n\r\nRun information can be nested to arbitrary levels and that seems to get correctly stored in the data, however, the information is not shown properly nested in the GUI and everything below the top level run is shown at the same level. \r\nIt would be extremely useful to visualize nested information properly. \r\n\r\n## Motivation\r\n\r\nAlmost all proper ML experiments are nested more deeply than one level: an experiment consists maybe of several runs with different hyperparameter values, where each nested run is e.g. a cross validation estimation step, which consists of k training\/test evaluation steps. \r\n\r\n","256":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nHello everyone,\r\n\r\nI would like to be able to add the possibility to add user rights to mlflow tracking, in order to limit the view of experiments only to people who have the right to do so, all this using a single tracking server, so a user to connect to the tracking server will provide a token.\r\n\r\nI'm a new mlflow user so I'd like to have some hints to start and if you think it's feasible (with a plugin or by modifying the base source code),\r\n\r\nThanks in advance for your answers !\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [x] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n","257":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**:binary\r\n- **MLflow version (run ``mlflow --version``)**:1.18\r\n- **Python version**:3.8.5\r\n- **npm version, if running the dev UI**:NA\r\n- **Exact command to reproduce**:NA\r\n\r\n### Describe the problem\r\n- Docker image has been created by command 'mlflow sagemaker build-and-push-container'\r\n- Model is a pyfunc wrapper around PyTorch Lightning model (for GPU)\r\n- Later execution of 'mlflow sagemaker deploy -t ml.g4dn.4xlarge ...' fails due to an error in the process of creation of new endpoint:\r\n\"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/torch\/cuda\/__init__.py:52: UserWarning: CUDA initialization: CUDA driver initialization failed, you might not have a CUDA gpu. (Triggered internally at  \/opt\/conda\/conda-bld\/pytorch_1623448265233\/work\/c10\/cuda\/CUDAFunctions.cpp:115.)\r\n  return torch._C._cuda_getDeviceCount() > 0\"\r\n  \r\n  it seems that default image does not support gpu, what fix\/workaround can you recommend?\r\n\r\n### Other info \/ logs\r\n[log-events-viewer-result (4).csv](https:\/\/github.com\/mlflow\/mlflow\/files\/6806850\/log-events-viewer-result.4.csv)\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [x] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","258":"## What changes are proposed in this pull request?\r\n\r\nGCS has a default chunk size of 100Mb and a default timeout per chunk of 60 seconds, so an upload speed of 13.3Mbps is required to be able to log an artifact over 100Mb with the default settings. This is discussed at length in this issue on the python-storage module of googleapis: https:\/\/github.com\/googleapis\/python-storage\/issues\/74. I propose we increase the default timeout from 1 minute to 10, thereby allowing a minimum upload speed of 1.3Mbps to complete a 100Mb upload in the allotted time. At the very least I think Mlflow should accept a user override for this parameter. Thanks for reading!\r\n\r\n## How is this patch tested?\r\n\r\nJust tested it locally by overriding the default timeout like so:\r\n```python\r\nfrom google.cloud import storage\r\nstorage.blob._DEFAULT_TIMEOUT = 600\r\n\r\n# and then this works!\r\nmlflow.log_artifact('\/path\/to\/some\/big\/file.tar.gz')\r\n```\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nYou can now pass a `timeout=` keyword argument to `log_artifact` and `log_artifacts`. It will be passed along to the calls to GCS.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","259":"I'm deploying an model locally as REST API: `mlflow models serve -m file:\/\/\/D:\/MLflow_code\/mlruns\/0\/{model_id}\/artifacts\/model -p {port} `\r\n\r\nI would like to use a command to stop the local model deployment, but I've not found anyway to do it.\r\n`mlflow deployment delete` seems to work on the deployment in other locations, not locally.\r\n\r\nHow do I achieve this work?","260":"**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nI feel like the current solution for passing loader_module's as a string that importlib.importmodule is run on can be amended to also allow for directly adding the _load_pyfunc function as an object to the model as it is being saved. This way the loader_module is also more robust because it doesn't matter if the original function is changed or moved.\r\n\r\n## Motivation\r\n- What is the use case for this feature? The use case is for model logging.\r\n- Why is this use case valuable to support for MLflow users in general? It is safer and more robust.\r\n- Why is this use case valuable to support for your project(s) or organization? It allows us to log models with a more Pythonic and safe to change way.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient) Because we must pass in a string with the exact path to the loader_module.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n","261":"## What changes are proposed in this pull request?\r\n\r\nPrint in the logs the Docker build errors to ease debugging issues.\r\nCurrently if an error occurs in this phase, the user is completely blind and this makes the debugging very complicated.\r\n\r\n## How is this patch tested?\r\n\r\nManually\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nSee PR description.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","262":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS BigSur\r\n- **MLflow installed from (source or binary)**:  source\r\n- **MLflow version (run ``mlflow --version``)**: 1.18.0\r\n- **Python version**: 3.8.10\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: \r\n`mlflow server --backend-store-uri sqlite:\/\/\/mlflow.db --default-artifact-root .\/artifacts &`\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\nWhen trying to start mlflow server I get the error RuntimeError: Could not parse python long as longdouble: -64 (Invalid argument). Though if I try a couple of times, it goes away w\/o doing anything.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nmlflow server --backend-store-uri sqlite:\/\/\/mlflow.db --default-artifact-root .\/artifacts &\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nthe full env is here: [reqs_bug_report.txt](https:\/\/github.com\/mlflow\/mlflow\/files\/6762058\/reqs_bug_report.txt)\r\nthe error log:\r\n```\r\nmlflow server --backend-store-uri sqlite:\/\/\/mlflow.db --default-artifact-root .\/artifacts &\r\n[2021-07-05 12:46:35 +0800] [67549] [INFO] Starting gunicorn 20.1.0\r\n[2021-07-05 12:46:35 +0800] [67549] [INFO] Listening at: http:\/\/127.0.0.1:5000 (67549)\r\n[2021-07-05 12:46:35 +0800] [67549] [INFO] Using worker: sync\r\n[2021-07-05 12:46:35 +0800] [67551] [INFO] Booting worker with pid: 67551\r\n[2021-07-05 12:46:35 +0800] [67552] [INFO] Booting worker with pid: 67552\r\n[2021-07-05 12:46:35 +0800] [67553] [INFO] Booting worker with pid: 67553\r\n[2021-07-05 12:46:35 +0800] [67554] [INFO] Booting worker with pid: 67554\r\n[2021-07-05 12:46:36 +0800] [67554] [ERROR] Exception in worker process\r\nTraceback (most recent call last):\r\n  File \"\/Users\/user\/opt\/anaconda3\/envs\/traffic-prediction\/lib\/python3.8\/site-packages\/gunicorn\/arbiter.py\", line 589, in spawn_worker\r\n    worker.init_process()\r\n  File \"\/Users\/user\/opt\/anaconda3\/envs\/traffic-prediction\/lib\/python3.8\/site-packages\/gunicorn\/workers\/base.py\", line 134, in init_process\r\n    self.load_wsgi()\r\n  File \"\/Users\/user\/opt\/anaconda3\/envs\/traffic-prediction\/lib\/python3.8\/site-packages\/gunicorn\/workers\/base.py\", line 146, in load_wsgi\r\n    self.wsgi = self.app.wsgi()\r\n  File \"\/Users\/user\/opt\/anaconda3\/envs\/traffic-prediction\/lib\/python3.8\/site-packages\/gunicorn\/app\/base.py\", line 67, in wsgi\r\n    self.callable = self.load()\r\n  File \"\/Users\/user\/opt\/anaconda3\/envs\/traffic-prediction\/lib\/python3.8\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 58, in load\r\n    return self.load_wsgiapp()\r\n  File \"\/Users\/user\/opt\/anaconda3\/envs\/traffic-prediction\/lib\/python3.8\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 48, in load_wsgiapp\r\n    return util.import_app(self.app_uri)\r\n  File \"\/Users\/user\/opt\/anaconda3\/envs\/traffic-prediction\/lib\/python3.8\/site-packages\/gunicorn\/util.py\", line 359, in import_app\r\n    mod = importlib.import_module(module)\r\n  File \"\/Users\/user\/opt\/anaconda3\/envs\/traffic-prediction\/lib\/python3.8\/importlib\/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 961, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 848, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"\/Users\/user\/opt\/anaconda3\/envs\/traffic-prediction\/lib\/python3.8\/site-packages\/mlflow\/__init__.py\", line 50, in <module>\r\n    import mlflow.catboost as catboost  # noqa: E402\r\n  File \"\/Users\/user\/opt\/anaconda3\/envs\/traffic-prediction\/lib\/python3.8\/site-packages\/mlflow\/catboost.py\", line 24, in <module>\r\n    from mlflow import pyfunc\r\n  File \"\/Users\/user\/opt\/anaconda3\/envs\/traffic-prediction\/lib\/python3.8\/site-packages\/mlflow\/pyfunc\/__init__.py\", line 210, in <module>\r\n    import numpy as np\r\n  File \"\/Users\/user\/opt\/anaconda3\/envs\/traffic-prediction\/lib\/python3.8\/site-packages\/numpy\/__init__.py\", line 228, in <module>\r\n    core.getlimits._register_known_types()\r\n  File \"\/Users\/user\/opt\/anaconda3\/envs\/traffic-prediction\/lib\/python3.8\/site-packages\/numpy\/core\/getlimits.py\", line 184, in _register_known_types\r\n    epsneg_f80 = exp2(ld(-64))\r\nRuntimeError: Could not parse python long as longdouble: -64 (Invalid argument)\r\n[2021-07-05 12:46:36 +0800] [67554] [INFO] Worker exiting (pid: 67554)\r\n[2021-07-05 12:46:37 +0800] [67551] [INFO] Worker exiting (pid: 67551)\r\n[2021-07-05 12:46:37 +0800] [67552] [INFO] Worker exiting (pid: 67552)\r\n[2021-07-05 12:46:37 +0800] [67553] [INFO] Worker exiting (pid: 67553)\r\n[2021-07-05 12:46:37 +0800] [67549] [INFO] Shutting down: Master\r\n[2021-07-05 12:46:37 +0800] [67549] [INFO] Reason: Worker failed to boot.\r\nRunning the mlflow server failed. Please see the logs above for details.\r\n```\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [x] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","263":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this documentation issue template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages documentation fix contributions. Would you or another member of your organization be willing to contribute a fix for this documentation issue to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a documentation fix independently.\r\n- [x] Yes. I would be willing to contribute a document fix with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a documentation fix at this time.\r\n\r\n### URL(s) with the issue:\r\nhttps:\/\/www.mlflow.org\/docs\/latest\/tutorials-and-examples\/tutorial.html#conda-example\r\n\r\n### Description of proposal (what needs changing):\r\nIn the R part of the documentation it is stated that one should use the `mlflow_snapshot` function to create a R dependencies Packrat file. Later the `mlflow_restore_snapshot` function is mentioned. Both functions don't exist anymore. They have been deliberately removed: https:\/\/github.com\/mlflow\/mlflow\/pull\/1263.\r\nIt is not clear to me what the new way of managing dependencies based upon `renv` is. I cannot find any documentation about it.\r\nThe documentation should be changed to reflect the current way to manage dependencies in R in MLflow.","264":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [X] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- No custom code\r\n- Databricks Cluster running on AWS c4.2xlarge, Databricks Runtime: 7.3 LTS (includes Apache Spark 3.0.1, Scala 2.12)\r\n- source\r\n- version 1.18.0\r\n- Python 3.7.5\r\n- N\/A\r\n- N\/A\r\n\r\n### Describe the problem\r\nWhen pushing to SageMaker via a Databricks scheduled job the container fails to initialize with the following message:\r\n\r\n```The primary container for production variant testendpoint1-model--oeh3uvttxe4vqzcfyablvg did not pass the ping health check. Please check CloudWatch logs for this endpoint.```\r\n\r\nWhen inspecting the CloudWatch logs one sees the following message\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"\/opt\/mlflow\/mlflow\/models\/container\/__init__.py\", line 48, in _init\r\n    _serve()\r\n  File \"\/opt\/mlflow\/mlflow\/models\/container\/__init__.py\", line 63, in _serve\r\n    m = Model.load(model_config_path)\r\n  File \"\/opt\/mlflow\/mlflow\/models\/__init__.py\", line 60, in load\r\n    return cls(**yaml.safe_load(f.read()))\r\nTypeError: __init__() got an unexpected keyword argument 'databricks_runtime'\r\n```\r\n### Code to reproduce issue\r\n1. Create a notebook that pushes a model to SageMaker\r\n2. Schedule the notebook to run by scheduling a job within Databricks\r\n3. Check CloudWatch logs to see error message.\r\n\r\n```\r\nregion = \"us-west-2\"\r\nlogged_model = 'runs:\/' + run_id + '\/model'\r\nimage_ecr_url = \"414351767826.dkr.ecr.us-west-2.amazonaws.com\/mlflow-pyfunc:1.4.0\"\r\nmfs.deploy(app_name='endpoint_name', model_uri=logged_model, image_url=image_ecr_url, region_name=region, mode=\"replace\")\r\n```\r\n### Other info \/ logs\r\nI inspected the MLmodel files that were generated. I noticed that there is an additional 'databricks_runtime' that is added to the file which it seems is a keyword arg not compatible with the hosting container. I'm not sure why this databricks_runtime field is being added all of a sudden (perhaps an MLFlow upgrade on our end?). I am pretty sure we have 1.18 MLFlow, and the container is 1.4 -- so this is likely the culprit.\r\n```\r\nartifact_path: model\r\ndatabricks_runtime: 7.3.x-scala2.12\r\nflavors:\r\n  python_function:\r\n    artifacts:\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [X] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","265":"Checks the OS, and if Windows, then formats model_path so that mlflow_load_flavor() and read_yaml() in mlflow_load_model() can read from the right directory, which otherwise throws an error.\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nA check that if on Windows, corrects the local model_path so that R in Windows can read it.\r\n\r\n## How is this patch tested?\r\n\r\nTested by building R package, and by loading a model in both Windows (works now) and Ubuntu (did not break anything). \r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [x] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [x] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","266":"## What changes are proposed in this pull request?\r\n\r\n- Add support for azure-identity when authenticating with an Azure storage accounts. See https:\/\/pypi.org\/project\/azure-identity\/ for more details of the authentication types available. \r\n- Namespace the environment variable for AZURE_STORAGE_CONNECTION_STRING to MLFLOW_AZURE_STORAGE_CONNECTION_STRING to avoid conflict. \r\n-  Address  #3483\r\n## How is this patch tested?\r\n\r\nBit week on that front but I'm open to advises. \r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n- Add support for azure-identity credentials when setting MLFLOW_USE_AZURE_IDENTITY environment variable to True. \r\n- MLFLOW_AZURE_STORAGE_CONNECTION_STRING is also a valid environment variable for AZURE_STORAGE_CONNECTION_STRING \r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [x] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","267":"I wonder if there is the possibility to use mlflow for embedded machine learning where ml-models are trained and afterward optimized with certain quantization methods with the use of e.g. TensorFlow-Lite Converter and are deployed to remote target (bare-metal or embedded Linux device). I am looking to track their accuracy vs. the original floating-point model (reference) and its latency. I'd like to monitor this over time and improve it by retraining, acquiring more real-time data, and its use case deployment as well there are multiple remote target scenarios to execute (so-called delegates - TensorFlow terminology) \r\nI'd like to have it distinguishable (configurable) within or per mlflow project.\r\n\r\nIs it possible to use mlflow to deploy, monitor, and track ml-model over full ml life-cycle for remote embedded devices (e.g. RPi-class, bare-metal device, freeRTOS, etc..)?\r\nIs it possible to start off with pre-trained models (e.g. tfhub)?\r\n\r\nIf so, can you refer to some mlflow examples on embedded machine learning and its deployment for embedded remote target?\r\n\r\nThank you.","268":"### URL(s) with the issue: https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.azureml.html#mlflow.azureml.deploy\r\n\r\nObserved a conflict between the mlflow document &  code . mlflow.azureml.deploy doc says model_uri takes \r\n`models:\/<model_name>\/<stage>` format but code accepts only `models:\/<model_name>\/<model_version>`\r\n\r\nwhile the code comment says it is not supported yet\r\n```\r\n# If we are passed a 'models' uri, we will attempt to extract a name and version which\r\n# can be used to retreive an AzureML Model. This will ignore stage based model uris,\r\n```\r\n##code:\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/9ce80db9c344076806264f00cb80c17c0efef808\/mlflow\/azureml\/__init__.py#L397\r\n\r\n\r\nPassed model uri: models:\/model-name\/Production got into error\r\n`ValueError: invalid literal for int() with base 10: 'Production'`\r\n\r\n### Description of proposal (what needs changing):\r\nRemove `models:\/<model_name>\/ <stage>` from the model_uri parameter option in the doc\r\n\r\n","269":"\r\n\r\n\r\n\r\n**Please fill in this installation issue template to ensure a timely and thorough response.**\r\n\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: window \r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.18.0\r\n- **Python version**:  3.8.3\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nRun mlflown on window os. step below:\r\n1. `mlflow ui --backend-store-uri sqlite:\/\/\/mlflow.db --default-artifact-root file:\/\/\/D:\/opensource\/mlruns --host 127.0.0.1 -p 5001`\r\n2. `mlflow run mlflow-example -P alpha=0.3 --no-conda`\r\n\r\nproblem:\r\nNo artifacts    \r\n![image](https:\/\/user-images.githubusercontent.com\/648508\/123220944-ff9b0d80-d500-11eb-8927-0f82353de5c9.png)\r\n\r\n\r\n\r\n","270":"**URL(s) with the issue:** https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.tracking.html#mlflow.tracking.MlflowClient.download_artifacts\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/tracking\/client.py#L1351-L1391 \r\n\r\nThe code example provided in the link above -  for download_artifacts API is failing with error  - NotADirectoryError: [Errno 20] Not a directory: due to line#20 in the below code snippet. The last two lines need to be modified to refer to list local_dir instead of local_path . \r\n\r\n **Current issue code in the mlflow documentation for download_artifacts API**\r\n\r\n```\r\nimport os\r\nimport mlflow\r\nfrom mlflow.tracking import MlflowClient\r\n\r\nfeatures = \"rooms, zipcode, median_price, school_rating, transport\"\r\nwith open(\"features.txt\", 'w') as f:\r\n    f.write(features)\r\n\r\n# Log artifacts\r\nwith mlflow.start_run() as run:\r\n    mlflow.log_artifact(\"features.txt\", artifact_path=\"features\")\r\n\r\n# Download artifacts\r\nclient = MlflowClient()\r\nlocal_dir = \"\/tmp\/artifact_downloads\"\r\nif not os.path.exists(local_dir):\r\n    os.mkdir(local_dir)\r\nlocal_path = client.download_artifacts(run.info.run_id, \"features\", local_dir)\r\nprint(\"Artifacts downloaded in: {}\".format(local_path))\r\nprint(\"Artifacts: {}\".format(os.listdir(local_path)))\r\n```\r\n\r\n**The corresponding github page of the docs:** \r\n\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/tracking\/client.py#L1351-L1391 \r\n \r\n**Description of the proposal (what needs changing):**\r\n. The last two lines need to be modified to refer to list local_dir instead of local_path . \r\n","271":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this documentation issue template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages documentation fix contributions. Would you or another member of your organization be willing to contribute a fix for this documentation issue to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a documentation fix independently.\r\n- [x] Yes. I would be willing to contribute a document fix with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a documentation fix at this time.\r\n\r\n### URL(s) with the issue:\r\nhttps:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.register_model\r\n\r\n### Description of proposal (what needs changing):\r\n\r\nWhen you click \"source\", no source code appears. Instead you get an \"access denied\" error:\r\n```\r\n<Error>\r\n<Code>AccessDenied<\/Code>\r\n<Message>Access Denied<\/Message>\r\n<RequestId>STEZJ8TN2027Z5HQ<\/RequestId>\r\n<HostId>RD10\/JDYs3cP+z63gnwRB2\/qTtlK\/PyNGwpbsfUuHpDx+G1iQ7TzNdc\/zZPzuQgC+NfssfOcNlc=<\/HostId>\r\n<\/Error>\r\n```","272":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [X] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: 1.18.0\r\n- **Python version**: 3.8.5\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: Code below\r\n\r\n### Describe the problem\r\n`mlflow.tensorflow.log_model` is incompatible with modern TF2 model saving.\r\n\r\nThe documentation states `Note that autologging for tf.keras is handled by mlflow.tensorflow.autolog(), not mlflow.keras.autolog()` and this has lead to a few people (myself included) attempting to save keras models using the tensorflow package instead of the `mlflow.keras` package, believing that the `mlflow.keras` package is for v1 Keras models (prior to it being bought inside `tf.keras`. \r\n\r\nI'd suggest a few potential improvements:\r\n\r\n1. Being explicit in the documentation under `mlflow.tensorflow` and `mlflow.keras` that `tf.keras` models should be manually logged using `mlflow.keras` but automatically logged using `mlflow.tensorflow.autolog`\r\n2. Potentially checking the signatures of the model when using `mlflow.tensorflow.load_model` to provide a proper error message to the user that they should be using `mlflow.keras`\r\n3. Increasing the versatility of the `mlflow.tensorflow.save_model` function to handle both `tf` and `tf.keras` models. It seems this functionality must be buried somewhere in `mlflow` as the `autolog` function will correctly save and load both `tf` and `tf.keras` models.\r\n\r\n### Code to reproduce issue\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport pandas as pd\r\nimport mlflow.tensorflow\r\nimport mlflow.pyfunc\r\n\r\nif __name__ == \"__main__\":\r\n    mlflow.set_tracking_uri(\"mlruns\")\r\n    mlflow.set_experiment(\"Default\")\r\n    run = mlflow.start_run()\r\n    # Note that the model works correctly WITH autolog, but not when logging the\r\n    # model manually. Uncomment the below line and comment out the explicit\r\n    # log_model and the code will run. Which probably indicates in incompatibility\r\n    # with mlflow and the modern TF2 way of saving models, as autolog uses v1 methods\r\n    # under the hood\r\n    # mlflow.tensorflow.autolog()\r\n\r\n    # Create dummy data\r\n    n = 10000\r\n    cols = [\"a\", \"b\", \"c\"]\r\n    x_train = pd.DataFrame(10 * np.random.normal(size=(n, 3)), columns=cols)\r\n    x_test = pd.DataFrame(10 * np.random.normal(size=(n, 3)), columns=cols)\r\n    y_train = np.random.uniform(size=n) + x_train.sum(axis=1)\r\n    y_test = np.random.uniform(size=n) + x_test.sum(axis=1)\r\n\r\n    # Build the model\r\n    model = tf.keras.models.Sequential([tf.keras.layers.Dense(1)])\r\n    model.compile(loss=\"mae\")\r\n    model.fit(x_train, y_train, epochs=1)\r\n    model.evaluate(x_test, y_test)\r\n\r\n    # Save the model\r\n    tempdir = \"\/tmp\/model\"\r\n    model.save(tempdir)\r\n\r\n    # Verify the model works\r\n    model = tf.keras.models.load_model(tempdir)\r\n    print(model.predict(x_test))  # Works fine\r\n\r\n    # Log and load the model to mlflow\r\n    mlflow.tensorflow.log_model(\r\n        tf_saved_model_dir=tempdir,\r\n        tf_meta_graph_tags=None,\r\n        tf_signature_def_key=\"serving_default\",\r\n        artifact_path=\"model\",\r\n    )\r\n    mlflow.end_run()\r\n    model_uri = f\"mlruns\/0\/{run.info.run_id}\/artifacts\/model\"\r\n\r\n    # Load the model from mlflow\r\n    model = mlflow.pyfunc.load_model(model_uri)\r\n    # Invoke the model\r\n    print(model.predict(x_test))\r\n    # TypeError: signature_wrapper(*, dense_input) missing required arguments: dense_input\r\n```\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [X] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","273":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [*] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Container with python3.8-slim base image\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: anything greater than >1.11.0, i am trying to make it work for 1.17.0\r\n- **Python version**: 3.8-slim\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: exec gunicorn -b \"0.0.0.0:8080\" -w 4 --log-level debug --access-logfile=- --error-logfile=- --log-level=debug mlflow_auth:app\r\n------------------------\r\n### Describe the problem\r\nThe mlflow server is working fine with the same setup(deployed on cloud run, artifact store: gcs bucket, backend : postgresql db on gcp cloud sql instance) with mlflow version 1.11.0, and pg8000 version 1.16.5, when i try to upgrade the mlflow version to 1.17.0 or any other version greater thatn 1.11.0, it requires a pg8000 version >1.16.6, when i provide the greater version, i get many errors in the cloud run logs. \r\n\r\n### Code to reproduce issue\r\n- files and commands used mentioned below\r\n-----------------\r\nrequirements.txt\r\n------------------\r\ngoogle-cloud-storage==1.31.2\r\nmlflow==1.17.0\r\nclick==7.1.2\r\npg8000==1.16.6\r\ngunicorn==20.0.4\r\npsycopg2-binary==2.8.6\r\n\r\n-----------------\r\nmlflow_auth.py\r\n-----------------\r\nfrom mlflow.server import app as mlflow_app\r\nfrom wsgi_basic_auth import BasicAuth\r\n\r\napp = BasicAuth(mlflow_app)\r\n\r\n----------------\r\nentry-point.sh\r\n----------------\r\nexport _MLFLOW_SERVER_ARTIFACT_ROOT=gs:\/\/mybucket\r\nexport _MLFLOW_SERVER_FILE_STORE=postgresql+pg8000:\/\/username:pwd@\/mlflowdb?unix_sock=\/cloudsql\/my-project:us-central1:mlflow\/.s.PGSQL.5432\r\n\r\nexec gunicorn -b \"0.0.0.0:8080\" -w 4 --log-level debug --access-logfile=- --error-logfile=- --log-level=debug mlflow_auth:app\r\n\r\n\r\n\r\n### Other info \/ logs\r\nlocal\/lib\/python3.8\/site-packages\/mlflow\/store\/db\/utils.py\", line 80, in make_managed_session yield session File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/store\/tracking\/sqlalchemy_store.py\", line 304, in get_experiment return self._get_experiment( File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/store\/tracking\/sqlalchemy_store.py\", line 272, in _get_experiment session.query(SqlExperiment) File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/orm\/query.py\", line 2776, in one_or_none return self._iter().one_or_none() File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/orm\/query.py\", line 2834, in _iter result = self.session.execute( File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/orm\/session.py\", line 1689, in execute result = conn._execute_20(statement, params or {}, execution_options) File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/base.py\", line 1582, in _execute_20 return meth(self, args_10style, kwargs_10style, execution_options) File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/sql\/elements.py\", line 324, in _execute_on_connection return connection._execute_clauseelement( File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/base.py\", line 1451, in _execute_clauseelement ret = self._execute_context( File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/base.py\", line 1813, in _execute_context self._handle_dbapi_exception( File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/base.py\", line 1994, in _handle_dbapi_exception util.raise_( File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/util\/compat.py\", line 207, in raise_ raise exception File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/base.py\", line 1770, in _execute_context self.dialect.do_execute( File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/default.py\", line 717, in do_execute cursor.execute(statement, parameters) File \"\/usr\/local\/lib\/python3.8\/site-packages\/pg8000\/core.py\", line 341, in execute self._c.execute_unnamed( File \"\/usr\/local\/lib\/python3.8\/site-packages\/pg8000\/core.py\", line 1225, in execute_unnamed self.handle_messages(cursor) File \"\/usr\/local\/lib\/python3.8\/site-packages\/pg8000\/core.py\", line 1381, in handle_messages raise self.error sqlalchemy.exc.ProgrammingError: (pg8000.exceptions.ProgrammingError) {'S': 'ERROR', 'V': 'ERROR', 'C': '42883', 'M': 'operator does not exist: integer = character varying', 'H': 'No operator matches the given name and argument types. You might need to add explicit type casts.', 'P': '276', 'F': 'parse_oper.c', 'L': '731', 'R': 'op_error'}\r\n\r\n[SQL: SELECT experiments.experiment_id AS experiments_experiment_id, experiments.name AS experiments_name, experiments.artifact_location AS experiments_artifact_location, experiments.lifecycle_stage AS experiments_lifecycle_stage\r\nDefault\r\n2021-06-22T15:57:48.560678ZFROM experiments\r\nWHERE experiments.experiment_id = %s AND experiments.lifecycle_stage IN (%s, %s)]\r\nDefault\r\n2021-06-22T15:57:48.560777Z[parameters: ('0', 'active', 'deleted')]\r\nDefault\r\n2021-06-22T15:57:48.560788Z(Background on this error at: http:\/\/sqlalche.me\/e\/14\/f405)\r\nError\r\n2021-06-22T15:57:48.560828ZTraceback (most recent call last): File \"\/usr\/local\/lib\/python3.8\/site-packages\/flask\/app.py\", line 2070, in wsgi_app response = self.full_dispatch_request() File \"\/usr\/local\/lib\/python3.8\/site-packages\/flask\/app.py\", line 1515, in full_dispatch_request rv = self.handle_user_exception(e) File \"\/usr\/local\/lib\/python3.8\/site-packages\/flask\/app.py\", line 1513, in full_dispatch_request rv = self.dispatch_request() File \"\/usr\/local\/lib\/python3.8\/site-packages\/flask\/app.py\", line 1499, in dispatch_request return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args) File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/server\/handlers.py\", line 217, in wrapper response.set_data(e.serialize_as_json()) File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/exceptions.py\", line 60, in serialize_as_json return json.dumps(exception_dict) File \"\/usr\/local\/lib\/python3.8\/json\/__init__.py\", line 231, in dumps return _default_encoder.encode(obj) File \"\/usr\/local\/lib\/python3.8\/json\/encoder.py\", line 199, in encode chunks = self.iterencode(o, _one_shot=True) File \"\/usr\/local\/lib\/python3.8\/json\/encoder.py\", line 257, in iterencode return _iterencode(o, 0) File \"\/usr\/local\/lib\/python3.8\/json\/encoder.py\", line 179, in default raise TypeError(f'Object of type {o.__class__.__name__} ' TypeError: Object of type ProgrammingError is not JSON serializable\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [*] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [*] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [*] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [*] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\npython\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\nGCP ","274":"Similar to Python [custom functions](https:\/\/mlflow.org\/docs\/latest\/models.html#id38), does custom R function API is exposed? \r\n","275":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [- ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 20\r\n- **MLflow installed from (source or binary)**: pip\r\n- **MLflow version (run ``mlflow --version``)**: pip stable version\r\n- **Python version**: 3.7\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: mlflow run . -P alpha=0.5\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\nI am working on docker example of mlflow. (examples\/docker)\r\nThe docker image is build successfully using the docker build command\r\nOnce image is build, I am executing: mlflow run . -P alpha=0.5 and mlflow run examples\/docker -P alpha=0.5\r\nOutput:\r\nElasticnet model (alpha=0.600000, l1_ratio=0.100000):\r\n  RMSE: 0.7985733780987151\r\n  MAE: 0.6202991221099381\r\n  R2: 0.17633705471063543\r\n2021\/06\/21 01:57:56 INFO mlflow.projects: === Run (ID 'edcca3a2895e44f2b8ed2e3dd564e173') succeeded ===\r\n\r\nChecking the mlruns folder there is no model saved in folder.\r\nAlso when running the mlflow run command there are two folder creating \r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/85923718\/122722529-75983e00-d28f-11eb-90c1-f0cd584fb37e.png)\r\n\r\nThere is no model saved in these two folder.\r\n\r\nThe folder which is locked has the meticrs rmse-mae values stored in that.\r\nWhere as the folder runid which is logged has no metrics stored in the folder.\r\n\r\ndo help for solving the issue \r\n\r\nAlso I tried running the python script directly\r\npython train.py 0.5 0.1\r\nThe model is saved during these process in the mlruns folder.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [- ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ -] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","276":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nIs there any plan to serve rest api endpoints\u00a0`\/api`\u00a0under static prefix? With the path of\u00a0`\/ajax-api` I can use the api\u00a0under the static prefix (cf. https:\/\/github.com\/mlflow\/mlflow\/pull\/1413#pullrequestreview-252098403 ), but this path seems not called from mlflow client (because of\u00a0[this const value](https:\/\/github.com\/mlflow\/mlflow\/blob\/1904e3631569b687dd3cde5e72b7d13685b4d490\/mlflow\/utils\/rest_utils.py#L18)).\r\n\r\nSo I cannot specify tracking uri with static prefix in mlflow client, even though mlflow server is running with static prefix. For example, let mlflow server is running with this command: `mlflow server --static-prefix=\/mlflow`.  I can open the web ui with this url `http:\/\/localhost:5000\/mlflow` without any problems. But in order to send metrics to the mlflow server during the training routine, the tracking uri is needed to set to `http:\/\/localhost:5000\/` without `\/mlflow` but with just a root path `\/` since the client internally calls `\/api\/2.0` endpoint under the root path (if with static prefix `\/mlflow`, this causes 404 not found).\r\n\r\nIf root path is accessible directly, of course this is ok. But in the environment which is not allowed to access root context (e.g. behind web proxy or already used for the other services), some path rewrite processes will be needed to serve the api.\r\n\r\n## Motivation\r\n\r\n- What is the use case for this feature?\r\n    - When mlflow server is running with a static prefix.\r\n- Why is this use case valuable to support for MLflow users in general?\r\n    - They can send metrics to the mlflow server using the mlflow client even if the root path is inaccessible or already used.\r\n- Why is this use case valuable to support your project(s) or organization?\r\n    - We have been managing personal mlflow microservices behind of ingress for routing on GKE kubernetes, but GKE ingress has no functionality of path rewriting.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n    - Same as above.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [x] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nI think the rest api can be served with prefix by adding a command line option like\u00a0`--restapi-prefix`. The implementation proposal and the command line example are as follows:\r\n\r\nProposal: [ciela@2ceecd8](https:\/\/github.com\/ciela\/mlflow\/commit\/2ceecd894c9f3ad220f953d9f15334e877426282)\r\nUse cases:\r\n\r\n```bash\r\n# web ui and rest api are accessible under same static prefix `\/mlflow1` \r\nmlflow server --static-prefix=\/mlflow1 --restapi-prefix=\/mlflow1\r\n\r\n# web ui is accessible under prefix `\/mlflow1` and rest api is accessible under `\/mlflow2`\r\nmlflow server --static-prefix=\/mlflow1 --restapi-prefix=\/mlflow2\r\n\r\n# web ui is accessible under prefix `\/mlflow1` and rest api is accessible under `\/` (just as usual)\r\nmlflow server --static-prefix=\/mlflow1\r\n```\r\n\r\nHere are the other possible ways:\r\n\r\n- Append rest api with static prefix to endpoints list (like as `\/ajax-api`)\r\n  - append `_add_static_prefix(\"\/api\/2.0{}\".format(base_path))` to the following line\r\n  - https:\/\/github.com\/mlflow\/mlflow\/blob\/1904e3631569b687dd3cde5e72b7d13685b4d490\/mlflow\/server\/handlers.py#L814\r\n- Make api endpoint selectable in mlflow client (maybe via environment variables?)\r\n  - `\/api\/2.0` or `\/ajax-api\/2.0`\r\n  - https:\/\/github.com\/mlflow\/mlflow\/blob\/1904e3631569b687dd3cde5e72b7d13685b4d490\/mlflow\/utils\/rest_utils.py#L18","277":"## What changes are proposed in this pull request?\r\n\r\nPropagates GUNICORN_CMD_ARGS to built docker container when using `mlflow models build-docker`\r\n\r\n## How is this patch tested?\r\n\r\nTested via manual actuation on my end, e.g. passing GUNICORN_CMD_ARGS=\"--workers=20\" and noting that 20 workers spawn.  Let me know if other tests should be done \/ written, and I'd be happy to implement them.\r\n\r\n## Release Notes\r\n\r\nGUNICORN_CMD_ARGS environment variable is now copied to the built docker container when using `mlflow models build-docker`\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","278":"## Proposal Summary\r\nAutomatically track all relevant hardware\/compute metrics of the instance\/VM running the experiment.\r\n\r\nSimilar to how Wandb.ai or other experiment tracking solutions are doing:\r\n\r\n- CPU Utilization over the experiment run\r\n- RAM Utilization over ...\r\n- Disk I\/O Utilization (read\/writes MB\/s)\r\n- Network I\/O Utilization (read\/writes MB\/s)\r\n- GPU Utilization\r\n- GPU Temperature\r\n- GPU Time Spent Accessing Memory\r\n- GPU Memory Allocated\r\n\r\n## Motivation\r\nUnderstanding resources usage is a feature of major importance, it helps ML engineers understand bottlenecks in their experiments. Buy doing this out of the box the user no longer needs to switch to another tool or do this manually every time.\r\nIt's also relevant for comparing runs over time.\r\n\r\n- [x] No. I cannot contribute this feature at this time.","279":"We use Horovod to  train Keras model and use Mlflow to register model,\r\n\r\nFrom the  MLflow guide doc:\r\n```\r\nmlflow.keras.log_model(keras_model, artifact_path, conda_env=None, custom_objects=None, keras_module=None, registered_model_name=None, signature: Optional[mlflow.models.signature.ModelSignature] = None, input_example: Optional[Union[pandas.core.frame.DataFrame, numpy.ndarray, dict, list]] = None, await_registration_for=300, **kwargs)\r\n\r\nkwargs \u2013 kwargs to pass to keras_model.save method.\r\n\r\n```\r\nSo we passed extra argument _floatx=\"float32\"\r\n```\r\n>>> mlflow.keras.log_model(regmodel, \"kwargs-model\", None, None, None, \"kwargs-model-reg\", None, None, 300, _floatx=\"float32\")\r\n```\r\nBut encounter\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"\/root\/miniconda2\/envs\/keras\/lib\/python3.8\/site-packages\/mlflow\/keras.py\", line 377, in log_model\r\n    Model.log(\r\n  File \"\/root\/miniconda2\/envs\/keras\/lib\/python3.8\/site-packages\/mlflow\/models\/model.py\", line 182, in log\r\n    flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\r\n  File \"\/root\/miniconda2\/envs\/keras\/lib\/python3.8\/site-packages\/mlflow\/keras.py\", line 260, in save_model\r\n    keras_model.save(model_path, **kwargs)\r\nTypeError: save() got an unexpected keyword argument '_floatx'\r\n\r\n```\r\nWe have not got the cause. Is it a bug?\r\n\r\n@harupy @smurching \r\n\r\nThanks.\r\n\r\n\r\n\r\n\r\n\r\n","280":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [X ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nExpand `mlflow_log_model()` in R so you can specify a model signature and an input example for the model that is logged to the tracking server.\r\n\r\n## Motivation\r\n- What is the use case for this feature? Add documentation to the logged model\r\n- Why is this use case valuable to support for MLflow users in general? Better documentation for models in the model repository\/served by MLflow.\r\n- Why is this use case valuable to support for your project(s) or organization? Better documentation for models in the model repository\/served by MLflow.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient) As far as I know there is no support for these features in `mlflow_log_model()`. \r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [X] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","281":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this documentation issue template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages documentation fix contributions. Would you or another member of your organization be willing to contribute a fix for this documentation issue to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a documentation fix independently.\r\n- [x] Yes. I would be willing to contribute a document fix with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a documentation fix at this time.\r\n\r\n### URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry in question.\r\n\r\n### Description of proposal (what needs changing):\r\nProvide a clear description. Why is the proposed documentation better?\r\nJust recently used Mlflow in a project both in Python and Java APIs. I should admit it is quite useful and practical but you should really standardize its Java API documentation alongside with Python API. Scala API for Spark is a first class citizen for ML data prep, we had to reverse engineer everything by being improvised in the java api. It was quite troublesome to register models with versioning whilst it is very straightforward in python api with log_model method. I recommend you to ensure the methods in Java API to provide the same functionality as Python API (https:\/\/www.mlflow.org\/docs\/latest\/java_api\/index.html) and to provide the Scala\/java API examples of each script in the MLflow Examples documentation.","282":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [X] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nAs mentioned in #1515, there is a Java implementation for downloading artifacts. The current implementation invokes the python library which invokes the CLI. This mechanism forces anyone using this Java library to add Python to their runtime environment. Especially for production releases, this is suboptimal. It makes a Docker setup more complex and adds overhead.\r\n\r\nThe proposal is to provide native support for downloading models in either the Java library or as documented REST endpoints.\r\n\r\n## Motivation\r\n\r\n- What is the use case for this feature?\r\nA Java library that depends on python is not really a Java library! This feature eliminates a run-time dependency on the Python ecosystem for users looking to download MLflow artifacts from Databricks.\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\nEliminating the need to have a container that hosts both a Java and a Python run-time environment makes containers more stable, easier to understand and analyze.\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nAs an organization we try to follow best practices, common standards and make things easy to operate. Using the current Java library would involve a non-standard setup that is more difficult to operate. We feel like the addition of Python is unwarranted considering the purpose that it serves (i.e. firing two regular HTTP requests).\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nCompared to our current setup, which uses a basic Java container, we would need to install both Java and Python into the container that runs our production workload. Both of these use resources (CPU and memory) so they require additional tuning to make sure both have enough resources to work with while not taking too much that the other process runs out of resources. Monitoring also becomes more involved because we now have two processes to monitor inside that container.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [X] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [X] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [X] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nWe did some digging to figure out how the Python CLI actually downloads files from Databricks. Upon inspection, we found that it is very simple: it uses an undocumented REST endpoint at `\/api\/2.0\/mlflow\/artifacts\/credentials-for-read` which returns a direct URL (including STS credentials) to the underlying S3 file.\r\n\r\nWe are willing to contribute a change to `mlflow` to invoke this particular endpoint directly from the Java library, rather than deferring to the Python CLI which in turn invokes the same endpoint.\r\n\r\nAn alternative option, perhaps easier, is to document the existence of the `credentials-for-read` endpoint and allow it to be used by REST clients. This would allow anyone to download mlflow models regardless of the language\/library used.\r\n\r\nPlease let me know which option you prefer, and if you are willing to accept a contribution that solves this feature request.","283":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [X] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux\r\nMy image is based on python:3.6-stretch\r\n- **MLflow installed from (source or binary)**:\r\nbinary\r\n- **MLflow version (run ``mlflow --version``)**:\r\n1.17.0\r\n- **Python version**:\r\nPython 3.6.13\r\n- **Exact command to reproduce**:\r\n- mlflow server \\\r\n  --backend-store-uri postgresql:\/\/mlflow_data:mlflow_data@$MLFLOW_DB_URI\/ \\\r\n  --default-artifact-root artifacts \\\r\n  --workers 16 \\\r\n  --host 0.0.0.0 \\\r\n  --port 8888 \\\r\n  --gunicorn-opts \"--timeout 180 --log-level=DEBUG\"\r\n\r\n### Describe the problem\r\nMLFlow server in AWS ECS on c5.xlarge instance works but it is *very* slow.\r\nAccess using API and command line works fine but some requests hang for ~30 seconds before completition\r\nMLFlow UI is extremely slow even though I have only 1 experiment and 1 run and use an external Postgres\r\n\r\nrunning the same container locally (on my laptop with SSD) works fast\r\n\r\nOur current hypothesis is that EBS disks make it very slow. We tried using an instance with SSD and it works fine but for technical reasons we can't use a different (from c5.xlarge) instance type.\r\n\r\nSo out current hypothesis is that slow IO leads to gunicorn workers to timeout all the time\r\nWe do see\r\n> [33] [CRITICAL] WORKER TIMEOUT (pid:206)\r\nconstantly\r\n\r\nrunning MLFlow under strace reveals that to server the front page mlflow reads a lot of static files and may also create a folder for artifacts\r\n\r\n### Code to reproduce issue\r\n- mlflow server \\\r\n  --backend-store-uri postgresql:\/\/mlflow_data:mlflow_data@$MLFLOW_DB_URI\/ \\\r\n  --default-artifact-root artifacts \\\r\n  --workers 16 \\\r\n  --host 0.0.0.0 \\\r\n  --port 8888 \\\r\n  --gunicorn-opts \"--timeout 180 --log-level=DEBUG\"\r\n\r\non AWS c5.xlarge instance\r\n\r\n### Other info \/ logs\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","284":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [x] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: NO\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Max OS (big Sur)\r\n- **MLflow installed from (source or binary)**: source (pip install)\r\n- **MLflow version (run ``mlflow --version``)**: 1.17.0\r\n- **Python version**: 3.7\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n```client.download_artifacts(run.info.run_id, \"\", local_dir)```\r\n\r\n### Describe the problem\r\nWhen invoking the `download_artifacts` method, the following exception is thrown ```OSError: [Errno 30] Read-only file system: '\/ml'```.\r\nThe expected behavior- artifacts are downloaded to `local_dir`.\r\n\r\n### Code to reproduce issue\r\n```\r\n# env \r\n# MLFLOW_TRACKING_URI=databricks\r\n\r\nclient = MlflowClient()\r\nlocal_dir = \"\/tmp\/artifact_downloads\"\r\nif not os.path.exists(local_dir):\r\n    os.mkdir(local_dir)\r\nclient.download_artifacts(run.info.run_id, \"features\", local_dir)\r\n```\r\n### Other info \/ logs\r\nThe tracking server is set to DataBricks (Azure)\r\n```\r\nclient.download_artifacts(run.info.run_id, \"\", local_dir)\r\nTraceback (most recent call last):\r\n  File \"<input>\", line 1, in <module>\r\n  File \"\/Users\/yoav\/Workspace\/mlflow-export-import\/venv\/lib\/python3.7\/site-packages\/mlflow\/tracking\/client.py\", line 1364, in download_artifacts\r\n    return self._tracking_client.download_artifacts(run_id, path, dst_path)\r\n  File \"\/Users\/yoav\/Workspace\/mlflow-export-import\/venv\/lib\/python3.7\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 315, in download_artifacts\r\n    return self._get_artifact_repo(run_id).download_artifacts(path, dst_path)\r\n  File \"\/Users\/yoav\/Workspace\/mlflow-export-import\/venv\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact\/artifact_repo.py\", line 134, in download_artifacts\r\n    return download_artifact_dir(artifact_path)\r\n  File \"\/Users\/yoav\/Workspace\/mlflow-export-import\/venv\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact\/artifact_repo.py\", line 108, in download_artifact_dir\r\n    download_file(file_info.path)\r\n  File \"\/Users\/yoav\/Workspace\/mlflow-export-import\/venv\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact\/artifact_repo.py\", line 89, in download_file\r\n    os.makedirs(local_dir_path)\r\n  File \"\/usr\/local\/Cellar\/python@3.7\/3.7.10_2\/Frameworks\/Python.framework\/Versions\/3.7\/lib\/python3.7\/os.py\", line 213, in makedirs\r\n    makedirs(head, exist_ok=exist_ok)\r\n  File \"\/usr\/local\/Cellar\/python@3.7\/3.7.10_2\/Frameworks\/Python.framework\/Versions\/3.7\/lib\/python3.7\/os.py\", line 213, in makedirs\r\n    makedirs(head, exist_ok=exist_ok)\r\n  File \"\/usr\/local\/Cellar\/python@3.7\/3.7.10_2\/Frameworks\/Python.framework\/Versions\/3.7\/lib\/python3.7\/os.py\", line 213, in makedirs\r\n    makedirs(head, exist_ok=exist_ok)\r\n  [Previous line repeated 2 more times]\r\n  File \"\/usr\/local\/Cellar\/python@3.7\/3.7.10_2\/Frameworks\/Python.framework\/Versions\/3.7\/lib\/python3.7\/os.py\", line 223, in makedirs\r\n    mkdir(name, mode)\r\nOSError: [Errno 30] Read-only file system: '\/ml'\r\n```\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [x] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [x] `integrations\/databricks`: Databricks integrations\r\n","285":"When saving artifacts or models with a long name, the MLflow UI does not provide the full path of the artifact. \r\n\r\n<img width=\"1379\" alt=\"Screenshot 2021-06-12 at 8 47 06 PM\" src=\"https:\/\/user-images.githubusercontent.com\/39826655\/121780831-b7562400-cbbf-11eb-9790-3951100c64da.png\">\r\n\r\nI'm saving the model using mlflow.pytorch.log_model() after some epochs, now I want to load the model using mlflow.pytorch.load_model(). Going to the UI to get the pathname is not very convenient, can you suggest some workflow to programmatically access the models saved in the previous run. Also, I don't want to store run_ids. ","286":"Hi everyone, \r\n\r\nFirst of all thank you for maintaining this tool!\r\nI am trying to save a RL model trained with stablebaselines3 via mlflow, not all information is needed from the model, and stable baselines3 algorithms is based on pytorch underneath, just a richer model.  \r\n\r\nIs there a way to define a custom model based on the flavors mlflow supports, that Mlflow can save automatically? If yes, any ideas will help, if not, is there a plan to add a feature like this?  \r\n\r\nThank you for your help","287":"## What changes are proposed in this pull request?\r\n\r\nAddresses issue #4442 \r\n\r\n## How is this patch tested?\r\n\r\nUnit test.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nAllow mlflow.spacy.load_model() to take in keyword arguments to pass through to spacy.load() internally. Allows loading models with config overrides, exclude, disable components, etc.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","288":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nCurrently the[ `mlflow.spacy.load_model()`](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/spacy.py#L263) function takes in only the `model_uri` as a parameter to fetch and load the spaCy model. Internally it calls `spacy.load()` passing in the directory where the model was downloaded. `spacy.load()` also takes in [additional keyword arguments](https:\/\/spacy.io\/api\/top-level#spacy.load) to pass config overrides, options to exclude and disable components, etc. which the current implementation of `mlflow.spacy.load_model()` does not take advantage of.\r\n\r\n## Motivation\r\n- What is the use case for this feature? _Load spaCy models with customizations as required easily._\r\n- Why is this use case valuable to support for MLflow users in general? _Load spaCy models with customizations as required easily._\r\n- Why is this use case valuable to support for your project(s) or organization? _Load spaCy models with customizations as required easily._\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient) _Current API does not support the use case and workarounds involve touching some internal functions. See below for a workaround._\r\n\r\n```\r\nmodel_uri = f\"models:\/{model_name}\/{model_version}\"\r\nlocal_model_path = _download_artifact_from_uri(artifact_uri=model_uri)\r\nflavor_conf = _get_flavor_configuration(model_path=local_model_path, flavor_name=\"spacy\")\r\nspacy_model_file_path = os.path.join(local_model_path, flavor_conf.get(\"data\", \"model.spacy\"))\r\nnlp = spacy.load(spacy_model_file_path, config=config)\r\n```\r\n\r\nThe proposed method should allow this to be:\r\n```\r\nmodel_uri = f\"models:\/{model_name}\/{model_version}\"\r\nnlp = mlflow.spacy.load_model(model_uri, config=config)\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\nAllow `mlflow.spacy.load_model()` to take in pass through keyword argument parameters to be passed to `spacy.load()` internally.","289":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nAdd a way to see more characters in the experiments panel.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nWe have long names in my company using the template <namespace>.<model name> and with the current design we can only see the domain name.\r\n- Why is this use case valuable to support for MLflow users in general?\r\nSince mlflow doenst support namespace\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nwe would like to scale the number of models on mlflow. Today we have 1 namespace but in the future we would have between 2-5 namespaces. Adding a namespace or increasing the number of characters visible would solve our issue\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nN\/A\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n![image](https:\/\/user-images.githubusercontent.com\/35231495\/121377771-9f0cad80-c910-11eb-9671-8303abb2cd75.png)\r\n","290":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nAllow serving a model from within the UI. The feature seems to be available on [data bricks](https:\/\/docs.microsoft.com\/en-us\/azure\/databricks\/applications\/mlflow\/model-serving#validate-model-serving)\r\n![image](https:\/\/user-images.githubusercontent.com\/17325189\/121001882-a488bd00-c783-11eb-9657-f4979de7d355.png)\r\n\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nServe a model more easily. \r\n- Why is this use case valuable to support for MLflow users in general?\r\nIt makes it easier to do the standard action of serving a model. It will also help with the consistency of the stage of the model and its serving.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nWe need a process as automated as possible with little place for manual error.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nNo UI support for model serving\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details","291":"- [ ] Yes. I can contribute this feature independently.\r\n- [v] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nI'm not absolutely sure but now there is not built-in feature for logging best K models. The only way to do it is to create custom callback using MLFlowLogger but it's not really cover all the needs (you can't log to created run, because logger initialization create it's own run, and other limitations...)\r\nMy idea is to implement parameter for .log_model method, that will help researchers to set approach for model saving (last epoch model, best epoch model, K best epochs model), becuase usually last epoch accuracy is not the best accuracy from the entire training process.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [v] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n","292":"Signed-off-by: Daniel Takabayashi <daniel.takabayashi@gmail.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nMaking SQLite the default scheme for store backend, also to address the issue #4415.\r\n\r\n## How is this patch tested?\r\n\r\n - Unit tests\r\n - Using the UI interface according to the instruction found [here](https:\/\/github.com\/mlflow\/mlflow\/issues\/4415)\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [x] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","293":"### System information\r\n- Windows 10\r\n- MLflow installed from binary: pip install mlflow\r\n- MLflow version: 1.17.0\r\n- Python version: 3.6.13\r\n- R version: 4.1.0\r\n- RStudio version: 1.4.1106\r\n- Exact command to reproduce:\r\n```\r\ndevtools::install_github(\"mlflow\/mlflow\", subdir = \"mlflow\/R\/mlflow\")\r\nmlflow::install_mlflow()\r\n```\r\n\r\n### Describe the problem\r\nI try to install the latest version of the mlflow package from github in R.\r\nOpen RStudio. Execute:\r\n```\r\ndevtools::install_github(\"mlflow\/mlflow\", subdir = \"mlflow\/R\/mlflow\")\r\nmlflow::install_mlflow()\r\n```\r\nThe first statement executes succesfully. So the mlflow package is installed and available in R (version 1.17.1).\r\nHowever, the second statement yields an error:\r\n\r\n```\r\nERROR: Could not find a version that satisfies the requirement mlflow==1.17.1 (from versions: 0.0.1, 0.1.0, 0.2.0, 0.2.1, 0.3.0, 0.4.0, 0.4.1, 0.4.2, 0.5.0, 0.5.1, 0.5.2, 0.6.0, 0.7.0, 0.8.0, 0.8.1, 0.8.2, 0.9.0, 0.9.0.1, 0.9.1, 1.0.0, 1.1.0, 1.1.1.dev0, 1.2.0, 1.3.0, 1.4.0, 1.5.0, 1.6.0, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.9.0, 1.9.1, 1.10.0, 1.11.0, 1.12.0, 1.12.1, 1.13, 1.13.1, 1.14.0, 1.14.1, 1.15.0, 1.16.0, 1.17.0)\r\nERROR: No matching distribution found for mlflow==1.17.1\r\nError: Error installing package(s): \"mlflow==1.17.1\"\r\n```\r\n\r\n### Other info \/ logs\r\n\r\nOutput in the console:\r\n\r\n```\r\nCreating conda environment r-mlflow-1.17.1\r\nCollecting package metadata (current_repodata.json): ...working... done\r\nSolving environment: ...working... done\r\n\r\n## Package Plan ##\r\n\r\n  environment location: C:\\Users\\willy\\.conda\\envs\\r-mlflow-1.17.1\r\n\r\n  added \/ updated specs:\r\n    - python=3.6\r\n\r\n\r\nThe following NEW packages will be INSTALLED:\r\n\r\n  certifi            conda-forge\/win-64::certifi-2021.5.30-py36ha15d459_0\r\n  pip                conda-forge\/noarch::pip-21.1.2-pyhd8ed1ab_0\r\n  python             conda-forge\/win-64::python-3.6.13-h39d44d4_0_cpython\r\n  python_abi         conda-forge\/win-64::python_abi-3.6-1_cp36m\r\n  setuptools         conda-forge\/win-64::setuptools-49.6.0-py36ha15d459_3\r\n  vc                 conda-forge\/win-64::vc-14.2-hb210afc_4\r\n  vs2015_runtime     conda-forge\/win-64::vs2015_runtime-14.28.29325-h5e1d092_4\r\n  wheel              conda-forge\/noarch::wheel-0.36.2-pyhd3deb0d_0\r\n  wincertstore       conda-forge\/win-64::wincertstore-0.2-py36ha15d459_1006\r\n\r\n\r\nPreparing transaction: ...working... done\r\nVerifying transaction: ...working... done\r\nExecuting transaction: ...working... done\r\n#\r\n# To activate this environment, use\r\n#\r\n#     $ conda activate r-mlflow-1.17.1\r\n\r\n#\r\n# To deactivate an active environment, use\r\n#\r\n#     $ conda deactivate\r\n\r\nERROR: Could not find a version that satisfies the requirement mlflow==1.17.1 (from versions: 0.0.1, 0.1.0, 0.2.0, 0.2.1, 0.3.0, 0.4.0, 0.4.1, 0.4.2, 0.5.0, 0.5.1, 0.5.2, 0.6.0, 0.7.0, 0.8.0, 0.8.1, 0.8.2, 0.9.0, 0.9.0.1, 0.9.1, 1.0.0, 1.1.0, 1.1.1.dev0, 1.2.0, 1.3.0, 1.4.0, 1.5.0, 1.6.0, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.9.0, 1.9.1, 1.10.0, 1.11.0, 1.12.0, 1.12.1, 1.13, 1.13.1, 1.14.0, 1.14.1, 1.15.0, 1.16.0, 1.17.0)\r\nERROR: No matching distribution found for mlflow==1.17.1\r\nError: Error installing package(s): \"mlflow==1.17.1\"\r\n```","294":"I am able to see all the experiments on the left side of the pane. I am also able to see all the records of a particular experiments, but on the selection of a particular row of run records I am getting \"something went wrong\" page.\r\n\r\n<img width=\"942\" alt=\"Error\" src=\"https:\/\/user-images.githubusercontent.com\/64940907\/120428181-d3bcba00-c390-11eb-9633-fa55e0bd14e9.PNG\">\r\n\r\n","295":"Hi,\r\nI trained a BERT Classification model with Pytorch in Azure Databricks and moved it to production. But I couldn't find how to add a `handler` script for preprocessing the `text` input from user. \r\nCan anyone plz help how to proceed further..","296":"`mlflow` library is installed in R. However, while executing any mllfow function in R(R-Studio) is returning an error as,\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/12031936\/120095157-65f36280-c0f2-11eb-9db6-ff63e5fbe938.png)\r\n\r\n```\r\n> sessionInfo()\r\nR version 4.1.0 (2021-05-18)\r\nPlatform: x86_64-w64-mingw32\/x64 (64-bit)\r\nRunning under: Windows Server x64 (build 14393)\r\n\r\nMatrix products: default\r\n\r\nlocale:\r\n[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252   \r\n[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C                          \r\n[5] LC_TIME=English_United States.1252    \r\n\r\nattached base packages:\r\n[1] stats     graphics  grDevices utils     datasets  methods   base     \r\n\r\nother attached packages:\r\n[1] mlflow_1.17.0\r\n\r\nloaded via a namespace (and not attached):\r\n [1] Rcpp_1.0.6       magrittr_2.0.1   rappdirs_0.3.3   lattice_0.20-44  R6_2.5.0        \r\n [6] rlang_0.4.11     httr_1.4.2       tools_4.1.0      grid_4.1.0       png_0.1-7       \r\n[11] withr_2.4.2      askpass_1.1      openssl_1.4.4    yaml_2.2.1       forge_0.2.0     \r\n[16] processx_3.5.2   Matrix_1.3-3     ini_0.3.1        purrr_0.3.4      later_1.2.0     \r\n[21] fs_1.5.0         base64enc_0.1-3  promises_1.2.0.1 ps_1.6.0         curl_4.3.1      \r\n[26] zeallot_0.1.0    compiler_4.1.0   swagger_3.33.1   reticulate_1.20  jsonlite_1.7.2  \r\n[31] httpuv_1.6.1 \r\n```\r\n\r\nAm I missing anything out her? Thanks in advance.","297":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 18.04)**: Linux Ubuntu 18.04\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: mlflow, version 1.17.0\r\n- **Python version**: 3.9.0\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: mlflow run --no-conda hypertuning_mlflow -P data=hypertuning_mlflow\/datasets\/fct_calculation_int.csv\r\n\r\n\r\n### Describe the problem\r\n```mlflow run``` always tries to create a conda environment (or use an existing) though supplying the ```--no-conda``` flag .\r\n\r\n### Code to reproduce issue\r\n```mlflow run --no-conda hypertuning_mlflow -P data=hypertuning_mlflow\/datasets\/fct_calculation_int.csv```\r\n\r\n\r\n### Other info \/ logs\r\n2021\/05\/29 12:13:02 INFO mlflow.projects.utils: === Created directory \/tmp\/tmptmiwzscb for downloading remote URIs passed to arguments of type 'path' ===\r\n2021\/05\/29 12:13:02 INFO mlflow.projects.backend.local: === Running command 'python search.py --data .\/datasets\/hypertuning_mlflow\/fct_calculation_int.csv --max-runs 12 --epochs 32 --metric sparse_categorical_crossentropy --algo tpe.suggest' in run with ID 'eb7caf81624f40bb85e7bfaa61319036' === \r\n  0%|                                                                                                                                                                                                                                | 0\/12 [00:00<?, ?trial\/s, best loss=?]2021\/05\/29 12:13:04 INFO mlflow.utils.conda: === Creating conda environment mlflow-da39a3ee5e6b4b0d3255bfef95601890afd80709 ===\r\n\r\nCollecting package metadata (current_repodata.json): done\r\nSolving environment: done\r\n...\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [x] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","298":"## Feature Request\r\n\r\nThis proposal is to make `mlflow.log_param()` return the passed parameter value so it can be used in a functional way, as an expression.  This will reduce the likelihood of usage errors and increase the speed of development for machine learning practitioners.\r\n\r\n\r\n## Willingness to contribute\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nThis feature will allow `mlflow.log_param()` to return the logged parameter value.  This would allow the in-line use of `log_param`, ensuring that the logged value is actually identical to the value used in the model or process.  \r\n\r\n## Motivation\r\n**- What is the use case for this feature?**\r\n\r\nThis feature can be used in machine learning experiments to ensure that the parameter value used is the same as the value that is logged.\r\n\r\n**- Why is this use case valuable to support for MLflow users in general?**\r\n\r\nThis use case is valuable because it enables rapid, agile development while reducing the likelihood of errors.  It's also backwards compatible.\r\n\r\n**- Why is this use case valuable to support for your project(s) or organization?**\r\n\r\nThis use case supports all data science efforts across our companies' projects.\r\n\r\n**- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)**\r\n\r\nCurrently this use case cannot be achieved as `mlflow.log_param()` is imperative and does not currently return the value.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nCurrently `mlflow.log_param()` is an imperative statement. Because of this, multiple lines of code are needed to use `log_param` and parametrize a model. In particular:\r\n\r\n1. A variable must be created and set to the desired value (ideally a constant, which isn't really supported in Python)\r\n2. The machine learning model is parametrized with that variable's value\r\n3. `mlflow.log_param()` is called using that variable's value\r\n\r\nFor example:\r\n```python\r\nNUM_HIDDEN = 30\r\nmodel.add(Dense(NUM_HIDDEN))\r\nmlflow.log_param(\"NUM_HIDDEN\", NUM_HIDDEN)  # Current MLflow usage pattern\r\n```\r\n\r\nSeveral things can go wrong when an implementer uses the current interface:\r\n- the implementer might inadvertently use a different variable **name** from the name used in the `log_param` call.  This could cause confusion in interpreting the logged parameters w.r.t. the source code.\r\n- the implementer might inadvertently change the **value** of `NUM_HIDDEN` between steps 2 and 3.  This would result in the wrong value being logged.\r\n- the implementer may inadvertently **omit** step 3, resulting in the model running but no value being logged for that parameter.\r\n\r\nIf the proposal describe in this issue is adopted, the 3 lines of Python above could be rewritten as:\r\n\r\n```python\r\nmodel.add(Dense(mlflow.log_param(\"NUM_HIDDEN\", 30)))   # Proposed MLflow usage pattern\r\n```\r\n\r\nThis would greatly reduce the possibility of errors in the use of MLflow.\r\n","299":"Hi,\r\n\r\nI went through MLFlow documentation (Tracking, Projects, Model, Registry) and I found a few gaps regarding some capabilities. Plz suggest whether below things are possible or not - \r\n\r\n1.  Can I deploy `python_function` flavor of any model (SKLearn, torch, tensorflow etc) using `mlflow models serve` ( which gives a REST API ) with custom `handler` script ?\r\n2.  Is there any UI component available to see all the deployments and make a new deployment ?\r\n3.  Is there a generic UI screen available for each deployment which accepts standard data like `json`, `tensor` or `image` based on `signature` and calls deployed model and outputs data in that screen? This will be easier to quickly share deployments with clients so that they can quickly test. \r\n4.  As data preparation is an integral part of ML life cycle, Is there a way to keep track of all my versions of dataset (Data Versioning) ?","300":"Signed-off-by: Jakub Hettler <jakub.hettler@gmail.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nEnable masking of parameters in mlflow log AWS S3 secret keys, etc.\r\nfrom\r\n`mlflow.projects.backend.local: === Running command 'docker run --rm --name advert_distance -e MLFLOW_RUN_ID=ffef -e MLFLOW_TRACKING_URI=http:\/\/mlflow.prod -e MLFLOW_EXPERIMENT_ID=5 -e AWS_SECRET_ACCESS_KEY=secr -e AWS_ACCESS_KEY_ID=654a  -e MLFLOW_SNOW_PWD=abcd -e MLFLOW_SNOW_USER=efgh advert_distance:29d3590 python advert_distance\/calculate_dist.py --env PROD ' in run with ID 'ffef02009c24474db47db0911880d099' ===\r\n`\r\nto\r\n`mlflow.projects.backend.local: === Running command 'docker run --rm --name advert_distance -e MLFLOW_RUN_ID=ffef -e MLFLOW_TRACKING_URI=http:\/\/mlflow.prod -e MLFLOW_EXPERIMENT_ID=5 -e AWS_SECRET_ACCESS_KEY=**** -e AWS_ACCESS_KEY_ID=****  -e MLFLOW_SNOW_PWD=**** -e MLFLOW_SNOW_USER=**** advert_distance:29d3590 python advert_distance\/calculate_dist.py --env PROD ' in run with ID 'ffef02009c24474db47db0911880d099' ===\r\n`\r\n\r\n## How is this patch tested?\r\n\r\nCheck the first lines of log after executing mlflow run. It just replaces the defined items in string with command, which is printed to the log and replaces those items with **** and instead of original command it prints the masked one (log_command).\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nEnable masking of parameters in mlflow log AWS S3 secret keys, etc. by setting a property in project configuration. \r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [x] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","301":"can anyone please help with this? i am using python and running on localhost\r\n\r\nNo Artifacts Recorded\r\nUse the log artifact APIs to store file outputs from MLflow runs.\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/53460267\/119797243-40086b00-bf04-11eb-9f0e-46c8b5eebca7.png)\r\n","302":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nTL;DR: transitioning a model from staging to production causes the URI `models:\/x\/Staging` to break. In my use case, ideally a model could remain in Staging when it is also in Production.\r\n\r\nHello MLflow team! I absolutely adore this project and am getting tons of utility out of it. One thing that feels a little funky to me is that in the model registry, a model can only be in one stage at a time, so if I promote a model to Production, it can no longer be Staging. I would like to open a discussion around the design of this single stage system, because it's quite possible that I am simply misunderstanding something and I certainly do not have the full context on the motivations behind the choices made by your team. If it turns out that we are in agreement, I would be happy to spend some effort on putting a PR together to enact the system I'm envisioning.\r\n\r\n\r\n## Motivation\r\nI would like to be able to use the stage feature in such a way that a new model can be tested as \"Staging\" and then transitioned to \"Production\", but still serve as \"Staging\". In my use case, we run Flask apps that load models from the MLflow model registry. For each model, there are two copies of the Flask app, `stg` and `prd`. Currently I use environment variables to pass a model URI to each instance of the Flask app, and then reboot it to pick up whatever model I specified. I am currently kind of limited to using version numbers, and would like to use the really cool stage system, but because transitioning from Staging to Production causes something like `mlflow.pyfunc.load_model('models:\/x\/Staging')` to throw an exception like `MlflowException: No versions of model with name 'x' and stage 'Staging' found`, I cannot do that without some error handling that would couple my applications to the specific error messaging patterns y'all are using in the current particular version.\r\n\r\nAnother reason this could be useful to the community at large is if we were to implement something like the feature request outlined in https:\/\/github.com\/mlflow\/mlflow\/issues\/4328. I believe these two features could be quite useful together.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nThinking back to my days of using Heroku, I really liked working with their pipeline promotion feature (for reference: https:\/\/devcenter.heroku.com\/articles\/pipelines#promoting-from-the-heroku-dashboard), and I think the ideology could be applied here. I haven't thought too far into what an implementation would look like, or how best to introduce this in a backwards compatible way. I think first it would be great to discuss it together. Cheers!","303":"## Willingness to contribute\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nThe idea is to let users stop training runs via the MLflow experiment UI (or corresponding REST API).\r\nThe tracking client will detect that the user wants the current run to stop, and will stop the running process.\r\n\r\n## Motivation\r\n\r\nAt [DAGsHub](https:\/\/DAGsHub.com\/), we've heard from several users who would benefit a lot from the ability to stop runs directly from the experiment visualization UI.  \r\nWe've even had a user say that they use WandB instead of MLflow, just because they have this specific feature.\r\n\r\nThe scenario is:\r\n1. The user is triggering multiple long-running training runs in parallel, in separate processes, probably on some cloud machines and with different hyperparams or code in each run.\r\n1. While the training runs are ongoing, the user checks the MLflow UI or API to check if the metrics are converging nicely, or looks at logged artifacts to see if they're going in the right direction. Example - log some generated GAN images after each epoch, and check which training runs are starting to show good looking images.\r\n1. The user would then like to cancel runs which look hopeless - to save money or free resources for more runs.\r\n    * Note that they might not know in advance the criteria for stopping a run, otherwise it could have been automated in code. The decision to terminate runs can depend on how the specific training run is faring in comparison to other current runs for example.\r\n1. It would be possible for them to do it by SSH'ing directly to the training machine or via whatever cluster manager they're using, but it's:\r\n    a.  Very inconvenient and disconnected from where the user made the actual decision - in the MLflow UI\r\n    b.  Might require permissions the user doesn't have, even though they're the actual data scientists who should be making this decision\r\n    c.  Difficult to find the exact process on the physical machine, which corresponds to a specific training run - meaning it's easy to make a mistake and kill the wrong process.\r\n\r\nAnother interesting corollary:  \r\nThis is hinting at a more general need - realtime monitoring. Right now, a complete page refresh is needed to reload metrics in the UI for a given run. It could be worth it to consider some auto refresh.  \r\nAlso, the user we talked to who uses WandB for this use case also set up a Slack bot to send live updates from WandB to their phone - loss curves, screenshots of generated artifacts, etc. Then they can know right away if a run is doing poorly, and cancel it via a Slack bot which activates the WandB API. This is also an interesting area of development in the future, probably not requiring any changes to core MLflow but instead as new examples, side projects or plugins.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n\r\n## Details\r\n\r\nMy proposal for how to implement this:\r\n* Use the existing tracking APIs (`log_params`, `log_metrics` etc.)\r\n* Add a new field to the response - this should be backwards compatible by leveraging protobuf, meaning older clients will just ignore it\r\n* This field will be a \"flag\" that indicates what the user wants to do with the run - 0 means nothing, 1 can mean \"stop\", and we can use more bit flags for other possible future functionality\r\n* On each relevant `log_X` function in the tracking client, it will check the returned flag and trigger a handler if required.\r\n* The tracking client will have a handler for the received flag - the default handler will just send a SIGINT to the current process, triggering an orderly shutdown, or else just call `sys.exit`.\r\n* This default handler can be overridden by the user to do something different\r\n* In terms of the backend - a new REST API endpoint will be created to cancel a specific run\r\n* This will store the instruction as a persistent flag in the DB, attached to the run\r\n* Then this flag will be checked and returned to the client on each relevant `log_X` call from the client\r\n\r\nThanks MLflow team! Looking forward to working on this after your design review.","304":"I try to integrate mlflow with [hydra](https:\/\/hydra.cc\/docs\/intro\/), but unfortunately have a problem when pass parameters to  `mlflow.run(..., parameters=parameters)`:\r\n\r\nseems like mlflow run parameters in format: `--p1 v1 --p2 v2`\r\nbut hydra understand only format: `p1=v1 p2=v2`\r\n\r\nand vice versa((\r\n\r\nHow better to fix this issue?\r\nIt would be useful, if in `mlflow.run(..., parameters=parameters)` we can specify format of how to pass parametrs","305":"Hi. I have a python script that does the following:\r\n\r\n`mlflow.projects.run(...)`\r\n\r\nThis script is executed in a container. When this script is executed, I get an error because the docker daemon is not accessible inside the container. Is there a workaround to this problem? Thanks.","306":"In the module utils.proto_json_utils, in the class NumpyEncoder the method try_convert() should return a Tuple[object, bool]. However, if the obyect o is of type np.object, then a single value is returned. This can be seen in line 67 of the module.\r\n\r\nThis bug affects serving tensorflow models with multiple outputs. \r\n\r\n\r\n\r\n\r\n\r\n\r\n","307":"https:\/\/github.com\/mlflow\/mlflow\/blob\/86322180259727f163b7ac9f914b274a2f8ede3f\/mlflow\/projects\/databricks.py#L197\r\n\r\nHi guys,\r\n\r\nunfortunately, everytime an mlflow experiment is run on a remote databricks cluster, mlflow is installed automatically as dependency via pypi (that requires access to the public internet). It follows that you cannot run experiments if you need to install dependencies via an (private) external source like [Jfrog Artifactory](https:\/\/jfrog.com\/artifactory) since the cluster setup fails.\r\nAfter setting up the cluster machines, the installation of mlflow is the direct successor, so it is not even possible to use an init script as a workaround.\r\n\r\nCould you fix that and make it optional?","308":"Hi.\r\n\r\nI have a use case where I need to run multiple projects on Kubernetes cluster. However, each of these projects require a different set of dependencies which I can set up in the Dockerfile and then create an image with the tag, let's say, _dep_image_ image. This image is referenced in the MLProject file in the **docker_env** property and everything works fine. \r\n\r\nHowever, this entire process is very time-consuming as it requires time to build and push **dep_image** and then when mlflow.projects.run is performed using python, it needs to create and push the final image which will start the training. \r\n\r\n1. Is it possible to specify the conda environment in the final image (without having to create a dependencies base image)?\r\n2. Is it possible to build \/ push this final image in an async manner?\r\n3. What is the parameter **use_conda** used for?\r\n\r\nPlease advice. Thanks!","309":"## Willingness to contribute\r\n\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [X] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nThe `pyfunc.spark_udf` method allows the caller to specify the result type like 'int'. However it does not accept 'boolean'. The proposal is simply to add this, corresponding to `BooleanType` \/ pandas `bool` to the list of supported types.\r\n\r\n## Motivation\r\n\r\n- What is the use case for this feature?\r\n\r\nFor example, 'sklearn' models can definitely return `boolean` from `predict`, so it's useful to be able to consume the predictions as a boolean column in Spark. \r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\n\r\nSee above and, more generally, Pyspark and pandas certainly support boolean types.\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n\r\nThis arose while constructing a demo of MLflow and a simple sklearn model, but, I think that's a proxy for real use cases.\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nOtherwise it has to result in a string column with values like \"True\", which is easy enough to turn into a boolean by testing for `== \"True\"`. Not a big deal, but also possibly no big change.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\n\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [X] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nPretty straightforward. BooleanType is not supported at https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/pyfunc\/__init__.py#L795\r\n\r\nThis seems to even have been on purpose, but wasn't clear to me what the reason was - not used?\r\nhttps:\/\/github.com\/mlflow\/mlflow\/pull\/719#discussion_r240415702","310":"**Python dependencies do not specify a version**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**:\r\n- **Python version**:\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nPython dependencies in `setup.py` do not specify versions. Over the last month , Flask and Jinja2 released new major versions, breaking compatibility with other packages. Installing mlflow with other packages that depend on older versions of Flask creates issues.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [x] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","311":"## MLflow Roadmap Item\r\n\r\nThis is an MLflow Roadmap item that has been prioritized by the MLflow maintainers.\r\n\r\n### System information\r\n- **OS Platform and Distribution**: MLflow docker image based on 'python:3.9-slim-buster'. Deployed in k8s cluster.\r\n- **MLflow installed from**: official pip \\ pypi\r\n- **MLflow version**: 1.16.0\r\n- **MLflow backend store**: AWS RDS MySQL 8.0.23\r\n- **MLflow artifact root**: AWS S3 bucket\r\n- **Python version**: 3.9\r\n- ** command** : `mlflow server --host 0.0.0.0  --port 5000 --default-artifact-root ${BUCKET}  --backend-store-uri mysql+pymysql:\/\/${USERNAME}:${PASSWORD}@${HOST}:${PORT}\/${DATABASE}`\r\n\r\n### Describe the problem\r\nI have been performing load test on the Mlflow Tracking server with a multiprocessing sample code. For few of the runs the following issue was raised :\r\n\r\n> mlflow.exceptions.MlflowException: (pymysql.err.OperationalError) (1213, 'Deadlock found when trying to get lock; try restarting transaction')\r\n[SQL: INSERT INTO latest_metrics (`key`, value, timestamp, step, is_nan, run_uuid) VALUES (%(key)s, %(value)s, %(timestamp)s, %(step)s, %(is_nan)s, %(run_uuid)s)]\r\n[parameters: {'key': 'rmse', 'value': 0.859125957974236, 'timestamp': 1620801352207, 'step': 0, 'is_nan': 0, 'run_uuid': 'eb6d1876d37d4706a97cec4db51937a6'}]\r\n\r\n### Code to reproduce issue\r\n```\r\nimport time\r\nimport multiprocessing\r\nfrom multiprocessing import Pool\r\nimport os\r\nimport warnings\r\nimport sys\r\nimport pandas as pd\r\nimport numpy as np\r\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.linear_model import ElasticNet\r\nimport mlflow\r\nimport mlflow.sklearn\r\n\r\nmlflow.set_tracking_uri({REMOTE_TRACKING_SERVER_URI}) \r\nmlflow.set_experiment({EXPERIMENT_NAME})\r\n\r\ndef eval_metrics(actual, pred):\r\n    # compute relevant metrics\r\n    rmse = np.sqrt(mean_squared_error(actual, pred))\r\n    mae = mean_absolute_error(actual, pred)\r\n    r2 = r2_score(actual, pred)\r\n    return rmse, mae, r2\r\n    \r\ndef load_data(data_path):\r\n    data = pd.read_csv(data_path)\r\n    # Split the data into training and test sets. (0.75, 0.25) split.\r\n    train, test = train_test_split(data)\r\n    \r\n    # The predicted column is \"quality\" which is a scalar from [3, 9]\r\n    train_x = train.drop([\"quality\"], axis=1)\r\n    test_x = test.drop([\"quality\"], axis=1)\r\n    train_y = train[[\"quality\"]]\r\n    test_y = test[[\"quality\"]]\r\n    return train_x, train_y, test_x, test_y\r\n\r\ndef train(x, alpha=0.5, l1_ratio=0.5):\r\n    # train a model with given parameters\r\n    warnings.filterwarnings(\"ignore\")\r\n    np.random.seed(40)\r\n    mlflow.sklearn.autolog()\r\n\r\n    # Read the wine-quality csv file (make sure you're running this from the root of MLflow!)\r\n    data_path = \".\/data\/wine-quality.csv\"\r\n    train_x, train_y, test_x, test_y = load_data(data_path)\r\n    # Useful for multiple runs (only doing one run in this sample notebook)\r\n\r\n    with mlflow.start_run(run_name='run-infy 1000 - ' + str(x)):\r\n        # Execute ElasticNet\r\n        lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\r\n        lr.fit(train_x, train_y)\r\n        # Evaluate Metrics\r\n        predicted_qualities = lr.predict(test_x)\r\n        (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\r\n\r\n        print(\"##############  logging params and metrics for \" + str(x) + \"\/\" + str(500) + \" ###########\")\r\n        # Log parameter, metrics, and model to MLflow\r\n        mlflow.log_param(key=\"alpha\", value=alpha)\r\n        mlflow.log_param(key=\"l1_ratio\", value=l1_ratio)\r\n        mlflow.log_metric(key=\"rmse\", value=rmse)\r\n        mlflow.log_metrics({\"mae\": mae, \"r2\": r2})\r\n        mlflow.log_artifact(data_path)\r\n        mlflow.sklearn.log_model(lr, \"model\")\r\n\r\ndef multiprocessing_func(x):\r\n    time.sleep(2)\r\n    (x, train(x, 0.5, 0.8))\r\n\r\nif __name__ == '__main__':\r\n    starttime = time.time()\r\n    pool = Pool()\r\n    pool.map(multiprocessing_func, range(1, 1000))\r\n    pool.close()\r\n    print()\r\n    print('Time taken = {} seconds'.format(time.time() - starttime))\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\n- [X] `help wanted`: Need help from community\r\n\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [X] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\n","312":"pride@ubuntu:~\/code\/mlflow-master\/examples$ python sklearn_logistic_regression\/train.py \r\nScore: 0.6666666666666666\r\nModel saved in run 8cd9354bea59432fb71fa575a5a3efd9\r\npride@ubuntu:~\/code\/mlflow-master\/examples$ mlflow models serve -m runs:\/8cd9354bea59432fb71fa575a5a3efd9\/model --port 1234\r\n2021\/05\/12 01:31:24 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\r\n2021\/05\/12 01:31:31 INFO mlflow.utils.conda: === Creating conda environment mlflow-7cddf73fb0d259cce996e88d1483ae63674b251e ===\r\nCollecting package metadata (repodata.json): \/ Traceback (most recent call last):\r\n  File \"\/home\/pride\/.local\/bin\/mlflow\", line 11, in <module>\r\n    sys.exit(cli())\r\n  File \"\/home\/pride\/.local\/lib\/python3.6\/site-packages\/click\/core.py\", line 829, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\/home\/pride\/.local\/lib\/python3.6\/site-packages\/click\/core.py\", line 782, in main\r\n    rv = self.invoke(ctx)\r\n  File \"\/home\/pride\/.local\/lib\/python3.6\/site-packages\/click\/core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/home\/pride\/.local\/lib\/python3.6\/site-packages\/click\/core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/home\/pride\/.local\/lib\/python3.6\/site-packages\/click\/core.py\", line 1066, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\/home\/pride\/.local\/lib\/python3.6\/site-packages\/click\/core.py\", line 610, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"\/home\/pride\/.local\/lib\/python3.6\/site-packages\/mlflow\/models\/cli.py\", line 56, in serve\r\n    ).serve(model_uri=model_uri, port=port, host=host)\r\n  File \"\/home\/pride\/.local\/lib\/python3.6\/site-packages\/mlflow\/pyfunc\/backend.py\", line 92, in serve\r\n    conda_env_path, command, self._install_mlflow, command_env=command_env\r\n  File \"\/home\/pride\/.local\/lib\/python3.6\/site-packages\/mlflow\/pyfunc\/backend.py\", line 149, in _execute_in_conda_env\r\n    conda_env_name = get_or_create_conda_env(conda_env_path, env_id=env_id)\r\n  File \"\/home\/pride\/.local\/lib\/python3.6\/site-packages\/mlflow\/utils\/conda.py\", line 95, in get_or_create_conda_env\r\n    stream_output=True,\r\n  File \"\/home\/pride\/.local\/lib\/python3.6\/site-packages\/mlflow\/utils\/process.py\", line 40, in exec_cmd\r\n    raise ShellCommandException(\"Non-zero exitcode: %s\" % (exit_code))\r\nmlflow.utils.process.ShellCommandException: Non-zero exitcode: -9","313":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Red Hat Enterprise Linux release 8.2 (Ootpa) (Remote Server)\r\n- **MLflow installed from (source or binary)**: Binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.16.0\r\n- **Python version**: 3.8.6\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n\r\n### Describe the problem\r\nMlflow gives a strange error if I log a numpy array as artifact while running autolog() on a remote server. On my local machine there  is no error. This behaviour seems to be connected to not having enough time for the logging because either waiting a few seconds or logging a smaller array doesn't reproduce the issue for the minimal working example. However, in my real script where I logged several arrays I noticed that even waiting 2 min was not enough and I could not make it work there. The exception arises the moment the script is closed.\r\nNote that this is a different issue than #4327. \r\nIt seems to be a paramiko issue (https:\/\/stackoverflow.com\/questions\/60037299\/attributeerror-nonetype-object-has-no-attribute-time-paramiko) but I was wondering if there is anything one can do from the mlflow point of view and it is weird that it only happens on the remote server. Btw my paramiko version is 2.7.2.\r\n\r\n### Code to reproduce issue\r\n```python\r\nimport mlflow\r\nimport numpy as np\r\nimport tempfile\r\nimport time\r\nimport os\r\n\r\n# Define functions for connecting to mlflow server.\r\ndef load_env(env_path: str):\r\n    \"\"\"Loads an .env file in your home directory.\r\n    To access the mlflow api, you need log in credentials. These can be stored in a local environment file which you\r\n    should protect with `chmod 600 .env`.\r\n    In this .env file you should define:\r\n    MLFLOW_TRACKING_USERNAME=your_username\r\n    MLFLOW_TRACKING_PASSWORD=your_password\r\n    MLFLOW_TRACKING_URI=***\r\n\r\n  Returns:\r\n      env: (dict) A dictionary containing the defined key value pairs.\r\n  \"\"\"\r\n  home = os.path.expanduser(\"~\")\r\n  with open(env_path, 'r') as f:\r\n      env = dict()\r\n      for line in f.readlines():\r\n          key, value = line.split('=')\r\n          env[key] = value.split('\\n')[0]\r\n      return env\r\n\r\ndef export_env(env_path: str):\r\n    \"\"\"Loads your .env file and exports the three variables important for mlflow.\r\n    MLFLOW_TRACKING_USERNAME, MLFLOW_TRACKING_PASSWORD, MLFLOW_TRACKING_URI\r\n    \"\"\"\r\n    env = load_env(env_path)\r\n    for key in [\"MLFLOW_TRACKING_USERNAME\", \"MLFLOW_TRACKING_PASSWORD\", \"MLFLOW_TRACKING_URI\"]:\r\n        os.environ[key] = env[key]\r\n\r\ndef log_array(a, name: str):\r\n    \"\"\"Logs an array as artifact to the currently active run.\r\n    Args:\r\n        a: (anything convertible to np.array) Array to store as artifact.\r\n        name: (str) Name to give the folder and file under th current mlflow run.\r\n    \"\"\"\r\n    a = np.array(a)\r\n    tmpdir = tempfile.mkdtemp()\r\n    save_path = os.path.join(tmpdir, name+\".npy\")\r\n    np.save(save_path, a)\r\n    mlflow.log_artifact(save_path, 'meta_data')\r\n    return\r\n\r\n# Export environment variables for the ssh connection of MLflow.\r\nenv_path = os.path.join(os.path.expanduser('~'), '.env')\r\nexport_env(env_path)\r\n\r\n# This is the important part.\r\nmlflow.autolog()\r\na = np.ones(1000)    # 10 is not enough to break it here\r\nlog_array(a, 'a')\r\n# time.sleep(15)        # workaround fixes exception\r\n```\r\n\r\n### Other info \/ logs\r\nTraceback: \r\n```\r\nException ignored in: <function Connection.__del__ at 0x14cbda767f70>\r\nTraceback (most recent call last):\r\n  File \"\/home\/kit\/stud\/uoeci\/conda\/envs\/Masterarbeit\/lib\/python3.8\/site-packages\/pysftp\/__init__.py\", line 1013, in __del__\r\n  File \"\/home\/kit\/stud\/uoeci\/conda\/envs\/Masterarbeit\/lib\/python3.8\/site-packages\/pysftp\/__init__.py\", line 785, in close\r\n  File \"\/home\/kit\/stud\/uoeci\/conda\/envs\/Masterarbeit\/lib\/python3.8\/site-packages\/paramiko\/sftp_client.py\", line 195, in close\r\n  File \"\/home\/kit\/stud\/uoeci\/conda\/envs\/Masterarbeit\/lib\/python3.8\/site-packages\/paramiko\/channel.py\", line 671, in close\r\n  File \"\/home\/kit\/stud\/uoeci\/conda\/envs\/Masterarbeit\/lib\/python3.8\/site-packages\/paramiko\/transport.py\", line 1846, in _send_user_message\r\nAttributeError: 'NoneType' object has no attribute 'time'\r\n```\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","314":"\r\n### Willingness to contribute\r\n\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- used example\/pytorch from https:\/\/github.com\/mlflow\/mlflow.git\r\n- Centos 7 \r\n- MLFlow installed from binary\r\n- MLFlow 1.16.0\r\n- Python 3.7.9 (NOTE: python 3.6 is used from the MLproject file)\r\n- mlflow models serve -m s3:\/\/ml-bucket\/YOURIDHERE\/artifacts\/pytorch-model\r\n\r\n\r\n### Describe the problem\r\n\r\nUsing the standard pytorch example in examples\/pytorch. \r\nNeeded some modifications to get it to work: \r\n1. add boto3 to the conda.yaml file\r\n2. line 238 of mnist_tensorboard_artifact, replated eval_data by eval_data.cuda()\r\n\r\nRunning the example using mlflow run . -Pepochs=1 works and gives results in s3 and mlflow. \r\nNow trying the serve the model fails with the following error\r\n\r\n`2021\/05\/09 20:03:27 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\r\n2021\/05\/09 20:03:28 INFO mlflow.utils.conda: === Creating conda environment mlflow-43ca95bd58d044f041c10a60bd564ce0673c7489 ===\r\nCollecting package metadata (repodata.json): done\r\nSolving environment: failed\r\n\r\nResolvePackageNotFound: \r\n  - torchvision=0.9.1+cu102\r\n  - pytorch=1.8.1+cu102\r\n\r\nTraceback (most recent call last):\r\n  File \"\/home\/erik\/miniconda3\/envs\/ds\/bin\/mlflow\", line 10, in <module>\r\n    sys.exit(cli())\r\n  File \"\/home\/erik\/miniconda3\/envs\/ds\/lib\/python3.7\/site-packages\/click\/core.py\", line 829, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\/home\/erik\/miniconda3\/envs\/ds\/lib\/python3.7\/site-packages\/click\/core.py\", line 782, in main\r\n    rv = self.invoke(ctx)\r\n  File \"\/home\/erik\/miniconda3\/envs\/ds\/lib\/python3.7\/site-packages\/click\/core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/home\/erik\/miniconda3\/envs\/ds\/lib\/python3.7\/site-packages\/click\/core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/home\/erik\/miniconda3\/envs\/ds\/lib\/python3.7\/site-packages\/click\/core.py\", line 1066, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\/home\/erik\/miniconda3\/envs\/ds\/lib\/python3.7\/site-packages\/click\/core.py\", line 610, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"\/home\/erik\/miniconda3\/envs\/ds\/lib\/python3.7\/site-packages\/mlflow\/models\/cli.py\", line 56, in serve\r\n    ).serve(model_uri=model_uri, port=port, host=host)\r\n  File \"\/home\/erik\/miniconda3\/envs\/ds\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/backend.py\", line 92, in serve\r\n    conda_env_path, command, self._install_mlflow, command_env=command_env\r\n  File \"\/home\/erik\/miniconda3\/envs\/ds\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/backend.py\", line 149, in _execute_in_conda_env\r\n    conda_env_name = get_or_create_conda_env(conda_env_path, env_id=env_id)\r\n  File \"\/home\/erik\/miniconda3\/envs\/ds\/lib\/python3.7\/site-packages\/mlflow\/utils\/conda.py\", line 95, in get_or_create_conda_env\r\n    stream_output=True,\r\n  File \"\/home\/erik\/miniconda3\/envs\/ds\/lib\/python3.7\/site-packages\/mlflow\/utils\/process.py\", line 40, in exec_cmd\r\n    raise ShellCommandException(\"Non-zero exitcode: %s\" % (exit_code))\r\nmlflow.utils.process.ShellCommandException: Non-zero exitcode: 1\r\n`\r\nClearly, it is looking for torchvision=0.9.1+cu102 and pytorch=1.8.1+cu102 but these versions do not exist. Also they are different from the conda.yaml file. \r\n\r\nInterestingly, the conda.yaml file uploaded to S3 is also wrong: \r\n\r\n`\r\nchannels:\r\n- defaults\r\n- conda-forge\r\n- pytorch\r\ndependencies:\r\n- python=3.6.13\r\n- pytorch=1.8.1+cu102\r\n- torchvision=0.9.1+cu102\r\n- pip\r\n- pip:\r\n  - mlflow\r\n  - cloudpickle==1.6.0\r\nname: mlflow-env\r\n`\r\n\r\n### Code to reproduce issue\r\n\r\nSee the github examples. \r\n\r\n### Other info \/ logs\r\n\r\n-\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ x] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ x] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","315":"parametrs of the server:\r\nmlflow server --host localhost --port 5000 --backend-store-uri sqlite:\/\/\/C:\/\/Users\/Python\/\/airflow+mlflow\/\/mlflow.db --default-artifact-root C:\/\/Users\/\/Python\/\/airflow+mlflow\/\/\r\nPython 3.8\r\n\r\nCode below:\r\n\r\nalpha=1\r\nl1_ratio=1\r\nmlflow.set_tracking_uri(\"http:\/\/localhost:5000\")\r\nmlflow.set_experiment('name_experiment1')\r\n\r\nwith mlflow.start_run():\r\n    lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\r\n    lr.fit(train_x, train_y)\r\n    \r\n    predicted_qualities = lr.predict(test_x)\r\n\r\n    (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\r\n    \r\n    print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\r\n    print(\"  RMSE: %s\" % rmse)\r\n    print(\"  MAE: %s\" % mae)\r\n    print(\"  R2: %s\" % r2)\r\n\r\n    mlflow.log_param(\"alpha\", alpha)\r\n    mlflow.log_param(\"l1_ratio\", l1_ratio)\r\n    mlflow.log_metric(\"rmse\", rmse)\r\n    mlflow.log_metric(\"r2\", r2)\r\n    mlflow.log_metric(\"mae\", mae)\r\n    \r\n    mlflow.sklearn.log_model(lr, \"model\")\r\n\r\n   \r\n    \r\n    mlflow.end_run()\r\n\r\nerror i have:\r\nMlflowException: Could not find a registered artifact repository for: c:\/\/Users\/\/\/Python\/\/airflow+mlflow\/\/artifacts\/2\/b79982e9be364051a3f36fd40a3a0aa2\/artifacts. Currently registered schemes are: ['', 'file', 's3', 'gs', 'wasbs', 'ftp', 'sftp', 'dbfs', 'hdfs', 'viewfs', 'runs', 'models', 'mssql']\r\n\r\n","316":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nWhen running a project (with `mlflow run` the API) using a Docker container environment, MLflow has an option to automatically build (or re-build) the Docker image based on a Dockerfile specified in the MLproject file.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nUsers that make frequent changes in their Docker image and do not want to re-build it themselves.\r\n- Why is this use case valuable to support for MLflow users in general?\r\nMakes working with Docker container environments much easier.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nIt would simplify the adoption of MLflow in my team. Relying on conda environments is not an option we are considering.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nI could not see a way to implement this as a plugin and ended up creating a really simple wrapper, but I feel this feature is interesting enough to be part of MLflow.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nI created a very simple wrapper for MLflow to do this feature and a few others (not the subject of this FR):\r\nhttps:\/\/github.com\/saulvargas\/mlflux\/blob\/master\/mlflux\/cli\/run.py#L70-L106 (it does a few other things that are irrelevant to this FR).","317":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: 1.16.0\r\n- **Python version**: 3.6.8\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: not relevant\r\n\r\n### Describe the problem\r\nI want to integrate some dashboards in mlflow. Particularly, I'm using an ExplainerDashboard. My model displays well when I open it in a separate tab, but not in mlflow itself, where it stays stuck on \"loading...\"\r\n\r\nThe idea is to register an iframe containing my dashboard as an html, which is then saved as an artifact.\r\n\r\n```python\r\nf'''<!DOCTYPE html>\r\n    <html>\r\n    <iframe src=\"{dashboard_url}\" style='width: 700px; height: 450px' sandbox='allow-same-origin allow-scripts'>\r\n    <\/iframe>\r\n    <\/html>''' \r\n```\r\n\r\nThe server running the dashboard is a flask app containing a dash app. The flask part seems to be displayed correctly and I can interact with (menu, tabs, etc...), but not the dash part. I'm working on a toy example, I will provide it asap.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","318":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [X] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nCurrently model stages are fixed - Staging, Production and Archived. This FR would extend this list of three to be configurable, such that custom stages could be added. For example \"Dev, UAT, Production, Archived\"\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n\r\nUsers who want more fine-grained control of the model lifecycle\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\n\r\nMLflow is a great experiment tracker, and this would help improve its ease-of-integration with model serving solutions by, as an example, promoting\/deploying models at different stages to different locations\/severs\/environments.\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n\r\nSame as the above.\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nCurrently model stages are few (only two active stages - Staging and Production), and they are hard coded.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [X] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [X] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nWould love help figuring this out. I did a quick search for [\"Staging\"](https:\/\/github.com\/mlflow\/mlflow\/search?q=Staging) in the repo, and I can see that the stages are hard coded in two places:\r\n\r\n```\r\nmlflow\/server\/js\/src\/model-registry\/constants.js\r\nmlflow\/entities\/model_registry\/model_version_stages.py\r\n```\r\n\r\nIf the active stages could be bought out into config file, and then exposed so the UI can request them, I am hoping there will be minimal other changes. The code utilising ACTIVE_STAGES in the js should be able to handle extensions to the list, a same for the ALL_STAGES python variable. I believe this is because the stages are used mostly by clients through the cil or python API, so are more like useful semantic tags rather than something utilised significantly by mlflow in its own internal logic.","319":"### Willingness to contribute\r\nYes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 20.10\r\n- **MLflow installed from (source or binary)**: binary (pip install mlflow)\r\n- **MLflow version (run ``mlflow --version``)**: 1.16.0\r\n- **Python version**: 3.8.5.\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: \r\n\r\n### Describe the problem\r\nMy goal is to configure ML Flow to run on a remote Linux server, with logs stored in the PostgreSQL database and artifacts in \/home\/aw\/mlfow\/mllogs, where \"aw\" is my user name with root privileges.\r\n\r\nWhen I run my simple python code (see section below):\r\n- when it's last line (\"mlflow.log_artifact(\"features.txt\")) is commented out: I get no errors in Python, but when I enter log details via browser, in the artifact section I get the warning: \"Unable to list artifacts stored undersftp:\/\/mlflow_user@194.39.141.27:~\/mlflow\/mlruns\/0\/d1eb9ce83b6b4ede96a9ea5203c097da\/artifacts\"\r\n- in case the last line is active, python compiler returns a long list of errors, ending with \"ValueError: Port could not be cast to integer value as '~'\"\r\n\r\nI tried running the server from the CLI in many different ways, each time changing the --default-artifact-root parameter (see section below). Interestingly, the printout of the mlflow.get_artifact_uri() variable from the Python code remains the same, despite changes in the CLI server parameters: it always shows up as \r\nsftp:\/\/mlflow_user@94.39.141.27:~\/mlflow\/mlruns\/0\/c613c110839946a3adc198377cc82c0c\/artifacts\r\n\r\nSo, it looks like there is a problem of setting this parameter up during MLFlow server run from CLI. Maybe it's cached somewhere? Linux server reboot doesn't help.\r\n\r\nMy apologies if it's my mistake, not a BUG: I feel more a DataScientist than programmer...\r\n\r\n### Code to reproduce issue\r\nServer CLI run (credentials are just examples):\r\n\r\noption 1 (based on https:\/\/towardsdatascience.com\/setup-mlflow-in-production-d72aecde7fef):\r\nmlflow server --backend-store-uri postgresql:\/\/mlflow_user:mlflow321@localhost\/mlflow_db --default-artifact-root sftp:\/\/mlflow_user@194.39.141.27:~\/mlflow\/mlruns -h 0.0.0.0 -p 8000&\r\n\r\noptions 2.1 and 2.2 (aw is my user name on the machine, with root privileges):\r\nmlflow server --backend-store-uri postgresql:\/\/mlflow_user:mlflow321@localhost\/mlflow_db --default-artifact-root sftp:\/\/aw:aw_pass@194.39.141.27:~\/mlflow\/mlruns -h 0.0.0.0 -p 8000&\r\n\r\nmlflow server --backend-store-uri postgresql:\/\/mlflow_user:mlflow321@localhost\/mlflow_db --default-artifact-root sftp:\/\/aw:@194.39.141.27:~\/home\/aw\/mlflow\/mlruns -h 0.0.0.0 -p 8000&\r\n\r\noption 3:\r\nmlflow server --backend-store-uri postgresql:\/\/mlflow_user:mlflow321@localhost\/mlflow_db --default-artifact-root sftp:\/\/mlflow_user:mlflow_pass#@194.39.141.27:~\/mlflow\/mlruns -h 0.0.0.0 -p 8000&\r\n\r\n\r\nPython code:\r\n```\r\nimport mlflow\r\n\r\nif __name__ == \"__main__\":\r\n    mlflow.set_tracking_uri(\"http:\/\/194.39.141.27:8000\") #hostname IP here is just an example\r\n\r\n    features = \"rooms, zipcode, median_price, school_rating, transport\"\r\n    with open(\"features.txt\", 'w') as f:\r\n        f.write(features)\r\n\r\n    with mlflow.start_run():\r\n\r\n        tracking_uri = mlflow.get_tracking_uri()\r\n        artifact_uri = mlflow.get_artifact_uri()\r\n        print(\"Tracking uri: {}\".format(tracking_uri))\r\n        print(\"Artifact uri: {}\".format(artifact_uri))\r\n\r\n        mlflow.log_artifact(\"features.txt\")\r\n```\r\n\r\n\r\n### Other info \/ logs\r\nPython compiler log:\r\n\r\nTraceback (most recent call last):\r\n  File \"1.py\", line 18, in <module>\r\n    mlflow.log_artifact(\"features.txt\")\r\n  File \"\/home\/aw\/anaconda3\/lib\/python3.8\/site-packages\/mlflow\/tracking\/fluent.py\", line 544, in log_artifact\r\n    MlflowClient().log_artifact(run_id, local_path, artifact_path)\r\n  File \"\/home\/aw\/anaconda3\/lib\/python3.8\/site-packages\/mlflow\/tracking\/client.py\", line 903, in log_artifact\r\n    self._tracking_client.log_artifact(run_id, local_path, artifact_path)\r\n  File \"\/home\/aw\/anaconda3\/lib\/python3.8\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 271, in log_artifact\r\n    artifact_repo = self._get_artifact_repo(run_id)\r\n  File \"\/home\/aw\/anaconda3\/lib\/python3.8\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 262, in _get_artifact_repo\r\n    return get_artifact_repository(artifact_uri)\r\n  File \"\/home\/aw\/anaconda3\/lib\/python3.8\/site-packages\/mlflow\/store\/artifact\/artifact_repository_registry.py\", line 102, in get_artifact_repository\r\n    return _artifact_repository_registry.get_artifact_repository(artifact_uri)\r\n  File \"\/home\/aw\/anaconda3\/lib\/python3.8\/site-packages\/mlflow\/store\/artifact\/artifact_repository_registry.py\", line 71, in get_artifact_repository\r\n    return repository(artifact_uri)\r\n  File \"\/home\/aw\/anaconda3\/lib\/python3.8\/site-packages\/mlflow\/store\/artifact\/sftp_artifact_repo.py\", line 32, in __init__\r\n    \"port\": parsed.port,\r\n  File \"\/home\/aw\/anaconda3\/lib\/python3.8\/urllib\/parse.py\", line 174, in port\r\n    raise ValueError(message) from None\r\nValueError: Port could not be cast to integer value as '~'\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n\r\nLanguage \r\n- Python","320":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Bib Sur 11.1 M1 \r\n- **MLflow installed from (source or binary)**:binary\r\n- **MLflow version (run ``mlflow --version``)**:1.16.1.dev0\r\n- **Python version**:3.8.7\r\n- **npm version, if running the dev UI**: NA\r\n- **Exact command to reproduce**:``mlflow sagemaker build-and-push-container``\r\n\r\n### Describe the problem\r\nWhen running mlflow sagemaker build-and-push-container on stage 6\/11  getting error: \r\n``pip: not found``\r\nWhich results the following error\r\n``ERROR: executor failed running [\/bin\/sh -c pip install mlflow==1.16.1.dev0]: exit code: 127``\r\n### Code to reproduce issue\r\n``mlflow sagemaker build-and-push-container on macOS with m1 chip``\r\n\r\n### Other info \/ logs\r\n``\r\n2021\/05\/07 13:25:10 INFO mlflow.models.docker_utils: Building docker image with name mlflow-pyfunc\r\n\/var\/folders\/ld\/lrxd9nms3cxb4n5zc9hbmkx00000gn\/T\/tmp7yj4slms\/\r\n\/var\/folders\/ld\/lrxd9nms3cxb4n5zc9hbmkx00000gn\/T\/tmp7yj4slms\/\/Dockerfile\r\n#1 [internal] load build definition from Dockerfile\r\n#1 sha256:79326039823528e49952a7933dcae18811abe46550e93ecc41b50189929c4896\r\n#1 transferring dockerfile: 1.48kB done\r\n#1 DONE 0.0s\r\n\r\n#2 [internal] load .dockerignore\r\n#2 sha256:61e7d84907517aae41ea69247955c08101c06e54c354b0e4fb106c27f00ece93\r\n#2 transferring context: 2B done\r\n#2 DONE 0.0s\r\n\r\n#3 [internal] load metadata for docker.io\/library\/ubuntu:18.04\r\n#3 sha256:fbbba859d4013c87b395abe2d64c63aab916412a50c1cc26385876cb51f47d98\r\n#3 DONE 4.6s\r\n\r\n#4 [ 1\/11] FROM docker.io\/library\/ubuntu:18.04@sha256:538529c9d229fb55f50e6746b119e899775205d62c0fc1b7e679b30d02ecb6e8\r\n#4 sha256:fd5b87d4f0bd2d6328ae795f7178cc805c37fbe857c59b6f78998994d03ba061\r\n#4 DONE 0.0s\r\n\r\n#5 [ 2\/11] RUN apt-get -y update && apt-get install -y --no-install-recommends          wget          curl          nginx          ca-certificates          bzip2          build-essential          cmake          openjdk-8-jdk          git-core          maven     && rm -rf \/var\/lib\/apt\/lists\/*\r\n#5 sha256:dc87dd6b630771b6beb63f9e91b6a533d81beb84944e77fbe40e94c8e3cd163a\r\n#5 CACHED\r\n\r\n#6 [ 3\/11] RUN curl -L https:\/\/repo.anaconda.com\/miniconda\/Miniconda3-latest-Linux-x86_64.sh >> miniconda.sh\r\n#6 sha256:e71fba969340a16eb60e402965a64ec87456daeecd1fe0f44639f354213bd012\r\n#6 CACHED\r\n\r\n#7 [ 4\/11] RUN bash .\/miniconda.sh -b -p \/miniconda; rm .\/miniconda.sh;\r\n#7 sha256:bbead9c45a9ae378f3672ab6862561ff2e2770e540ad0b45395e33a156dfa4c5\r\n#7 CACHED\r\n\r\n#8 [ 5\/11] WORKDIR \/opt\/mlflow\r\n#8 sha256:96fb5418c5c5673f2c9aa1b64ea2e26b3e37f6d9f3856b8bbca848339c0eac29\r\n#8 CACHED\r\n\r\n#9 [ 6\/11] RUN pip install mlflow==1.16.1.dev0\r\n#9 sha256:f7f0439b6732bec2cb1b8d5245faaddc44c2fc6c1984ac5149cfaf5383cb07c9\r\n#9 0.171 \/bin\/sh: 1: pip: not found\r\n#9 ERROR: executor failed running [\/bin\/sh -c pip install mlflow==1.16.1.dev0]: exit code: 127\r\n------\r\n > [ 6\/11] RUN pip install mlflow==1.16.1.dev0:\r\n------\r\n\r\nexecutor failed running [\/bin\/sh -c pip install mlflow==1.16.1.dev0]: exit code: 127\r\n2021\/05\/07 13:25:16 INFO mlflow.sagemaker: Pushing image to ECR\r\n^[[A2021\/05\/07 13:25:18 INFO mlflow.sagemaker: Pushing docker image mlflow-pyfunc to 236435545375.dkr.ecr.ap-southeast-2.amazonaws.com\/mlflow-pyfunc:1.16.1.dev0\r\n2021\/05\/07 13:25:18 INFO mlflow.sagemaker: Executing: aws ecr get-login-password | docker login  --username AWS  --password-stdin 236435545375.dkr.ecr.ap-southeast-2.amazonaws.com;\r\ndocker tag mlflow-pyfunc 236435545375.dkr.ecr.ap-southeast-2.amazonaws.com\/mlflow-pyfunc:1.16.1.dev0;\r\ndocker push 236435545375.dkr.ecr.ap-southeast-2.amazonaws.com\/mlflow-pyfunc:1.16.1.dev0\r\nLogin Succeeded\r\nError response from daemon: No such image: mlflow-pyfunc:latest\r\nThe push refers to repository [236435545375.dkr.ecr.ap-southeast-2.amazonaws.com\/mlflow-pyfunc]\r\nAn image does not exist locally with the tag: 236435545375.dkr.ecr.ap-southeast-2.amazonaws.com\/mlflow-pyfunc\r\n``\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [x ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","321":"## What changes are proposed in this pull request?\r\n\r\nChanges required to implement this feature (mostly in mlflow\/projects\/kubernetes.py):\r\n\r\n_run_kubernetes_job() checks the \"kind\" field of the job template, retaining backwards-compatibility if the object's \"kind\" field is \"Job\". Otherwise, a CRD is assumed, i.e. api_instance = kubernetes.client.CustomObjectsApi() rather than kubernetes.client.BatchV1Api(), api_instance.create_namespaced_custom_object() rather than api_instance.create_namespaced_job(), etc...\r\n\r\n_get_kubernetes_job_definition(): renders the job YAML as a template with access to MLProject information, similar to how MLProject entry_point commands are rendered.\r\n\r\nKubernetesSubmittedRun: constructor (__init__) accepts the rendered job template, parses out additional variables (kind, apiVersion, namespace, etc). The wait, _update_status, and cancel methods are updated similarly to _run_kubernetes_job() (step 1 above).\r\n\r\nDocumentation and testing updates to reflect the template rendering changes and CRD support.\r\n\r\n## How is this patch tested?\r\n\r\nExisting pytest framework, and manually via examples directory.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nExtended Kubernetes project backend to support CRDs.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [x] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","322":" Hello, \r\nI am trying to bring up the mlflow server on gcp VM and storing the artifacts in gcs bucket. The artifacts, metrics and parameters are getting logged, but the information about the models UI, i.e schema, predictions using spark and pandas dataframe, is not gettign loaded. instead - \"Couldn't load model information due to an error\". this message is being displayed. I am using xgboost model, tried the same with autologging for native flavour also with manual logging of the model using xgboost.log_model(). Either way im facing the same problem. \r\nPlease help me fix this. ","323":"## What changes are proposed in this pull request?\r\n\r\n* In feature request #2770, @persas proposed adding flavor support for Gensim.\r\n* In pull request #2878, @persas attempted to merge their changes, albeit encountered issues.\r\n\r\nThis pull request attempts to finalize the changes made by @persas. I have done the following:\r\n* cherry-picked the relevant commits from @persas' fork's [branch](https:\/\/github.com\/persas\/mlflow\/tree\/gensim_flavor)\r\n* updated linting\/formatting, added a few new function parameters\r\n* tested locally\r\n\r\nI will preempt a code review question posted in #2878:\r\n\r\n> Does this pickled object have a predict method that takes a DataFrame as input?\r\n\r\nTo be honest, I don't know how to implement this. Syntactically, sure, but I don't think `predict` maps cleanly to Gensim's models.\r\n\r\nFor example, a Gensim Word2Vec model has the following methods (just off the top of my head... I'm sure there are others):\r\n\r\n```\r\n# a tiny model trained on a handful of European Union regulations\r\n\r\nIn[1]:\r\nmodel.wv.most_similar('bank')\r\n\r\nOut[1]: \r\n[('central', 0.7694460153579712),\r\n ('gaza', 0.580155611038208),\r\n ('banking', 0.570080041885376),\r\n ('saderat', 0.5607864856719971),\r\n ('intelligence', 0.5576319098472595),\r\n ('government', 0.5570472478866577),\r\n ('pyongyang', 0.5333139300346375),\r\n ('subsidiary', 0.5194635391235352),\r\n ('credit', 0.5088622570037842),\r\n ('549300re88ojp9j24z18', 0.497680127620697)]\r\n\r\nIn[2]:\r\nmodel.wv.n_similarity(['grain'], ['wheat'])\r\n\r\nOut[2]: \r\n0.47097108\r\n\r\nIn[3]:\r\nmodel.wv.relative_cosine_similarity('grain', 'barley')\r\n\r\nOut[3]: \r\n0.11125039338027068\r\n\r\nIn[4]:\r\nmodel.wv.similar_by_word('meat')\r\n\r\nOut[4]: \r\n[('offal', 0.6513410806655884),\r\n ('frozen', 0.6433013677597046),\r\n ('carcase', 0.6225498914718628),\r\n ('boned', 0.6214909553527832),\r\n ('boneless', 0.6209194660186768),\r\n ('cut', 0.6071479916572571),\r\n ('sheep', 0.5907434821128845),\r\n ('poultry', 0.5677666068077087),\r\n ('bone', 0.5666332840919495),\r\n ('chilled', 0.5539602041244507)]\r\n\r\n```\r\nIt is not clear to me what `predict`'s input `dataframe` would contain, and I don't know what the output ought to be.\r\n\r\n## How is this patch tested?\r\n\r\n1. Unit tests\r\n2. `.\/dev\/run-small-python-tests.sh`, albeit some fail (Hadoop and such?)\r\n3. Manual testing using an existing MLflow instance and PyCharm's console:\r\n```\r\nimport gensim\r\nimport mlflow\r\n\r\nmlflow.set_tracking_uri('https:\/\/my.datascience.server\/mlflow\/')\r\nmlflow.set_experiment('gensim_flavor')\r\nmodel = gensim.models.word2vec.Word2Vec([['hello', 'world']*5])\r\nwith mlflow.start_run(run_name='test_1') as run:\r\n    mlflow.gensim.log_model(model, 'model.gensim', registered_model_name='registered_model_name')\r\n```\r\nI do not expect these changes to pass first tests. Hopefully I will be able to address accordingly.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nThis pull request adds flavor support for Gensim models.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","324":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [X] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nMany organizations use existing JFrog Adrtifactory servers to govern artifacts produced by development pipelines. The same JFrog Artifactory server can certainly be used to govern models produced from machine learning training and development pipelines. JFrog has a multitude of connectors and for this particular case most of them can be used. For instance, it is possible to leverage the existing nuget connector for JFrog Artifactory\r\n\r\n\r\n## Motivation\r\n- **What is the use case for this feature?** As the title says, support for more backend store integrations. One that's widely used.\r\n- **Why is this use case valuable to support for MLflow users in general?** This will avoid scattered artifactory storage places.\r\n- **Why is this use case valuable to support for your project(s) or organization?** We already use JFrog. This will avoid using a different storage for ML artifacts\r\n- **Why is it currently difficult to achieve this use case?** MLFlow doesn't support this at all.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [X] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [X] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [X] `language\/python`: R APIs and clients\r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nThere's already an abstract class meant for the extension of supported stores, it's called ``ArtifactRepository``\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/store\/artifact\/artifact_repo.py\r\n\r\nWe can add support for nuget integration in MLFlow and that will indirectly enable integration to JFrog as well.\r\nHit two birds with one stone.\r\n\r\nHere are two links that are useful for this:\r\nhttps:\/\/jfrog.com\/integration\/nuget-repository\/\r\nhttps:\/\/www.jfrog.com\/confluence\/display\/RTF\/Nuget+Repositories","325":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 16.04.6 LTS\r\n- **MLflow installed from (source or binary)**:pip\r\n- **MLflow version (run ``mlflow --version``)**:1.16.0\r\n- **Python version**:3.8.5\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: mlflow ui --host 192.168.0.162:8005 --backend-store-uri 'postgresql+psycopg2:\/\/<username>:<password>@localhost:5432\/mlflow'\r\n\r\n### Describe the problem\r\nI have set up MLflow on a remote server on which I run my notebooks. I use postgres database on the same server as a backend uri and  save artifacts locally on the server. When running the above command on my server, I was successfully able to open MLflow ui for couple of days but now the same command produces a worker timeout error and the ui is just blank page with nothing on it. I have not changed anything which can explain this change. I have also tried to use just mlflow ui --host 192.168.0.162:8005 (taking default backend uri and artifact root ) on server but it produces same error. Changing the port to 5000 , or setting a custom gunicorn timeout does not help.\r\n### Code to reproduce issue\r\n mlflow ui --host 192.168.0.162:8005 --backend-store-uri 'postgresql+psycopg2:\/\/<username>:<password>@localhost:5432\/mlflow'\r\n\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [  ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","326":"## What changes are proposed in this pull request?\r\n\r\nThe current implementation supports basic password, token based authentication and server certs. A more popular frame work is the oath2 flow, I have implemented the oath2 schema of working, may need fixes. Welcome other contributors\r\n\r\n## How is this patch tested?\r\n\r\nManual testing\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ x ] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ x ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ x ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","327":"## MLflow Roadmap Item\r\n\r\nThis is an MLflow Roadmap item that has been prioritized by the MLflow maintainers. We're seeking help with the implementation of roadmap items tagged with the `help wanted` label.\r\n\r\nFor requirements clarifications and implementation questions, or to request a PR review, please tag @WeichenXu123 in your communications related to this issue.\r\n\r\n## Proposal Summary\r\nSince MLFlow can easily get really slow, it would be great if the log_batch method really would log in batches. This method currently only iterates over all metrics, params and tags and then calls the log_metric\/param\/tag methods on each. In my understanding each of these calls opens a new database connection which is very slow. It seriously slows down my training loop when I log the losses in each batch of each epoch.\r\n\r\n## Motivation\r\nSee the following snippet from `sqlalchemy_store.py`:\r\n\r\n```python\r\ndef log_batch(self, run_id, metrics, params, tags):\r\n    _validate_run_id(run_id)\r\n    _validate_batch_log_data(metrics, params, tags)\r\n    _validate_batch_log_limits(metrics, params, tags)\r\n    with self.ManagedSessionMaker() as session:\r\n        run = self._get_run(run_uuid=run_id, session=session)\r\n        self._check_run_is_active(run)\r\n    try:\r\n        for param in params:\r\n            self.log_param(run_id, param)\r\n        for metric in metrics:\r\n            self.log_metric(run_id, metric)\r\n        for tag in tags:\r\n            self.set_tag(run_id, tag)\r\n    except MlflowException as e:\r\n        raise e\r\n    except Exception as e:\r\n        raise MlflowException(e, INTERNAL_ERROR)\r\n```\r\n\r\n- What is the use case for this feature?\r\nImagine you are doing a hyperparameter search (e.g. using hyperopt or optuna) and you want to log each of the trials in detail. In my example I am traning 20 models in parallel on 4 GPUs and I want to log the losses. When using the default file storage (mlruns folder), this works very well, but then the UI gets extremely slow. Therefore I am switching to a database backend which makes the UI really fast, but unfortunately the logging very slow.\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\nPerformance is always important and I have already seen many questions about performance issues in MLFlow.\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nSame as above.\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nLogging slows down my training loop a lot. Logging should be highly optimized and the number of DB transactions should be as low as possible.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [x] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","328":"Signed-off-by: Tianchen Wu <wu.tianchhen.business@gmail.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nallow user to build prediction server docker image behind enterprise proxy (implementation details: allow mvn in dockerfile from pull to accept proxy setting through command line)\r\n\r\nThe following environment variables can be configured:\r\n\r\n* MLFLOW_MVN_HTTP_PROXY_HOST\r\n* MLFLOW_MVN_HTTP_PROXY_PORT\r\n* MLFLOW_MVN_HTTPS_PROXY_HOST\r\n* MLFLOW_MVN_HTTPS_PROXY_PORT\r\n* MLFLOW_MVN_NO_PROXY_HOSTS\r\n\r\n## How is this patch tested?\r\n\r\ntested with command mlflow models build-docker within enterprise proxy setting\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nThis is a new feature for user. Now they can configure mvn proxy when mlflow models build-docker\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","329":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nThe proposal is to add pagination to experiments in the UI, so the UI is still responsive when there are thousands of experiments.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n  - Our ML use case involves creating thousands of experiments but the UI loads very slowly (almost unusable) when there are more than 2-3 thousand experiments. There are many experiments because we train customer-specific models on a schedule for many customers, and each customer is represented as an experiment.\r\n- Why is this use case valuable to support for MLflow users in general?\r\n  - There are probably other users who create or would like to create many experiments.\r\n  - Competitors like Neptune use the limitation around number of experiments to [convince users to use other tools](https:\/\/neptune.ai\/blog\/the-best-mlflow-alternatives). This feature can make mlflow more useful to a wider audience.\r\n- Why is this use case valuable to support your project(s) or organization?\r\n  - We intend to use mlflow in production settings that train thousands of models over thousands of experiments daily. It's hard to do so with the current limitation.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n  - The most natural and useful way to organize our ML workflow information is across many experiments. The current limitation means we'll need to figure out a workaround.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [X] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nImplementation-wise, it seems like [this PR](https:\/\/github.com\/mlflow\/mlflow\/pull\/3881) is a prerequisite, we'd need an endpoint to search experiments to preserve search behavior, and we'd need to change the front-end code.\r\n","330":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\nTensorboardX (https:\/\/github.com\/lanpa\/tensorboardX) provides Tensorboard functionality for PyTorch models.\r\n\r\nPresently, MLflow's TensorFlow autologging functionality integrates with Tensorboard to automatically capture parameters, metrics, etc from TensorFlow training session. \r\n\r\nComparable functionality for tensorboardX would provide better support for non-TF workflows that make use of tensorboard-style logging APIs.\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [X] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nThis FR proposes to provide autologging functionality to intercept TensorboardX events emitted during model training (e.g. PyTorch training) and log corresponding metrics \/ tags \/ parameters to MLflow Tracking.\r\n\r\n## Motivation\r\n- What is the use case for this feature? Easing the incorporation of MLflow Tracking into existing training workflows that make use of the popular tensorboardX tool (including other libraries, such as https:\/\/github.com\/microsoft\/DeepSpeed)\r\n- Why is this use case valuable to support for MLflow users in general? Broadens the ecosystem of supported Tracking-compatible ML frameworks to include a variety of prominent tools.\r\n- Why is this use case valuable to support for your project(s) or organization? MLflow collaborators, including Microsoft, use tensorboardX-integrated tools.\r\n- Why is it currently difficult to achieve this use case? Without tensorboardX integrations, users must currently add both MLflow & tensorboardX logging statements to their training code. For certain libraries that leverage tensorboardX (e.g. DeepSpeed), users often cannot directly control the instrumentation themselves.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nPerhaps an `mlflow.tensorboardx.autolog()` API makes sense for exposing this functionality; we'll have to work on designing \/ naming API(s) for this feature.\r\n\r\nWe could also consider a plugin system for autologging integrations.","331":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nIn order to do statistical analysis for model performance, we want to plot error bars (mean, std) for performance metrics of multiple runs. Here is an example of error bars plot for an object detection model (5 runs in total).\r\n<img width=\"671\" alt=\"Screen Shot 2021-04-21 at 11 20 46 AM\" src=\"https:\/\/user-images.githubusercontent.com\/22140633\/115602302-a231d880-a293-11eb-8671-e098668eb4c9.png\">\r\n- Why is this use case valuable to support for MLflow users in general?\r\nI believe many ML engineers require this feature since the statistical analysis of model performance is important.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nWe are using mlflow to track our experiments. However, we need this feature to visualize model performance for multiple runs, which mlflow compare UI don't have it right now.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nI assume we need to modify codes in CompareRunView components (https:\/\/github.com\/mlflow\/mlflow\/tree\/c635d1aa12e1749ab1321128ac61c0f3e6309c1d\/mlflow\/server\/js\/src\/experiment-tracking\/components). But I'm not an expert in javascript and CSS. I need some help on that. \r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","332":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [X] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nIt would be great if MLFlow could be instructed to build images with [JIB](https:\/\/github.com\/GoogleContainerTools\/jib) instead of Docker. This would be especially useful when running MLFlow in Kubernetes, where one usually cannot execute Docker.\r\n\r\n## Motivation\r\n- What is the use case for this feature? Building images in environments where Docker cannot be executed, for example, Kubernetes.\r\n- Why is this use case valuable to support for MLflow users in general? Currently, users cannot use MLFlow to build images for running projects, serving models, etc. in Kubernetes\r\n- Why is this use case valuable to support for your project(s) or organization? We are automating the execution of MLFlow projects in Kubernetes.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient) Currently, MLFlow is only able to build images where Docker is available, which is not the case in Kubernetes.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [X] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","333":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [X] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n[MLflow Model Serving](https:\/\/docs.microsoft.com\/en-us\/azure\/databricks\/applications\/mlflow\/model-serving) is a great way to surface MLFlow models over a REST API endpoint. These endpoints are easily consumed using python, curl, etc. However, due to web browser level restrictions on cross-origin requests, javascript web applications are not able to consume these RESTful model endpoints (i.e., using XMLHttpRequest). The typical way around this is to serve the REST API with [CORS headers](https:\/\/developer.mozilla.org\/en-US\/docs\/Web\/HTTP\/CORS), which specifically allow HTTP verbs, headers, etc from remote servers (i.e., servers other than the one serving the model).\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n  - This will enable integration with javascript web applications. Modern web frameworks (react, angular, vue) can't connect to remote APIs unless the destination server's CORS headers allow cross-origin requests. This is in contrast to traditional, server-side web languages\/frameworks (C#, python, PHP) that don't have that CORS header requirement\r\n- Why is this use case valuable to support for MLflow users in general?\r\n  - Increased availability of a shared model will facilitate integration into more environments -- especially  modern javascript web frameworks\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n  - We would like to incorporate the results of an MLFlow model into a web application without having to set up and maintain other server-side infrastructure to proxy the calls between our javascript web app and our model's REST endpoint.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n  - MLflow Model Serving is currently so close to making this possible, but because there is no ability to add HTTP headers to the model's HTTP responses, we are unable to integrate cleanly with our javascript web app. If MLflow Model Serving had functionality to add custom HTTP headers to every response, we would have a much easier time integrating with our web application. Specifically, I would want to add the following headers:\r\n    - `Access-Control-Allow-Credentials: true`\r\n    - `Access-Control-Allow-Headers: Authorization, Accept, Content-Type`\r\n    - `Access-Control-Allow-Methods: POST`\r\n    - `Access-Control-Allow-Origin: *`\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [X] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nIs there precedent for using the `Cluster Settings > Tags` for customizations to the model's web server? That's where I first looked when I was searching for a \"Add Custom HTTP Headers\" UI element. Setting a tag key:value pair that corresponds to an HTTP header key:value pair wouldn't require any UI changes, although it would make discoverability difficult.\r\n\r\nHere's a mockup:\r\n![image](https:\/\/user-images.githubusercontent.com\/57339\/115472576-051d6400-a1ef-11eb-96d5-2b4fb5b27ce3.png)\r\n\r\nHaving a dedicated \"Custom HTTP Headers\" section within the `Cluster Settings` section would be a more natural UI.","334":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nHello,\r\n\r\nI'm trying to figure out if it is possible to show the metrics values for a specific step in the MLflow UI.\r\nCurrently when I go to a specific run I only see the latest values of the metrics and the history is only visible in the graph UI, the same is true when comparing different runs.\r\nThis makes it hard to compare multiple metrics between different steps of a run and even harder to compare data from different steps of multiple runs.\r\n\r\nIt would be extremely useful to have this kind of capability in the UI without resorting to the REST API.\r\n\r\nThanks in advance\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","335":"Many MLflow users have expressed a desire to know the MLflow roadmap. Having a ROADMAP file in github would enable us to be more transparent. \r\nA good example is https:\/\/github.com\/kubeflow\/kfserving\/blob\/master\/ROADMAP.md.","336":"OS: Windows 10 Home\r\nProcessor: Intel(R) Core(TM), i7-8550U CPU @ 1.80 GHz 1.99 GHz\r\nSystem type: 64 bit\r\nPython: Python 3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]\r\nmlflow==1.15.0\r\n\r\nERROR: Everything is fine but when I initiate the server on localhost:5000 and click on the artifacts folder it gives me an error.\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/54699234\/115155598-be910380-a04e-11eb-9b4b-0671a4320c17.png)\r\n\r\nWhen I click on model, it gives me this error:\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/54699234\/115155613-c94b9880-a04e-11eb-81fd-94f5d2b751a4.png)\r\n\r\nI wasn't getting this error until yesterday. No change in my environment or installations.\r\n","337":"## Continue runs by run id\r\n\r\nWe train on AWS spot instances, meaning that they are sometimes stopped. We would like our MLFlow logs to continue when the job is restarted on a new instance, with a syntax like below\r\n\r\n```\r\nif new:\r\n    mlflow.start_run(experiment_id=1, run_name=x)\r\nelse:\r\n    mlflow.set_run(run_id)\r\n```\r\n\r\nI would be willing to contribute this feature with guidance from the MLflow community.\r\n\r\n`area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n","338":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [X] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nHave the capacity to build virtual environment with other tools than conda when using MLFlow Projects. For example poetry (https:\/\/github.com\/python-poetry\/poetry)\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [X] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\nCurrently MLFlow use conda to automatically create virtual environment when using the MLFlow Projects. If you don't want to use conda you only have docker or system environment left. But that does not leave the same \"reproductibility\" capacity because you can't directly run a git repository without having to be sure that either:\r\n- The docker image is up to date (and stored locally or in dockerhub, private repos are not accessibles)\r\n- The system environment have all the packages that you need\r\n\r\nI know that there are many package manager for python out there, but having the capacity to automatically build environment with other tools than conda will be well appreciated !\r\n\r\nThank for the hard and good works :) ","339":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nThis proposal would add a [Transformers](https:\/\/github.com\/huggingface\/transformers) [pretrained model](https:\/\/huggingface.co\/transformers\/pretrained_models.html) flavor to MLflow.\r\n\r\n## Motivation\r\n\r\n### What is the use case for this feature?\r\n\r\nThe custom model flavor will enable full integration of Transformer pretrained model artifacts with tracking server runs and the MLflow model registry, and enable downstream integration with [Seldon](https:\/\/docs.seldon.io\/projects\/seldon-core\/en\/v1.1.0\/servers\/mlflow.html) via the resulting MLmodel. Users will be able to serialise transformers model artifacts via a simple `mlflow.log_model` call, and load via `mlflow.pyfunc.load_model`.\r\n\r\n### Why is this use case valuable to support for MLflow users in general?\r\n\r\nTransformers is a very popular NLP library (it has significantly more stars, for example, than [Catboost](https:\/\/github.com\/catboost\/catboost), for which a flavor was recently added). Its integration with the MLflow tracking server and model registry will support many NLP use cases for experimentation and deployment. Many MLflow users will have interests in NLP projects.\r\n\r\n### Why is this use case valuable to support for your project(s) or organization?\r\n\r\nMy projects involve fine-tuning transformers pretrained models for specific use cases. This involves experimentation using the MLflow tracking server and publishing new model versions via the MLflow model registry, which is connected to production pipelines. A transformers pretrained model flavor supports seamless integration of the full model artifacts with the tracking server runs and model registry.\r\n\r\n### Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nTransformers pretrained models use [custom serialisation methods](https:\/\/github.com\/huggingface\/transformers\/blob\/4b919657313103f1ee903e32a9213b48e6433afe\/src\/transformers\/modeling_utils.py#L784), that save and load a number of model dependencies in addition to the Pytorch model binary. Transformers pretrained models are also generally expected to be serialised together with a [tokenizer](https:\/\/github.com\/huggingface\/transformers\/blob\/cb38ffcc5e0ae2fac653342ac36dc75c15ea178f\/src\/transformers\/tokenization_utils_base.py#L1839).\r\n\r\nAdditionally, the PyFunc wrapper for a transformers pretrained model should ideally include tokenisation. By contrast, the [existing Pytorch model flavor](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/pytorch\/__init__.py) assumes only the bare `torch.save` and `torch.load` functions are used for (de)serialisation, and has a parsimonious `_PyTorchWrapper` that cannot currently include tokenisation.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nThis proposal would add a [Transformers](https:\/\/github.com\/huggingface\/transformers) [pretrained model](https:\/\/huggingface.co\/transformers\/pretrained_models.html) flavor to MLflow.\r\n\r\nSince the underlying models are Pytorch-based, the implementation would be similar to the [existing Pytorch model flavor](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/pytorch\/__init__.py).\r\n\r\nHowever, it would specifically add saving and loading functionality for [Transformers pretrained models](https:\/\/huggingface.co\/transformers\/pretrained_models.html) and [tokenizers](https:\/\/huggingface.co\/transformers\/main_classes\/tokenizer.html).\r\n\r\nInstead of using the bare `torch.save` and `torch.load`, it would invoke the `save_pretrained` methods for [Transformers pretrained models](https:\/\/github.com\/huggingface\/transformers\/blob\/4b919657313103f1ee903e32a9213b48e6433afe\/src\/transformers\/modeling_utils.py#L784) and [tokenizers](https:\/\/github.com\/huggingface\/transformers\/blob\/cb38ffcc5e0ae2fac653342ac36dc75c15ea178f\/src\/transformers\/tokenization_utils_base.py#L1839).\r\n\r\nThis flavor would also implement a custom `_TransformerPretrainedWrapper` for the PyFunc implementation.\r\n","340":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 20.04.1 LTS\r\n- **MLflow installed from (source or binary)**: pip\r\n- **MLflow version (run ``mlflow --version``)**: 1.14.1\r\n- **Python version**: 3.7.3\r\n\r\n### Describe the problem\r\nI want to be able reuse the same run on different notebooks of my execution pipeline. For that purpose, I start the run in the first notebook with `mlflow.start_run()` and withouth the context manager.\r\n\r\nIn the second notebook I continue the run with `mlflow.start_run(run_id=...)`. However, when this notebook ends the run changes it's state to finished so I can't continue this run in the third notebook.\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n","341":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Reproducible with example from [official docs](https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.pytorch.html)\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Docker image: `nvidia\/cuda:10.2-base-ubuntu16.04`\r\n- **MLflow installed from (source or binary)**: Python package\r\n- **MLflow version (run ``mlflow --version``)**: 1.15.0\r\n- **Python version**: 3.8.8\r\n- **npm version, if running the dev UI**: No\r\n- **Exact command to reproduce**: See code snippet\r\n\r\n### Describe the problem\r\nExpected behavior:\r\nIf I'm using `mlflow.autolog()` with a `pl.LightningModule` and use `self.log(\"train_loss\", loss, on_epoch=True, on_step=True, logger=True)` inside its `training_step` function, MLflow should log `train_loss_step` metric for every logged **step** and `train_loss_epoch` for every logged **epoch**\r\n\r\nActual behavior:\r\n`train_loss_step` and `train_loss_epoch` are recorded for every logged **epoch** only.\r\n\r\nAfter running code in below sample, `train_loss_epoch`  contains 1 entry per epoch:\r\n```\r\n1617996945494 1.3506861925125122 0\r\n1617996966448 1.201533317565918 1\r\n1617996986735 1.1901590824127197 2\r\n1617997007487 1.190608024597168 3\r\n1617997028088 1.1838353872299194 4\r\n1617997048012 1.1807078123092651 5\r\n1617997068702 1.18239426612854 6\r\n1617997089547 1.1766492128372192 7\r\n1617997110542 1.175412654876709 8\r\n1617997130747 1.1763886213302612 9\r\n1617997150977 1.1739486455917358 10\r\n1617997171487 1.1722205877304077 11\r\n1617997191321 1.170091152191162 12\r\n1617997211502 1.1701279878616333 13\r\n1617997232425 1.1694077253341675 14\r\n1617997252996 1.1664137840270996 15\r\n1617997273641 1.1662592887878418 16\r\n1617997294056 1.1691796779632568 17\r\n1617997314113 1.164090871810913 18\r\n1617997335002 1.1653193235397339 19\r\n```\r\n`train_loss_step` also contains 1 entry per **epoch**\r\n```\r\n1617996945494 1.0488566160202026 0\r\n1617996966448 1.0117261409759521 1\r\n1617996986735 0.9437647461891174 2\r\n1617997007487 1.1345815658569336 3\r\n1617997028088 0.9712427854537964 4\r\n1617997048012 0.9615302681922913 5\r\n1617997068702 0.9383407235145569 6\r\n1617997089547 0.9366243481636047 7\r\n1617997110542 0.9363885521888733 8\r\n1617997130747 0.9403294324874878 9\r\n1617997150977 0.9360908269882202 10\r\n1617997171487 1.0088082551956177 11\r\n1617997191321 0.9398048520088196 12\r\n1617997211502 0.9855148792266846 13\r\n1617997232425 0.9356205463409424 14\r\n1617997252996 0.9355267286300659 15\r\n1617997273641 0.937127947807312 16\r\n1617997294056 0.9390522837638855 17\r\n1617997314113 0.9355039000511169 18\r\n1617997335002 0.9383139610290527 19\r\n```\r\n\r\n\r\n### Code to reproduce issue\r\nSmall modifications to [code snippet in documentation](https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.pytorch.html)\r\n\r\n```\r\nimport os\r\n\r\nimport pytorch_lightning as pl\r\nimport torch\r\nfrom torch.nn import functional as F\r\nfrom torch.utils.data import DataLoader\r\nfrom torchvision import transforms\r\nfrom torchvision.datasets import MNIST\r\n\r\nimport mlflow.pytorch\r\n\r\n\r\nclass MNISTModel(pl.LightningModule):\r\n    def __init__(self):\r\n        super(MNISTModel, self).__init__()\r\n        self.l1 = torch.nn.Linear(28 * 28, 10)\r\n\r\n    def forward(self, x):\r\n        return torch.relu(self.l1(x.view(x.size(0), -1)))\r\n\r\n    def training_step(self, batch, batch_nb):\r\n        x, y = batch\r\n        loss = F.cross_entropy(self(x), y)\r\n\r\n        # Use the current of PyTorch logger\r\n        self.log(\"train_loss\", loss, on_epoch=True, on_step=True, logger=True)\r\n        return loss\r\n\r\n    def configure_optimizers(self):\r\n        return torch.optim.Adam(self.parameters(), lr=0.02)\r\n\r\n\r\ndef print_auto_logged_info(r):\r\n    print(\"metrics: {}\".format(r.data.metrics))\r\n\r\n\r\ndef main() -> None:\r\n    mlflow.set_experiment(\"Autolog issue\")\r\n\r\n    # Initialize our model\r\n    mnist_model = MNISTModel()\r\n\r\n    # Initialize DataLoader from MNIST Dataset\r\n    train_ds = MNIST(os.getcwd(), train=True,\r\n                     download=True, transform=transforms.ToTensor())\r\n    train_loader = DataLoader(train_ds, batch_size=32)\r\n\r\n    # Initialize a trainer\r\n    trainer = pl.Trainer(max_epochs=20, progress_bar_refresh_rate=20)\r\n\r\n    # Auto log all MLflow entities\r\n    mlflow.pytorch.autolog()\r\n\r\n    # Train the model\r\n    with mlflow.start_run() as run:\r\n        trainer.fit(mnist_model, train_loader)\r\n\r\n        # fetch the auto logged parameters and metrics\r\n        print_auto_logged_info(mlflow.get_run(run_id=run.info.run_id))\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\n\r\n### Other info \/ logs\r\nPyTorch Lightning adds the `_step` and `_epoch` suffixes to the logged metrics, so on our side we used this info and slightly adjusted [__MLflowPLCallback](https:\/\/github.com\/mlflow\/mlflow\/blob\/86a03e9488f7cf2c7c0e46531fd2168923c79ec2\/mlflow\/pytorch\/_pytorch_autolog.py#L83) by adding the following hook:\r\n```\r\n        def on_train_batch_end(\r\n            self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx\r\n        ):\r\n           # ADD CODE TO FILTER ON `_step` SUFFIX\r\n\r\n           # Then we log filtered metrics on pl_module.global_step instead of  pl_module.current_epoch\r\n           metrics_logger.record_metrics(step_metrics, pl_module.global_step)\r\n```\r\nWe also adjusted `__MLflowPLCallback._log_epoch_metrics()` to filter out metrics with the `_step` suffix.\r\n\r\nAre there any plans to make classes such as [__MLflowPLCallback](https:\/\/github.com\/mlflow\/mlflow\/blob\/86a03e9488f7cf2c7c0e46531fd2168923c79ec2\/mlflow\/pytorch\/_pytorch_autolog.py#L83) accessible so that we can subclass them to add\/modify such functionality?\r\n\r\nThanks!\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","342":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nmlflow server currently support Azure Storage Blob as default-artifact-root. Azure Stack Hub enables company  to create storage account on their own data centers (private cloud).  However  mlflow currently doesn't support this type of storage. \r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- \r\nCompany will be able to use their own azure-like  blob storage to save mflow artifiacts.\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\n\r\n   Users using Azure stack hub will be more willing to use MLflow\r\n\r\n- Why is it currently difficult to achieve this use case? \r\n\r\n  MLflow currently supports Azure Storage blob through hardcoded endpoint suffix like \"blob.core.windows.net\". This suffix doesn't apply to Azure Stack Hub Storage blob.   \r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ x] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","343":"Signed-off-by: Shivani Patel 41974238+shivp950@users.noreply.github.com\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nAdding for details in the readme for MLflow skinny client \r\n\r\n## How is this patch tested?\r\n\r\nn\/a\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","344":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [X] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nIn order  to have Mlflow as a central component in the model deployment and governance process, we would like to trigger \r\nmodel deployments by also using the MLFLOW UI and using the  mlflow model stage button . \r\n\r\nRight now this is not available and the work around is to have a small daemon running all the time, pulling information from the model registry and deploy or undeploy models accordingly . If we could have an even triggered from MLFLOW server when a model state transition is happening then we could save a lot of time . \r\n\r\nI could be willing to investigate how much effort this is and potentially implement this. \r\nWhat I would like is some direction on where in the code to look for propagating those events from the GUI to the backend server.\r\n\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ x] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [x ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","345":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this installation issue template to ensure a timely and thorough response.**\r\n\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian\r\n- **MLflow installed from (source or binary)**: Source\r\n- **MLflow version (run ``mlflow --version``)**: It would be 1.15.0\r\n- **Python version**: 3.7.9\r\n- **Exact command to reproduce**: `pip install mlflow` or `poetry add mlflow`\r\n\r\n### Describe the problem\r\nI would like to install MLflow for our project. This project has as a dependency that the version of alembic is 1.4.2. I have seen that the requirements for MLflow's alembic are <=1.4.1 (due to [#3363](https:\/\/github.com\/mlflow\/mlflow\/pull\/3363)). \r\nSince future projects with other packages are likely going to need higher alembic versions it would be nice to remove this limiting requirement. Maybe the issue of failing installs was fixed in higher alembic versions already.\r\n\r\n### Other info \/ logs\r\n```\r\nBecause mlflow (1.15.0) depends on alembic (<=1.4.1) \r\nand no versions of mlflow match >1.15.0,<2.0.0, mlflow (>=1.15.0,<2.0.0) requires alembic (<=1.4.1).\r\n```\r\n","346":"I have below questions about managed mlflow\r\n\r\n1. How experiments\/runs metadata gets stored. Is it using any database? If so, is it centralized?\r\n2. How artifacts gets stored. If its in dbfs, can we customize to use blob or adls?\r\n3. Pricing for managed mlflow","347":"Hello MLFlow team,\r\n\r\nI'm one of the co-chairs of the CNCF SIG-Runtime, I'm reaching out and think it would be great for you to present\/discuss the project at one of our meetings. An overview of the project would be great.\r\n\r\nLet me know if this something you'd be interested in doing. If yes, please feel free to add it to our [agenda](https:\/\/bit.ly\/cncf-sig-runtime-meeting-notes) or reach out to me (raravena80 at gmail.com)\r\n\r\nThanks!","348":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [X] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nIntroduce a Python decorator `log_arguments` in the tracking API, so that the decorated function will register all of its arguments as MLFlow parameters when called. Working example:\r\n\r\n```\r\nimport mlflow\r\n\r\n@mlflow.log_arguments\r\ndef my_experiment(learning_rate, n_estimators=10):\r\n    pass\r\n        \r\nwith mlflow.start_run():\r\n    my_experiment(0.1) # This will log params learning_rate as 0.1 and n_estimators as 10.\r\n```\r\n\r\n## Motivation\r\n\r\n- What is the use case for this feature?\r\n\r\nThis decorator would streamline using the arguments of functions as source for MLFlow parameters.\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nCurrently, my personal use case involves long sequences of `mlflow.log_param` at the beginning of some functions, basically repeating the function arguments. This is a burden to maintain and very error-prone. It could be easily done programmatically instead.\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\n\r\n0. If other people use MLFlow tracking in a similar way, it would streamline their parameters logging.\r\n1. it could make the integration of new frameworks easier and more compact.\r\n2. it would make it easier for new users to integrate their custom functions into the MLFlow workflow, even if they are not using any supported machine learning framework.\r\n\r\nOf course this comes at the expense of added complexity in MLFlow, one more Tracking API function to maintain, and inspection being introduced. I would perfectly understand if this forbids this feature to be added, and will continue to use it only in my personal projects. I am creating this issue just to check whether is there any interest from the community in merging this.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\n## Details\r\n\r\nI have already implemented this function in a personal fork using Python [inspect.BoundArguments](https:\/\/docs.python.org\/3\/library\/inspect.html#inspect.BoundArguments) object. The implementation seems to be easy and short (<10 lines). I will be glad to prepare a PR right away if there is interest.\r\n","349":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [X] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Custom\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: 1.14.1\r\n- **Python version**: 3.7\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: \r\n\r\n### Describe the problem\r\nHi,\r\n\r\nI am using a Scikit-Learn wrapper for XGBoost (XGBRegressor).\r\n\r\nNow when logging the model with mlflow (mlflow.xgboost.log_model), it crashes as anticipated by the official documentation:\r\n\r\nhttps:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.xgboost.html\r\n\r\nI noticed that if I use mlflow.sklearn.log_model instead, the artifact gets saved as expected.\r\n\r\n1. What are the implications of using mlflow.sklearn.log_model with an XGBoost model? Not clear to me.\r\n2. What alternatives do I have to log my XGBRegressor model correctly with mlflow?\r\n\r\nObviously if I instead use a RandomForest, then mlflow.sklearn.log_model works perfectly as expected, so again my issue is to log the XGBRegressor model.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nmlflow.xgboost.log_model(pipeline, \"model\") (where pipeline combines transformers and the XGBRegressor)\r\n\r\n### Other info \/ logs\r\n\r\n    151\r\n    152     # Save an XGBoost model\r\n--> 153     xgb_model.save_model(model_data_path)\r\n    154\r\n    155     conda_env_subpath = \"conda.yaml\"\r\n\r\nAttributeError: 'Pipeline' object has no attribute 'save_model'\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [X] `area\/artifacts`: Artifact stores and artifact logging\r\n- [X] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n\r\n","350":"### URLS with the issue:\r\n\r\n* https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.log_param\r\n* https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.log_metric\r\n* https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.set_tag\r\n\r\n### Description of proposal:\r\n\r\nDocument the maximum value and legal characters for log_param, log_metric and set_tag. Note that log_metric's value is already documented as float.\r\n\r\nTags:\r\n* Apparently there is a 250  character limit for tag keys. See https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/utils\/validation.py#L31.\r\n* There is a 5000 character limit for tag values. See: https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/utils\/validation.py#L30.\r\n\r\nSample error messages for set_tag::\r\n* `Tag value 'x...' had length 5001, which exceeded length limit of 250`\r\n* `Tag value 'vv...' had length 5001, which exceeded length limit of 5000`\r\n\r\nHowever, there seems to be no limit to a parameter's key or value.\r\n\r\nMetrics:\r\n* MlflowException: Invalid metric name: '01: running time in mins'. Names may only contain alphanumerics, underscores (_), dashes (-), periods (.), spaces ( ), and slashes (\/)\r\n\r\n","351":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: yes \r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**: 1.14.1\r\n- **Python version**: 3.6.4\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nWe recently upgraded to 1.14.1 from 1.9, and we no longer have a button to register our models through the UI. \r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n### Other info \/ logs\r\n\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [x ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","352":"\r\n### URL(s) with the issue:\r\n\r\n* https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.create_experiment\r\n* https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.sklearn.html#mlflow.sklearn.log_model\r\n\r\n### Description of proposal (what needs changing):\r\n\r\nWe should document the legal characters for experiment names, run names and artifacts.","353":"### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**: pip\r\n- **MLflow version (run ``mlflow --version``)**: 1.14.1\r\n- **Python version**:   3.7\r\n   - mlflow==1.14.1\r\n   - pg8000==1.16.5\r\n- **Exact command to reproduce**:\r\n   ```shell\r\n   mlflow server \\\r\n      --host 0.0.0.0 \\\r\n      --port 5000 \\\r\n      --backend-store-uri \"postgresql+pg8000:\/\/${USERNAME}:${URL_COMPATIBLE_PASSWORD}@${HOST}:${PORT}\/${DATABASE_NAME}\" \\\r\n    --default-artifact-root ${DEFAULT_ARTIFACT_ROOT}\r\n   ```\r\n\r\n### Describe the problem\r\n\r\nWhen using AWS RDS Serverless (postgres) as the backend data store, the MLFLOW server doesn't create a new database session whenever the Serverless database comes online after pausing due to no activity. Currently running MLFLOW  on a AWS ECS cluster. So, whenever I encounter the issue, I kill the existing ECS task and create a new one and the error goes away.\r\n\r\n### Other info \/ logs\r\n\r\n```shell\r\n2021-03-22 13:24:412021\/03\/22 13:24:41 ERROR mlflow.server: Exception on \/ajax-api\/2.0\/preview\/mlflow\/experiments\/list [GET]\r\n2021-03-22 13:24:41Traceback (most recent call last):\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/mlflow\/store\/db\/utils.py\", line 80, in make_managed_session\r\n2021-03-22 13:24:41yield session\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/mlflow\/store\/tracking\/sqlalchemy_store.py\", line 258, in list_experiments\r\n2021-03-22 13:24:41for exp in self._list_experiments(session=session, view_type=view_type, eager=True)\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/mlflow\/store\/tracking\/sqlalchemy_store.py\", line 252, in _list_experiments\r\n2021-03-22 13:24:41return session.query(SqlExperiment).options(*query_options).filter(*conditions).all()\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/sqlalchemy\/orm\/query.py\", line 3373, in all\r\n2021-03-22 13:24:41return list(self)\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/sqlalchemy\/orm\/query.py\", line 3535, in __iter__\r\n2021-03-22 13:24:41return self._execute_and_instances(context)\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/sqlalchemy\/orm\/query.py\", line 3557, in _execute_and_instances\r\n2021-03-22 13:24:41querycontext, self._connection_from_session, close_with_result=True\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/sqlalchemy\/orm\/query.py\", line 3572, in _get_bind_args\r\n2021-03-22 13:24:41mapper=self._bind_mapper(), clause=querycontext.statement, **kw\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/sqlalchemy\/orm\/query.py\", line 3550, in _connection_from_session\r\n2021-03-22 13:24:41conn = self.session.connection(**kw)\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/sqlalchemy\/orm\/session.py\", line 1145, in connection\r\n2021-03-22 13:24:41execution_options=execution_options,\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/sqlalchemy\/orm\/session.py\", line 1151, in _connection_for_bind\r\n2021-03-22 13:24:41engine, execution_options\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/sqlalchemy\/orm\/session.py\", line 433, in _connection_for_bind\r\n2021-03-22 13:24:41conn = bind._contextual_connect()\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/base.py\", line 2302, in _contextual_connect\r\n2021-03-22 13:24:41self._wrap_pool_connect(self.pool.connect, None),\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/base.py\", line 2336, in _wrap_pool_connect\r\n2021-03-22 13:24:41return fn()\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/sqlalchemy\/pool\/base.py\", line 364, in connect\r\n2021-03-22 13:24:41return _ConnectionFairy._checkout(self)\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/sqlalchemy\/pool\/base.py\", line 809, in _checkout\r\n2021-03-22 13:24:41result = pool._dialect.do_ping(fairy.connection)\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/default.py\", line 575, in do_ping\r\n2021-03-22 13:24:41cursor.execute(self._dialect_specific_select_one)\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/pg8000\/core.py\", line 340, in execute\r\n2021-03-22 13:24:41self._c.execute_unnamed(self, \"begin transaction\")\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/pg8000\/core.py\", line 1213, in execute_unnamed\r\n2021-03-22 13:24:41self._flush()\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/socket.py\", line 607, in write\r\n2021-03-22 13:24:41return self._sock.send(b)\r\n2021-03-22 13:24:41TimeoutError: [Errno 110] Connection timed out\r\n2021-03-22 13:24:41During handling of the above exception, another exception occurred:\r\n2021-03-22 13:24:41Traceback (most recent call last):\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/mlflow\/server\/handlers.py\", line 214, in wrapper\r\n2021-03-22 13:24:41return func(*args, **kwargs)\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/mlflow\/server\/handlers.py\", line 510, in _list_experiments\r\n2021-03-22 13:24:41experiment_entities = _get_tracking_store().list_experiments(request_message.view_type)\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/mlflow\/store\/tracking\/sqlalchemy_store.py\", line 258, in list_experiments\r\n2021-03-22 13:24:41for exp in self._list_experiments(session=session, view_type=view_type, eager=True)\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/contextlib.py\", line 130, in __exit__\r\n2021-03-22 13:24:41self.gen.throw(type, value, traceback)\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/mlflow\/store\/db\/utils.py\", line 87, in make_managed_session\r\n2021-03-22 13:24:41raise MlflowException(message=e, error_code=INTERNAL_ERROR)\r\n2021-03-22 13:24:41mlflow.exceptions.MlflowException: [Errno 110] Connection timed out\r\n2021-03-22 13:24:41During handling of the above exception, another exception occurred:\r\n2021-03-22 13:24:41Traceback (most recent call last):\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/flask\/app.py\", line 2447, in wsgi_app\r\n2021-03-22 13:24:41response = self.full_dispatch_request()\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/flask\/app.py\", line 1952, in full_dispatch_request\r\n2021-03-22 13:24:41rv = self.handle_user_exception(e)\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/flask\/app.py\", line 1821, in handle_user_exception\r\n2021-03-22 13:24:41reraise(exc_type, exc_value, tb)\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/flask\/_compat.py\", line 39, in reraise\r\n2021-03-22 13:24:41raise value\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/flask\/app.py\", line 1950, in full_dispatch_request\r\n2021-03-22 13:24:41rv = self.dispatch_request()\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/flask\/app.py\", line 1936, in dispatch_request\r\n2021-03-22 13:24:41return self.view_functions[rule.endpoint](**req.view_args)\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/mlflow\/server\/handlers.py\", line 217, in wrapper\r\n2021-03-22 13:24:41response.set_data(e.serialize_as_json())\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/site-packages\/mlflow\/exceptions.py\", line 60, in serialize_as_json\r\n2021-03-22 13:24:41return json.dumps(exception_dict)\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/json\/__init__.py\", line 231, in dumps\r\n2021-03-22 13:24:41return _default_encoder.encode(obj)\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/json\/encoder.py\", line 199, in encode\r\n2021-03-22 13:24:41chunks = self.iterencode(o, _one_shot=True)\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/json\/encoder.py\", line 257, in iterencode\r\n2021-03-22 13:24:41return _iterencode(o, 0)\r\n2021-03-22 13:24:41File \"\/usr\/local\/lib\/python3.7\/json\/encoder.py\", line 179, in default\r\n2021-03-22 13:24:41raise TypeError(f'Object of type {o.__class__.__name__} '\r\n2021-03-22 13:24:41TypeError: Object of type TimeoutError is not JSON serializable\r\n```\r\n","354":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian 9\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.14.1\r\n- **Python version**: 3.7\r\n- **npm version, if running the dev UI**: \r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nWhen running MLflow server on a linux environment with an FTP artifact store on a windows environment, the UI can't display artifacts on a run page. It fails with a display message `Unable to list artifacts stored under for the current run. Please contact your tracking server administrator to notify them of this error, which can happen when the tracking server lacks permission to list artifacts under the current run's root artifact directory.`\r\nThe MLflow server logs display an error (complete log here under) saying that `the specified access path can't be found` regarding the artifact path using the value `artifact_store_path\/[EXPERIMENT_ID]\/[RUN_ID]\/artifacts\/artifacts\/Sklearn` (notice the repeated \"artifacts\" in the path)\r\n\r\nThe python API `list_artifacts` functions fail with the same error.\r\n\r\nA precision : the artifacts are normally stored on the FTP. It's just the UI display and the API calls that fails.\r\n\r\nAfter some diging, I think I found the issue : \r\n- IMO, it comes from the fact that the FTP artifact store is on a windows host and that the MLflow server is on a Linux host\r\n- In that case, the `list_artifacts` method of the `FTPArtifactRepository` class in the `mlflow\/store\/artifact\/ftp_artifact_repo.py` file fails\r\n- Indeed, in this case, at runtime, the `list_dir` object contains linux type paths (ex : `\/path\/to\/artifact_store\/1\/c716604157c04a7b99552cde1b20d8a4\/artifacts`), but then at line 104, the `ftp.nlst(list_dir)` call returns paths with a mix of linux and windows slash convention (because the artifact store is on a windows host) : `\/path\/to\/artifact_store\/1\/c716604157c04a7b99552cde1b20d8a4\/artifacts\\\\Sklearn`\r\n- Then because of this mix with Windows paths the `artifact_files = [os.path.basename(f) for f in artifact_files]` line ends up returning \"file names\" like `artifacts\\Sklearn` instead of just `Sklearn` which then explains why the path where the UI try to find the artifacts is erronous (the \"file name\" `artifacts\\Sklearn` is appended to the artifact base path `\/path\/to\/artifact_store\/1\/c716604157c04a7b99552cde1b20d8a4\/artifacts`, hence the repeated \"artifacts\" in the path)\r\n\r\nA quick hack would be to replace `\\\\` with `\/` in paths, like in the function proposed here under, but there may be some side effects : \r\n```python\r\ndef list_artifacts(self, path=None):\r\n    with self.get_ftp_client() as ftp:\r\n        artifact_dir = self.path\r\n        list_dir = posixpath.join(artifact_dir, path) if path else artifact_dir\r\n        if not self._is_dir(ftp, list_dir):\r\n            return []\r\n        artifact_files = ftp.nlst(list_dir)\r\n        artifact_files = list(filter(lambda x: x != \".\" and x != \"..\", artifact_files))\r\n        ################## BUG CORRECTION ###################\r\n        artifact_files = [x.replace('\\\\', '\/') for x in artifact_files]\r\n        ################## BUG CORRECTION END ###################\r\n        # Make sure artifact_files is a list of file names because ftp.nlst\r\n        # may return absolute paths.\r\n        artifact_files = [os.path.basename(f) for f in artifact_files]\r\n        infos = []\r\n        for file_name in artifact_files:\r\n            file_path = file_name if path is None else posixpath.join(path, file_name)\r\n            full_file_path = posixpath.join(list_dir, file_name)\r\n            if self._is_dir(ftp, full_file_path):\r\n                infos.append(FileInfo(file_path, True, None))\r\n            else:\r\n                size = self._size(ftp, full_file_path)\r\n                infos.append(FileInfo(file_path, False, size))\r\n    return infos\r\n```\r\n\r\nTo be more clean, we could use `ntpath.basename` instead of `os.path.basename`, but there would still be the caveat of linux files with name containing a `\\` (see https:\/\/stackoverflow.com\/a\/8384788).\r\n\r\nTo account for all cases, we might have to separate the linux and windows cases using `sys.platform`.\r\n\r\nAny ideas \/ opinions regarding this ?\r\n\r\n### Code to reproduce issue\r\n- FTP on a windows host\r\n- MLflow server on a windows host\r\n- Save an artifact on a run and try to display a list using the `MlflowClient().list_artifacts()` function or try to go on the Run UI page and to see artifacts on the UI\r\n\r\n### Other info \/ logs\r\nTraceback of error displayed on the MLflow server logs : \r\n```\r\n2021\/03\/19 09:06:55 ERROR mlflow.server: Exception on \/ajax-api\/2.0\/preview\/mlflow\/artifacts\/list [GET]\r\nTraceback (most recent call last):\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/flask\/app.py\", line 2447, in wsgi_app\r\n    response = self.full_dispatch_request()\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/flask\/app.py\", line 1952, in full_dispatch_request\r\n    rv = self.handle_user_exception(e)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/flask\/app.py\", line 1821, in handle_user_exception\r\n    reraise(exc_type, exc_value, tb)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/flask\/_compat.py\", line 39, in reraise\r\n    raise value\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/flask\/app.py\", line 1950, in full_dispatch_request\r\n    rv = self.dispatch_request()\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/flask\/app.py\", line 1936, in dispatch_request\r\n    return self.view_functions[rule.endpoint](**req.view_args)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/mlflow\/server\/handlers.py\", line 214, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/mlflow\/server\/handlers.py\", line 487, in _list_artifacts\r\n    artifact_entities = _get_artifact_repo(run).list_artifacts(path)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 116, in list_artifacts\r\n    size = self._size(ftp, full_file_path)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 63, in _size\r\n    size = ftp.size(full_file_path)\r\n  File \"\/usr\/local\/lib\/python3.7\/ftplib.py\", line 636, in size\r\n    resp = self.sendcmd('SIZE ' + filename)\r\n  File \"\/usr\/local\/lib\/python3.7\/ftplib.py\", line 273, in sendcmd\r\n    return self.getresp()\r\n  File \"\/usr\/local\/lib\/python3.7\/ftplib.py\", line 246, in getresp\r\n    raise error_perm(resp)\r\nftplib.error_perm: 550 \/path\/to\/artifact_store\/1\/ab5998807dc8479397eb4f22132afae0\/artifacts\/artifacts\/Sklearn: Le chemin d'acc\u00e8s sp\u00e9cifi\u00e9 est introuvable. \r\n```\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","355":"## Willingness to contribute\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nCurrent `FlavorBackend` implementation for `pyfunc` model flavor serves REST API endpoint for inference. The proposed feature would add an option to deploy `pyfunc` models as gRPC endpoints as well. I have begun a rough draft of the feature in a separate repository ([mlflow-grpc](https:\/\/github.com\/tokoko\/mlflow-grpc)) but i'm unsure how the feature can be incorporated into the main `mlflow` project.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\ndeployment of mlflow pyfunc models as gRPC endpoints. \r\n- Why is this use case valuable to support for MLflow users in general?\r\nability to expose faster gRPC inference endpoints might be crucial in production for many ml use cases.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nIt could be implemented by writing a custom Dockerfile and protobuf definitions and keeping them up-to-date with changes in model dependencies and\/or input features.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nSeems to me, there are several ways to incorporate this feature into the project, but I don't know which if any would be the right approach.\r\n\r\n- implement it as part of `mlflow.pyfunc.backend.PyFuncBackend` in already existing serve() and build_docker() functions. they would need additional parameters to determine whether to serve REST or gRPC. `mlflow models` API will need to be changed accordingly. This approach seems too messy.\r\n\r\n- implement it as a separate `FlavorBackend`. This seems like a cleaner approach, but there are some problems. `get_flavor_backend` function in `mlflow.models.flavor_backend_registry` right now assumes that there will be at most one `FlavorBackend` per each model `flavor`. if this assumption was dropped, `mlflow models` API would need to be changed to add an additional parameter to specify which `FlavorBackend` should be used. another minor issue with this approach is that it will probably never make sense to have more than one `predict()` implementations per `flavor` and flavor backends would probably need to share it. The way I decided to implement my POC version of the feature is by writing `PyFuncGrpcBackend` that extends `PyFuncBackend` and overrides only `serve` and `build_docker` methods.\r\n\r\n- implement it as a plugin. If I'm not mistaken `FlavorBackend` is not pluggable as of now and I'm not sure if `deployments` plugin mechanism is appropriate for this use case. would love to hear your view on this.\r\n","356":"Fixing \"Error: File waitress-serve could not be found.\"","357":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n\r\n## Proposal Summary\r\n\r\nLet the contour color in the comparison graph more accessible to color blindness\r\n\r\n## Motivation\r\nIn my case, I could not clearly distinguish green from orange. These two color appears in the graph when there are more than two contour. I always need other's help to read the graph. I think this FR could benefit someone likes me. Indeed, their are about 12% mean and 0.5% women in the world have various degrees of color blindness.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n\r\n## Details\r\nIt seems(?) not difficult if I just want to change the color map. I found the code in [`mlflow\/mlflow\/server\/js\/src\/experiment-tracking\/components\/CompareRunContour.js`](https:\/\/github.com\/mlflow\/mlflow\/blob\/8e74cdd108ff324175e38d621b12d9b2aced05bd\/mlflow\/server\/js\/src\/experiment-tracking\/components\/CompareRunContour.js#L98)\r\n```javascript\r\n    const colorscale = [\r\n      [0, 'rgb(5,10,172)'],\r\n      [0.35, 'rgb(40,60,190)'],\r\n      [0.5, 'rgb(70,100,245)'],\r\n      [0.6, 'rgb(90,120,245)'],\r\n      [0.7, 'rgb(106,137,247)'],\r\n      [1, 'rgb(220,220,220)'],\r\n    ];\r\n```\r\nHowever, that would be better to adding a new toggle (just below the Points toggle) to switch this feature on\/off. Another issue is to find the best color map for the color blindness. It might takes some time.\r\n\r\n\r\n","358":"\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nWe need to add a mlflow.delete_artifact method to the API as an analog to mlflow.log_artifact. \r\n\r\n## Motivation\r\n\r\nIf clients can add an artifact they should be able to delete it.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\n\r\n\r\n\r\n","359":"Signed-off-by: Yitao Li <yitao@rstudio.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\n(Please fill in changes proposed in this fix)\r\n\r\n## How is this patch tested?\r\n\r\n(Details)\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","360":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [X] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **Linux Ubuntu 18.04)**:\r\n- **MLflow installed from source**:\r\n- **MLflow version: 1.13.1**\r\n- **Python version: 3.8.5**\r\n- **Pytorch version: 1.7.1** \r\n\r\n### Describe the problem\r\nI was using `mlflow.pytorch.autolog(log_every_n_epoch=1, log_models=False, disable=True, exclusive=False)` to log Pytorch run. But I ran into an issue where it was not logging any of my metrics and parameters. \r\n\r\n### Code to reproduce issue\r\n    with mlflow.start_run() as run:\r\n        mlflow.pytorch.autolog(log_every_n_epoch=1, log_models=False, disable=True, exclusive=False)    \r\n        for epoch in tqdm(range(EPOCHS)):\r\n            start_time = time.monotonic()\r\n\r\n            train_loss, train_acc_1, train_acc_5 = train(\r\n            model, train_iterator, optimizer, criterion, scheduler, device)\r\n            valid_loss, valid_acc_1, valid_acc_5 = evaluate(\r\n            model, valid_iterator, criterion, device)\r\n\r\n            if valid_loss < best_valid_loss:\r\n                best_valid_loss = valid_loss\r\n                torch.save(model.state_dict(), \"model.pt\")\r\n\r\n            end_time = time.monotonic()\r\n\r\n            epoch_mins, epoch_secs = epoch_time(start_time, end_time)\r\n            print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\r\n            print(f\"\\tTrain Loss: {train_loss:.3f} | Train Acc @1: {train_acc_1*100:6.2f}%\")\r\n            print(f\"\\tValid Loss: {valid_loss:.3f} | Valid Acc @1: {valid_acc_1*100:6.2f}%\")\r\n    \r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, auto logging\r\n\r\nInterface \r\n- [X] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n\r\n","361":"----------------------------------------------------------------------------------------------------------------------\r\n----------------------------------------------------------------------------------------------------------------------\r\n----------------------------------------------------------------------------------------------------------------------\r\n\r\n\r\nHI TEAM,\r\n Without setting tracking uri able to generate metrics, below is the command we tried\r\nmlflow run https:\/\/github.com\/mlflow\/mlflow-example.git -P alpha=0.2 --run-id  ecb8e7c8dfbc418cb211e7703fb61d4c \r\n\r\n\r\nwhen  i set an tracking uri to store model registry getting not found exception like below ***\r\n#Use sqlite:\/\/\/mlruns.db as the local store for tracking and registery\r\n mlflow.set_tracking_uri(\"sqlite:\/\/\/mlruns.db\")\r\nPLEASE REFER BELOW ERROR**\r\n\r\n\r\n----------------------------------------------------------------------------------------------------------------------\r\n----------------------------------------------------------------------------------------------------------------------\r\n----------------------------------------------------------------------------------------------------------------------\r\n\r\n**(base)** C:\\Users\\lenovo\\Desktop\\mlflow>mlflow run https:\/\/github.com\/mlflow\/mlflow-example.git -P alpha=0.2 --run-id 810be4e0ce7c40f08a341357e7d72dd7\r\n2021\/03\/15 10:53:28 INFO mlflow.projects.utils: === Fetching project from https:\/\/github.com\/mlflow\/mlflow-example.git into C:\\Users\\lenovo\\AppData\\Local\\Temp\\tmp5rbw24dd ===\r\n2021\/03\/15 10:53:33 INFO mlflow.projects.utils: === Created directory C:\\Users\\lenovo\\AppData\\Local\\Temp\\tmpz2urzd3d for downloading remote URIs passed to arguments of type 'path' ===\r\n2021\/03\/15 10:53:33 INFO mlflow.projects.backend.local: === Running command 'conda activate mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b && python train.py 0.2 0.1' in run with ID '810be4e0ce7c40f08a341357e7d72dd7' ===\r\nC:\\Users\\lenovo\\anaconda3\\envs\\mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b\\lib\\site-packages\\sklearn\\utils\\__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\r\n  from collections import Sequence\r\nC:\\Users\\lenovo\\anaconda3\\envs\\mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b\\lib\\site-packages\\sklearn\\model_selection\\_split.py:18: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\r\n  from collections import Iterable\r\nC:\\Users\\lenovo\\anaconda3\\envs\\mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b\\lib\\site-packages\\sklearn\\model_selection\\_search.py:16: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\r\n  from collections import Mapping, namedtuple, defaultdict, Sequence\r\nElasticnet model (alpha=0.200000, l1_ratio=0.100000):\r\n  RMSE: 0.7836984021909766\r\n  MAE: 0.6142020452688988\r\n  R2: 0.20673590971167466\r\n2021\/03\/15 10:53:35 INFO mlflow.projects: === Run (ID '810be4e0ce7c40f08a341357e7d72dd7') succeeded ===\r\n\r\n----------------------------------------------------------------------------------------------------------------------\r\n----------------------------------------------------------------------------------------------------------------------\r\n----------------------------------------------------------------------------------------------------------------------\r\n\r\n\r\nHI TEAM,\r\n\r\n\r\nwhen  i set an tracking uri to store model registry getting not found exception like below ***\r\nPLEASE REFER BELOW ERROR**\r\n\r\n\r\n----------------------------------------------------------------------------------------------------------------------\r\n----------------------------------------------------------------------------------------------------------------------\r\n----------------------------------------------------------------------------------------------------------------------\r\n(base) C:\\Users\\lenovo\\Desktop\\mlflow>mlflow run https:\/\/github.com\/mlflow\/mlflow-example.git -P alpha=0.2 --run-id  7d92ea4ed32f44369cdabee824d396e3\r\n2021\/03\/15 11:50:17 INFO mlflow.projects.utils: === Fetching project from https:\/\/github.com\/mlflow\/mlflow-example.git into C:\\Users\\lenovo\\AppData\\Local\\Temp\\tmp8cchydu9 ===\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\lenovo\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"c:\\users\\lenovo\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\lenovo\\anaconda3\\Scripts\\mlflow.exe\\__main__.py\", line 7, in <module>\r\n  File \"c:\\users\\lenovo\\anaconda3\\lib\\site-packages\\click\\core.py\", line 829, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"c:\\users\\lenovo\\anaconda3\\lib\\site-packages\\click\\core.py\", line 782, in main\r\n    rv = self.invoke(ctx)\r\n  File \"c:\\users\\lenovo\\anaconda3\\lib\\site-packages\\click\\core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"c:\\users\\lenovo\\anaconda3\\lib\\site-packages\\click\\core.py\", line 1066, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"c:\\users\\lenovo\\anaconda3\\lib\\site-packages\\click\\core.py\", line 610, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"c:\\users\\lenovo\\anaconda3\\lib\\site-packages\\mlflow\\cli.py\", line 168, in run\r\n    projects.run(\r\n  File \"c:\\users\\lenovo\\anaconda3\\lib\\site-packages\\mlflow\\projects\\__init__.py\", line 293, in run\r\n    submitted_run_obj = _run(\r\n  File \"c:\\users\\lenovo\\anaconda3\\lib\\site-packages\\mlflow\\projects\\__init__.py\", line 92, in _run\r\n    submitted_run = backend.run(\r\n  File \"c:\\users\\lenovo\\anaconda3\\lib\\site-packages\\mlflow\\projects\\backend\\local.py\", line 51, in run\r\n    active_run = get_or_create_run(\r\n  File \"c:\\users\\lenovo\\anaconda3\\lib\\site-packages\\mlflow\\projects\\utils.py\", line 219, in get_or_create_run\r\n    return tracking.MlflowClient().get_run(run_id)\r\n  File \"c:\\users\\lenovo\\anaconda3\\lib\\site-packages\\mlflow\\tracking\\client.py\", line 142, in get_run\r\n    return self._tracking_client.get_run(run_id)\r\n  File \"c:\\users\\lenovo\\anaconda3\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py\", line 54, in get_run\r\n    return self.store.get_run(run_id)\r\n  File \"c:\\users\\lenovo\\anaconda3\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 497, in get_run\r\n    run_info = self._get_run_info(run_id)\r\n  File \"c:\\users\\lenovo\\anaconda3\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 516, in _get_run_info\r\n    raise MlflowException(\r\nmlflow.exceptions.MlflowException: Run '7d92ea4ed32f44369cdabee824d396e3' not found","362":"After successfully installing mlflow using `pip install mlflow` on my Windows system, I am trying to run the `mlflow ui` command but it throws the following error.\r\n```code\r\n(base) C:\\Users\\MAC Pathak\\Documents\\Projects\\kaggle_stroke_prediction>mlflow ui\r\nTraceback (most recent call last):\r\n  File \"c:\\programdata\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"c:\\programdata\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\ProgramData\\Anaconda3\\Scripts\\mlflow.exe\\__main__.py\", line 7, in <module>\r\n  File \"C:\\Users\\MAC Pathak\\AppData\\Roaming\\Python\\Python38\\site-packages\\click\\core.py\", line 829, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"C:\\Users\\MAC Pathak\\AppData\\Roaming\\Python\\Python38\\site-packages\\click\\core.py\", line 782, in main\r\n    rv = self.invoke(ctx)\r\n  File \"C:\\Users\\MAC Pathak\\AppData\\Roaming\\Python\\Python38\\site-packages\\click\\core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"C:\\Users\\MAC Pathak\\AppData\\Roaming\\Python\\Python38\\site-packages\\click\\core.py\", line 1066, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"C:\\Users\\MAC Pathak\\AppData\\Roaming\\Python\\Python38\\site-packages\\click\\core.py\", line 610, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\mlflow\\cli.py\", line 280, in ui\r\n    _run_server(backend_store_uri, default_artifact_root, host, port, None, 1)\r\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\mlflow\\server\\__init__.py\", line 138, in _run_server\r\n    exec_cmd(full_command, env=env_map, stream_output=True)\r\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\mlflow\\utils\\process.py\", line 34, in exec_cmd\r\n    child = subprocess.Popen(\r\n  File \"c:\\programdata\\anaconda3\\lib\\subprocess.py\", line 854, in __init__\r\n    self._execute_child(args, executable, preexec_fn, close_fds,\r\n  File \"c:\\programdata\\anaconda3\\lib\\subprocess.py\", line 1307, in _execute_child\r\n    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\r\nFileNotFoundError: [WinError 2] The system cannot find the file specified\r\n```","363":"Hi, we are trying to access mlflow project in github enterprise repository and while running \r\nmlflow run <github_link> getting error that it cannot connect to the repo. But when I run the same command from local I see that it accepts git repo but fails at accessing \/dbfs\/mlflow_experiment directory. Is this the default directory mlflow tries to access on databricks instance? if so is there a way to change the location to user specific directory. Thanks in advance for any help.","364":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\n\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n-   [ ] Yes. I can contribute this feature independently.\r\n-   [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n-   [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nIt would be nice to add support for tensorflow model versions so it's compatible with TF-serving. \r\n\r\nTF-serving expects the following structure:\r\n\r\n```\r\n.\r\n|-- tensorflow model\r\n|       -- 1\r\n|       |-- saved_model.pb\r\n|       -- variables\r\n|           |-- variables.data-00000-of-00001\r\n|           -- variables.index\r\n```\r\n\r\nAdd an argument `model_version` to `mlflow.tensorflow.log_model` so the resulting model is saved under `model_version` folder and not the default `tfmodel`\r\n\r\nOr:\r\n\r\nadd an option to not save the model under `tfmodel` folder by default:\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/4f4f002d19f5f7e29d1717a6a8c833a383a761da\/mlflow\/tensorflow.py#L269\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/4f4f002d19f5f7e29d1717a6a8c833a383a761da\/mlflow\/tensorflow.py#L270\r\nand then the model could be saved as:\r\n```\r\nmodel_dir = 'project_name\/1'\r\ntf.saved_model.save(model, model_dir)\r\nmlflow.tensorflow.log_model(tf_saved_model_dir=model_dir,        \r\n                                                tf_signature_def_key=\"serving_default\", \r\n                                                tf_meta_graph_tags=\"serve\",     \r\n                                                artifact_path=model_dir)\r\n```\r\n\r\nThank you\r\n\r\n## Motivation\r\n\r\n-   What is the use case for this feature?\r\n    -   Use TF-serving to serve models logged in MLflow\r\n-   Why is this use case valuable to support for MLflow users in general?\r\n    -   Tensorflow serving is widely used way of model serving and it would be nice to support it\r\n-   Why is this use case valuable to support for your project(s) or organization?\r\n    -  We use tensorflow serving to serve models in production. We also use MLflow to track experiments and log models.  We would like to pass the path to an S3 storage where models are logged to TF-serving  \r\n-   Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\n\r\nComponents\r\n\r\n-   [x] `area\/artifacts`: Artifact stores and artifact logging\r\n-   [ ] `area\/build`: Build and test infrastructure for MLflow\r\n-   [ ] `area\/docs`: MLflow documentation pages\r\n-   [ ] `area\/examples`: Example code\r\n-   [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n-   [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n-   [ ] `area\/projects`: MLproject format, project running backends\r\n-   [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n-   [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n-   [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n\r\n-   [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n-   [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n-   [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n-   [ ] `area\/windows`: Windows support\r\n\r\nLanguages\r\n\r\n-   [ ] `language\/r`: R APIs and clients\r\n-   [ ] `language\/java`: Java APIs and clients\r\n-   [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n\r\n-   [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n-   [ ] `integrations\/sagemaker`: SageMaker integrations\r\n-   [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nIf I log a tensorflow model with tensorflow like this:\r\n\r\n```python\r\nmodel_dir = 'project_name\/1'\r\ntf.saved_model.save(model, model_dir)\r\nmlflow.tensorflow.log_model(tf_saved_model_dir=model_dir,      \r\n                                                tf_signature_def_key=\"serving_default\",                                  \r\n                                                tf_meta_graph_tags=\"serve\",     \r\n                                                artifact_path=model_dir)\r\n```\r\n\r\nThe resulting structure in MLflow is:\r\n\r\n```\r\n|-- project_name\r\n|\u00a0\u00a0\u00a0-- 1\r\n|\u00a0\u00a0 -- tfmodel\r\n| \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| -- saved_model.pb|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| -- variables| \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| -- variables.data-00000-of-00001\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| -- variables.index\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| --variables\r\n```\r\n\r\nWhen we try to load the model to tensorflow serving docker there is the following error:\r\n\r\n```\r\nLoading servable: {name: project_name version: 1} failed: Not found: Specified file path does not appear to contain a SavedModel bundle (should have a file called `saved_model.pb`)\r\n```","365":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages documentation fix contributions. Would you or another member of your organization be willing to contribute a fix for this documentation issue to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a documentation fix independently.\r\n- [ x] Yes. I would be willing to contribute a document fix with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a documentation fix at this time.\r\n\r\n### URL(s) with the issue:\r\n\r\n- https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.azureml.html#mlflow.azureml.build_image\r\n- https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.azureml.html#mlflow.azureml.deploy\r\n\r\n### Description of proposal (what needs changing):\r\n\r\nThe documentation for these two methods is practically identical. If there is a difference it needs to be called out. Otherwise, one of them is redundant. \r\n\r\n- [mlflow.azureml.build_image](https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.azureml.html#mlflow.azureml.build_image) - Register an MLflow model with Azure ML and build an Azure ML ContainerImage for deployment. The resulting image can be deployed as a web service to Azure Container Instances (ACI) or Azure Kubernetes Service (AKS).\r\n- [mlflow.azureml.deploy](https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.azureml.html#mlflow.azureml.deploy) - Register an MLflow model with Azure ML and deploy a websevice to Azure Container Instances (ACI) or Azure Kubernetes Service (AKS).\r\n\r\n","366":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nSince version 1.14.0 the models inference API accepts numpy\/tensor input using TF serving's \"instances\" or \"inputs\" format. However, the API does not yet support \"signature_name\" as part of the request. \"signature_name\" is optional in tensorflow serving and is used to call serving signatures of the saved tensorflow model to execute custom logic on request data (e.g. transformation of input data).\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nEnables calling a serving signature of a Tensorflow model to do transformations before inference.\r\n- Why is this use case valuable to support for MLflow users in general?\r\nUsers will be able to call custom serving signatures for their Tensorflow models like in TF Serving.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nIn our project, we want to normalize the data before inference.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nFeature is not supported yet by mlflow.\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/utils\/proto_json_utils.py throws an exception when passing the \"signature_name\" via the model server REST API (line 195)\r\n\r\n> MlflowException: Failed to parse data as TF serving input. \\\"signature_name\\\" is currently not supported.\\n\"\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nStack trace post request\r\n\r\n> {\r\n>     \"error_code\": \"MALFORMED_REQUEST\",\r\n>     \"message\": \"Failed to parse data as TF serving input. \\\"signature_name\\\" is currently not supported.\",\r\n>     \"stack_trace\": \"Traceback (most recent call last):\\n  File \\\"\/home\/mlflow\/.conda\/envs\/mlflow-7ad5f264a0d35e69dfdd82514dfafa2ea482e888\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/scoring_server\/__init__.py\\\", line 90, in infer_and_parse_json_input\\n    return parse_tf_serving_input(decoded_input, schema=schema)\\n  File \\\"\/home\/mlflow\/.conda\/envs\/mlflow-7ad5f264a0d35e69dfdd82514dfafa2ea482e888\/lib\/python3.7\/site-packages\/mlflow\/utils\/proto_json_utils.py\\\", line 197, in parse_tf_serving_input\\n    'Failed to parse data as TF serving input. \\\"signature_name\\\" is currently'\\nmlflow.exceptions.MlflowException: Failed to parse data as TF serving input. \\\"signature_name\\\" is currently not supported.\\n\"\r\n> }\r\n","367":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nCurrently, the 'mlflow.pyfunc.load_model(MODEL_URI)' just accepts the remote model URI (S3 in our case) when trying to load a Python flavored MLFlow model and its artifacts. As part of this call, the load_model method, downloads the artifacts registered when logging the MLFLow model to a temporary directory in the local filesystem for serving. I would like to open a feature request, to allow specifying a local path when calling the load_model function, this would enable the users to download the artifacts and the model to a specific location for further analysis.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n      - Enables downloading the remote model and its artifacts to a specified location which caters to reduced model loading \r\n         times as the model is directly loaded from a local file path and can be reused by other programs, if required.\r\n- Why is this use case valuable to support for MLflow users in general?\r\n      - The feature will reduce the overall model serving time for large models as the artifacts and the model itself would be \r\n         available at a local filesystem path for multiple programs to use.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n      - This will help us to tackle the long loading times when iniializing the model serving framework as our production \r\n         deployment consists of ensemble of models rather than a single model.\r\n- Why is it currently difficult to achieve this use case?\r\n      - We have a workaround in place to shutil the models and their artifacts from the temporary directories to a different \r\n         location everytime it is initialized by a program, this is not optimized and can be error prone.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n```python\r\nimport mlflow\r\n\r\nLOGGED_MODEL_S3_URI : \"s3:\/\/buckeet\/path\/to\/the\/model\/artifacts\"\r\n\r\n# Current API Call\r\nmodel = mlflow.pyfunc.load_model(LOGGED_MODEL_S3_URI)\r\n\r\n# Proposed API Call\r\nmodel = mlflow.pyfunc.load_model(\r\n                    LOGGED_MODEL_S3_URI, \r\n                    local_dst_path=os.path.join(os.path.expanduser(\"~\"), \"model\")\r\n               )\r\n```\r\n\r\n## Proposed solution\r\n\r\nChanges in pyfunc.__init__.py\r\n\r\n```python\r\n\r\n# Current load_model implementation\r\n\r\ndef load_model(model_uri: str, suppress_warnings: bool = True) -> PyFuncModel:\r\n    \"\"\"\r\n    Load a model stored in Python function format.\r\n\r\n    :param model_uri: The location, in URI format, of the MLflow model. For example:\r\n\r\n                      - ``\/Users\/me\/path\/to\/local\/model``\r\n                      - ``relative\/path\/to\/local\/model``\r\n                      - ``s3:\/\/my_bucket\/path\/to\/model``\r\n                      - ``runs:\/<mlflow_run_id>\/run-relative\/path\/to\/model``\r\n                      - ``models:\/<model_name>\/<model_version>``\r\n                      - ``models:\/<model_name>\/<stage>``\r\n\r\n                      For more information about supported URI schemes, see\r\n                      `Referencing Artifacts <https:\/\/www.mlflow.org\/docs\/latest\/concepts.html#\r\n                      artifact-locations>`_.\r\n    :param suppress_warnings: If ``True``, non-fatal warning messages associated with the model\r\n                              loading process will be suppressed. If ``False``, these warning\r\n                              messages will be emitted.\r\n    \"\"\"\r\n    local_path = _download_artifact_from_uri(artifact_uri=model_uri)\r\n    model_meta = Model.load(os.path.join(local_path, MLMODEL_FILE_NAME))\r\n\r\n    conf = model_meta.flavors.get(FLAVOR_NAME)\r\n    if conf is None:\r\n        raise MlflowException(\r\n            'Model does not have the \"{flavor_name}\" flavor'.format(flavor_name=FLAVOR_NAME),\r\n            RESOURCE_DOES_NOT_EXIST,\r\n        )\r\n    model_py_version = conf.get(PY_VERSION)\r\n    if not suppress_warnings:\r\n        _warn_potentially_incompatible_py_version_if_necessary(model_py_version=model_py_version)\r\n    if CODE in conf and conf[CODE]:\r\n        code_path = os.path.join(local_path, conf[CODE])\r\n        mlflow.pyfunc.utils._add_code_to_system_path(code_path=code_path)\r\n    data_path = os.path.join(local_path, conf[DATA]) if (DATA in conf) else local_path\r\n    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\r\n    return PyFuncModel(model_meta=model_meta, model_impl=model_impl)\r\n\r\n\r\n# Proposed load_model implementation\r\n\r\ndef load_model(model_uri: str, local_dst_path: str = None, suppress_warnings: bool = True) -> PyFuncModel:\r\n    \"\"\"\r\n    Load a model stored in Python function format.\r\n\r\n    :param model_uri: The location, in URI format, of the MLflow model. For example:\r\n\r\n                      - ``\/Users\/me\/path\/to\/local\/model``\r\n                      - ``relative\/path\/to\/local\/model``\r\n                      - ``s3:\/\/my_bucket\/path\/to\/model``\r\n                      - ``runs:\/<mlflow_run_id>\/run-relative\/path\/to\/model``\r\n                      - ``models:\/<model_name>\/<model_version>``\r\n                      - ``models:\/<model_name>\/<stage>``\r\n\r\n                      For more information about supported URI schemes, see\r\n                      `Referencing Artifacts <https:\/\/www.mlflow.org\/docs\/latest\/concepts.html#\r\n                      artifact-locations>`_.\r\n    :param local_dst_path: The local file system path to download model and its artifacts. \r\n                              Defaults to `None`.\r\n    :param suppress_warnings: If ``True``, non-fatal warning messages associated with the model\r\n                              loading process will be suppressed. If ``False``, these warning\r\n                              messages will be emitted.\r\n    \"\"\"\r\n    local_path = _download_artifact_from_uri(artifact_uri=model_uri, output_path=local_dst_path)\r\n    model_meta = Model.load(os.path.join(local_path, MLMODEL_FILE_NAME))\r\n\r\n    conf = model_meta.flavors.get(FLAVOR_NAME)\r\n    if conf is None:\r\n        raise MlflowException(\r\n            'Model does not have the \"{flavor_name}\" flavor'.format(flavor_name=FLAVOR_NAME),\r\n            RESOURCE_DOES_NOT_EXIST,\r\n        )\r\n    model_py_version = conf.get(PY_VERSION)\r\n    if not suppress_warnings:\r\n        _warn_potentially_incompatible_py_version_if_necessary(model_py_version=model_py_version)\r\n    if CODE in conf and conf[CODE]:\r\n        code_path = os.path.join(local_path, conf[CODE])\r\n        mlflow.pyfunc.utils._add_code_to_system_path(code_path=code_path)\r\n    data_path = os.path.join(local_path, conf[DATA]) if (DATA in conf) else local_path\r\n    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\r\n    return PyFuncModel(model_meta=model_meta, model_impl=model_impl)\r\n```","368":"**fixing \"AttributeError: module 'mlflow' has no attribute 'protos'\" bug when importing package, caused by line 25**\r\n\r\n## What changes are proposed in this pull request?\r\n\r\n(Please fill in changes proposed in this fix)\r\n\r\n## How is this patch tested?\r\n\r\n(Details)\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","369":"**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux 5.10.15-1-MANJARO\r\n- **MLflow installed from (source or binary)**: binary (`pip install`)\r\n- **MLflow version (run ``mlflow --version``)**: mlflow, version 1.14.0\r\n- **Python version**: Python 3.8.8\r\n- **npm version, if running the dev UI**: --\r\n- **Exact command to reproduce**: `mlflow models build-docker -m \"models:\/MY_EXPERIMENT_NAME\/Production\" -n \"mlflow-test-docker-image-model\"` (replace MY_EXPERIMENT_NAME)\r\n\r\n### Describe the problem\r\n\r\nDuring the last step of the `mlflow models build-docker` command (step 17 of 17), the following error occurs:\r\n\r\n```\r\nStep 17\/17 : ENTRYPOINT [\"python\", \"-c\", \"from mlflow.models import container as C; C._serve()\"]\r\n ---> Running in 654d293b33eb\r\nRemoving intermediate container 654d293b33eb\r\n ---> 4555f8ea4314\r\nSuccessfully built 4555f8ea4314\r\nSuccessfully tagged mlflow-test-docker-image-model:latest\r\nException ignored in: <function Connection.__del__ at 0x7f8000ccc4c0>\r\nTraceback (most recent call last):\r\n  File \"\/home\/julius\/anaconda3\/envs\/mlflow\/lib\/python3.8\/site-packages\/pysftp\/__init__.py\", line 1013, in __del__\r\n  File \"\/home\/julius\/anaconda3\/envs\/mlflow\/lib\/python3.8\/site-packages\/pysftp\/__init__.py\", line 785, in close\r\n  File \"\/home\/julius\/anaconda3\/envs\/mlflow\/lib\/python3.8\/site-packages\/paramiko\/sftp_client.py\", line 195, in close\r\n  File \"\/home\/julius\/anaconda3\/envs\/mlflow\/lib\/python3.8\/site-packages\/paramiko\/channel.py\", line 671, in close\r\n  File \"\/home\/julius\/anaconda3\/envs\/mlflow\/lib\/python3.8\/site-packages\/paramiko\/transport.py\", line 1846, in _send_user_message\r\nAttributeError: 'NoneType' object has no attribute 'time'\r\n```\r\n\r\n**Importantly, the docker image is built successfully nevertheless. It is shown by `docker images` and can also be started with `docker run -p 5001:8080 \"mlflow-test-docker-image-model\"`. Also, the server successfully serves the model as tested with `\r\ncurl -d '{\"columns\":\\[\"x\"\\], \"data\":\\[\\[1\\], \\[-1\\]\\]}' -H 'Content-Type: application\/json; format=pandas-split' -X POST localhost:5001\/invocations`.**\r\n\r\nAlso, maybe of relevance, serving the model with an anaconda environment works flawlessly.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n- go to `mlflow\/examples\/sklearn_logistic_regression`\r\n- (using remote sftp tracking server, so I set: `export MLFLOW_TRACKING_URI=http:\/\/127.0.0.1:4000`\r\n- set experiment name with: `export MLFLOW_EXPERIMENT_NAME=MY_EXPERIMENT_NAME`\r\n- `mlflow run .`\r\n- `mlflow models build-docker -m \"models:\/MY_EXPERIMENT_NAME\/Production\" -n \"mlflow-test-docker-image-model\"`\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [x] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [x] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [x] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","370":"I am executing an ML process using PySpark on a cluster with HDFS. The ML artifacts are being written to HDFS and I don't have an easy way to get them on my local file system. Am I able to log those artifacts to my artifact store (on S3) without getting them on my local filesystem first?","371":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nSupport to run MLFlow projects in Kubeflow clusters.\r\n\r\n## Motivation\r\n\r\nNow we support Kubernetes jobs for MLFlow projects. I think we can also integrate with Kubeflow to gain more users from the kubeflow community.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n\r\nTBA","372":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\n\r\nin the main UI, in the search field, make it possible to search for multiple criteria, eg runs with different specific names, and see the union of these results, by joining them with `or`.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nBeing able to compare two runs\r\n- Why is this use case valuable to support for MLflow users in general?\r\nIf have lots of runs, impossible to find two specific runs to compare without using a search clause. No way to search for one at a time, if one wants to see the runs in a parameter comparison page\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nI have lots of runs, and which to compare pairs of them sometimes.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nIf have lots of runs, impossible to find two specific runs to compare without using a search clause. No way to search for one at a time, if one wants to see the runs in a parameter comparison page\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","373":"**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:  Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04, running a Jupyter Notebook\r\n- **MLflow installed from (source or binary)**: Binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.10.0\r\n- **Python version**: 3.7.3\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI've created a PySpark model in Python and logged it using MLflow. Then, I tried to create a Spark UDF and run a prediction with it on a toy dataset. It's throwing an error on the columns when I try to show the resulting DataFrame. Also, if I try to use `.toPandas()` to convert it to Pandas, it returns an empty DataFrame even though the number of rows and columns is (2, 5)\r\n\r\n### Code to reproduce issue\r\n#### First create the model and log it with MLflow\r\n```python\r\nfrom pyspark.ml.classification import LogisticRegression\r\nfrom pyspark.ml import Pipeline\r\nfrom pyspark.sql import Row, SparkSession\r\n\r\nspark_session = SparkSession.builder.appName('spark-udf-deployment').getOrCreate()\r\n\r\nFEATURES = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"]\r\n\r\nSPARK_DATA = spark_session.createDataFrame(\r\n    [\r\n        (5.1, 3.5, 1.4, 0.2, \"A\"),\r\n        (6.7, 3.3, 5.7, 2.1, \"B\"),\r\n    ],\r\n    FEATURES\r\n)\r\n\r\nfeature_cols = SPARK_DATA.columns[:-1]\r\n\r\nassembler = pyspark.ml.feature.VectorAssembler(inputCols=feature_cols, outputCol='features')\r\nlabel_indexer = pyspark.ml.feature.StringIndexer(inputCol='species', outputCol='label')\r\nmodel = LogisticRegression(maxIter=2, regParam=0.001)\r\npipeline = Pipeline(stages=[assembler, label_indexer, model])\r\n\r\nmodel = pipeline.fit(SPARK_DATA)\r\n\r\nwith mlflow.start_run() as run:\r\n    mlflow.spark.log_model(model, \"sparkmodel\")\r\n```\r\n\r\n#### Now create the UDF and run it\r\n```python\r\nimport mlflow.pyfunc\r\nimport pandas as pd\r\nfrom pyspark.sql.types import ArrayType, FloatType\r\nfrom pyspark.sql import Row, SparkSession\r\n\r\nMODEL_PATH = \"s3:\/\/mlflow\/0\/5a27e53916914a66af08266ba04a75d1\/artifacts\/sparkmodel\"\r\nFEATURES = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\r\n\r\nspark_session = SparkSession.builder.appName('spark-udf-deployment').getOrCreate()\r\nSPARK_DATA = spark_session.createDataFrame(\r\n    [\r\n        (5.1, 3.5, 1.4, 0.2),\r\n        (6.7, 3.3, 5.7, 2.1),\r\n    ],\r\n    FEATURES\r\n)\r\n\r\npred_udf = mlflow.pyfunc.spark_udf(spark=spark_session, model_uri=MODEL_PATH, result_type=ArrayType(FloatType()))\r\nSPARK_DATA.show()\r\n\r\nresult = SPARK_DATA.withColumn(\"prediction\", pred_udf(*FEATURES))\r\n\r\nprint(result.count(), len(result.columns)) # prints 2 5 \r\ndisplay(result) # prints nothing\r\nresult.toPandas() # prints DataFrame[sepal_length: double, sepal_width: double, petal_length: double, petal_width: double, prediction: array<float>]\r\nprint(result.toPandas()) # prints an empty Pandas DataFrame\r\nresult.show() # throws the error\r\n```\r\n\r\n\r\n\r\n### Other info \/ logs\r\nThe last line of `result.show()` throws a large exception. I think the important part is:\r\n\r\n```\r\npyspark.sql.utils.IllegalArgumentException: 'Field \"sepal_length\" does not exist.\\nAvailable fields: 0, 1, 2, 3'\r\n```\r\n\r\nHere is the full logs if useful:\r\n\r\n```\r\nPy4JJavaError                             Traceback (most recent call last)\r\n<ipython-input-93-4ac216c0e3a8> in <module>\r\n     25 result.toPandas()\r\n     26 print(result.toPandas())\r\n---> 27 result.show()\r\n\r\n\/usr\/local\/spark\/python\/pyspark\/sql\/dataframe.py in show(self, n, truncate, vertical)\r\n    376         \"\"\"\r\n    377         if isinstance(truncate, bool) and truncate:\r\n--> 378             print(self._jdf.showString(n, 20, vertical))\r\n    379         else:\r\n    380             print(self._jdf.showString(n, int(truncate), vertical))\r\n\r\n\/usr\/local\/spark\/python\/lib\/py4j-0.10.7-src.zip\/py4j\/java_gateway.py in __call__(self, *args)\r\n   1255         answer = self.gateway_client.send_command(command)\r\n   1256         return_value = get_return_value(\r\n-> 1257             answer, self.gateway_client, self.target_id, self.name)\r\n   1258 \r\n   1259         for temp_arg in temp_args:\r\n\r\n\/usr\/local\/spark\/python\/pyspark\/sql\/utils.py in deco(*a, **kw)\r\n     61     def deco(*a, **kw):\r\n     62         try:\r\n---> 63             return f(*a, **kw)\r\n     64         except py4j.protocol.Py4JJavaError as e:\r\n     65             s = e.java_exception.toString()\r\n\r\n\/usr\/local\/spark\/python\/lib\/py4j-0.10.7-src.zip\/py4j\/protocol.py in get_return_value(answer, gateway_client, target_id, name)\r\n    326                 raise Py4JJavaError(\r\n    327                     \"An error occurred while calling {0}{1}{2}.\\n\".\r\n--> 328                     format(target_id, \".\", name), value)\r\n    329             else:\r\n    330                 raise Py4JError(\r\n\r\nPy4JJavaError: An error occurred while calling o6659.showString.\r\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 739.0 failed 1 times, most recent failure: Lost task 0.0 in stage 739.0 (TID 841, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\r\n  File \"\/usr\/local\/spark\/python\/lib\/pyspark.zip\/pyspark\/sql\/utils.py\", line 63, in deco\r\n    return f(*a, **kw)\r\n  File \"\/usr\/local\/spark\/python\/lib\/py4j-0.10.7-src.zip\/py4j\/protocol.py\", line 328, in get_return_value\r\n    format(target_id, \".\", name), value)\r\npy4j.protocol.Py4JJavaError: An error occurred while calling o63.transform.\r\n: java.lang.IllegalArgumentException: Field \"sepal_length\" does not exist.\r\nAvailable fields: 0, 1, 2, 3\r\n\tat org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:274)\r\n\tat org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:274)\r\n\tat scala.collection.MapLike$class.getOrElse(MapLike.scala:128)\r\n\tat scala.collection.AbstractMap.getOrElse(Map.scala:59)\r\n\tat org.apache.spark.sql.types.StructType.apply(StructType.scala:273)\r\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$6.apply(VectorAssembler.scala:162)\r\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$6.apply(VectorAssembler.scala:161)\r\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\r\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\r\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\r\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)\r\n\tat scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\r\n\tat scala.collection.mutable.ArrayOps$ofRef.flatMap(ArrayOps.scala:186)\r\n\tat org.apache.spark.ml.feature.VectorAssembler.transformSchema(VectorAssembler.scala:161)\r\n\tat org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:74)\r\n\tat org.apache.spark.ml.feature.VectorAssembler.transform(VectorAssembler.scala:86)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"\/usr\/local\/spark\/python\/lib\/pyspark.zip\/pyspark\/worker.py\", line 377, in main\r\n    process()\r\n  File \"\/usr\/local\/spark\/python\/lib\/pyspark.zip\/pyspark\/worker.py\", line 372, in process\r\n    serializer.dump_stream(func(split_index, iterator), outfile)\r\n  File \"\/usr\/local\/spark\/python\/lib\/pyspark.zip\/pyspark\/serializers.py\", line 286, in dump_stream\r\n    for series in iterator:\r\n  File \"<string>\", line 1, in <lambda>\r\n  File \"\/usr\/local\/spark\/python\/lib\/pyspark.zip\/pyspark\/worker.py\", line 101, in <lambda>\r\n    return lambda *a: (verify_result_length(*a), arrow_return_type)\r\n  File \"\/usr\/local\/spark\/python\/lib\/pyspark.zip\/pyspark\/worker.py\", line 92, in verify_result_length\r\n    result = f(*a)\r\n  File \"\/usr\/local\/spark\/python\/lib\/pyspark.zip\/pyspark\/util.py\", line 99, in wrapper\r\n    return f(*args, **kwargs)\r\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py\", line 644, in predict\r\n    result = model.predict(pdf)\r\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py\", line 418, in predict\r\n    return self._model_impl.predict(data)\r\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/spark.py\", line 542, in predict\r\n    self.spark_model.transform(spark_df).select(\"prediction\").collect()]\r\n  File \"\/usr\/local\/spark\/python\/lib\/pyspark.zip\/pyspark\/ml\/base.py\", line 173, in transform\r\n    return self._transform(dataset)\r\n  File \"\/usr\/local\/spark\/python\/lib\/pyspark.zip\/pyspark\/ml\/pipeline.py\", line 262, in _transform\r\n    dataset = t.transform(dataset)\r\n  File \"\/usr\/local\/spark\/python\/lib\/pyspark.zip\/pyspark\/ml\/base.py\", line 173, in transform\r\n    return self._transform(dataset)\r\n  File \"\/usr\/local\/spark\/python\/lib\/pyspark.zip\/pyspark\/ml\/wrapper.py\", line 312, in _transform\r\n    return DataFrame(self._java_obj.transform(dataset._jdf), dataset.sql_ctx)\r\n  File \"\/usr\/local\/spark\/python\/lib\/py4j-0.10.7-src.zip\/py4j\/java_gateway.py\", line 1257, in __call__\r\n    answer, self.gateway_client, self.target_id, self.name)\r\n  File \"\/usr\/local\/spark\/python\/lib\/pyspark.zip\/pyspark\/sql\/utils.py\", line 79, in deco\r\n    raise IllegalArgumentException(s.split(': ', 1)[1], stackTrace)\r\npyspark.sql.utils.IllegalArgumentException: 'Field \"sepal_length\" does not exist.\\nAvailable fields: 0, 1, 2, 3'\r\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\r\n\tat org.apache.spark.sql.execution.python.ArrowPythonRunner$$anon$1.read(ArrowPythonRunner.scala:172)\r\n\tat org.apache.spark.sql.execution.python.ArrowPythonRunner$$anon$1.read(ArrowPythonRunner.scala:122)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat org.apache.spark.sql.execution.python.ArrowEvalPythonExec$$anon$2.<init>(ArrowEvalPythonExec.scala:98)\r\n\tat org.apache.spark.sql.execution.python.ArrowEvalPythonExec.evaluate(ArrowEvalPythonExec.scala:96)\r\n\tat org.apache.spark.sql.execution.python.EvalPythonExec$$anonfun$doExecute$1.apply(EvalPythonExec.scala:127)\r\n\tat org.apache.spark.sql.execution.python.EvalPythonExec$$anonfun$doExecute$1.apply(EvalPythonExec.scala:89)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\r\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:365)\r\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\r\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3383)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2544)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2544)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3364)\r\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3363)\r\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2544)\r\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2758)\r\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\r\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\r\n\tat sun.reflect.GeneratedMethodAccessor171.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\r\n  File \"\/usr\/local\/spark\/python\/lib\/pyspark.zip\/pyspark\/sql\/utils.py\", line 63, in deco\r\n    return f(*a, **kw)\r\n  File \"\/usr\/local\/spark\/python\/lib\/py4j-0.10.7-src.zip\/py4j\/protocol.py\", line 328, in get_return_value\r\n    format(target_id, \".\", name), value)\r\npy4j.protocol.Py4JJavaError: An error occurred while calling o63.transform.\r\n: java.lang.IllegalArgumentException: Field \"sepal_length\" does not exist.\r\nAvailable fields: 0, 1, 2, 3\r\n\tat org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:274)\r\n\tat org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:274)\r\n\tat scala.collection.MapLike$class.getOrElse(MapLike.scala:128)\r\n\tat scala.collection.AbstractMap.getOrElse(Map.scala:59)\r\n\tat org.apache.spark.sql.types.StructType.apply(StructType.scala:273)\r\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$6.apply(VectorAssembler.scala:162)\r\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$6.apply(VectorAssembler.scala:161)\r\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\r\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\r\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\r\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)\r\n\tat scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\r\n\tat scala.collection.mutable.ArrayOps$ofRef.flatMap(ArrayOps.scala:186)\r\n\tat org.apache.spark.ml.feature.VectorAssembler.transformSchema(VectorAssembler.scala:161)\r\n\tat org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:74)\r\n\tat org.apache.spark.ml.feature.VectorAssembler.transform(VectorAssembler.scala:86)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"\/usr\/local\/spark\/python\/lib\/pyspark.zip\/pyspark\/worker.py\", line 377, in main\r\n    process()\r\n  File \"\/usr\/local\/spark\/python\/lib\/pyspark.zip\/pyspark\/worker.py\", line 372, in process\r\n    serializer.dump_stream(func(split_index, iterator), outfile)\r\n  File \"\/usr\/local\/spark\/python\/lib\/pyspark.zip\/pyspark\/serializers.py\", line 286, in dump_stream\r\n    for series in iterator:\r\n  File \"<string>\", line 1, in <lambda>\r\n  File \"\/usr\/local\/spark\/python\/lib\/pyspark.zip\/pyspark\/worker.py\", line 101, in <lambda>\r\n    return lambda *a: (verify_result_length(*a), arrow_return_type)\r\n  File \"\/usr\/local\/spark\/python\/lib\/pyspark.zip\/pyspark\/worker.py\", line 92, in verify_result_length\r\n    result = f(*a)\r\n  File \"\/usr\/local\/spark\/python\/lib\/pyspark.zip\/pyspark\/util.py\", line 99, in wrapper\r\n    return f(*args, **kwargs)\r\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py\", line 644, in predict\r\n    result = model.predict(pdf)\r\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py\", line 418, in predict\r\n    return self._model_impl.predict(data)\r\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/spark.py\", line 542, in predict\r\n    self.spark_model.transform(spark_df).select(\"prediction\").collect()]\r\n  File \"\/usr\/local\/spark\/python\/lib\/pyspark.zip\/pyspark\/ml\/base.py\", line 173, in transform\r\n    return self._transform(dataset)\r\n  File \"\/usr\/local\/spark\/python\/lib\/pyspark.zip\/pyspark\/ml\/pipeline.py\", line 262, in _transform\r\n    dataset = t.transform(dataset)\r\n  File \"\/usr\/local\/spark\/python\/lib\/pyspark.zip\/pyspark\/ml\/base.py\", line 173, in transform\r\n    return self._transform(dataset)\r\n  File \"\/usr\/local\/spark\/python\/lib\/pyspark.zip\/pyspark\/ml\/wrapper.py\", line 312, in _transform\r\n    return DataFrame(self._java_obj.transform(dataset._jdf), dataset.sql_ctx)\r\n  File \"\/usr\/local\/spark\/python\/lib\/py4j-0.10.7-src.zip\/py4j\/java_gateway.py\", line 1257, in __call__\r\n    answer, self.gateway_client, self.target_id, self.name)\r\n  File \"\/usr\/local\/spark\/python\/lib\/pyspark.zip\/pyspark\/sql\/utils.py\", line 79, in deco\r\n    raise IllegalArgumentException(s.split(': ', 1)[1], stackTrace)\r\npyspark.sql.utils.IllegalArgumentException: 'Field \"sepal_length\" does not exist.\\nAvailable fields: 0, 1, 2, 3'\r\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\r\n\tat org.apache.spark.sql.execution.python.ArrowPythonRunner$$anon$1.read(ArrowPythonRunner.scala:172)\r\n\tat org.apache.spark.sql.execution.python.ArrowPythonRunner$$anon$1.read(ArrowPythonRunner.scala:122)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat org.apache.spark.sql.execution.python.ArrowEvalPythonExec$$anon$2.<init>(ArrowEvalPythonExec.scala:98)\r\n\tat org.apache.spark.sql.execution.python.ArrowEvalPythonExec.evaluate(ArrowEvalPythonExec.scala:96)\r\n\tat org.apache.spark.sql.execution.python.EvalPythonExec$$anonfun$doExecute$1.apply(EvalPythonExec.scala:127)\r\n\tat org.apache.spark.sql.execution.python.EvalPythonExec$$anonfun$doExecute$1.apply(EvalPythonExec.scala:89)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ x ] `area\/examples`: Example code\r\n- [ x ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n\r\nInterface \r\n- [ x ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n\r\n","374":"Hi,\r\nI have installed mlflow using pip on windows 10. When I try to run mlflow_tracking.py from mlflow\/examples\/quickstart the .py file runs ok from cmd but when I try to run mlflow ui from cmd to open the user interface it gives the not recognized error.\r\n\r\nPlease help me here.\r\nThank you\r\n![mlflow_rror](https:\/\/user-images.githubusercontent.com\/7506647\/108614290-32a08980-73c7-11eb-9778-52ec81616613.png)\r\n\r\n","375":"Hello all\uff0c When I started mlflow tracking server, the following error occurred FileNotFoundError: [Errno 2] No such file or directory: 'gunicorn' \uff1a\r\n\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Centos7.7)**:\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version =1.13.1**:\r\n- **Python version=3.8.5**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nTraceback (most recent call last):\r\n  File \"\/root\/anaconda3\/bin\/mlflow\", line 8, in <module>\r\n    sys.exit(cli())\r\n  File \"\/root\/anaconda3\/lib\/python3.8\/site-packages\/click\/core.py\", line 829, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\/root\/anaconda3\/lib\/python3.8\/site-packages\/click\/core.py\", line 782, in main\r\n    rv = self.invoke(ctx)\r\n  File \"\/root\/anaconda3\/lib\/python3.8\/site-packages\/click\/core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/root\/anaconda3\/lib\/python3.8\/site-packages\/click\/core.py\", line 1066, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\/root\/anaconda3\/lib\/python3.8\/site-packages\/click\/core.py\", line 610, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"\/root\/anaconda3\/lib\/python3.8\/site-packages\/mlflow\/cli.py\", line 392, in server\r\n    _run_server(\r\n  File \"\/root\/anaconda3\/lib\/python3.8\/site-packages\/mlflow\/server\/__init__.py\", line 138, in _run_server\r\n    exec_cmd(full_command, env=env_map, stream_output=True)\r\n  File \"\/root\/anaconda3\/lib\/python3.8\/site-packages\/mlflow\/utils\/process.py\", line 34, in exec_cmd\r\n    child = subprocess.Popen(\r\n  File \"\/root\/anaconda3\/lib\/python3.8\/subprocess.py\", line 854, in __init__\r\n    self._execute_child(args, executable, preexec_fn, close_fds,\r\n  File \"\/root\/anaconda3\/lib\/python3.8\/subprocess.py\", line 1702, in _execute_child\r\n    raise child_exception_type(errno_num, err_msg, err_filename)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'gunicorn' \r\n\r\nBut there is gunicorn command in my system, Why does it still report this error\uff1f\r\n","376":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nWhen running many runs, as a grid, some of the names can get long, or else have to use unreadable abbreviations. Would be nice to see the full code name for each run on a graph, eg by mouseover.\r\n- Why is this use case valuable to support for MLflow users in general?\r\nOther people might also run grid searches and have long-ish run name\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nI run lots of grid searches over many hyper-parameters, and want to be able to compare runs in a graph, and remember easily what each run is, without having to cross-reference each run name against a table of hyper-parameters\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nneed to look up a short reference name in a table of hyper-parameters. tedious and hard to use.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","377":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nHave selected one or more runs, and clikced on a metrci to show a graph. Now want to add a new run to the graph. Currently have to go back to main page, reselect all runs, click on compare, and then reclick on a metric. Would be nice to just be able to add adidtional runs directly to the plot, in a simlar way to how we can already add additional metrics to the same plot.\r\n- Why is this use case valuable to support for MLflow users in general?\r\nSaves time. convenient. same use case as mlflow in general :)\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nSaves time. convenient.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nas stated above, have to go through multiple hoops to add a new run to an exsiting graph.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","378":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: CentOS 3.10.0-1160.11.1.el7.x86_64\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.13.1\r\n- **Python version**: 3.8.5\r\n- **npm version, if running the dev UI**: N\/A\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n\r\nIf naively starting multiple processes, each of them creating the same experiment conditionally on a response if experiment already exists I quickly get into race condition:\r\n\r\n```mlflow.exceptions.RestException: RESOURCE_ALREADY_EXISTS: Experiment(name=\/zejml\/test_sz) already exists. Error: (raised as a result of Query-invoked autoflush; consider using a session.no_autoflush block if this flush is occurring prematurely)\r\n(MySQLdb._exceptions.IntegrityError) (1062, \"Duplicate entry '\/zejml\/test_sz' for key 'name'\")\r\n[SQL: INSERT INTO experiments (name, artifact_location, lifecycle_stage) VALUES (%s, %s, %s)]\r\n[parameters: ('\/zejml\/test_sz', '', 'active')]\r\n(Background on this error at: http:\/\/sqlalche.me\/e\/13\/gkpj)\r\n```\r\n\r\nNow, what is the recommended way to handle this problem in MLFlow? \r\nWould it be safe to catch this error and proceed, assuming the experiment exists? \r\nOr perhaps I would have to create something more sophisticated like master and slave processes, with creation being the master's responsibility?\r\nOr anything else?\r\n\r\nI need to assume that processes are started separately, i.e., they cannot be spawned by some root process that could also deal with the experiment creation. This is because I am trying to add MLFLow on top of an existing infra that works in such a way.\r\n\r\n### Code to reproduce issue\r\nRun simultaneously multiple processes for the same experiment, calling into:\r\n```\r\n    def _get_or_create_experiment(self, experiment_name: str):\r\n        experiment = self._client.get_experiment_by_name(experiment_name)\r\n        if experiment is None:\r\n            logger.info(f\"Creating experiment {experiment_name}...\")\r\n            return self._client.create_experiment(experiment_name)\r\n        else:\r\n            return self._get_experiment(experiment)\r\n```\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","379":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nBeing able to select some experiments, and open a compare. Then select other experiments, and open a compare. Currently, have to click 'back', redo the search, and then can reselect. Cannot currently reuse the same search to compare multiple sets of experiments\r\n- Why is this use case valuable to support for MLflow users in general?\r\nSaves time. Convenient. Same reasons we want to use mlflow in the first place :)\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nOften need to compare multiple sets of experiments. Very tedious to have to redo the search query from scratch multiple times. Or copy and paste the search query, etc.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nclicking on 'compare' overwrites the current window. no way to launch the compare in a new tab.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","380":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this documentation issue template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages documentation fix contributions. Would you or another member of your organization be willing to contribute a fix for this documentation issue to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a documentation fix independently.\r\n- [ ] Yes. I would be willing to contribute a document fix with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a documentation fix at this time.\r\n\r\n### URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry in question.\r\n\r\n### Description of proposal (what needs changing):\r\nProvide a clear description. Why is the proposed documentation better?\r\n\r\nMake it easier to find the exact way to search for runName, source name etc. Ideally, provide a mouse-over for the columns on the results table, that gives the method to search for taht thing. eg if you mouse over the 'RunName' column, it will say 'tags.mlflow.runName'.\r\n","381":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nsee mlflow version without logging into server\r\n- Why is this use case valuable to support for MLflow users in general?\r\nsaves having to login to server to see the mlflow version\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nsaves time\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nnot difficult, just inconvenient.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [x] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","382":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this documentation issue template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages documentation fix contributions. Would you or another member of your organization be willing to contribute a fix for this documentation issue to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a documentation fix independently.\r\n- [ ] Yes. I would be willing to contribute a document fix with guidance from the MLflow community.\r\n- [ x] No. I cannot contribute a documentation fix at this time.\r\n\r\n### URL(s) with the issue:\r\n\r\nhttps:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.log_artifact\r\nhttps:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.log_artifacts\r\n\r\n### Description of proposal (what needs changing):\r\n\r\nLegal values for the \"artifact_path\" are not clearly described in the documentation for [log_artifact](https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.log_artifact) and [log_artifacts](https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.log_artifacts) methods. For these 2 methods it says \"artifact_path \u2013 If provided, the directory in artifact_uri to write to.\" and there is no reference what \"artifact_uri\" is. We should  add content that says that the \"artifact_path\" is a relative path to the experiment's \"[artifact_location](https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.create_experiment)\". It cannot be an absolute path.","383":"## Willingness to contribute\r\n- [X] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n\r\n## Proposal Summary\r\nThe proposal is to standardize the way MLFlow builds docker images for training and serving. Currently MLFlow has different utilities for building Docker images under the projects module and models module. \r\n\r\nIn projects, the user must provide a base image that captures all Experiment dependencies. There is no support for activating a Conda environment within the Docker training image. A hack solution is to use a shell script as Docker entry point that activates the Conda environment before passing the arguments to the actual ML project entry point.\r\n\r\nIn contrast, the models build process for the server image demands that all requirements be installed via Conda. Additionally, the base image is fixed as Ubuntu 18.04 LTS. \r\n\r\nMLFlow should standardize image building across both modules to ensure that projects can seamlessly move from training to serving. \r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nMy company wants to use MLFlow as a complete training and deployment solution but is having trouble automating training given the inconsistency between training and serving images.\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\nMLFlow users should be able to train using docker environments (for deployment on docker swarm, kubernetes ..) without abandoning Conda training environments. Additionally the server images created by MLFlow should support dependencies outside of Conda. \r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nThis would allow us to deploy our AutoML infrastructure using docker images while logging all results using MLFlow. We can seamlessly move to serving the models with the MLFlow server. \r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nTo achieve the desired workflow, we have to use shell scripts to activate Conda environments within training images. We also need to be sure that the Conda training environment is captured accurately in the server build step.  \r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [X] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [X] `area\/projects`: MLproject format, project running backends\r\n- [X] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n\r\nInterfaces\r\n- [X] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n\r\n## Details\r\n\r\nImplementation seems fairly straightforward. \r\n\r\nFor the model module, the build should accept an argument for a different base image. It can remain up to the user to verify that the base image will support the installed server dependencies. Perhaps this is as easy as demanding the base image be built from Ubuntu 18.04 LTS or similar. \r\n\r\nFor the project module, the build should make use of the same code used in the model module to install miniconda and configure a custom environment (if a Conda environment is requested). MLFlow can then generate a shell script in the working directory when building the image that activates the Conda environment and calls the project entry point. \r\n","384":"## Willingness to contribute\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nNew `xgboost` version implement a new JSON based serialization format. This format is currently experimental but is aimed to replace the existing binary format.\r\nThe way to have your model serialized as JSON is to have the output filename with a `.json` suffix.\r\nCurrent code hardcodes a `.xgb` suffix\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/xgboost.py#L149\r\nMaking it impossible to use `log_model` to store in JSON format.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n","385":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 10.15.6\r\n- **MLflow installed from (source or binary)**: Binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.13.1\r\n- **Python version**: 3.8.5\r\n- **npm version, if running the dev UI**: N\/A\r\n- **Exact command to reproduce**: mlflow models serve -m \"models:\/SeasonalAD\/1\" -p 1234\r\n\r\n### Describe the problem\r\nMlflow details-\r\nI have mlflow running in k8s container with s3 storage (models being stored at s3:\/\/mlflow\/ bucket) on a remote cluster.\r\nOn my mac:\r\nI have a custom anomaly detection python class with training and prediction method. I am using jupyter notebook(running on my mac) to train and save the model.\r\nI have set suitable env variables from my jupyter notebook to communicate to remote mlflow process. Below vars are set -\r\nimport os\r\nos.environ[\"MLFLOW_S3_ENDPOINT_URL\"]=\"XXXX\"\r\nos.environ[\"AWS_ACCESS_KEY_ID\"]=\"XXXX\"\r\nos.environ[\"AWS_SECRET_ACCESS_KEY\"]=\"XXXX\"\r\nos.environ[\"MLFLOW_TRACKING_INSECURE_TLS\"]=\"true\"\r\nos.environ[\"MLFLOW_TRACKING_URI\"]=\"XXXX\"\r\nimport mlflow\r\nmlflow.set_experiment(\"aj-experiment\")\r\n\r\nI am training this model using a sample data and registering the model using below command-\r\nmlflow.pyfunc.log_model(artifact_path=\"seasonalAD\",python_model=seasonalADTrained, registered_model_name=\"SeasonalAD\")\r\n\r\nModel is successfully registered and I can view the model from s3 minIO UI under **Models** tab. Following are the contents-\r\nseasonalAD\r\n  |--MLModel\r\n  |--conda.yaml\r\n  |--python_model.pkl\r\n\r\nNow, when I try to serve this model as a REST API through cli from my mac it is giving me below trace-\r\n\r\n(base) akhiljain@akhil-jain ~ % mlflow models serve -m \"models:\/SeasonalAD\/1\" -p 1234\r\n\/Users\/akhiljain\/miniconda3\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'XXXX'. Adding certificate verification is strongly advised. See: https:\/\/urllib3.readthedocs.io\/en\/latest\/advanced-usage.html#ssl-warnings\r\n  warnings.warn(\r\nTraceback (most recent call last):\r\n  File \"\/Users\/akhiljain\/miniconda3\/bin\/mlflow\", line 8, in <module>\r\n    sys.exit(cli())\r\n  File \"\/Users\/akhiljain\/miniconda3\/lib\/python3.8\/site-packages\/click\/core.py\", line 829, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\/Users\/akhiljain\/miniconda3\/lib\/python3.8\/site-packages\/click\/core.py\", line 782, in main\r\n    rv = self.invoke(ctx)\r\n  File \"\/Users\/akhiljain\/miniconda3\/lib\/python3.8\/site-packages\/click\/core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/Users\/akhiljain\/miniconda3\/lib\/python3.8\/site-packages\/click\/core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/Users\/akhiljain\/miniconda3\/lib\/python3.8\/site-packages\/click\/core.py\", line 1066, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\/Users\/akhiljain\/miniconda3\/lib\/python3.8\/site-packages\/click\/core.py\", line 610, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"\/Users\/akhiljain\/miniconda3\/lib\/python3.8\/site-packages\/mlflow\/models\/cli.py\", line 55, in serve\r\n    return _get_flavor_backend(\r\n  File \"\/Users\/akhiljain\/miniconda3\/lib\/python3.8\/site-packages\/mlflow\/models\/cli.py\", line 180, in _get_flavor_backend\r\n    model = Model.load(local_path)\r\n  File \"\/Users\/akhiljain\/miniconda3\/lib\/python3.8\/site-packages\/mlflow\/models\/model.py\", line 112, in load\r\n    with open(path) as f:\r\nFileNotFoundError: [Errno 2] No such file or directory: '\/tmp\/tmpv459n53j\/MLmodel\/MLmodel'\r\n\r\nExpected behavior: Serve a model saved with MLflow by launching a webserver on the specified port\r\n\r\n### Code to reproduce issue\r\nimport pandas as pd\r\nimport numpy as np\r\nimport mlflow.pyfunc\r\ndf = pd.read_csv(\"data\/seasonal.csv\", index_col=\"Time\", parse_dates=True)\r\ndf_train = df.iloc[0:7000]\r\nfrom SeasonalAD_class_mlflow import SeasonalAD\r\nseasonalADTrained = SeasonalAD(adjust_trend = False)\r\ndf_train_r, anomalies_f =  seasonalADTrained.fit(df_train[\"Traffic\"],return_result=True)\r\nwith mlflow.start_run():\r\n    mlflow.pyfunc.log_model(artifact_path=\"seasonalAD\",python_model=seasonalADTrained,\r\n                        registered_model_name=\"SeasonalAD\")\r\n\r\n### Other info \/ logs\r\nThis issue comes even when I try to serve model as REST API created by running the ElasticnetWineModel tutorial present on mlflow documentation page.\r\n(base) akhiljain@akhil-jain ~ % mlflow models serve -m \"models:\/ElasticnetWineModel\/1\" -p 1234\r\n\/Users\/akhiljain\/miniconda3\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'XXXX'. Adding certificate verification is strongly advised. See: https:\/\/urllib3.readthedocs.io\/en\/latest\/advanced-usage.html#ssl-warnings\r\n  warnings.warn(\r\nTraceback (most recent call last):\r\n  File \"\/Users\/akhiljain\/miniconda3\/bin\/mlflow\", line 8, in <module>\r\n    sys.exit(cli())\r\n  File \"\/Users\/akhiljain\/miniconda3\/lib\/python3.8\/site-packages\/click\/core.py\", line 829, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\/Users\/akhiljain\/miniconda3\/lib\/python3.8\/site-packages\/click\/core.py\", line 782, in main\r\n    rv = self.invoke(ctx)\r\n  File \"\/Users\/akhiljain\/miniconda3\/lib\/python3.8\/site-packages\/click\/core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/Users\/akhiljain\/miniconda3\/lib\/python3.8\/site-packages\/click\/core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/Users\/akhiljain\/miniconda3\/lib\/python3.8\/site-packages\/click\/core.py\", line 1066, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\/Users\/akhiljain\/miniconda3\/lib\/python3.8\/site-packages\/click\/core.py\", line 610, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"\/Users\/akhiljain\/miniconda3\/lib\/python3.8\/site-packages\/mlflow\/models\/cli.py\", line 55, in serve\r\n    return _get_flavor_backend(\r\n  File \"\/Users\/akhiljain\/miniconda3\/lib\/python3.8\/site-packages\/mlflow\/models\/cli.py\", line 180, in _get_flavor_backend\r\n    model = Model.load(local_path)\r\n  File \"\/Users\/akhiljain\/miniconda3\/lib\/python3.8\/site-packages\/mlflow\/models\/model.py\", line 112, in load\r\n    with open(path) as f:\r\nFileNotFoundError: [Errno 2] No such file or directory: '\/tmp\/tmpjakqqrk7\/MLmodel\/MLmodel'\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n","386":"Signed-off-by: harupy <17039389+harupy@users.noreply.github.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\n(Please fill in changes proposed in this fix)\r\n\r\n## How is this patch tested?\r\n\r\n(Details)\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","387":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\n\r\nCurrently, the API `mlflow.projects.run` only uses the passed `run_id` argument when the backend is `local`.\r\nAllow the use of `run_id` for backends `kubernetes` and `databricks`.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nWhen `mlflow.projects.run` fails to start a Kubernetes pod (e.g., due to limited resources), it raises an exception. However, it still creates an MLflow run. But, the client does not have the MLflow Run ID and thus cannot take action on the created MLflow run, such as deleting it. To solve this, first create an MLflow run via `mlflow.tracking.MlflowClient().create_run` and then pass the `run_id` of the created run to `mlflow.projects.run`.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n- [x] `language\/python`: Python APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n- [x] `integrations\/kubernetes`: Kubernetes integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n\r\nGiven that the API `mlflow.projects.run` already accepts the argument `run_id`, the implementation of this feature is trivial.\r\nThe following changes are made to `mlflow\/projects\/__init__.py`:\r\n1. Add `run_id=run_id` as the last argument in the call to `_run` on line 309 in the definition of `run`.\r\n2. Add `run_id` as the last argument in the function signature of `run` on line 86.\r\n3. Replace `None` with `run_id` in the call to `get_or_create_run` in line 120.","388":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: tried building a docker image with the base `continuumio\/miniconda3` and also tried running on MacOS locally\r\n- **MLflow installed from (source or binary)**:source\r\n- **MLflow version (run ``mlflow --version``)**:1.11.0\r\n- **Python version**:3.7.6\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:mlflow models serve -m .\/custom-pyfunc-model --port 5000\r\n\r\n### Describe the problem\r\nEnv:\r\nPython 3.7.6\r\nMLFLow 1.11.0\r\nSKLearn 0.22.1\r\nCloudpickle 1.3.0\r\n\r\nI am using databricks to run MLflow.I have created a Pyfunc model that calls sk-learn model to predict. When I download model artifacts and run mlflow serve from local I get the following error:\r\n<details>\r\n  <summary>Error<\/summary>\r\n  \r\n[2021-02-11 12:30:21 +0000] [24] [INFO] Starting gunicorn 20.0.4\r\n[2021-02-11 12:30:21 +0000] [24] [INFO] Listening at: http:\/\/127.0.0.1:8000 (24)\r\n[2021-02-11 12:30:21 +0000] [24] [INFO] Using worker: gevent\r\n[2021-02-11 12:30:21 +0000] [37] [INFO] Booting worker with pid: 37\r\n[2021-02-11 12:30:21 +0000] [38] [INFO] Booting worker with pid: 38\r\n[2021-02-11 12:30:24 +0000] [38] [ERROR] Exception in worker process\r\nTraceback (most recent call last):\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py\", line 583, in spawn_worker\r\n    worker.init_process()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/ggevent.py\", line 162, in init_process\r\n    super().init_process()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py\", line 119, in init_process\r\n    self.load_wsgi()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py\", line 144, in load_wsgi\r\n    self.wsgi = self.app.wsgi()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/base.py\", line 67, in wsgi\r\n    self.callable = self.load()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 49, in load\r\n    return self.load_wsgiapp()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 39, in load_wsgiapp\r\n    return util.import_app(self.app_uri)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/util.py\", line 358, in import_app\r\n    mod = importlib.import_module(module)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/importlib\/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/models\/container\/scoring_server\/wsgi.py\", line 4, in <module>\r\n    app = scoring_server.init(pyfunc.load_pyfunc(\"\/opt\/ml\/model\/\"))\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/utils\/annotations.py\", line 42, in deprecated_func\r\n    return func(*args, **kwargs)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py\", line 548, in load_pyfunc\r\n    return load_model(model_uri, suppress_warnings)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py\", line 522, in load_model\r\n    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/model.py\", line 223, in _load_pyfunc\r\n    python_model = cloudpickle.load(f)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/cloudpickle\/cloudpickle.py\", line 415, in _builtin_type\r\n    return getattr(types, name)\r\nAttributeError: module 'types' has no attribute 'ClassType'\r\n[2021-02-11 12:30:24 +0000] [38] [INFO] Worker exiting (pid: 38)\r\n[2021-02-11 12:30:24 +0000] [37] [ERROR] Exception in worker process\r\nTraceback (most recent call last):\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py\", line 583, in spawn_worker\r\n    worker.init_process()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/ggevent.py\", line 162, in init_process\r\n    super().init_process()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py\", line 119, in init_process\r\n    self.load_wsgi()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py\", line 144, in load_wsgi\r\n    self.wsgi = self.app.wsgi()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/base.py\", line 67, in wsgi\r\n    self.callable = self.load()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 49, in load\r\n    return self.load_wsgiapp()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 39, in load_wsgiapp\r\n    return util.import_app(self.app_uri)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/util.py\", line 358, in import_app\r\n    mod = importlib.import_module(module)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/importlib\/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/models\/container\/scoring_server\/wsgi.py\", line 4, in <module>\r\n    app = scoring_server.init(pyfunc.load_pyfunc(\"\/opt\/ml\/model\/\"))\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/utils\/annotations.py\", line 42, in deprecated_func\r\n    return func(*args, **kwargs)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py\", line 548, in load_pyfunc\r\n    return load_model(model_uri, suppress_warnings)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py\", line 522, in load_model\r\n    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/model.py\", line 223, in _load_pyfunc\r\n    python_model = cloudpickle.load(f)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/cloudpickle\/cloudpickle.py\", line 415, in _builtin_type\r\n    return getattr(types, name)\r\nAttributeError: module 'types' has no attribute 'ClassType'\r\n<\/details>\r\n\r\n### Code to reproduce issue\r\n```\r\nimport os\r\nimport warnings\r\nimport sys\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\nimport cloudpickle\r\nimport sklearn\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.linear_model import ElasticNet\r\nfrom sklearn import datasets\r\n\r\nimport mlflow\r\n\r\n# Load Diabetes datasets\r\ndiabetes = datasets.load_diabetes()\r\nX = diabetes.data\r\ny = diabetes.target\r\n\r\n# Create pandas DataFrame for sklearn ElasticNet linear_model\r\nY = np.array([y]).transpose()\r\nd = np.concatenate((X, Y), axis=1)\r\ncols = ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6', 'progression']\r\ndata = pd.DataFrame(d, columns=cols)\r\n```\r\n```\r\nclass CustomPyFuncModel(mlflow.pyfunc.PythonModel):\r\n    def __init__(self, model, age_mul_factor, pre_process, post_process):\r\n        self.model = model\r\n        self.age_mul_factor=age_mul_factor\r\n        self.pre_process = pre_process\r\n        self.post_process = post_process\r\n\r\n    def predict(self, context, model_input):\r\n        model_input_processed = self.pre_process(model_input,self.age_mul_factor)       \r\n        \r\n        obj = self.model.predict(model_input_processed)\r\n        x = self.post_process(obj)\r\n        return x\r\n```\r\n```\r\ncustom_pyfunc_model_conda_env = {\r\n 'name': 'mlflow-env',\r\n 'channels': ['defaults', 'conda-forge'],\r\n 'dependencies': [\r\n   f'python={python_version}', \r\n   'pip',\r\n   f'scikit-learn={sklearn.__version__}',\r\n   {\r\n     'pip': [\r\n       f'mlflow',\r\n       f'cloudpickle=={cloudpickle.__version__}'\r\n     ]\r\n   }\r\n  ]\r\n}\r\n```\r\n```\r\ndef pre_process(data,age_mul_factor):\r\n  data['age']= data['age'].apply(lambda x: x*age_mul_factor)\r\n  return data\r\n\r\ndef post_process(data):\r\n  return [i\/100 for i in data]\r\n```\r\n```\r\nalpha = 0.05\r\nl1_ratio = 0.05\r\nnp.random.seed(40)\r\n\r\n# Split the data into training and test sets. (0.75, 0.25) split.\r\ntrain, test = train_test_split(data)\r\n\r\n# The predicted column is \"progression\" which is a quantitative measure of disease progression one year after baseline\r\ntrain_x = train.drop([\"progression\"], axis=1)\r\ntest_x = test.drop([\"progression\"], axis=1)\r\ntrain_y = train[[\"progression\"]]\r\ntest_y = test[[\"progression\"]]\r\n  \r\nwith mlflow.start_run() as run:\r\n  lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\r\n  lr.fit(train_x, train_y)\r\n\r\n  mlflow.sklearn.log_model(lr, \"model\")\r\n\r\nwith mlflow.start_run() as run:\r\n  custom_pyfunc_model = CustomPyFuncModel(\r\n    model=lr, \r\n    pre_process=pre_process, \r\n    post_process=post_process,\r\n    age_mul_factor=2\r\n  )\r\n\r\n  mlflow.pyfunc.log_model(\r\n                          artifact_path = \"model\",\r\n                          python_model = custom_pyfunc_model,\r\n                          conda_env = custom_pyfunc_model_conda_env\r\n  )\r\n```\r\nAfter this, I download the model artifacts from the run page and run following command:\r\n```\r\nmlflow models serve -m .\/model --port 5000\r\n```\r\nAnd this gives the above error.\r\nNote that when I serve the model within databricks, it works.\r\n\r\n### Other info \/ logs\r\nTo me this seems like a library version issue, most likely with cloudpickle. I used the exact same libraries that I used to train the model and then served the model locally.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n","389":"Duplicate of https:\/\/github.com\/mlflow\/mlflow\/issues\/2813, since that was ignored (backlogged) by devs. Thanks!","390":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Alpine\r\n- **MLflow installed from (source or binary)**: Binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.13.0\r\n- **Python version**: 3.7\r\n\r\n\r\n### Describe the problem\r\nConcurrent deployment calls cause `[Errno 2] No such file or directory: '\/tmp\/tmpuwt29r5d'` errors. It almost seems to lock the directory while deploying so other threads cannot create files or access the directory for reads. This doesn't happen if a deployment happens synchronously, where at any given time, only one deployment is happening to Azure across the server. However, if i'm deploying 5 Mlflow projects at the same time, where no project has finished deployment, atleast one of the deployments will fail with this error.\r\n\r\n\r\n### Code to reproduce issue\r\n\r\n1. Create a simple model and save\r\n```\r\nclass AddN(mlflow.pyfunc.PythonModel):\r\n    def __init__(self, n):\r\n        self.n = n\r\n\r\n    def predict(self, context, model_input):\r\n        return model_input.apply(lambda column: column + self.n)\r\n\r\nadd5_model = AddN(n=5)\r\nmlflow.pyfunc.save_model(path=path, python_model=add5_model)\r\n\r\n```\r\n2. Three files generated: Mlmodel, Conda.yaml, python_model.pkl\r\nMLmodel\r\n```\r\nflavors:\r\n  python_function:\r\n    cloudpickle_version: 1.6.0\r\n    env: conda.yaml\r\n    loader_module: mlflow.pyfunc.model\r\n    python_model: python_model.pkl\r\n    python_version: 3.7.5\r\nutc_time_created: '2021-01-28 21:04:48.582692'\r\n```\r\n\r\nconda.yaml\r\n```\r\nchannels:\r\n- defaults\r\n- conda-forge\r\ndependencies:\r\n- python=3.7.5\r\n- pip\r\n- pip:\r\n  - mlflow\r\n  - cloudpickle==1.6.0\r\nname: mlflow-env\r\n```\r\n3. 5 Threads concurrently deploying model\r\n```\r\nazure_image, azure_model = mlflow.azureml.build_image(\r\n        model_uri=model_temp_uri,\r\n        workspace=azure_workspace,\r\n        synchronous=True)\r\n\r\nwebservice = Webservice.deploy_from_image(\r\n                    image=azure_image,\r\n                    workspace=azure_workspace,\r\n                    name=service_name,\r\n                    deployment_config=aks_webservice_config,\r\n                    deployment_target=ComputeTarget(\r\n                        azure_workspace,\r\n                        os.environ.get('COMPUTE_TARGET_NAME')\r\n                        )\r\n                    )\r\nwebservice.wait_for_deployment(show_output=True)\r\n```\r\n\r\n4. ~3 Threads will successfully deploy. ~2 might fail with `No such file or directory: '\/tmp\/tmp13cmus54'` error\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nIntegrations\r\n- [x] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","391":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [X] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nIncrease logged parameter size limit. \r\nIn MLFlow the logged params can have a maximum size of 500 bytes. This limit can a blocker when the tracked parameter value is a list of strings (for instance, the list of all of the features to be considered in a model can often surpass 500 bytes). We request this limit to be increased. \r\n \r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nWhen storing parameters in the form of a list (for instance the results of feature selection optimization) the 500 bytes limit can be easily exceeded and then MLFlow fails. \r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\nIncreasing the parameter size limit would allow to log complex objects like lists, which would allow to easily include feature selection into the model tracking.\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nWe are working on a forecasting use-case where we have hundreds of potential external regressors that can serve as proxy for the forecast. We use MLFflow to track all the models that are trained and validated in a gridsearch or hyperopt parameter optimization. In this step, we also include feature selection (we evaluate different combination of external regressors and track the performance when including a particular combination of regressors in the model).\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nWe are thinking on saving the list of regressors as artefacts, but then they cannot be used in the MLFlow server interface to filter results (we use Databricks for that purpose). Saving the results as artefacts is not visually helpful for the users.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [X] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [X] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n","392":"## Willingness to contribute\r\n\r\n- [X] Yes. I can contribute this feature independently.\r\n\r\n## Proposal Summary\r\n\r\nBy default, artifacts are stored to `.\/mlruns` (hard coded constant: DEFAULT_LOCAL_FILE_AND_ARTIFACT_PATH). The idea is to give the possibility to change this behaviour by setting an env var.\r\n\r\nThe same mechanism exists but not generalized:\r\n\r\n```\r\n_TRACKING_DIR_ENV_VAR = \"MLFLOW_TRACKING_DIR\"\r\n\r\ndef _default_root_dir():\r\n    return get_env(_TRACKING_DIR_ENV_VAR) or os.path.abspath(DEFAULT_LOCAL_FILE_AND_ARTIFACT_PATH)\r\n```","393":"## Willingness to contribute\r\nNo. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nCurrently, if we want to use S3 as the artifact store we need to define the access and secret keys in env vars `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` or in the `~\/.aws\/credentials` file and Mlflow will use the default values it finds.\r\n\r\nThat means that for the whole execution of the client program one needs to make sure the specified credentials also work with the other AWS services used within the client program. There should be a way to specify to mlflow a particular AWS profile or set of keys.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nI'd like to separate the different access with a different set of keys in my program\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\nThere should be an option for this since it's what most program with AWS support does\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\n## Details\r\n\r\nWe should have something that accepts env vars such as  \r\n `MLFLOW_AWS_PROFILE` or `MLFLOW_AWS_ACCESS_KEY_ID`\/`MLFLOW_AWS_SECRET_ACCESS_KEY` or a way to specify a set of keys for the tracking server that is specific to MLFlow.\r\n","394":"Hi,\r\n\r\nI'm following the contribution guide of standing up the Development UI to test couple of changes mentioned in #2396 \r\nEverything works well until I start the UI with `--backend_store_uri` giving it MySQL location. It does not log info to the mysql store and gives the following error `\/home\/ubuntu\/mayub\/mlflow\/mlflow\/tracking\/_model_registry\/utils.py:148: UserWarning: Failure attempting to register store for scheme \"file-plugin\": No module named 'mlflow_test_plugin.sqlalchemy_store'\r\n  _model_registry_store_registry.register_entrypoints()`\r\n\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: 1.13.2.dev0\r\n- **Python version**: 3.7.6\r\n- **npm version, if running the dev UI**: \r\n- **Exact command to reproduce**: \r\n\r\n\r\n### Code to reproduce issue\r\nStart the MLFlow Development UI: \r\n`mlflow ui --backend-store-uri 'mysql:\/\/<username>:<paswd>@localhost:3306' --default-artifact-root file:\/home\/ubuntu\/mlruns -h 0.0.0.0`\r\n\r\n### Other info \/ logs:\r\n\r\nAttached is the log file for details:  \r\n[mlflow_filestore_dev_error.txt](https:\/\/github.com\/mlflow\/mlflow\/files\/5941436\/mlflow_filestore_dev_error.txt)\r\n\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [x] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [x] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nThanks !\r\n","395":"\r\n## Willingness to contribute\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [X] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nOn the MLflow UI, add a refresh button above the table. When clicking on this button, the runs are reloaded. \r\n\r\n## Motivation\r\n\r\nThis feature is useful when new runs have been made since we loaded the interface. The current way to display new runs on the interface is to refresh the whole page, but by doing it we loose the display adjustments we made (collapse experiments list, column lengths, filters, etc.).\r\nOne of my usage of MLFlow is to open the interface, then open runs on new tabs to compare them. Then, I perform new runs on my ML code, I come back to the interface, retrieve the new runs (painful step to refresh the whole page each time I come back to the interface) and open the new experiments on new tabs.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nInterfaces\r\n- [X] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\n## Details\r\n\r\nI propose to implement a button like this one (the left one). It seems to require to modify the components `ExperimentView` and `ExperimentPage`. It would be a pleasure to work on it (as my first contribution !) once I have your validation.\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/23191816\/107146079-22f46000-6946-11eb-9b3c-81742fab16f4.png)\r\n\r\n\r\n\r\n\r\n\r\n","396":"## What changes are proposed in this pull request?\r\n\r\nThis PR adds the synchronous flag to the `mlflow run` cli. This resolves #3777.\r\n\r\n## How is this patch tested?\r\n\r\nTest cases are added and a run with local backend was perfomed.\r\n\r\n## Release Notes\r\n\r\nThe `--synchronous` and `--asynchroneous` flags are added to the `mlflow run` cli to allow the user to control how experiments are executed.\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nThe `--synchronous` and `--asyncrhoneous` flags are now available on the `mlflow run` cli command. When not provided the default behaviour remains dependent on the backend chosen as in previous versions.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","397":"## Willingness to contribute\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nCurrently, `mlflow.shap.log_explanation` utilizes `shap.KernelExplainer` to generate the relevant artifacts. This, while being model agnostic comes at a significant computational cost. However, [Shap](https:\/\/github.com\/slundberg\/shap) offers model-specific explainers, which offer non-trivial benefits. I propose designing a mechanism to leverage the specific explainers and using shap.KernelExplainer as a fallback.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nArtifacts produced by `mlflow.shap.log_explanation` would be generated significantly faster for specific model types. Additionally, often, no sampling would be required and the resulting shap values or feature importances would be exact instead of an approximation (under some assumptions).   \r\n- Why is this use case valuable to support for MLflow users in general?\r\nCurrently `mlflow.shap.log_explanation` is rather computationally demanding. This is caused by the fact that `shap.kmeans` is used under the hood to summarize the background data. Apart from being expensive, it brings a host of other issues as described in #3985. In order for `mlflow.shap.log_explanation` to be useful in practice, it needs to be able to scale to large problems, without having to rely on approximation and sampling, unless necessary. \r\n- Why is this use case valuable to support for your project(s) or organization?\r\nEase of logging explanations is invaluable during early modeling stages. This is precisely the time, when quick iteration is required. However, the computational demand of the current implementation makes that difficult or even impossible for mid to large size datasets.  \r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nScaling to large problems is impossible due to the computational demands of the current implementation.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\nThe change I'm proposing would require (among other things) a change in the `shap.log_explanation` signature. More specifically, passing the predict_function of the _to-be-explained model_ would be replaced by passing the model itself. Internally a mapping between model types and explainer types would be used to yield a suitable explainer. This explainer would then produce all the artifacts, which the current implementation provides. \r\n \r\nThe mapping itself would be rather simple (there are not that many explainers available). Essentially:\r\n- Tree based models (RF, GBDT, DT) in the frameworks (XGBoost\/LightGBM\/CatBoost\/scikit-learn\/Pyspark) -> `TreeExplainer`\r\n- Tensorflow\/Keras\/Pytorch  -> `DeepExplainer`\r\n- Linear models of supported frameworks (really anything, which can provide coefficients) -> `LinearExplainer`\r\n\r\nIf a different model type is provided, `shap.log_explanation` would fall back to using the `Kernel Explainer`.  \r\n\r\nA simple benchmarks example: It takes ~1h in order for `shap.log_explanation` to complete on [Collab](https:\/\/colab.research.google.com\/drive\/18OGcOnFoTj01dLRhsGK0eORlBHfwcMYp?usp=sharing) (2 Intel(R) Xeon(R) CPU @ 2.20GHz) on a relatively small dataset (california_housing with dimensions (20640, 8)). This renders the functionality unusable in  any, even slightly more complex, real world application. This is especially true if the user would like to log explanations, let's say during hyperparameter optimization. ","398":"https:\/\/github.com\/mlflow\/mlflow\/blob\/b21549d2bc538d5a6cdfe0e7e0d8a5474ad6533d\/mlflow\/R\/mlflow\/R\/install.R#L52\r\n\r\nDue to our company's security restrictions our databricks workspaces have no access to public repositories.\r\nInstead we use JFrogs Artifactory remote repositories to access \"conda-forge\" channel (see [docs](https:\/\/www.jfrog.com\/confluence\/display\/JFROG\/Conda+Repositories)). \r\n\r\nThe issue from our perspective is that install_mlflow() does not offer the possibility to set a \"forge\" parameter to FALSE but instead uses the reticulate::install_conda() default parameter \"forge\"=TRUE. This leads to the situation that our URL to remote repository is concatenated by \"conda-forge\" and this causes an error. It seems that JFrog's concept of remote repositories and your settings in reticulate::install_conda collide (as you can see on screenshot below).\r\n<img width=\"1375\" alt=\"Screenshot 2021-02-03 at 13 16 22\" src=\"https:\/\/user-images.githubusercontent.com\/23058806\/106908199-614c0e00-66ff-11eb-9376-cdaf6b4eaddb.png\">\r\n\r\n\r\nIf we use a custom approach with reticulate::install_conda(..., forge=FALSE, ...) -it is working fine. \r\n\r\nCould you please provide the option to change default parameter \"forge\" of reticulate::install_conda() when using install_mlflow()?","399":"Signed-off-by: Chris Hughes <31883449+Chris-hughes10@users.noreply.github.com>\r\n\r\n## What changes are proposed in this pull request?\r\nAdded a convenience decorator to the fluent API which can be used in place of `mlflow.start_run` by wrapping the decorated function in an `ActiveRun` object. The decorator can be used with or without arguments, where the signature and defaults are consistent with `mlflow.start_run`.\r\n\r\nThis was discussed in : https:\/\/github.com\/mlflow\/mlflow\/issues\/3950\r\n\r\n## How is this patch tested?\r\nTests have been added to ` tests\/tracking\/fluent\/test_fluent.py` which test the decorator use with and without arguments.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nAdded a convenience decorator to the fluent API which can be used in place of `mlflow.start_run` by wrapping the decorated function in an `ActiveRun` object. The decorator can be used with or without arguments, where the signature and defaults are consistent with `mlflow.start_run`.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","400":"### System information\r\n- **Have I written custom code**: Yes, as shown below.\r\n- **OS Platform and Distribution**: win10 20H2\r\n- **MLflow installed from**: binary\r\n- **MLflow version**: mlflow, version 1.13.1\r\n- **Python version**: 3.8.5\r\n\r\n### Describe the problem\r\nCannot load multiple python_function models with the same script file name in one file, it seems that the second loaded model did not download artifact.\r\n\r\n### Code to reproduce issue\r\nproject tree:\r\n```\r\n$ tree\r\n.\r\n\u251c\u2500\u2500 model1\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_builder.py\r\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 regist_model1.py\r\n\u251c\u2500\u2500 model2\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_builder.py\r\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 regist_model2.py\r\n\u2514\u2500\u2500 model_load.py\r\n\r\n2 directories, 5 files\r\n```\r\nproject files: mlflow_bug.zip\r\n[mlflow_bug.zip](https:\/\/github.com\/mlflow\/mlflow\/files\/5924532\/mlflow_bug.zip)\r\n\r\ncore script:\r\n```python\r\n# model1.model_builder.py:\r\nclass Test1(mlflow.pyfunc.PythonModel):\r\n    def __init__(self):\r\n        super().__init__()\r\n\r\n    def load_context(self, context):\r\n        import numpy as np\r\n\r\n        return\r\n\r\n    def predict(self, context, model_input):\r\n        '''\r\n        Args:\r\n            model_input: ndarray, shape: (-1)\r\n        '''\r\n        res = np.sum(model_input)\r\n\r\n        return res\r\n\r\n\r\n# model2.model_builder.py:\r\nclass Test2(mlflow.pyfunc.PythonModel):\r\n    def __init__(self):\r\n        super().__init__()\r\n\r\n    def load_context(self, context):\r\n        import numpy as np\r\n\r\n        return\r\n\r\n    def predict(self, context, model_input):\r\n        '''\r\n        Args:\r\n            model_input: ndarray, shape: (-1)\r\n        '''\r\n        res = np.mean(model_input)\r\n\r\n        return res\r\n\r\n\r\n# model_load.py\r\nimport mlflow\r\nimport numpy as np\r\nfrom mlflow.pyfunc import load_model\r\n\r\n# config\r\ntracking_server = 'http:\/\/localhost:8088'\r\nmlflow.tracking.set_tracking_uri(tracking_server)\r\n\r\nmodel_1_reg_name = 'pyfunc_model_t1'\r\nmodel_2_reg_name = 'pyfunc_model_t2'\r\nstage = None\r\n\r\n# input\r\nx = np.arange(1, 10)\r\n\r\n# model inference\r\nloadedml_1 = load_model(f\"models:\/{model_1_reg_name}\/{stage}\")\r\nprint(f'loadedml_1.pred: {loadedml_1.predict(x)}')\r\n\r\nloadedml_2 = load_model(f\"models:\/{model_2_reg_name}\/{stage}\")\r\nprint(f'loadedml_2.pred: {loadedml_2.predict(x)}')\r\n```\r\n\r\nissue reproduce:\r\n```powershell\r\ncd xxx\\mlflow_bug\r\n# register model1\r\ncd .\\model1\\\r\npython .\\regist_model1.py\r\n# register model2\r\ncd ..\\model2\\\r\npython .\\regist_model2.py\r\ncd ..\r\n\r\n# load two python_function\r\npython .\\model_load.py\r\n```\r\n\r\n### Other info \/ logs\r\n```\r\nloadedml_1.pred: 45\r\nTraceback (most recent call last):\r\n  File \"E:\\mlflow_bug\\model_load.py\", line 20, in <module>\r\n    loadedml_2 = load_model(f\"models:\/{model_2_reg_name}\/{stage}\")\r\n  File \"D:\\Miniconda3\\lib\\site-packages\\mlflow\\pyfunc\\__init__.py\", line 522, in load_model\r\n    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\r\n  File \"D:\\Miniconda3\\lib\\site-packages\\mlflow\\pyfunc\\model.py\", line 223, in _load_pyfunc\r\n    python_model = cloudpickle.load(f)\r\nAttributeError: Can't get attribute 'Test2' on <module 'model_builder' from 'C:\\\\Users\\\\potoo\\\\AppData\\\\Local\\\\Temp\\\\tmps9pobp26\\\\code\\\\model_builder.py'>\r\n```\r\n","401":"Signed-off-by: cjwchonjac <cjwchonjac@naver.com>\r\n\r\n## What changes are proposed in this pull request?\r\n- Receive 'order_by', 'max_results', 'page_token' parameter in the search_model_versions API\r\n\r\n(Please fill in changes proposed in this fix)\r\n\r\n## How is this patch tested?\r\n\r\n- Added some new unit tests. please refer to changes in `tests` dir.\r\n- Ran the server and sent REST requests and checked the result.\r\n\r\n(Details)\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [x] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","402":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n   Organize my experiments in mlflow server\r\n- Why is this use case valuable to support for MLflow users in general?\r\n   Rapid access to experiments when we are working on different projects.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n   we have a big scroll and is difficult to focus on a project.\r\n- Why is it currently difficult to achieve this use case? \r\n  In the left panel I have accumulated many experiments (a long long list), I would like to be able to create folders to group them by projects or something similar.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n\r\n\r\n","403":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 11.1\r\n- **MLflow installed from (source or binary)**: \r\n- **MLflow version (run ``mlflow --version``)**: 1.13.1\r\n- **Python version**: 3.8.5\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: \r\n\r\n### Describe the problem\r\nPandas supports `ExtensionDtypes` for extending types from numpy. These types allow additional functionality (like `NA` support for bools or ints). However, calling `infer_signature` on a dataframe with these types fails because the columns are not of type `numpy.ndarray`.\r\n\r\n### Code to reproduce issue\r\n```\r\nimport pandas as pd\r\nfrom mlflow.models import infer_signature\r\n\r\ndf = pd.DataFrame(\r\n    {\r\n        \"ints\": [1, 2, 3],\r\n        \"bools\": [True, False, True],\r\n        \"strings\": [\"a\", \"b\", \"c\"]\r\n    }\r\n)\r\n\r\n# doing any of the following will cause infer_signature to fail\r\ndf[\"ints\"] = df[\"ints\"].astype(\"Int64\")\r\ninfer_signature(df)\r\n\r\ndf[\"bools\"] = df[\"bools\"].astype(\"boolean\")\r\ninfer_signature(df)\r\n\r\ndf[\"strings\"] = df[\"strings\"].astype(\"string\")\r\ninfer_signature(df)\r\n```\r\n\r\n### Other info \/ logs\r\n```\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-122-64641ea9310a> in <module>\r\n      1 df[\"strings\"] = df[\"strings\"].astype(\"string\")\r\n----> 2 infer_signature(df)\r\n\r\n~\/opt\/anaconda3\/envs\/fts\/lib\/python3.8\/site-packages\/mlflow\/models\/signature.py in infer_signature(model_input, model_output)\r\n    121     :return: ModelSignature\r\n    122     \"\"\"\r\n--> 123     inputs = _infer_schema(model_input)\r\n    124     outputs = _infer_schema(model_output) if model_output is not None else None\r\n    125     return ModelSignature(inputs, outputs)\r\n\r\n~\/opt\/anaconda3\/envs\/fts\/lib\/python3.8\/site-packages\/mlflow\/types\/utils.py in _infer_schema(data)\r\n     62     elif isinstance(data, pd.DataFrame):\r\n     63         schema = Schema(\r\n---> 64             [ColSpec(type=_infer_numpy_array(data[col].values), name=col) for col in data.columns]\r\n     65         )\r\n     66     elif isinstance(data, np.ndarray):\r\n\r\n~\/opt\/anaconda3\/envs\/fts\/lib\/python3.8\/site-packages\/mlflow\/types\/utils.py in <listcomp>(.0)\r\n     62     elif isinstance(data, pd.DataFrame):\r\n     63         schema = Schema(\r\n---> 64             [ColSpec(type=_infer_numpy_array(data[col].values), name=col) for col in data.columns]\r\n     65         )\r\n     66     elif isinstance(data, np.ndarray):\r\n\r\n~\/opt\/anaconda3\/envs\/fts\/lib\/python3.8\/site-packages\/mlflow\/types\/utils.py in _infer_numpy_array(col)\r\n    138 def _infer_numpy_array(col: np.ndarray) -> DataType:\r\n    139     if not isinstance(col, np.ndarray):\r\n--> 140         raise TypeError(\"Expected numpy.ndarray, got '{}'.\".format(type(col)))\r\n    141     if len(col.shape) > 1:\r\n    142         raise MlflowException(\"Expected 1d array, got array with shape {}\".format(col.shape))\r\n\r\nTypeError: Expected numpy.ndarray, got '<class 'pandas.core.arrays.string_.StringArray'>'\r\n```\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","404":"Description\r\n  \r\n  ### Willingness to contribute\r\n  The MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n  \r\n  - [ ] Yes. I can contribute a fix for this bug independently.\r\n  - [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n  - [ ] No. I cannot contribute a bug fix at this time.\r\n  \r\n  ### System information\r\n  - **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: `No`\r\n  - **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: `Yes`\r\n  - **MLflow installed from (source or binary)**: `binary`\r\n  - **MLflow version (run ``mlflow --version``)**: `1.13.1`\r\n  - **Python version**:  `3.7.6`\r\n  - **npm version, if running the dev UI**:\r\n  - **Exact command to reproduce**: `python examples\/tensorflow\/tf1\/train_predict.py`\r\n  \r\n  ### Description:\r\n\r\nRunning the example does not capture parameters and also evaluation metrics. It also shows some Info on export signatures like \r\n`INFO:tensorflow:'serving_default' : Regression input must be a single string Tensor; got {'features': <tf.Tensor 'features:0' shape=(?, 13) dtype=float32>}`  \r\nIs this fine to ignore? (Attaching log file for reference)\r\n\r\n\r\nLog File:  [train_predict_tf1_run_log.txt](https:\/\/github.com\/mlflow\/mlflow\/files\/5916072\/train_predict_tf1_run_log.txt)\r\n\r\nSnapshots: \r\n![image](https:\/\/user-images.githubusercontent.com\/7122670\/106697803-892b5c80-65ad-11eb-8d4d-f5fd59d01909.png)\r\n\r\n    \r\n  ### What component(s), interfaces, languages, and integrations does this bug affect?\r\n  Components \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [x] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nLet me know if I'm missing something. \r\nThanks !\r\n\r\n","405":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [X] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Pop!_OS 20.10\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.13.1\r\n- **Python version**: 3.8.5\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: echo \"from mlflow.tracking.client import MlflowClient\" > test_ml.py && pytest test_ml.py \r\n\r\n### Describe the problem\r\nWhen I use MLflow with numpy 1.20.0 (released a few days ago), I get the following types of warnings:\r\n\r\n```bash\r\n=============================== warnings summary ===============================\r\n..\/..\/..\/..\/..\/..\/..\/miniconda3\/envs\/rs-cloud\/lib\/python3.8\/site-packages\/mlflow\/types\/schema.py:47\r\n  \/home\/aloosley\/miniconda3\/envs\/rs-cloud\/lib\/python3.8\/site-packages\/mlflow\/types\/schema.py:47: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \r\n  Deprecated in NumPy 1.20; for more details and guidance: https:\/\/numpy.org\/devdocs\/release\/1.20.0-notes.html#deprecations\r\n    binary = (7, np.dtype(\"bytes\"), \"BinaryType\", np.object)\r\n\r\n-- Docs: https:\/\/docs.pytest.org\/en\/stable\/warnings.html\r\n```\r\n\r\nThis is because numpy has deprecated the usage of `np.object` (and `np.int`, `np.float`, etc.).\r\n\r\n### Code to reproduce issue\r\nAdd \r\n```python\r\nfrom mlflow.tracking.client import MlflowClient\r\n```\r\nto any test_xxx.py file and run pytest.  Then the Deprecation warning appears.\r\n\r\n### Other info \/ logs\r\nI have created a simple fix PR [here](https:\/\/github.com\/mlflow\/mlflow\/pull\/4045), but I am unable to get precommit hooks to work and do the file reformatting to get everything running.\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","406":"## What changes are proposed in this pull request?\r\n\r\nStarting in numpy 1.20.0, `np.int` and `np.object` have been deprecated.  As these are just aliases for `int` and `object`, respectively, I've changed them in mlflow accordingly.\r\n\r\nSee [here](https:\/\/numpy.org\/doc\/stable\/release\/1.20.0-notes.html#deprecations) for more details about these numpy dtype deprecations.\r\n\r\nSee [issue](https:\/\/github.com\/mlflow\/mlflow\/issues\/4048) for more details.\r\n\r\n## How is this patch tested?\r\n\r\nThere is nothing failing yet, just a DeprecationWarning thrown without this patch.  Should I check that a warning is explicitly not shown?\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [X] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [X] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","407":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nWhen serving a model using the \"mlflow models serve -m \"models:\/<MODEL_NAME>\/Production\"\" syntax to automatically fetch the production version of the given model, it would be great to have the model server automatically reload when a newer version of the model is set to the production stage. The same applies to Staging.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nUsing the above mentioned syntax is comfortable when you want to always use the latest production version of a model. But if you have to manually restart the model server after updating the model, most of this comfort is lost. \r\n- Why is this use case valuable to support for MLflow users in general?\r\nBecause everybody who is using the model server with this syntax will have the same issue.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nBecause we want to use the model server in production.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nBecause the model server is retrieving a local copy of the model on start, but is not watching the database or asking the model registry for updates.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nFor my purposes, periodic polling of the model registry to check for staging changes would be fine. If the effort for this is too high, the possibility to reload models via REST calls would be fine, too.\r\n","408":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.13.1\r\n- **Python version**: 3.8.5 (but same error on 3.6.5)\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\nfollows in the reproducible test case\r\n\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\nWhen querying MlFlow installed via Rest API the json returns string values for the attributes that according to documentation should be integers. Consider, for instance, the array of registered models `https:\/\/www.mlflow.org\/docs\/latest\/rest-api.html#mlflowregisteredmodel` which is returned when calling `https:\/\/www.mlflow.org\/docs\/latest\/rest-api.html#list-registeredmodels`.  The fields `creation_timestamp` and `last_updated_timestamp` are set to strings as shown below:\r\n\r\n```\r\ncurl http:\/\/localhost:5000\/api\/2.0\/mlflow\/registered-models\/list\r\n{\r\n  \"registered_models\": [\r\n    {\r\n      \"name\": \"test-model-1\",\r\n      \"creation_timestamp\": \"1612177566287\",\r\n      \"last_updated_timestamp\": \"1612177566757\",\r\n      \"latest_versions\": [\r\n        {\r\n          \"name\": \"test-model-1\",\r\n          \"version\": \"3\",\r\n          \"creation_timestamp\": \"1612177566757\",\r\n          \"last_updated_timestamp\": \"1612177566757\",\r\n          \"current_stage\": \"None\",\r\n          \"description\": \"\",\r\n          \"source\": \".\/mlruns\/1\/2ced310fbdfe479cb4539a7073a57519\/artifacts\/test-model-1\",\r\n          \"run_id\": \"2ced310fbdfe479cb4539a7073a57519\",\r\n          \"status\": \"READY\",\r\n          \"run_link\": \"\"\r\n        }\r\n      ]\r\n    },\r\n    {\r\n      \"name\": \"test-model-2\",\r\n      \"creation_timestamp\": \"1612177567205\",\r\n      \"last_updated_timestamp\": \"1612177567780\",\r\n      \"latest_versions\": [\r\n        {\r\n          \"name\": \"test-model-2\",\r\n          \"version\": \"3\",\r\n          \"creation_timestamp\": \"1612177567780\",\r\n          \"last_updated_timestamp\": \"1612177567780\",\r\n          \"current_stage\": \"None\",\r\n          \"description\": \"\",\r\n          \"source\": \".\/mlruns\/1\/3b4c0ece064040918d55a82d1a52a458\/artifacts\/test-model-2\",\r\n          \"run_id\": \"3b4c0ece064040918d55a82d1a52a458\",\r\n          \"status\": \"READY\",\r\n          \"run_link\": \"\"\r\n        }\r\n      ]\r\n    }\r\n  ]\r\n}\r\n```\r\nThis is, however, not the case, when quering the MlFlow on Azure Databricks cloud, which returns a compliant json:\r\n\r\n```\r\n{\r\n  \"registered_models\": [\r\n    {\r\n      \"name\": \"light-gbm\",\r\n      \"creation_timestamp\": 1610975275922,\r\n      \"last_updated_timestamp\": 1610975276654,\r\n      ...\r\n      }\r\n   ...\r\n   ]\r\n}\r\n```\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\n===mlflow_server===\r\nmlflow server --backend-store-uri sqlite:\/\/\/mlflow.db --default-artifact-root=.\/mlruns --host 0.0.0.0\r\n\r\n===register_model.py===\r\nimport warnings\r\n\r\nimport numpy as np\r\nimport mlflow.sklearn\r\nimport os\r\nfrom sklearn import datasets, svm\r\nfrom mlflow.tracking import MlflowClient\r\nfrom requests.exceptions import ConnectionError\r\n\r\n\r\n# Create dummy models\/runs on the local mlflow server for unit tests\r\nif __name__ == \"__main__\":\r\n    # if running inside docker, then use appropriate host name as set in docker-compose.yml\r\n    mlflow.set_tracking_uri(\"http:\/\/{}:5000\".format(os.environ.get('mlflow_server_host', 'localhost')))\r\n    while True:\r\n        try:\r\n            client = MlflowClient()\r\n            experiments = client.list_experiments()\r\n            break\r\n        except ConnectionError as e:\r\n            print(\"pinging mlflow...\")\r\n\r\n    mlflow.set_experiment(\"test-experiment\")\r\n\r\n    warnings.filterwarnings(\"ignore\")\r\n    np.random.seed(40)\r\n    iris = datasets.load_iris()\r\n    digits = datasets.load_digits()\r\n    clf = svm.SVC(gamma=0.001, C=100.)\r\n    for model_name in [\"test-model-1\", \"test-model-2\"]:\r\n        for _ in range(3):\r\n            with mlflow.start_run():\r\n                clf.fit(digits.data[:-1], digits.target[:-1])\r\n                mlflow.sklearn.log_model(clf, model_name, registered_model_name=model_name)\r\n```\r\n\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [x] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","409":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Amazon Linux 2\r\n- **MLflow installed from (source or binary)**: binary (using pip)\r\n- **MLflow version (run ``mlflow --version``)**: 1.13.1\r\n- **Python version**: 3.8\r\n- **npm version, if running the dev UI**: NA\r\n- **Exact command to reproduce**: mlflow models build-docker -m path_to_mode -n imag_name_to_be created\r\n\r\n### Describe the problem\r\n\r\nI am not able to create the docker image for the model.\r\nI think the problem is the ubuntu repository is being referred for installing and since it is amazon linux apt-get is failing. \r\n\r\n### Code to reproduce issue\r\n\r\nfrom command line:\r\nmlflow models build-docker -m path_to_mode -n imag_name_to_be created\r\n\r\n### Other info \/ logs\r\n\r\nMLFlow]$ mlflow models build-docker -m \"s3_path\" -n \"model_image_name\"\r\n2021\/01\/29 12:53:37 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\r\n2021\/01\/29 12:53:45 INFO mlflow.models.docker_utils: Building docker image with name iris_model_image\r\n\/tmp\/tmplg3tgz0s\/\r\n\/tmp\/tmplg3tgz0s\/model_dir\r\n\/tmp\/tmplg3tgz0s\/model_dir\/model\r\n\/tmp\/tmplg3tgz0s\/model_dir\/model\/MLmodel\r\n\/tmp\/tmplg3tgz0s\/model_dir\/model\/conda.yaml\r\n\/tmp\/tmplg3tgz0s\/model_dir\/model\/model.pkl\r\n\/tmp\/tmplg3tgz0s\/Dockerfile\r\nSending build context to Docker daemon  66.56kB\r\n\r\nStep 1\/17 : FROM ubuntu:18.04\r\n18.04: Pulling from library\/ubuntu\r\nd519e2592276: Already exists\r\nd22d2dfcfa9c: Already exists\r\nb3afe92c540b: Already exists\r\nDigest: sha256:ea188fdc5be9b25ca048f1e882b33f1bc763fb976a8a4fea446b38ed0efcbeba\r\nStatus: Downloaded newer image for ubuntu:18.04\r\n ---> c090eaba6b94\r\nStep 2\/17 : RUN apt-get -y update && apt-get install -y --no-install-recommends          wget          curl          nginx          ca-certificates          bzip2          build-essential          cmake          openjdk-8-jdk          git-core          maven     && rm -rf \/var\/lib\/apt\/lists\/*\r\n ---> Running in b35b1fb03971\r\nErr:1 http:\/\/security.ubuntu.com\/ubuntu bionic-security InRelease\r\n  Temporary failure resolving 'security.ubuntu.com'\r\nErr:2 http:\/\/archive.ubuntu.com\/ubuntu bionic InRelease\r\n  Temporary failure resolving 'archive.ubuntu.com'\r\nErr:3 http:\/\/archive.ubuntu.com\/ubuntu bionic-updates InRelease\r\n  Temporary failure resolving 'archive.ubuntu.com'\r\nErr:4 http:\/\/archive.ubuntu.com\/ubuntu bionic-backports InRelease\r\n  Temporary failure resolving 'archive.ubuntu.com'\r\nReading package lists...\r\nW: Failed to fetch http:\/\/archive.ubuntu.com\/ubuntu\/dists\/bionic\/InRelease  Temporary failure resolving 'archive.ubuntu.com'\r\nW: Failed to fetch http:\/\/archive.ubuntu.com\/ubuntu\/dists\/bionic-updates\/InRelease  Temporary failure resolving 'archive.ubuntu.com'\r\nW: Failed to fetch http:\/\/archive.ubuntu.com\/ubuntu\/dists\/bionic-backports\/InRelease  Temporary failure resolving 'archive.ubuntu.com'\r\nW: Failed to fetch http:\/\/security.ubuntu.com\/ubuntu\/dists\/bionic-security\/InRelease  Temporary failure resolving 'security.ubuntu.com'\r\nW: Some index files failed to download. They have been ignored, or old ones used instead.\r\nReading package lists...\r\nBuilding dependency tree...\r\nReading state information...\r\nPackage ca-certificates is not available, but is referred to by another package.\r\nThis may mean that the package is missing, has been obsoleted, or\r\nis only available from another source\r\n\r\nE: Unable to locate package wget\r\nE: Unable to locate package curl\r\nE: Unable to locate package nginx\r\nE: Package 'ca-certificates' has no installation candidate\r\nE: Unable to locate package build-essential\r\nE: Unable to locate package cmake\r\nE: Unable to locate package openjdk-8-jdk\r\nE: Unable to locate package git-core\r\nE: Unable to locate package maven\r\nThe command '\/bin\/sh -c apt-get -y update && apt-get install -y --no-install-recommends          wget          curl          nginx          ca-certificates          bzip2          build-essential          cmake          openjdk-8-jdk          git-core          maven     && rm -rf \/var\/lib\/apt\/lists\/*' returned a non-zero code: 100\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n\r\nInterface \r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n\r\nLanguage \r\n- [x] `language\/Python`: Python APIs and clients\r\n\r\n\r\nIntegrations\r\n- [x] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n","410":"Hello, first time user here.\r\nI am failing to use the mlflow ui because it is just awfully slow for even very low numbers of runs:\r\n`[CRITICAL] WORKER TIMEOUT`\r\n\r\n\r\nWhat I tried:\r\n1) Changed file store to shared file system for parallel training runs (using `mlflow.set_tracking_uri()`), but recognized that mlflow by default is awfully slow this way.\r\nSimply running `mlflow.search_runs()` for 120 runs and 9 metrics takes 30s.\r\n2) Tried to change to sqlite URI on shared filesystem, but this causes artifacts to land in the local folder again (why??).\r\n3) Try to find `mlflow.set_artifact_uri()` but cannot find one.\r\n\r\n**TL;DR:**\r\nHow do I make mlflow work with a shared filesystem?\r\nHow can I store the artifacts in the same folder as the `mlflow.db` file from sqlite?","411":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Red Hat Enterprise Linux Server release 7.4\r\n- **MLflow installed from (source or binary)**: pip install\r\n- **MLflow version (run ``mlflow --version``)**: 1.13.1\r\n- **Python version**: 3.8.5\r\n- **npm version, if running the dev UI**: 6.7.0\r\n- **Exact command to reproduce**: \r\n```\r\ntrainer = pl.Trainer(gpus=1, max_epochs=1)\r\n\r\nmlflow.pytorch.autolog()\r\n\r\nwith mlflow.start_run() as run:\r\n    trainer.fit(color_model, dataloaders['train'], dataloaders['val'])\r\n```\r\n\r\n### Describe the problem\r\nThe autologging does not save the trained model.\r\n\r\n### Code to reproduce issue\r\n`mlflow.pytorch.autolog()`\r\n\r\nthe thrown exception:\r\n`WARNING mlflow.utils.autologging_utils: Encountered unexpected error during autologging: cannot pickle '_thread.lock' object`\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","412":"### Willingness to contribute\r\n\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04\r\n- **MLflow installed from (source or binary)**: binary \r\n- **MLflow version (run ``mlflow --version``)**: 1.13\r\n- **Python version**: 3.7.5\r\n\r\n### Describe the problem\r\nI'm trying to log test parameters into a mlflow server that doesn't have an ssl cert. installed yet.\r\nHence, throws the following error:\r\n`raise SSLError(e, request=request)\r\nrequests.exceptions.SSLError: HTTPSConnectionPool(host='mlflow-hal.019c9d70145a4b27afea.westeurope.aksapp.io', port=443): Max retries exceeded with url: \/api\/2.0\/mlflow\/runs\/create (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1076)')))`\r\n\r\n### Code to reproduce issue\r\n`\r\nimport mlflow\r\n \r\n mlflow.start_run()\r\n mlflow.log_param(\"my\", \"param\")\r\n mlflow.log_metric(\"score\", 100)\r\n mlflow.end_run()\r\n`\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n\r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\n### Summary\r\nHow do I enable logging with ssl verification set to false ? Similar to what you do for REST - ex `verify=False`.  I am aware this is not a secure solution that should be used always. I require this option just to test a few thing temporarily. ","413":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [+] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: NO\r\n- **MLflow installed from (source or binary)**: pip\r\n- **MLflow version (run ``mlflow --version``)**: 1.11.0\r\n- **Python version**: 3.5\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: \r\n\r\n### Describe the problem\r\nI have model sklearn stored in my registry.\r\nwhen trying to load a model using python, I get an error:\r\nOSError: No such file or directory: '\/ ml \/ ml \/ mlflow \/ artifactstore \/ 0 \/ 79fe7d4d20ec4b1f9cbc9555d839e4e6 \/ artifacts \/ ModelName \/.'\r\nIndeed, there is no such path in the OS, and the model itself in the OS is on a different path:\r\n\/ ml \/ ml \/ mlflow \/ artifactstore \/ 0 \/ <other hash> \/ artifacts \/ ModelName \/. '\r\n\r\nI store an onnx type model in the register and do not observe such problems.\r\n\r\n### Code to reproduce issue\r\n```\r\nimport mlflow\r\nimport mlflow.sklearn\r\nimport sklearn\r\nimport mlflow.pyfunc\r\nfrom mlflow.tracking import MlflowClient\r\n\r\nmlflow.set_tracking_uri(\"http:\/\/localhost:5000\")\r\nmodel_name = \"MoDelName\"\r\nstage = 'Production'\r\nlocation_path=\"\/ml\/ml1_rgs\/exp_model\"\r\n\r\npath = \"models:\/\" + model_name + \"\/\" + stage\r\n\r\nsklearn_model = mlflow.sklearn.load_model(path)\r\n\r\nmlflow.sklearn.save_model(sklearn_model, location_path)\r\n```\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [+] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [+] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","414":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nAllow for streaming an artifact or redirecting the browser downloading an artifact through the mlflow tracking ui using a pre-signed url to the resource.\r\n\r\n## Motivation\r\n\r\nCurrently, when downloading artifacts through the get-artifact api route on the MLFlow Tracking server, the artifact is first downloaded to the tracking server and stored as a temporary file. Then, it is sent as an attachment for download to the web browser.\r\n\r\nDue to this temporary storage, if the tracking server is run as a web server, the web server will eventually run out of disk space. \r\n\r\nIt is hard to go around this issue without patching mlflow, as there doesn't seem to be a way to configure mlflow to use pre-signed urls or to stream files from s3 to the user (without storing a temporary copy on the tracking server).\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nI was inspired by [this TODO](https:\/\/github.com\/mlflow\/mlflow\/blob\/v1.13.1\/mlflow\/store\/artifact\/artifact_repo.py#L81) in the code base to try to implement a pre-signed url solution. download_artifacts could return a dictionary of pre-signed urls for all items in a folder if a folder is requested for a download, or a single pre-signed url to the single resource being requested for download.\r\n\r\nHowever, changing download_artifacts in this way seems to break previewing artifacts on the tracking server. I am guessing this is due to the fact previewing an artifact in the UI normally downloads the file(s) using download_artifacts.","415":"Is MLflow aware of the usage of resource, like GPU or memory?  Suppose the current resource is not enough for coming experiment run, what would happen for those runs? Would they fail or wait in a FIFO queue for resource available?","416":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 16.04.7 LTS\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**: 1.10.0\r\n- **Python version**: 3.6\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI use HDFS as a storage for MLflow artifacts. When the size of an artifact is greater than to 2gb, the **mlflow.pyfunc.log_model** throws an exception _\"HDFS Write failed\"_  (full stacktrace see in the section below). \r\nExpected behavior: the artifact is uploaded to HDFS.\r\n\r\nThe issue itself comes from pyarrow library, see https:\/\/issues.apache.org\/jira\/browse\/ARROW-11391 .\r\nAnswer from pyarrow community:\r\n```\r\nIt appears that writes over 2GB are implemented incorrectly.\r\nhttps:\/\/github.com\/apache\/arrow\/blob\/master\/cpp\/src\/arrow\/io\/hdfs.cc#L277\r\n\r\nthe tSize type in libhdfs is an int32_t. So that static cast is truncating data\r\n\r\nI would recommend breaking the work into smaller pieces as a workaround\r\n```\r\n\r\n### Code to reproduce issue\r\nHow to create a file with specific size:\r\n```\r\ntruncate -s 3G 3g.txt\r\n```\r\nCode to reproduce issue on MLflow side:\r\n```\r\nimport os\r\nimport sys\r\n\r\nimport mlflow\r\nfrom mlflow.pyfunc import PythonModel\r\n\r\nhost = \"<hadoop_master_namenode>\"\r\nport = \"8020\"\r\nmflow_artifact_location = \"\/<artifact_location_on_hdfs>\"\r\n\r\nhdfs_artifact_root = \"hdfs:\/\/{host}:{port}{path}\".format(\r\n    host=host,\r\n    port=port,\r\n    path=mflow_artifact_location\r\n)\r\n\r\nos.environ[\"JAVA_HOME\"] = \"\/opt\/adoptopenjdk\/jdk-8-default\/\"\r\nos.environ[\"ARTIFACT_ROOT_ENV_VAR\"] = hdfs_artifact_root\r\nos.environ[\"MLFLOW_KERBEROS_USER\"] = '<username>'\r\nos.environ['MLFLOW_TRACKING_URI'] = \"http:\/\/<host>:5000\/\"\r\nos.environ['ARROW_LIBHDFS_DIR'] = \"\/<path_to_libhdfs>\"\r\n\r\ndef get_and_create_experiment(experiment_name, artifact_location):\r\n    exp = mlflow.get_experiment_by_name(experiment_name)\r\n    if exp is None:\r\n         mlflow.create_experiment(name=experiment_name, artifact_location=artifact_location)\r\n         exp = mlflow.get_experiment_by_name(experiment_name)\r\n    return exp\r\n\r\nclass CustomModel(PythonModel):\r\n\r\n    def load_context(self, context):\r\n        print(\"=== load_context ===\")\r\n\r\n    def predict(self, context, model_input):\r\n        print(\"=== predict ===\")\r\n        return None\r\n    \r\nartifacts = {\r\n    \"data\": \"3g.txt\"\r\n}\r\n\r\nexperiment_name = \"custom_model_001\"\r\nexperiment = get_and_create_experiment(experiment_name, hdfs_artifact_root)\r\nwith mlflow.start_run(experiment_id=experiment.experiment_id):\r\n    result = mlflow.pyfunc.log_model(\r\n        artifact_path=\"custom_model\",\r\n        python_model=CustomModel(),\r\n        artifacts=artifacts)\r\n```\r\nCode to reproduce the issue on pyarrow side:\r\n```\r\nimport os\r\nimport pyarrow as pa\r\n\r\nos.environ[\"JAVA_HOME\"] = \"\/opt\/adoptopenjdk\/jdk-8-default\/\"\r\nos.environ['ARROW_LIBHDFS_DIR'] = \"\/<path_to_libhdfs>\"\r\n\r\nconnected = pa.hdfs.connect(host=\"<host>\",port=8020)\r\n\r\ndestination = \"hdfs:\/\/<host>:8020\/user\/tmp\/3g.txt\"\r\nsource = \"3g.txt\"\r\n\r\nwith connected.open(destination, \"wb\") as output_stream:\r\n    output_stream.write(open(source, \"rb\").read())\r\n\r\nconnected.close()\r\n```\r\n### Other info \/ logs\r\n```\r\nsite-packages\/mlflow\/store\/artifact\/hdfs_artifact_repo.py in log_artifacts(self, local_dir, artifact_path)\r\n     66                     destination = posixpath.join(hdfs_subdir_path, each_file)\r\n     67                     with hdfs.open(destination, 'wb') as output_stream:\r\n---> 68                         output_stream.write(open(source, \"rb\").read())\r\n     69 \r\n     70     def list_artifacts(self, path=None):\r\n\r\nsite-packages\/pyarrow\/io.pxi in pyarrow.lib.NativeFile.write()\r\nsite-packages\/pyarrow\/error.pxi in pyarrow.lib.check_status()\r\n\r\nOSError: HDFS Write failed, errno: 22 (Invalid argument)\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [x] `language\/python`\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","417":"Is it possible to enter docker run arguments (e.g. [Runtime constraints](https:\/\/docs.docker.com\/engine\/reference\/run\/#runtime-constraints-on-resources)) when specifying the `docker_env`?\r\n\r\nFor example, if I want to have a memory or CPU constraint.","418":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [x] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**:\r\n- **Python version**:\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\nUnable to see the list of the model versions in a model UI which has a lot model versions(>=10000)\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n- Register a model\r\n- Upload more than 10000 model verison to the model\r\n- See the list of model versions of the model in mlflow UI\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [x] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [x] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","419":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [X] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nAddition of 'SHAP' model flavor, Ability to log\/load SHAP explainers.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n    **ANS:** Enable users of SHAP to log and load explainers.\r\n- Why is this use case valuable to support for MLflow users in general?\r\n    **ANS:** Currently only explanations can be logged, allowing users to log the explainer itself can allow them to track and deploy them.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n   **ANS:** No support for logging a explainer object as is.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [X] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nLink to PR: https:\/\/github.com\/mlflow\/mlflow\/pull\/3989\r\n\r\n# Relevant Background \r\n\r\n## Current Support \r\n\r\nCurrently MLFlow supports log_explanation which saves the output of the explainer as an artifact (NumPy array). This is useful if the user wants to store the actual explanation once the explainer has run locally but does not allow for tracking of the explainer and deployment of the explainer. \r\n\r\n \r\n\r\n## Brief overview of SHAP ( https:\/\/github.com\/slundberg\/shap )  \r\n\r\nSHAP is a model-agnostic explainer of ML Models. \r\n\r\nContents of SHAP explainer: \r\n\r\n1) Underlying Model: This is the model SHAP is trying to explain. \r\n2) Masker: A function (explicit or inferred from data) that SHAP explainer uses to perturb and mask inputs. \r\n3) Other Parameters \r\n\r\nFunctionally a SHAP explainer takes in a particular sample that needs to be explained and outputs an explanation of the prediction. \r\n\r\n1) model input ---> underlying_model ---> prediction (NumPy array) \r\n2) model input ---> explainer ---> explanation of prediction (NumPy array) \r\n\r\n\r\nHence once the explainer is constructed it can be thought of as a python function that takes in input like the underlying model (same dimension as input) and output explanation (with a larger dimension than model output). \r\n\r\n \r\n## Recent Changes to SHAP \r\n\r\nIn Fall-2020 we added support for explainer serialization for few of the explainer types within SHAP (Some of this work is under review). This allows users to call explainer.save(out_file) and shap.explainer.load(in_file) to save and load the explainer to disk, respectively. \r\n\r\nAs a part of the serialization process SHAP tries to serialize the underlying model, currently it does cloudpickle.dump() on the model object. Since This might not always work for all model types, SHAP allows users to override the serialization used for models. \r\n\r\nPRs:\r\nhttps:\/\/github.com\/slundberg\/shap\/pull\/1660\r\nhttps:\/\/github.com\/slundberg\/shap\/pull\/1681\r\nhttps:\/\/github.com\/slundberg\/shap\/pull\/1748\r\n\r\n# Proposed Changes to MLFlow \r\n\r\n## \u2018SHAP\u2019 model flavor \r\n\r\nSince a SHAP explainer can be thought of as a python function (As mentioned above) we can think of it as a ML Model that takes in standard inputs and outputs explanations as \u2018predictions\u2019. Hence, we add an official \u2018SHAP\u2019 model flavor.  \r\n\r\nWith support for: \r\n\r\n1) log_explainer (similar to log_model) - logs explainer in current run \r\n2) load_explainer (similar to load_model) - loads explainer given URI\r\n3) save_model - saves explainer to disk in the MLFlow format (with MLModel file, conda.yaml ) \r\n4) _load_pyfunc \u2013 to make SHAP explainer model compliant with MLFlow standard \r\n\r\n \r\n## mlflow.shap.save_model() process \r\n\r\n\r\n![save_model](https:\/\/user-images.githubusercontent.com\/68928670\/105544176-a6684d00-5cc8-11eb-8592-d274ecbe6f06.png)\r\n","420":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 11.1\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**: 1.13.1\r\n- **Python version**: 3.8\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI've defined a basic Keras model and used the custom pyfunc flavor to create a model class and save this model to local file. I've tried several configurations but all lead to a \"TypeError: cannot pickle 'weakref' object\".\r\n\r\n### Code to reproduce issue\r\n```\r\n        model = keras.Sequential()\r\n        model.add(Bidirectional(LSTM(128, input_shape=[10,100])))\r\n        model.add(Dropout(rate=0.5))\r\n        model.add(Dense(6, activation='softmax'))\r\n        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\r\n        history = model.fit(x_train, y_train, epochs=64, validation_split=0.2, shuffle=True)\r\n\r\n        class NewModel(mlflow.pyfunc.PythonModel):\r\n            def __init__(self, model):\r\n                self.model = model\r\n            def predict(self, context, x_input):\r\n                return self.model.predict(x_input)\r\n        \r\n        mlflow.pyfunc.save_model(\r\n            path = '.\/_model\/test_model',\r\n            python_model = NewModel(model)\r\n        )\r\n```\r\n\r\n### Other info \/ logs\r\nTraceback (most recent call last):\r\n  File \"\/Users\/roderickmacintosh\/gDrive\/MAIN\/model_training\/src\/venv\/lib\/python3.8\/site-packages\/mlflow\/pyfunc\/model.py\", line 138, in _save_model_with_class_artifacts_params\r\n    cloudpickle.dump(python_model, out)\r\n  File \"\/Users\/roderickmacintosh\/gDrive\/MAIN\/model_training\/src\/venv\/lib\/python3.8\/site-packages\/cloudpickle\/cloudpickle_fast.py\", line 55, in dump\r\n    CloudPickler(\r\n  File \"\/Users\/roderickmacintosh\/gDrive\/MAIN\/model_training\/src\/venv\/lib\/python3.8\/site-packages\/cloudpickle\/cloudpickle_fast.py\", line 563, in dump\r\n    return Pickler.dump(self, obj)\r\nTypeError: cannot pickle 'weakref' object\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","421":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ x ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 20.04\r\n- **MLflow installed from (source or binary)**: Binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.13.1\r\n- **Python version**: 3.7.7\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n```\r\nsample = {\r\n    'Type': 'Cat',\r\n    'Age': 3\r\n}\r\n\r\ninput_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\r\nmodel = mlflow.pyfunc.load_model(...)\r\npredictions = model.predict(input_dict)\r\n```\r\n\r\nIn MLFlow this will throw error:\r\n```\r\nmlflow.exceptions.MlflowException: Expected input to be DataFrame or list. Found: dict\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\nMLFlow only allows the use of dataframe or lists for prediction, but not a dict - which is the recommended way to predict of Tensorflow modles with feature columns. (see https:\/\/www.tensorflow.org\/tutorials\/structured_data\/preprocessing_layers#inference_on_new_data)\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nBuild a Tensorflow v2 model with feature columns and then try to use it for prediction via MLFlow, see https:\/\/www.tensorflow.org\/tutorials\/structured_data\/preprocessing_layers#inference_on_new_data\r\n\r\n```\r\nsample = {\r\n    'Type': 'Cat',\r\n    'Age': 3\r\n}\r\n\r\ninput_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\r\nmodel = mlflow.pyfunc.load_model(...)\r\npredictions = model.predict(input_dict)\r\n```\r\n\r\nIn MLFlow this will throw error:\r\n```\r\nmlflow.exceptions.MlflowException: Expected input to be DataFrame or list. Found: dict\r\n```\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ x ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","422":"I am using MLflow (v 1.13.1) on AWS. I set up a tracking server on a Spark EMR master node then access EMR from SageMaker notebook instance by using Livy. Since I am developing models in Scala Spark, so I am using MLflow Java API to track my experiments. \r\n\r\nOne issue I have is that I need to update the location of model after I found I saved and logged a wrong model. However, I could not find a way in the API doc how to get an existing run and update the value of an existing parameter. Is this supported by MLflow?\r\n\r\nCurrently I could only create a nested run, and create the same parameter in the nested run with updated value.","423":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Using a custom pyfunc based model.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **MLflow installed from (source or binary)**: conda\r\n- **MLflow version (run ``mlflow --version``)**: 1.12.1\r\n- **Python version**: 3.8\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: `mlflow model serve ...`\r\n\r\n### Describe the problem\r\nThe schema validation of the model serving seems not to work well with boolean columns. Strings and null values are accepted and converted to something.\r\n\r\n### Code to reproduce issue\r\nInput schema with `ColSpec(\"boolean\", \"boolColumn\")` and pass a string (i.e. \"NotABoolean\") to the API after serving the model.\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging","424":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this documentation issue template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages documentation fix contributions. Would you or another member of your organization be willing to contribute a fix for this documentation issue to the MLflow code base?\r\n\r\n- [x] Yes. I can contribute a documentation fix independently (https:\/\/github.com\/mlflow\/mlflow\/pull\/2268.).\r\n- [ ] Yes. I would be willing to contribute a document fix with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a documentation fix at this time.\r\n\r\n### URL(s) with the issue:\r\n\r\nThe MLproject feature works for R, but this is not documented.\r\n\r\nhttps:\/\/mlflow.org\/docs\/latest\/projects.html\r\n\r\n### Description of proposal (what needs changing):\r\n\r\nSince MLproject is a major feature of MLflow, I think the docs should definitively cover this. Maybe we also want to add a test or two, as this feature is currently not well tested. Note that because of https:\/\/github.com\/mlflow\/mlflow\/issues\/3983, it worked only before 1.11.0 and now again after 1.13.1.\r\n\r\nAddressed in https:\/\/github.com\/mlflow\/mlflow\/pull\/2268 more than a year ago with no feedback from a contributor, positive feedback from other committer.\r\n","425":"Signed-off-by: Viswesh Periyasamy <viswesh.periyasamy@databricks.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nThis PR adds a parameter to `mlflow.shap.log_explanation` which allows the user to configure the sampling strategy for the background data provided to `shap.KernelExplainer`.\r\n\r\nPreviously, the strategy was to explicitly use `shap.kmeans` - however, this causes an error when the data has non-numeric columns. Typically, these columns are pre-processed to be numeric, however if the user is using a scikit-learn `Pipeline` as their model, the input matrix will still be non-numeric. In these cases, we can make the `log_explanation` function more robust by randomly sampling the input matrix for background data to provide to `KernelExplainer`. This is supported by `shap` in many documented examples, such as https:\/\/github.com\/slundberg\/shap#deep-learning-example-with-deepexplainer-tensorflowkeras-models.\r\n\r\nLastly, I've changed the default behavior to be random instead of kmeans, because that should work for all datasets.\r\n\r\n## How is this patch tested?\r\n\r\nUpdated shap unit tests for `classifier` and `regressor` to test both `random` and `kmeans`\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nAdd configuration option for sampling strategy used in `mlflow.shap.log_explanation`.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","426":"## What changes are proposed in this pull request?\r\n\r\nFixes #3973  assuming the code is ran as root.\r\n\r\n## How is this patch tested?\r\nTODO\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","427":"### Willingness to contribute\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X\r\n- **MLflow installed from (source or binary)**: pip\r\n- **MLflow version (run ``mlflow --version``)**: 1.12.1\r\n- **Python version**: 3.8\r\n- **npm version, if running the dev UI**: N\/A\r\n- **Exact command to reproduce**: `mlflow run .`\r\n\r\n### Describe the problem\r\nMLFLow is mounting AWS credentials into an incorrect directory inside the container, which causes `botocore.exceptions.NoCredentialsError: Unable to locate credentials` exception.\r\n\r\nThis is the command MLFlow runs:\r\n```docker run --rm -v \/Users\/<user>\/.aws:\/.aws [...]```\r\n\r\nThe credentials are mounted into `\/.aws`, but they must be mounted inside the running users' home directory, e.g. `\/root\/.aws`, if running as root.\r\n\r\n[This is the code](https:\/\/github.com\/levkk\/mlflow\/blob\/281f61cabb99867b9641cb6e999e0e13ba006ce2\/mlflow\/projects\/backend\/local.py#L282) that hardcodes that path, incorrectly.\r\n\r\nAWS documents this [here](https:\/\/boto3.amazonaws.com\/v1\/documentation\/api\/latest\/guide\/credentials.html#configuring-credentials).\r\n\r\n### Code to reproduce issue\r\nRun pretty much any example with code that's using any AWS service in any way, e.g. `s3 = boto3.client('s3')` and then try listing a bucket.\r\n\r\nThis is a patch that one can include in their code to overcome this:\r\n\r\n```python\r\nimport shutil\r\nimport os\r\n\r\nAWS_CREDS_PATH = os.path.expanduser(\"~\/.aws\")\r\n\r\nif not os.path.exists(AWS_CREDS_PATH):\r\n    if os.path.exists(\"\/.aws\"):\r\n        shutil.copytree(\"\/.aws\", AWS_CREDS_PATH)\r\n```\r\n\r\n### Other info \/ logs\r\nN\/A\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","428":"## What changes are proposed in this pull request?\r\nFix for #3969, workaround for #2016 \r\nParsing `.dockerignore` and ignoring mentioned patterns when creating temporary build context. This is an optimization to avoid copying ignored files when creating the temporary build context directory & a workaround for `docker-py` ignoring `.dockerignore`.\r\n\r\n## How is this patch tested?\r\nTODO\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nImplements `.dockerignore` pattern matching to accelerate runs and avoid copying ignored files and directories.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [x] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [x] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","429":"### Willingness to contribute\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X\r\n- **MLflow installed from (source or binary)**: pip\r\n- **MLflow version (run ``mlflow --version``)**: 1.12.1\r\n- **Python version**: 3.8\r\n- **npm version, if running the dev UI**: N\/A\r\n- **Exact command to reproduce**: `mlflow run .`\r\n\r\n### Describe the problem\r\nMLFlow `run` command copies the entire work directory without taking `.dockerignore` and `.gitignore` into account.\r\n\r\nThis opens it up to copying heavy directories like `venv` (virtualenv), secrets, environment variables (.e.g stored in `.env`), etc.\r\n\r\nWhy the Docker env ignores `.dockerignore` is an existing issue #2016.\r\n\r\nThis can be mitigated by adding an `ignore=func` parameter to `shutil.copytree` [used here](https:\/\/github.com\/mlflow\/mlflow\/blob\/fcf8b90b7c094e6939136fef8a96f3ee1b34d29a\/mlflow\/projects\/docker.py#L109). This would need to implement either `.dockerignore` or .`gitignore` patterns, or implement its own `.mlflowignore` file. This would also make MLFlow run faster because it won't need to copy heavy files around (twice with the `.dockerignore` bug).\r\n\r\n### Code to reproduce issue\r\nUse any of the example projects. Add any file into the folder and add it to `.dockerignore`. Build the image and note the file being present in the image.\r\n\r\n### Other info \/ logs\r\nN\/A\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [x] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [x] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","430":"## What changes are proposed in this pull request?\r\n\r\nMLflow will record the current branch used in the run. This is useful for people using MLflow locally.\r\n\r\n## How is this patch tested?\r\n\r\nNo test added. Can I have a mentor to add the tests needed?\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [X] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [X] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","431":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nCurrently, ``xgboost.dask`` training does not work with ``mlflow.xgboost.autolog``. In ``lightgbm==3.2.0`` a similar ``lightgbm.dask`` module will be introduced.\r\n\r\nAs a user, I would expect the autologging to work for XGBoost and LightGBM training in the distributed submodules.\r\n\r\n## Motivation\r\n- What is the use case for this feature? **autologging\/full compatibility with distributed training tracking**\r\n- Why is this use case valuable to support for MLflow users in general? **logging with distributed training**\r\n- Why is this use case valuable to support for your project(s) or organization? **adding distributed XGBoost and LightGBM tutorials to Azure Machine Learning examples https:\/\/github.com\/Azure\/azureml-examples\/pull\/324 and https:\/\/github.com\/Azure\/azureml-examples\/pull\/326**\r\n- Why is it currently difficult to achieve this use case? **i do not know**\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nI think more discussion by people familiar with mlflow is needed on how to handle this and similar cases. \r\n\r\nCC: @akshaya-a","432":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nThe scoring server (started with mlflow serve) does not offer authentication. In most use-cases people want to protect their model endpoints.\r\nSince the scoring server is implemented with flask, the flask-httpauth package could provide this functionality with very little overhead (https:\/\/flask-httpauth.readthedocs.io\/en\/latest\/).\r\n\r\n## Motivation\r\nEveryone who wants to protect an endpoint is in the need to put something like a reverse-proxy in front of the server.\r\nAn optional basic-auth could improve this.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\nImplementation should be straight forward.\r\nOptional activation of this feature could be handle via a cli option or an environment variable that is set.","433":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 18.04\r\n- **MLflow installed from (source or binary)**:Binary\r\n- **MLflow version (run ``mlflow --version``)**:1.13.1\r\n- **Python version**:3.7\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: mlflow run\r\n\r\n### Describe the problem\r\nThe entry point of the project is executed via `mlfow run`  using the Docker container environment. On each instance of the execution, mlflow is using the base image provided in MLproject file to create new docker image, and this process is taking significant amount of time.\r\n\r\nOne possible reason for the problem is the size of directory where `mlproject run` is executed (https:\/\/github.com\/mlflow\/mlflow\/issues\/2016). Even if the #2016 bug is fixed, the project has the data dependency and other artifacts which can grow immensely in size and consequently cause lot more time in building the docker container environment.\r\n\r\nHere is the size of docker container image and base image:\r\n\r\n<img width=\"620\" alt=\"docker images\" src=\"https:\/\/user-images.githubusercontent.com\/689777\/104094780-01597780-52b9-11eb-8fa6-d95c5312824c.png\">\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n","434":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [x] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 20.04\r\n- **MLflow installed from (source or binary)**: pip install mlflow\r\n- **MLflow version (run ``mlflow --version``)**: 1.13.1\r\n- **Python version**: 3.8.2\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: get_status() of KubernetesSubmittedRun object\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\nProblem:\r\nThe function `get_status()` of a `KubernetesSubmittedRun` object fails to connect to a Kubernetes cluster whose URI host name is not \"localhost\". (See \"Code to reproduce the issue\" below.)\r\n\r\nReason:\r\nFrom `mlflow\/projects\/kubernetes.py`:\r\nThe default `kube_api` argument in the `_update_status` function does not have the correct Kubernetes configuration. The reason for this is that, in Python, default arguments are evaluated once when the function is defined, not each time the function is invoked. At the time of function definition, the MLflow code has yet not loaded the Kubernetes configuration.\r\n\r\nSolution:\r\nMove the creation of the default value for `kube_api` to inside the function, so that it is created when the function is executed,\r\nat which time we are guaranteed to have the Kubernetes configuration loaded. The Kubernetes configuration is loaded when submitting an MLflow run in the `run_kubernetes_job` function. This `run_kubernetes_job` function is where the `KubernetesSubmittedRun` object is created.\r\nChange\r\n```\r\ndef _update_status(self, kube_api=kubernetes.client.BatchV1Api()):\r\n```\r\nto\r\n```\r\ndef _update_status(self, kube_api=None):\r\n    if not kube_api:\r\n        kube_api = kubernetes.client.BatchV1Api()\r\n```\r\n\r\n### Code to reproduce issueng _load_kube_context(context_kube_context)\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nCreate a Kubernetes cluster with a URI host name that is different from the Kubernetes default \"localhost\".\r\n```\r\nmlflow_submitted_run = mlflow.projects.run(<your parameters here>)\r\nmlflow_submitted_run.get_status()  # this line of code fails\r\n```\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\n  File \"\/home\/jcasse\/Beyond\/Bitbucket\/gi-infill\/mlflow-grpc-server\/run.py\", line 404, in submit_mlflow_run\r\n    status_code = mlflow_submitted_run.get_status()\r\n  File \"\/home\/jcasse\/.virtualenvs\/mlflow-grpc-server\/lib\/python3.8\/site-packages\/mlflow\/projects\/kubernetes.py\", line 166, in get_status\r\n    return status if RunStatus.is_terminated(status) else self._update_status()\r\n  File \"\/home\/jcasse\/.virtualenvs\/mlflow-grpc-server\/lib\/python3.8\/site-packages\/mlflow\/projects\/kubernetes.py\", line 141, in _update_status\r\n    api_response = kube_api.read_namespaced_job_status(\r\n  File \"\/home\/jcasse\/.virtualenvs\/mlflow-grpc-server\/lib\/python3.8\/site-packages\/kubernetes\/client\/api\/batch_v1_api.py\", line 1395, in read_namespaced_job_status\r\n    return self.read_namespaced_job_status_with_http_info(name, namespace, **kwargs)  # noqa: E501\r\n  File \"\/home\/jcasse\/.virtualenvs\/mlflow-grpc-server\/lib\/python3.8\/site-packages\/kubernetes\/client\/api\/batch_v1_api.py\", line 1482, in read_namespaced_job_status_with_http_info\r\n    return self.api_client.call_api(\r\n  File \"\/home\/jcasse\/.virtualenvs\/mlflow-grpc-server\/lib\/python3.8\/site-packages\/kubernetes\/client\/api_client.py\", line 350, in call_api\r\n    return self.__call_api(resource_path, method,\r\n  File \"\/home\/jcasse\/.virtualenvs\/mlflow-grpc-server\/lib\/python3.8\/site-packages\/kubernetes\/client\/api_client.py\", line 182, in __call_api\r\n    response_data = self.request(\r\n  File \"\/home\/jcasse\/.virtualenvs\/mlflow-grpc-server\/lib\/python3.8\/site-packages\/kubernetes\/client\/api_client.py\", line 375, in request\r\n    return self.rest_client.GET(url,\r\n  File \"\/home\/jcasse\/.virtualenvs\/mlflow-grpc-server\/lib\/python3.8\/site-packages\/kubernetes\/client\/rest.py\", line 239, in GET\r\n    return self.request(\"GET\", url,\r\n  File \"\/home\/jcasse\/.virtualenvs\/mlflow-grpc-server\/lib\/python3.8\/site-packages\/kubernetes\/client\/rest.py\", line 212, in request\r\n    r = self.pool_manager.request(method, url,\r\n  File \"\/home\/jcasse\/.virtualenvs\/mlflow-grpc-server\/lib\/python3.8\/site-packages\/urllib3\/request.py\", line 74, in request\r\n    return self.request_encode_url(\r\n  File \"\/home\/jcasse\/.virtualenvs\/mlflow-grpc-server\/lib\/python3.8\/site-packages\/urllib3\/request.py\", line 96, in request_encode_url\r\n    return self.urlopen(method, url, **extra_kw)\r\n  File \"\/home\/jcasse\/.virtualenvs\/mlflow-grpc-server\/lib\/python3.8\/site-packages\/urllib3\/poolmanager.py\", line 375, in urlopen\r\n    response = conn.urlopen(method, u.request_uri, **kw)\r\n  File \"\/home\/jcasse\/.virtualenvs\/mlflow-grpc-server\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 783, in urlopen\r\n    return self.urlopen(\r\n  File \"\/home\/jcasse\/.virtualenvs\/mlflow-grpc-server\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 783, in urlopen\r\n    return self.urlopen(\r\n  File \"\/home\/jcasse\/.virtualenvs\/mlflow-grpc-server\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 783, in urlopen\r\n    return self.urlopen(\r\n  File \"\/home\/jcasse\/.virtualenvs\/mlflow-grpc-server\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 755, in urlopen\r\n    retries = retries.increment(\r\n  File \"\/home\/jcasse\/.virtualenvs\/mlflow-grpc-server\/lib\/python3.8\/site-packages\/urllib3\/util\/retry.py\", line 573, in increment\r\n    raise MaxRetryError(_pool, url, error or ResponseError(cause))\r\nurllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: \/apis\/batch\/v1\/namespaces\/default\/jobs\/infill-ds-2021-01-08-12-06-15-842830\/status?pretty=True (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f40b1d5fd90>: Failed to establish a new connection: [Errno 111] Connection refused'))\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n- [x] Python\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n- [x] Kubernetes\r\n","435":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nExtend Kubernetes project backend to support Kubernetes [Custom Resource Definitions](https:\/\/kubernetes.io\/docs\/tasks\/extend-kubernetes\/custom-resources\/custom-resource-definitions\/) (aka \"CRDs\") in addition to the existing [Kubernetes Jobs](https:\/\/kubernetes.io\/docs\/concepts\/workloads\/controllers\/job\/).\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n  Kubernetes CRDs allow additional flexibility in ML training network architectures, such as for those that require closely-communicating parallel processes.\r\n- Why is this use case valuable to support for MLflow users in general?\r\n  Many Kubernetes users already rely on CRDs to train ML models, and may find it difficult to migrate their workflows to MLflow. Existing MLflow users may want additional functionality that Jobs alone cannot provide.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n  Same as above.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n  Many use-cases are not covered by Kubernetes Jobs. CRDs are more flexible - can create Jobs, StatefulSets, ConfigMaps, RBAC resources, and other objects - with custom controller logic to reconcile the states of these objects.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nChanges required to implement this feature (mostly in [mlflow\/projects\/kubernetes.py](https:\/\/github.com\/mlflow\/mlflow\/blob\/v1.13.1\/mlflow\/projects\/kubernetes.py)):\r\n\r\n1. `_run_kubernetes_job()` checks the \"kind\" field of the job template, retaining backwards-compatibility if the object's \"kind\" field is \"Job\". Otherwise, a CRD is assumed, i.e. `api_instance = kubernetes.client.CustomObjectsApi()` rather than `kubernetes.client.BatchV1Api()`, `api_instance.create_namespaced_custom_object()` rather than `api_instance.create_namespaced_job()`, etc...\r\n\r\n1. `_get_kubernetes_job_definition()`: renders the job YAML as a template with access to MLProject information, similar to how MLProject [entry_point commands are rendered](https:\/\/github.com\/mlflow\/mlflow\/blob\/v1.13.1\/mlflow\/projects\/_project_spec.py#L190).\r\n\r\n1. `KubernetesSubmittedRun`: constructor (`__init__`) accepts the rendered job template, parses out additional variables (kind, apiVersion, namespace, etc). The `wait`, `_update_status`, and `cancel` methods are updated similarly to `_run_kubernetes_job()` (step 1 above).\r\n\r\n1. Documentation and testing updates to reflect the template rendering changes and CRD support.\r\n\r\nOpen to feedback\/suggestions here or on the Slack channel.","436":"## What changes are proposed in this pull request?\r\n\r\nJava client does not support calls to [list registered model API](https:\/\/www.mlflow.org\/docs\/latest\/rest-api.html#list-registeredmodels).\r\n\r\n## How is this patch tested?\r\n\r\ntested with setting up [MLFlow Kafka source connector](https:\/\/github.com\/dwarszawski\/kafka-connect-mlflow) to track the changes in the MLFlow Model Registry.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [x] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","437":"Here is my mlproject file:\r\n\r\n```\r\nname: project\r\nentry_points:\r\n\r\n  load:\r\n    command: \"do some stuff\"\r\n\r\n  train:\r\n    command: \"python -m torch.distributed.launch --nproc_per_node=GPU_NUMBER train.py\"\r\n\r\n  main:\r\n    command: \"do some stuff\"\r\n```\r\n\r\nI have a config file when I have specified the number of GPUS, and I dont want to specify it in mlproject file.\r\nIs there a possibility that mlproject file can read it from config.py file somehow ?\r\n\r\nconfig.py:\r\n```\r\nGPU_NUMBER: 8\r\n```\r\n\r\nI can only use command:\r\n```\r\nmlflow run project\r\n```","438":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nI think it would be great if mlflow supports http artifact repository.\r\n\r\n```bash\r\n$ mlflow server --default-artifact-root http:\/\/some-http-artifact-storage  \r\n[2021-01-08 12:07:32 +0900] [86305] [INFO] Starting gunicorn 20.0.4\r\n[2021-01-08 12:07:32 +0900] [86305] [INFO] Listening at: http:\/\/127.0.0.1:5000 (86305)\r\n\r\n...\r\n\r\n$ MLFLOW_TRACKING_URI=http:\/\/localhost:5000 python train.py\r\n(it works!)\r\n```\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n   MLflow Server as a sharable ML experiment dashboard\r\n- Why is this use case valuable to support for MLflow users in general?\r\n   This is for those who want to share ML experiment results in their team using Web Browser.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n   If this feature is available, it's possible to deploy MLflow Tracking Server as a standalone tracking dashboard and remote user can submit artifact remotely via http interface in CLI or their code.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n   Only storage-like artifact repository is supported yet. this make hard to deploy MLflow Tracking Server as a standalone deployment\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n\r\nActually, I make HttpArtifactRepository as a MLflow plugin private for just my private usages but it works like proxy of Google Storage yet. I know Http-based Artifact Repository requires another storage issues but I think it can be start with supporting local file storage like `filestore` and extending as a proxy to file transfer protocol or cloud storage.","439":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MLflow is running on Linux Ubuntu Server 18.04; my client PC is Windows 10 which connects to the remote server\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: mlflow (1.13.1)\r\n- **Python version**: Python 3.6.9\r\n- **npm version, if running the dev UI**: ---\r\n- **Exact command to reproduce**: \r\nI have stared the server as follows, either \"mlflow server --backend-store-uri \/media\/ailabshare1\/mlflow_test --default-artifact-root \/media\/ailabshare1\/mlflow_test --host 0.0.0.0\" or \"mlflow server --backend-store-uri sqlite:\/\/\/mlflow.db --default-artifact-root \/media\/ailabshare1\/mlflow_test --host 0.0.0.0\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\nCase 1:\r\nI start the server with `mlflow server --backend-store-uri \/media\/ailabshare1\/mlflow_test --default-artifact-root \/media\/ailabshare1\/mlflow_test --host 0.0.0.0` and upload\/log a model with `mlflow.pytorch.log_model(pytorch_model=model, registered_model_name=\"pytorch-model\", artifact_path=new_path)`\r\n\r\nThis prints the status message, that the model is registered:\r\n```\r\nRegistered model 'pytorch-model' already exists. Creating a new version of this model...\r\n2021\/01\/07 15:07:31 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: pytorch-model, version 6\r\nCreated version '6' of model 'pytorch-model'.\r\n```\r\n\r\nImage Case 1 Experiments and Models: https:\/\/imgur.com\/a\/0oN8SUE\r\n\r\nCase 2\r\nAs the error on the UI in the tab models advises me to use for example sqlite I am starting the server in the second case as follows:\r\n`mlflow server --backend-store-uri sqlite:\/\/\/mlflow.db --default-artifact-root \/media\/ailabshare1\/mlflow_test --host 0.0.0.0`\r\nAgain I am logging a model with `mlflow.pytorch.log_model(pytorch_model=model, registered_model_name=\"pytorch-model\", artifact_path=new_path)`.\r\nIt appears in the artifacts but not in the UI of Registered Models although the code\r\n```\r\n# print current models in registry\r\n    from pprint import pprint\r\n    client = MlflowClient()\r\n    for rm in client.list_registered_models():\r\n        pprint(dict(rm), indent=4)\r\n```\r\nan output of registered models shows:\r\n```\r\n{   'creation_timestamp': 1610017108891,\r\n    'description': None,\r\n    'last_updated_timestamp': 1610017108891,\r\n    'latest_versions': [],\r\n    'name': 'alexnet_membranfeder',\r\n    'tags': {}}\r\n{   'creation_timestamp': 1610017809482,\r\n    'description': None,\r\n    'last_updated_timestamp': 1610030717165,\r\n```\r\n\r\nImage Case 2 Experiments and Models: https:\/\/imgur.com\/a\/HTrdGiZ\r\n\r\nWhat am I doing wrong, that the models are not showing up in the UI?\r\nBest regards\r\n\r\n### Code to reproduce issue\r\nStart server as follow:\r\n\"mlflow server --backend-store-uri \/media\/ailabshare1\/mlflow_test --default-artifact-root \/media\/ailabshare1\/mlflow_test --host 0.0.0.0\"\r\nor\r\n\"mlflow server --backend-store-uri sqlite:\/\/\/mlflow.db --default-artifact-root \/media\/ailabshare1\/mlflow_test --host 0.0.0.0\"\r\n\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nLog for case 1:\r\n ```\r\nin _list_run_infos\r\n    run_info = self._get_run_info_from_dir(r_dir)\r\n  File \"\/home\/ailab\/virtualenv-mlflow\/lib\/python3.6\/site-packages\/mlflow\/store\/tracking\/file_store.py\", line 529, in _get_run_info_from_dir\r\n    meta = read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\r\n  File \"\/home\/ailab\/virtualenv-mlflow\/lib\/python3.6\/site-packages\/mlflow\/utils\/file_utils.py\", line 170, in read_yaml\r\n    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\r\nmlflow.exceptions.MissingConfigException: Yaml file '\/media\/ailabshare1\/mlflow_test\/0\/505b4e8272df4259ba21509f913223b7\/meta.yaml' does not exist.\r\nWARNING:root:Malformed run '5a312e035a664143bd440fcdd7eefe29'. Detailed error Yaml file '\/media\/ailabshare1\/mlflow_test\/0\/5a312e035a664143bd440fcdd7eefe29\/meta.yaml' does not exist.\r\nTraceback (most recent call last):\r\n  File \"\/home\/ailab\/virtualenv-mlflow\/lib\/python3.6\/site-packages\/mlflow\/store\/tracking\/file_store.py\", line 699, in _list_run_infos\r\n    run_info = self._get_run_info_from_dir(r_dir)\r\n  File \"\/home\/ailab\/virtualenv-mlflow\/lib\/python3.6\/site-packages\/mlflow\/store\/tracking\/file_store.py\", line 529, in _get_run_info_from_dir\r\n    meta = read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\r\n  File \"\/home\/ailab\/virtualenv-mlflow\/lib\/python3.6\/site-packages\/mlflow\/utils\/file_utils.py\", line 170, in read_yaml\r\n    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\r\nmlflow.exceptions.MissingConfigException: Yaml file '\/media\/ailabshare1\/mlflow_test\/0\/5a312e035a664143bd440fcdd7eefe29\/meta.yaml' does not exist.\r\nWARNING:root:Malformed run 'e1575667004a4fac9c65a736955d9a6a'. Detailed error Yaml file '\/media\/ailabshare1\/mlflow_test\/0\/e1575667004a4fac9c65a736955d9a6a\/meta.yaml' does not exist.\r\nTraceback (most recent call last):\r\n  File \"\/home\/ailab\/virtualenv-mlflow\/lib\/python3.6\/site-packages\/mlflow\/store\/tracking\/file_store.py\", line 699, in _list_run_infos\r\n    run_info = self._get_run_info_from_dir(r_dir)\r\n  File \"\/home\/ailab\/virtualenv-mlflow\/lib\/python3.6\/site-packages\/mlflow\/store\/tracking\/file_store.py\", line 529, in _get_run_info_from_dir\r\n    meta = read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\r\n  File \"\/home\/ailab\/virtualenv-mlflow\/lib\/python3.6\/site-packages\/mlflow\/utils\/file_utils.py\", line 170, in read_yaml\r\n    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\r\nmlflow.exceptions.MissingConfigException: Yaml file '\/media\/ailabshare1\/mlflow_test\/0\/e1575667004a4fac9c65a736955d9a6a\/meta.yaml' does not exist.\r\nWARNING:root:Malformed run '509627168073427aaa51a3de0c3c5e31'. Detailed error Yaml file '\/media\/ailabshare1\/mlflow_test\/0\/509627168073427aaa51a3de0c3c5e31\/meta.yaml' does not exist.\r\nTraceback (most recent call last):\r\n  File \"\/home\/ailab\/virtualenv-mlflow\/lib\/python3.6\/site-packages\/mlflow\/store\/tracking\/file_store.py\", line 699, in _list_run_infos\r\n    run_info = self._get_run_info_from_dir(r_dir)\r\n  File \"\/home\/ailab\/virtualenv-mlflow\/lib\/python3.6\/site-packages\/mlflow\/store\/tracking\/file_store.py\", line 529, in _get_run_info_from_dir\r\n    meta = read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\r\n  File \"\/home\/ailab\/virtualenv-mlflow\/lib\/python3.6\/site-packages\/mlflow\/utils\/file_utils.py\", line 170, in read_yaml\r\n    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\r\nmlflow.exceptions.MissingConfigException: Yaml file '\/media\/ailabshare1\/mlflow_test\/0\/509627168073427aaa51a3de0c3c5e31\/meta.yaml' does not exist.\r\nWARNING:root:Malformed run '6b080de05105476b99c02a0dae896e40'. Detailed error Yaml file '\/media\/ailabshare1\/mlflow_test\/0\/6b080de05105476b99c02a0dae896e40\/meta.yaml' does not exist.\r\nTraceback (most recent call last):\r\n  File \"\/home\/ailab\/virtualenv-mlflow\/lib\/python3.6\/site-packages\/mlflow\/store\/tracking\/file_store.py\", line 699, in _list_run_infos\r\n    run_info = self._get_run_info_from_dir(r_dir)\r\n  File \"\/home\/ailab\/virtualenv-mlflow\/lib\/python3.6\/site-packages\/mlflow\/store\/tracking\/file_store.py\", line 529, in _get_run_info_from_dir\r\n    meta = read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\r\n  File \"\/home\/ailab\/virtualenv-mlflow\/lib\/python3.6\/site-packages\/mlflow\/utils\/file_utils.py\", line 170, in read_yaml\r\n    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\r\nmlflow.exceptions.MissingConfigException: Yaml file '\/media\/ailabshare1\/mlflow_test\/0\/6b080de05105476b99c02a0dae896e40\/meta.yaml' does not exist.\r\n```\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","440":"When I send a ModelSignature while registering a model, if I check it in mlflow UI then i'm getting \"Something went wrong If this error persists, please report an issue here\" in Model section. Please someone can help me.","441":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [X] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.15.7 \r\n- **MLflow installed from (source or binary)**: Binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.13.1\r\n- **Python version**: 3.8.3\r\n- **npm version, if running the dev UI**: N\/A\r\n- **Exact command to reproduce**:  mlflow models serve -m runs:\/cf028fedbe554a1b82f8a634dba26abb\/model\r\n\r\n### Describe the problem\r\nAfter successfully running example sklearn_logistic_regression, I attempted to serve one of the runs using the command specified in your Quickstart section: mlflow models serve -m runs:\/<RUN_ID>\/model from the sklearn_logistic_regression folder. See above for the actual command. When I attempt to serve the model, which I have done several times with different runs, I am sent to your GitHub page where \"Something Went Wrong\" is displayed, with instructions to create an issue.\r\n\r\n### Code to reproduce issue\r\nFollow instructions from Quickstart\/Saving and Serving Models\r\n\r\n### Other info \/ logs\r\n```\r\nimport numpy as np\r\nfrom sklearn.linear_model import LogisticRegression\r\n\r\nimport mlflow\r\nimport mlflow.sklearn\r\n\r\nif __name__ == \"__main__\":\r\n    X = np.array([-2, -1, 0, 1, 2, 1]).reshape(-1, 1)\r\n    y = np.array([0, 0, 1, 1, 1, 0])\r\n    lr = LogisticRegression()\r\n    lr.fit(X, y)\r\n    score = lr.score(X, y)\r\n    print(\"Score: %s\" % score)\r\n    mlflow.log_metric(\"score\", score)\r\n    mlflow.sklearn.log_model(lr, \"model\")\r\n    print(\"Model saved in run %s\" % mlflow.active_run().info.run_uuid)\r\n\r\n```\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [X ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [X] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","442":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nWith the current tracking API, some boilerplate code is required to create an experiment and start a run. Specifically, it is quite common to see code blocks such as:\r\n```\r\nmlflow.set_tracking_uri(MLFLOW_TRACKING_SERVICE_URI)\r\nexperiment_id = mlflow.set_experiment(EXPERIMENT_NAME)\r\nwith mlflow.start_run(experiment_id=experiment_id):\r\n    ...\r\n``` \r\nat the start of a training script.\r\n\r\nIn an effort to remove this when using mlflow for personal projects, I implemented a decorator that can be added to a training function, which can set some of these parameters using decorator arguments or environment variables. The syntax currently looks like:\r\n```\r\n@mlflow_experiment\r\ndef train_model_1():\r\n   ...\r\n\r\n@mlflow_experiment(experiment_name='Train Random Forest', autolog=True)\r\ndef train_sklearn_model():\r\n    ...\r\n```\r\n\r\nThis has worked well for me and has resulted in my training scripts requiring less mlflow specific code - especially when combined with autologging - and eases adoption. I have primarily used this in scripts that are deployed on platforms such as AzureML, Kubeflow and Argo as opposed to in a notebook environment. This approach has received positive feedback from my colleagues at Microsoft, and I believe this could be a useful feature for other members of the community, and as a single function which uses existing components, it would be simple to integrate.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nTo remove boilerplate code from training scripts when using the tracking API for simple use cases.\r\n- Why is this use case valuable to support for MLflow users in general?\r\nLess code is required to start using mlflow, and it arguably provides a cleaner approach than a context manager.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nThis enabled me to remove some boilerplate code that I was observing in every training script in which I was using mlflow\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nCurrently, the use, and knowledge, of additional components in the tracking API are required to create experiments and log results to a remote tracking server, which ends up becoming boilerplate.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [x] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n\r\nI shall include the implementation (and tests) that I am currently using, which have worked well for my use cases, below:\r\n```\r\nimport functools\r\nimport os\r\n\r\nimport mlflow\r\n\r\ndef mlflow_experiment(\r\n    _func=None,\r\n    *,\r\n    experiment_name=None,\r\n    tracking_uri=None,\r\n    autolog=False,\r\n    run_name=None,\r\n    tags=None,\r\n):\r\n    def experiment_decorator(func):\r\n        @functools.wraps(func)\r\n        def experiment_wrapper(*args, **kwargs):\r\n            nonlocal experiment_name, tracking_uri\r\n\r\n            if tracking_uri is None:\r\n                tracking_uri = os.getenv(\r\n                    \"MLFLOW_TRACKING_SERVICE_URI\", mlflow.get_tracking_uri()\r\n                )\r\n            mlflow.set_tracking_uri(tracking_uri)\r\n\r\n            if experiment_name is None:\r\n                experiment_name = os.getenv(\"MLFLOW_EXPERIMENT_NAME\", None)\r\n\r\n            experiment_id = (\r\n                mlflow.set_experiment(experiment_name)\r\n                if experiment_name is not None\r\n                else None\r\n            )\r\n\r\n            if autolog:\r\n                mlflow.autolog()\r\n\r\n            with mlflow.start_run(\r\n                experiment_id=experiment_id, run_name=run_name, tags=tags\r\n            ):\r\n                value = func(*args, **kwargs)\r\n\r\n            return value\r\n\r\n        return experiment_wrapper\r\n\r\n    if _func is None:\r\n        return experiment_decorator\r\n    else:\r\n        return experiment_decorator(_func)\r\n\r\n---\r\n\r\nfrom unittest.mock import MagicMock\r\n\r\nfrom pytest import fixture\r\n\r\nfrom mlflow_decorator import mlflow_experiment\r\n\r\n\r\nEXPERIMENT_NAME = \"experiment_name\"\r\nEXPERIMENT_ID = \"experiment_id\"\r\nTRACKING_URI = \"tracking_uri\"\r\nRUN_NAME = \"run_name\"\r\nTAGS = \"tags\"\r\nFUNCTION_ARG = \"arg1\"\r\nFUNCTION_KWARG = \"kwarg1\"\r\n\r\nMLFLOW_TRACKING_SERVICE_URI_ENV_VAR = \"MLFLOW_TRACKING_SERVICE_URI_ENV_VAR\"\r\nMLFLOW_EXPERIMENT_NAME_ENV_VAR = \"MLFLOW_EXPERIMENT_NAME_ENV_VAR\"\r\n\r\n@fixture\r\ndef target_func():\r\n    return MagicMock()\r\n\r\ndef get_env_fake(env_name, *args):\r\n    if env_name == \"MLFLOW_TRACKING_SERVICE_URI\":\r\n        return MLFLOW_TRACKING_SERVICE_URI_ENV_VAR\r\n    elif env_name == \"MLFLOW_EXPERIMENT_NAME\":\r\n        return MLFLOW_EXPERIMENT_NAME_ENV_VAR\r\n\r\n\r\ndef test_experiment_decorator_no_args(mocker, target_func):\r\n    mlflow_mock = MagicMock()\r\n    get_tracking_uri_mock = MagicMock(return_value=TRACKING_URI)\r\n    mlflow_mock.get_tracking_uri = get_tracking_uri_mock\r\n    mocker.patch(\"mlflow_decorator.mlflow\", mlflow_mock)\r\n\r\n    decorated_func = mlflow_experiment(target_func)\r\n    decorated_func(FUNCTION_ARG, FUNCTION_KWARG=FUNCTION_KWARG)\r\n\r\n    mlflow_mock.get_tracking_uri.assert_called_once()\r\n    mlflow_mock.set_tracking_uri.assert_called_once_with(TRACKING_URI)\r\n    mlflow_mock.start_run.assert_called_once_with(\r\n        experiment_id=None, run_name=None, tags=None\r\n    )\r\n    target_func.assert_called_once_with(FUNCTION_ARG, FUNCTION_KWARG=FUNCTION_KWARG)\r\n\r\ndef test_experiment_decorator_with_env_vars(mocker, target_func):\r\n    # patch os.getenv to return specified values\r\n    os_mock = MagicMock()\r\n    os_mock.getenv = get_env_fake\r\n    mocker.patch(\"mlflow_decorator.os\", os_mock)\r\n\r\n    mlflow_mock = MagicMock()\r\n    mlflow_mock.set_experiment.return_value = EXPERIMENT_ID\r\n    mocker.patch(\"mlflow_decorator.mlflow\", mlflow_mock)\r\n\r\n    decorated_func = mlflow_experiment(target_func)\r\n    decorated_func(FUNCTION_ARG, FUNCTION_KWARG=FUNCTION_KWARG)\r\n\r\n    mlflow_mock.set_tracking_uri.assert_called_once_with(\r\n        MLFLOW_TRACKING_SERVICE_URI_ENV_VAR\r\n    )\r\n    mlflow_mock.set_experiment.assert_called_once_with(MLFLOW_EXPERIMENT_NAME_ENV_VAR)\r\n    mlflow_mock.start_run.assert_called_once_with(\r\n        experiment_id=EXPERIMENT_ID, run_name=None, tags=None\r\n    )\r\n    target_func.assert_called_once_with(FUNCTION_ARG, FUNCTION_KWARG=FUNCTION_KWARG)\r\n\r\n\r\ndef test_experiment_decorator_with_args(mocker, target_func):\r\n    mlflow_mock = MagicMock()\r\n    mlflow_mock.set_experiment.return_value = EXPERIMENT_ID\r\n    mocker.patch(\"mlflow_decorator.mlflow\", mlflow_mock)\r\n\r\n    decorator_with_args = mlflow_experiment(\r\n        experiment_name=EXPERIMENT_NAME,\r\n        run_name=RUN_NAME,\r\n        tracking_uri=TRACKING_URI,\r\n        tags=TAGS,\r\n    )\r\n    decorated_func = decorator_with_args(target_func)\r\n    decorated_func(FUNCTION_ARG, FUNCTION_KWARG=FUNCTION_KWARG)\r\n\r\n    mlflow_mock.set_tracking_uri.assert_called_once_with(TRACKING_URI)\r\n    mlflow_mock.set_experiment.assert_called_once_with(EXPERIMENT_NAME)\r\n    mlflow_mock.start_run.assert_called_once_with(\r\n        experiment_id=EXPERIMENT_ID, run_name=RUN_NAME, tags=TAGS\r\n    )\r\n    target_func.assert_called_once_with(FUNCTION_ARG, FUNCTION_KWARG=FUNCTION_KWARG)\r\n\r\n\r\ndef test_experiment_decorator_can_enable_autologging(mocker, target_func):\r\n    mlflow_mock = MagicMock()\r\n    mocker.patch(\"mlflow_decorator.mlflow\", mlflow_mock)\r\n\r\n    decorator_with_args = mlflow_experiment(autolog=True)\r\n    decorated_func = decorator_with_args(target_func)\r\n    decorated_func()\r\n\r\n    mlflow_mock.autolog.assert_called_once()\r\n```\r\n","443":"## What changes are proposed in this pull request?\r\n\r\nAdds the ability to specify backend-store connection string on command line that invokes a python callback function to ultimately generate a SQLAlchemy database URI connection string; the effective backend-store-uri for MLFlow Tracking Server.\r\n\r\n## How is this patch tested?\r\n\r\nManually, by varying backend-store-uri connection strings on mlflow tracker startup\r\n\r\n## Release Notes\r\n- Add ability to generate backend-store-uri via python callback function\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [x] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n","444":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [X] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: CentOS 7\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: 1.13.1\r\n- **Python version**: 3.6\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: \r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\nWhen accessing in the UI an experiment with many runs that have models (with files stored on HDFS), the UI becomes very slow. It takes a lot of time to load model informations and display the links (~10 seconds), and scrolling down to see the all the runs is very laggy.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nCreate an experiment with 200 runs that have models stored on HDFS, and access this experiment in the UI.\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [X] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","445":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [X] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nConfigure different backends for experiment tracking and model registration. \r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n\r\nUsing the same backend for experiment tracking and model registration places limitations on custom plugins. For instance, a user may want to create a custom model registration plugin to use something like Zookeeper for model registration but continue to use the OOB Postgres backend for experiment tracking.\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\n\r\nThis would decouple the implementation of the experiment tracking backend and the model registration backend, ultimately providing more flexibility around what custom plugins can be utilized for each backend. \r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n\r\nWe are currently looking for a way to have centralized live model configuration for a distributed system used for model deployments and inference. We are trying to prototype this with Zookeeper and want to experiment with using Zookeeper as the backend store for model registration without impacting the experiment tracking backend.\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nCurrently users can only specify a single backend that is shared by both the experiment tracking and model registration components.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [X] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nMy initial thoughts around this is to just decouple the shared dependency of the experiment tracking and model registration backends into independent backends. The server would be started with the following command\r\n\r\n```bash\r\nmlfow server --tracking-backend-store-uri <PATH> --model-registry-backend-store-uri <PATH>\r\n```\r\n\r\nA user can continue to specify a shared backend with `--backend-store-uri` which will maintain backwards compatibility.\r\n","446":"**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: mlflow, version 1.12.1\r\n- **Python version**: 3.6\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n```\r\nimport mlflow\r\n\r\nrun = mlflow.start_run(experiment_id=2)\r\nmlflow.log_metric('mymetric', 1323)\r\nmlflow.set_tag('set', 'test')\r\nexit()\r\nmlflow.end_run()\r\n```\r\nThis code produces a run with 'Status: FINISHED' where I would expect a Status: FAILED\r\n\r\nThe following code works correctly and produces a Status: FAILED:\r\n\r\n```\r\nwith mlflow.start_run(experiment_id=2) as run:\r\n    mlflow.log_metric('mymetric', 1323)\r\n    mlflow.set_tag('set', 'test')\r\n    exit()\r\n```\r\n\r\n### Describe the problem\r\nSee code above. I expect the both code examples to give the same result, Status: FAILED\r\n\r\n### Code to reproduce issue\r\nSee code above\r\n\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","447":"## Willingness to contribute\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [X] Yes. I would be willing to contribute this feature with guidance from the MLflow community. (review migrations)\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nIncrease maximum parameter value length from 250 to 2000 or only limit by request size.\r\n\r\n## Motivation\r\nWe use of parameter values longer than 250 characters. Those occur in parameters of naturally variable length:\r\n- URL references\r\n- Definitions of filtering steps: list of qualifiers\r\n- Definition of data augmentations: mapping of transformations to kwargs\r\n\r\nIn #1870 it was proposed to alter VARCHAR limits. It would be nice to not care of those alterations in migrations.\r\n\r\nOur length distribution has some outliers.\r\n```\r\n> select distinct length(value) from params order by length(value) desc limit 20;\r\n11991\r\n11978\r\n11976\r\n11488\r\n11481\r\n1115\r\n1113\r\n1003\r\n902\r\n431\r\n430\r\n396\r\n394\r\n345\r\n300\r\n296\r\n289\r\n287\r\n280\r\n275\r\n```\r\nOne solution for us would be to break apart outliers of >10k and settle on the somewhat [historic URL limit](https:\/\/stackoverflow.com\/a\/417184\/5149834) of 2k.\r\n\r\nAlternatively, the VARCHAR limit is dropped while the 1MB request limit stays for sanity. AFAICS a modern database wouldn't have any problem, nor does e.g. [wandb](https:\/\/wandb.ai\/site).\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [X] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","448":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**:\r\n- **Python version**:\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n\r\nPROBLEM STATEMENT\r\n\r\nMlflow model loading is not working for the combination of H2O with R. When try to load from model URI, it fails with the \u201cFile not found\u201d error.\u00a0\r\n\r\n```r\r\nmodel_uri <- \"models:\/sai_h2o_ml\/1\"\r\naa_model <- mlflow_load_model(model_uri)\r\n```\r\n\r\n```\r\nError in .h2o.doSafeREST(h2oRestApiVersion = h2oRestApiVersion, urlSuffix = page, : \r\n\r\nERROR MESSAGE: Illegal argument: dir of function: importModel: water.api.FSIOException: FS IO Failure: accessed path : file:\/tmp\/tmp14wfq1jm\/model.h2o\/GLM_model_R_1608625817138_1 msg: File not found \r\n```\r\n\r\nWhile logging the model using \u2192 mlflow_log_model(prostate_glm, \"model\"), the artifacts are saved in \/tmp directory.\r\n\r\nThe workaround seems to work:\r\n\r\n```R\r\nmlflow_start_run()\r\n# mlflow_log_model(prostate_glm, \"model\")  # fails\r\nmlflow_save_model(prostate_glm, \"temp\")\r\nmlflow_log_artifact(\"temp\", \"model\")\r\nmlflow_end_run()\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ x] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","449":"Hello! How can we increase response time of mlflow models in production? It there any tools or tricks? \r\nNow we have something like this :\r\nall time response = 0m0.327s\r\nmodel response = 0m0.014s\r\nSo we need decrease all time response\r\nAt the moment we are using more than 8 workers when we are running models","450":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**:\r\n- **Python version**:\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\nI built  mlflow docker image with Dockerfile to run a mlflow v1.13.0 server.\r\n\r\nWhen I run mlflow server with `mlflow server --host 0.0.0.0 --port 80` command, mlflow raised Error.\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"\/opt\/conda\/bin\/mlflow\", line 33, in <module>\r\n    sys.exit(load_entry_point('mlflow', 'console_scripts', 'mlflow')())\r\n  File \"\/opt\/conda\/bin\/mlflow\", line 25, in importlib_load_entry_point\r\n    return next(matches).load()\r\n  File \"\/opt\/conda\/lib\/python3.8\/importlib\/metadata.py\", line 77, in load\r\n    module = import_module(match.group('module'))\r\n  File \"\/opt\/conda\/lib\/python3.8\/importlib\/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 961, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"\/app\/mlflow\/__init__.py\", line 34, in <module>\r\n    import mlflow.tracking._model_registry.fluent\r\n  File \"\/app\/mlflow\/tracking\/__init__.py\", line 8, in <module>\r\n    from mlflow.tracking.client import MlflowClient\r\n  File \"\/app\/mlflow\/tracking\/client.py\", line 21, in <module>\r\n    from mlflow.tracking._model_registry.client import ModelRegistryClient\r\n  File \"\/app\/mlflow\/tracking\/_model_registry\/client.py\", line 15, in <module>\r\n    from mlflow.tracking._model_registry import utils, DEFAULT_AWAIT_MAX_SLEEP_SECONDS\r\n  File \"\/app\/mlflow\/tracking\/_model_registry\/utils.py\", line 6, in <module>\r\n    from mlflow.tracking._tracking_service.utils import (\r\n  File \"\/app\/mlflow\/tracking\/_tracking_service\/utils.py\", line 7, in <module>\r\n    from mlflow.store.tracking.file_store import FileStore\r\n  File \"\/app\/mlflow\/store\/tracking\/file_store.py\", line 26, in <module>\r\n    from mlflow.models import Model\r\n  File \"\/app\/mlflow\/models\/__init__.py\", line 23, in <module>\r\n    from .model import Model\r\n  File \"\/app\/mlflow\/models\/model.py\", line 12, in <module>\r\n    from mlflow.models.signature import ModelSignature\r\n  File \"\/app\/mlflow\/models\/signature.py\", line 16, in <module>\r\n    import pyspark.sql.dataframe\r\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/pyspark\/__init__.py\", line 51, in <module>\r\n    from pyspark.context import SparkContext\r\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/pyspark\/context.py\", line 31, in <module>\r\n    from pyspark import accumulators\r\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/pyspark\/accumulators.py\", line 97, in <module>\r\n    from pyspark.serializers import read_int, PickleSerializer\r\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/pyspark\/serializers.py\", line 71, in <module>\r\n    from pyspark import cloudpickle\r\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/pyspark\/cloudpickle.py\", line 145, in <module>\r\n    _cell_set_template_code = _make_cell_set_template_code()\r\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/pyspark\/cloudpickle.py\", line 126, in _make_cell_set_template_code\r\n    return types.CodeType(\r\nTypeError: an integer is required (got type bytes)\r\n```\r\n\r\nIn this container pyspark==2.4.0 is installed, but the package does not support python3.8.\r\n\r\nI guess that base image `continuumio\/miniconda3` upgrade to python3.8.\r\n\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","451":"Hi, is it possible to have HTML Hyperlinks clickable in MLFlow Tracking UI ? \r\nSuch as the following: \r\n\r\nJobUrl | <a href=\"https:\/\/someurl.com\/job\/develop\/185\/\">185<a>\r\n-- | --\r\n\r\nAlso, is there a REST API to edit the \"Notes\" section in the MLFlow run ? \r\n\r\nThanks","452":"## What changes are proposed in this pull request?\r\n\r\nThis change addresses the \"textcat-only\" limitations of the spacy pyfunc flavor as described in #2772 . This change surfaces more of spacy's functionality in the dataframe returned by `predict`.\r\n\r\nThis means, that instead of getting a single `predictions` column that contains a `dict` of text categorization predictions, like this:\r\n\r\n|  | predictions |\r\n| --- | --: |\r\n| **0** | {'SPAM': 0.9, 'HAM': 0.21} |\r\n| **1** | {'SPAM': 0.72, 'HAM': 0.46} |\r\n\r\nYou get more of the spacy `doc` features as additional columns, like this:\r\n\r\n| | text | ents | sents | cats | tokens | predictions\r\n| --- | --- | --- | --- | --- | --- | --- |\r\n**0** | Patient has pneumonia | [{'start': 12, 'end': 21, 'label': 'PNA'}] | [{'start': 0, 'end': 21}] | {'MILD': 0.8353676199913025, 'SEVERE': 0.98652... | [{'id': 0, 'start': 0, 'end': 7, 'pos': 'PROPN... | {'MILD': 0.8353676199913025, 'SEVERE': 0.98652...\r\n**1** | Patient has pneumothorax | [{'start': 12, 'end': 24, 'label': 'PTX'}] | [{'start': 0, 'end': 24}] | {'MILD': 0.018907491117715836, 'SEVERE': 0.883... | [{'id': 0, 'start': 0, 'end': 7, 'pos': 'PROPN... | {'MILD': 0.018907491117715836, 'SEVERE': 0.883...\r\n\r\nMore detail on the columns:\r\n* `text` (original text)\r\n* `ents` (named entity offsets and labels)\r\n* `sents` (sentence offsets)\r\n* `cats` (category dictionary, like `predictions` previously)\r\n* `tokens` (token offsets along with POS tagging)\r\n* `predictions` (just here for backwards compatibility)\r\n\r\n## How is this patch tested?\r\n\r\nI could use feedback on how to properly test this change. Other than running it successfully on my own installation of mlflow, I haven't done extensive testing or unit testing.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [X] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nPreviously, SpaCy models loaded via `pyfunc` were limited to text categorization predictions (the SpaCy `doc.cats` attribute on a pipeline that includes a `TextCategorizer`). This change makes additional SpaCy doc functionality available when loaded via `pyfunc` -- including text categorization, named-entity recognition, part-of-speech tagging, etc.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [X] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [X] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n\r\nNote, this PR is essentially identical to #3892 -- but without the rebase\/signoff issues","453":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n\r\n- **Exact command to reproduce**: Run the MLflow builds\r\n\r\n### Describe the problem\r\nThe MLflow python large build has failures in unrelated tests if tests\/test_cli.py is deleted or modified. This nuance in the code base can cause hard to debug failures in PRs since the files changed are not the files affected.\r\n\r\n### Code to reproduce issue\r\nA repro of the problem:\r\n\r\nhttps:\/\/github.com\/mlflow\/mlflow\/pull\/3879\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","454":"## What changes are proposed in this pull request?\r\n\r\nThis PR is a repro PR not meant to be checked in but to inform the MLflow maintainers of an odd behavior\r\n## How is this patch tested?\r\n\r\n(Details)\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","455":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04\r\n- **MLflow installed from (source or binary)**: Binary (pip install mlflow)\r\n- **MLflow version (run ``mlflow --version``)**: 1.12.1\r\n- **Python version**: 3.7.7\r\n- **npm version, if running the dev UI**: No UI\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nPytorch Lightning autologging fails on older versions of cloudpickle. It looks like MLflow is simply importing cloudpickle and using it as the pickle_module for `torch.save`, and this fails for certain cloudpickle versions. I think quick fix would be to just pin a minimum cloudpickle version in `setup.py`.\r\n\r\n### Code to reproduce issue\r\nFirst `pip install cloudpickle==1.1.1`.\r\n\r\nThen run the following simple example, with the Pytorch Lightning code taken straight from their guide:\r\n```\r\nimport torch\r\nfrom torch.nn import functional as F\r\nfrom torch import nn\r\nfrom pytorch_lightning.core.lightning import LightningModule\r\n\r\nclass LitMNIST(LightningModule):\r\n\r\n  def __init__(self):\r\n    super().__init__()\r\n\r\n    # mnist images are (1, 28, 28) (channels, width, height)\r\n    self.layer_1 = torch.nn.Linear(28 * 28, 128)\r\n    self.layer_2 = torch.nn.Linear(128, 256)\r\n    self.layer_3 = torch.nn.Linear(256, 10)\r\n\r\n  def forward(self, x):\r\n    batch_size, channels, width, height = x.size()\r\n\r\n    # (b, 1, 28, 28) -> (b, 1*28*28)\r\n    x = x.view(batch_size, -1)\r\n    x = self.layer_1(x)\r\n    x = F.relu(x)\r\n    x = self.layer_2(x)\r\n    x = F.relu(x)\r\n    x = self.layer_3(x)\r\n\r\n    x = F.log_softmax(x, dim=1)\r\n    return x\r\n\r\n  def training_step(self, batch, batch_idx):\r\n    x, y = batch\r\n    logits = self(x)\r\n    loss = F.nll_loss(logits, y)\r\n    return loss\r\n\r\n  def configure_optimizers(self):\r\n    return torch.optim.Adam(self.parameters(), lr=0.01)\r\n\r\nmodel = LitMNIST()\r\n\r\nfrom torch.utils.data import DataLoader, random_split\r\nfrom torchvision.datasets import MNIST\r\nimport os\r\nfrom torchvision import datasets, transforms\r\n\r\n# transforms\r\n# prepare transforms standard to MNIST\r\ntransform=transforms.Compose([transforms.ToTensor(),\r\n                              transforms.Normalize((0.1307,), (0.3081,))])\r\n\r\n# data\r\nmnist_train = MNIST(os.getcwd(), train=True, download=True, transform=transform)\r\nmnist_train = DataLoader(mnist_train, batch_size=64)\r\n\r\nfrom pytorch_lightning import Trainer\r\n\r\nimport mlflow\r\nmlflow.set_experiment(\"ptl_test\")\r\n\r\nmlflow.pytorch.autolog()\r\ntrainer = Trainer(max_steps=10)\r\ntrainer.fit(model, mnist_train)\r\n```\r\n### Other info \/ logs\r\nStack trace:\r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 62, in <module>\r\n    trainer.fit(model, mnist_train)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/pytorch\/_pytorch_autolog.py\", line 216, in fit\r\n    return _run_and_log_function(self, original, args, kwargs)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/pytorch\/_pytorch_autolog.py\", line 205, in _run_and_log_function\r\n    result = original(self, *args, **kwargs)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 439, in fit\r\n    results = self.accelerator_backend.train()\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/pytorch_lightning\/accelerators\/cpu_accelerator.py\", line 48, in train\r\n    results = self.train_or_test()\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/pytorch_lightning\/accelerators\/accelerator.py\", line 66, in train_or_test\r\n    results = self.trainer.train()\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 487, in train\r\n    self.train_loop.on_train_end()\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/training_loop.py\", line 182, in on_train_end\r\n    self.trainer.call_hook('on_train_end')\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 822, in call_hook\r\n    trainer_hook(*args, **kwargs)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/callback_hook.py\", line 117, in on_train_end\r\n    callback.on_train_end(self, self.get_model())\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/pytorch\/_pytorch_autolog.py\", line 124, in on_train_end\r\n    mlflow.pytorch.log_model(pytorch_model=trainer.model, artifact_path=\"model\")\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/pytorch\/__init__.py\", line 239, in log_model\r\n    **kwargs,\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/models\/model.py\", line 172, in log\r\n    flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/pytorch\/__init__.py\", line 405, in save_model\r\n    torch.save(pytorch_model, model_path, pickle_module=pickle_module, **kwargs)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/torch\/serialization.py\", line 372, in save\r\n    _save(obj, opened_zipfile, pickle_module, pickle_protocol)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/torch\/serialization.py\", line 476, in _save\r\n    pickler.dump(obj)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/cloudpickle\/cloudpickle.py\", line 357, in dump\r\n    return Pickler.dump(self, obj)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 437, in dump\r\n    self.save(obj)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 549, in save\r\n    self.save_reduce(obj=obj, *rv)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 662, in save_reduce\r\n    save(state)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 504, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 859, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 885, in _batch_setitems\r\n    save(v)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 535, in save\r\n    self.save_global(obj, rv)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/cloudpickle\/cloudpickle.py\", line 837, in save_global\r\n    if obj.__module__ == \"__main__\":\r\nAttributeError: 'torch.dtype' object has no attribute '__module__'\r\n```\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations","456":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nto decrease model predict response data io\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n   decrease model predict response data in case of big data response\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n#3865 ","457":"Signed-off-by: Dereck Li <monkeyboy.ljh@gmail.com>\r\n\r\n## What changes are proposed in this pull request?\r\nto decrease model predict response data io. \r\njust like lightgbm model server predict\uff0cwe need to transfer large matrix as paramters and return large matrix,if we do some change in the model function predict, then maybe,in the http json response\uff0cblank also is return\uff0cby add separators=(\",\", \":\") in the function predictions_to_json ,we can decrease data transmission\uff0cfilter blank\uff0cto improve network performance\r\n\r\nfix #3868 \r\n\r\n## How is this patch tested?\r\n\r\nunit test\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","458":"## Willingness to contribute\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [X] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nIn the MLflow UI, there is a link from child to parent steps but no link from parent to children. \r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nTo avoid having to return to the experiment page when exploring a particular run. \r\n- Why is this use case valuable to support for MLflow users in general?\r\nThis is valuable to anyone using the MLFlow UI to monitor and explore their runs.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nIt makes it easier to explore the details of a multi-step run.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nIt seems like a very simple addition but is lacking now. \r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ X] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n","459":"The mlflow.fastai Python API currently only works with fastaiV1, which is deprecated.\r\n\r\nProblem: cannot import mlflow.fastai\r\n\r\nError: cannot import name 'TabularList' from 'fastai.tabular'\r\n\r\nExplanation: TabularList is a class from fastaiV1; fastaiV2 uses TabularLoader","460":"### Problem description - \r\nI am trying run my project using MLflow Project. I have created Conda.yaml file for env specs and MLproject.yaml file for run specs. Along with supportive config file required as an argument, all the files are placed in the project directory. When I cd to the project location and run \"mlflow run . --no-conda\" I receive the output as below.\r\n\r\n2020\/12\/16 19:49:17 ERROR mlflow.cli: === Could not find main among entry points [] or interpret main as a runnable script. Supported script file extensions: ['.py', '.sh'] === \r\n\r\n### System specifications - \r\nEntry point - (Custom code) train.py contains main function.\r\nOS platform - Mac OS (macOS-10.15.7-x86_64-i386-64bit)\r\nMLflow installation source - pip3\r\nMLflow version - 1.12.1\r\nPython version - 3.9.0\r\nCommand to reproduce issue - (cd to project directory) Run \"mlflow run . --no-conda\" \r\n\r\nNote - I am not using any Conda env to. run this. Just to give a try, I tried to run the same within Conda env (both base and another customised one satisfying requirements of the project). Every time I faced the same error. \r\n\r\n### File specs - \r\n**conda.yaml -**\r\nname: yolo_env\r\nchannels:\r\n  - anaconda\r\n  - conda-forge\r\n  - defaults\r\ndependencies:\r\n  - awscli=1.18.191\r\n  - boto3=1.16.31\r\n  - cython=0.29.21\r\n  - dvc=0.54.1\r\n  - DateTime=4.3\r\n  - imgaug=0.4.0\r\n  - keras=2.2.5\r\n  - matplotlib=2.2.5\r\n  - mlflow=1.12.1\r\n  - numpy=1.19.2\r\n  - opencv=3.4.2\r\n  - pandas=1.1.3\r\n  - pillow=8.0.0\r\n  - pycocotools=2.0.2\r\n  - python=3.7.9\r\n  - seaborn=0.11.0\r\n  - slackclient=2.9.3\r\n  - tensorflow=1.14.0\r\nprefix: \/Users\/shrutid\/opt\/anaconda3\/envs\/yolo_env\r\n\r\n**MLproject.yamp -**\r\nname: Project1\r\n\r\nconda_env: complete_project_path_from_root\/conda.yaml\r\n\r\nentry_points:\r\n  main:\r\n    parameters:\r\n      config_file: complete_project_path_from_root\/config.json\r\n    command: \"python3 complete_project_path_from_root\/train.py -c {config_file}\"\r\n\r\nWhat am I missing?\r\n","461":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [X] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nAdd Pandas category dtype, to mlflow.types.schema().\r\n\r\nI currently have a ML model based on LightGBM running on production environment that contains categorical variables. Instead of label-encoding or OHE the categorical variables, I'm using Pandas dataframe with categorical columns set to be of the categorical dtype.\r\n\r\n` df['some_categorical_column'] = df['some_categorical_column'].astype('category') .`\r\n\r\nI'm trying to deploy this model on Databricks Serve Model that uses MLFlow as backend, but currently this category dtype is not supported for model signature according to the available dtypes on [https:\/\/www.mlflow.org\/docs\/latest\/_modules\/mlflow\/types\/schema.html](https:\/\/www.mlflow.org\/docs\/latest\/_modules\/mlflow\/types\/schema.html), so I'm unable to correctly cast the prediction Dataframe accordingly to the training phase.\r\n\r\nIt makes me think that deploying models that were trained with LightGBM using Pandas category dtypes, cannot be correctly deployed since this dtype is not availabe, so it would occur some casting error during the prediction leading to incorrect scores\/predictions. \r\n\r\nI could of course OHE the data and outline the problem, but I'm trying to deploy the current model into MLFlow.\r\nI'm not sure if this is a FR or something else.\r\n\r\n![bug2](https:\/\/user-images.githubusercontent.com\/3441278\/102220152-2f68b900-3ebf-11eb-9417-871fd027cca8.PNG)\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [X] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [X] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\n","462":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nCurrently, we are running multi-step pipelines with a kubernetes backend where a \"master\" pod executes the pipeline and starts the respective jobs. To do so, we mounted the docker socket of the host machine in order to be able to execute `mlflow.projects.run`. Since kubernetes is deprecating docker, executing multi-step pipelines with mlflow on kubernetes will not be possible in the future.\r\n\r\nWe propose to enable multi-step pipelines with a kubernetes backend also in the future after kubernetes deprecates docker by either 1) enabling building the image also without docker, e.g. with containerd or 2) by optionally allowing to execute `mlflow.projects.run` with a fixed imaged tag argument which would mean that no new images would be built for the individual pipeline steps that all require the same version of the code as already used by the \"pipeline master pod\".\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nRunning multi-step pipelines with a kubernetes backend fully remotely is a central feature for us in our workflows - presumably also for many other users. It is thus important for us to enable this ability also after kubernetes deprecates docker. \r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nThe best option would be to optionally enable `mlflow.projects.run` to build the new image also without docker, e.g. with containerd. Another and much easier option would be to add a new argument `image_tag` to `mlflow.projects.run` which would mean that no new image is built and that all steps of the pipeline could be executed with the same version of the code as the \"pipeline master\" but with different entry points.\r\n","463":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [X] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nWhen working with images, it is useful to compare two image artifact.\r\n\r\n![mlflow-fr](https:\/\/user-images.githubusercontent.com\/1506457\/102169056-58437b00-3ecc-11eb-9c31-40a09a1ce355.png)\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n\r\n  Jane is experimenting with a image filter. Jane uses MLflow to apply the filter to different images and saves the output image as MLflow artifact. Jane visit MLflow Tracking UI and have a side by side view of the the images when comparing two filters\/experiments.\r\n\r\n  Sarah is experimenting with some machine learning to identify particles. Sarah is aware of some edge cases that Sarah must be careful with. Sarah record the edge cases as artifacts and uses MLflow Tracking UI to inspect the improve of the machine learning implementation.\r\n- Why is this use case valuable to support for MLflow users in general?\r\n\r\n  This feature will benefit MLflow users that work with images.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n\r\n  This feature will be time saving for us.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n  MLflow \"Comparing 2 Runs\" Tracking UI doesn't list artifacts.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [X] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations","464":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [X] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nProvide a way to set the backend storage connection string that removes the security risk of placing secrets (password) on the command line.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nI would like to be able to run MLFlow connected to a database server, with a database user that requires a password, without exposing that password on a command line.\r\n- Why is this use case valuable to support for MLflow users in general?\r\nPrimarily to lower the security risk, but also could add more extendability with regard to backend connection configuration.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nWe are reluctant to deploy MLFlow in our environment with the password exposed in the current manner.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nWhile the related (AWS S3) artifact root config poses the same issue, those secrets can be removed from command line by using ~\/.aws\/credentials. Unfortunately there is no such alternative for the backend connection string.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [X] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n\r\n## Details\r\n\r\nI would like to add support for specifying a python function callback as a connection string via command line. This connection string would be interpreted by `store\/db\/utils.py:create_sqlalchemy_engine(str)`. If the connection string looks like a callback string (see format below), the referenced python package\/module:function would be dynamically imported and invoked. This function would serve as a connection string factory; in other words, the return value of said function would be passed into `sqlalchemy.create_engine(...)`\r\n\r\n`create_sqlalchemy_engine(str)` would process a connection string as a callback iff the \"driver\" portion of the connection string is \"pycallback\". Otherwise the connection string would be used as-is.\r\n\r\n**Proposed callback connection string format:**\r\n`pycallback:\/\/{target_package}\/{module}:{function_name}?{options...}`\r\n- **target_package**: optional; name of python package where module and factory function reside\r\n- **module**: required;  name of the python module containing the factory function\r\n- **function_name**: optional; name of the factory function (default: get_db_url)\r\n- **options**: optional; a query string ('&' separated pairs, each pair is '=' separated. These are parsed into a dict and passed into the factory function as kwargs\r\n\r\n**Example Connection Strings:**\r\n`pycallback:\/\/my_module`\r\n- attempts to invoke `my_module.py:get_db_url` function with no kwargs\r\n\r\n`pycallback:\/\/my_package\/my_module:my_connection_factory?user=mlflow&secret_location=\/somewhere\/safe\/passwd_file&host=192.168.1.10`\r\n- attempts to invoke `my_package.my_module.py:my_connection_factory` with kwargs: `{'user': 'mlflow', 'secret_location': '\/secrets\/passwd_file', 'host': '192.168.1.10'}`\r\n\r\n**Example Factory Function (pseudo-code):**\r\n```\r\ndef get_db_url(**kwargs):\r\n     secret = load_secret_from(kwargs['secret_location']\r\n     # ...\r\n     return 'mysql:\/\/{user}:{passwd}@....'.format(user=kwargs['user'], passwd=secret, ...)\r\n```","465":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.04\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: 1.12.1\r\n- **Python version**: 3.7.6\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: See below.\r\n\r\n### Describe the problem\r\nWhen creating a model with a model signature with space-separated fields, like:\r\n```\r\nsignature:\r\n  inputs: '[{\"name\": \"fixed acidity\", \"type\": \"double\"}, {\"name\": \"volatile acidity\",\r\n    \"type\": \"double\"}, {\"name\": \"citric acid\", \"type\": \"double\"}, {\"name\": \"residual\r\n    sugar\", \"type\": \"double\"}, {\"name\": \"chlorides\", \"type\": \"double\"}, {\"name\": \"free\r\n    sulfur dioxide\", \"type\": \"double\"}, {\"name\": \"total sulfur dioxide\", \"type\": \"double\"},\r\n    {\"name\": \"density\", \"type\": \"double\"}, {\"name\": \"pH\", \"type\": \"double\"}, {\"name\":\r\n    \"sulphates\", \"type\": \"double\"}, {\"name\": \"alcohol\", \"type\": \"double\"}]'\r\n```\r\n..the UI for registered models displaying the schema crashes when trying to parse this field:\r\n\r\n```\r\nSyntaxError: Unexpected token \r\n in JSON at position 155\r\n    at JSON.parse (<anonymous>)\r\n    at _t (reducers.js:140)\r\n    at Function.mapToProps (ModelVersionPage.js:228)\r\n    at r (wrapMapToProps.js:41)\r\n    at h (selectorFactory.js:41)\r\n    at selectorFactory.js:74\r\n    at Object.run (connectAdvanced.js:72)\r\n    at a.componentWillReceiveProps (connectAdvanced.js:192)\r\n    at l (react-dom.production.min.js:2237)\r\n    at updateClassInstance (react-dom.production.min.js:2369)\r\n```\r\nSpecifically at:\r\n```\r\nif (artifact.signature.inputs) {\r\n        schemaMap['inputs'] = JSON.parse(artifact.signature.inputs);\r\n      }\r\n```\r\nIt will probably crash for outputs too, have not tested.\r\n\r\nWhen filling in the spaces with underscores for every feature before inferring the model signature (`data.columns = [c.replace(\" \", \"_\") for c in data.columns]`) the bug disappears.\r\n\r\nError is related to JSON-parsing, or that it shouldn't be possible to log models where signatures contain spaces for feature-names.\r\n\r\n### Code to reproduce issue\r\n\r\nHave an MLFlow tracking server online, insert the url \/ token into your envs, run this script:\r\n\r\n```\r\nimport os\r\nimport warnings\r\nimport pandas as pd\r\nfrom mlflow.models.signature import infer_signature\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.linear_model import ElasticNet\r\nfrom urllib.parse import urlparse\r\nimport mlflow\r\nimport mlflow.sklearn\r\nimport os\r\nimport logging\r\n\r\nlogging.basicConfig(level=logging.WARN)\r\nlogger = logging.getLogger(__name__)\r\n\r\nos.environ['MLFLOW_TRACKING_URI'] = \"\"\r\nos.environ['MLFLOW_TRACKING_TOKEN'] = \"\"\r\n\r\nif __name__ == \"__main__\":\r\n    warnings.filterwarnings(\"ignore\")\r\n    # Read the wine-quality csv file from the URL\r\n    csv_url = (\r\n        \"http:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/wine-quality\/winequality-red.csv\"\r\n    )\r\n    try:\r\n        data = pd.read_csv(csv_url, sep=\";\")\r\n        # Uncomment line below to make bug related to signature parsing in MLFlow UI to disappear\r\n        #  data.columns = [c.replace(\" \", \"_\") for c in data.columns]\r\n    except Exception as e:\r\n        logger.exception(\r\n            \"Unable to download training & test CSV, check your internet connection. Error: %s\", e\r\n        )\r\n    # Split the data into training and test sets. (0.75, 0.25) split.\r\n    train, test = train_test_split(data)\r\n    # The predicted column is \"quality\" which is a scalar from [3, 9]\r\n    train_x = train.drop([\"quality\"], axis=1)\r\n    test_x = test.drop([\"quality\"], axis=1)\r\n    train_y = train[[\"quality\"]]\r\n    test_y = test[[\"quality\"]]\r\n\r\n    mlflow.set_experiment('default')\r\n    with mlflow.start_run():\r\n        lr = ElasticNet(alpha=0.5, l1_ratio=0.5, random_state=42)\r\n        lr.fit(train_x, train_y)\r\n        signature = infer_signature(train_x, lr.predict(train_x))\r\n        mlflow.sklearn.log_model(lr, \"default-model\", signature=signature)\r\n```\r\n* Browse your MLFlow UI into the model you created.\r\n* Register the model\r\n* Browse into the Model Registry\r\n* Click into the model you registered\r\n* Click at the newest version\r\n* UI Crash.  \r\n\r\n\r\n### Other info \/ logs\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [x] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","466":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu\r\n- **MLflow installed from (source or binary)**: pip\r\n- **MLflow version (run ``mlflow --version``)**: mlflow, version 1.12.1\r\n- **Python version**: Python 3.6.11\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n    ```python\r\n      # Below commands were run on a SageMaker Notebook instance\r\n      import sagemaker\r\n      import mlflow\r\n      from mlflow import sagemaker as mfs   \r\n   \r\n      role = sagemaker.get_execution_role()\r\n\r\n      mfs.deploy(app_name='test-model',\r\n                        model_uri=\"s3:\/\/sagemaker-mlflow-test\/mlruns\/aeab55a0f9c94acc8123d499a758a95E\/artifacts\/model\",\r\n                        execution_role_arn=role,\r\n                        # execution_role_arn='arn:aws:iam::830861123456:role\/service-role\/AmazonSageMaker-ExecutionRole-20201213T185603'\r\n                        image_url='830861123456.dkr.ecr.us-east-1.amazonaws.com\/mlflow-pyfunc',\r\n                        region_name='us-east-1',\r\n                        mode=mlflow.sagemaker.DEPLOYMENT_MODE_CREATE,\r\n                        instance_type='ml.t2.medium',\r\n                        instance_count=1)\r\n     ```\r\n\r\n I also updated my SageMaker execution role's policy\r\n\r\n  ```json\r\n \r\n         {\r\n            \"Sid\": \"VisualEditor2\",\r\n            \"Effect\": \"Allow\",\r\n            \"Action\": [\r\n                \"s3:DeleteObjectTagging\",\r\n                \"s3:DeleteStorageLensConfigurationTagging\",\r\n                \"s3:ReplicateTags\",\r\n                \"s3:PutStorageLensConfigurationTagging\",\r\n                \"s3:PutObjectVersionTagging\",\r\n                \"s3:PutJobTagging\",\r\n                \"s3:DeleteObjectVersionTagging\",\r\n                \"s3:PutObject\",\r\n                \"s3:GetObject\",\r\n                \"s3:DeleteJobTagging\",\r\n                \"s3:PutBucketTagging\",\r\n                \"s3:PutObjectTagging\",\r\n                \"s3:DeleteObject\"\r\n            ],\r\n            \"Resource\": \"arn:aws:s3:::arn:aws:s3:::mlflow-sagemaker-us-east-1-830861123456\/*\"\r\n         }\r\n\r\n  ```\r\n \r\n### Describe the problem\r\nUnable to deploy to a SageMaker Endpoint. I keep getting the `PutObjectTagging operation: Access Denied` exception\r\n\r\n### Code to reproduce issue\r\nAdded above\r\n\r\n### Other info \/ logs\r\n```python\r\n2020\/12\/14 18:37:55 INFO mlflow.sagemaker: Using the python_function flavor for deployment!\r\n2020\/12\/14 18:37:55 INFO mlflow.sagemaker: No model data bucket specified, using the default bucket\r\n2020\/12\/14 18:37:57 INFO mlflow.sagemaker: Default bucket `mlflow-sagemaker-us-east-1-830861123456` already exists. Skipping creation.\r\n---------------------------------------------------------------------------\r\nClientError                               Traceback (most recent call last)\r\n<ipython-input-73-3619a973e6f4> in <module>\r\n     15                         mode=mlflow.sagemaker.DEPLOYMENT_MODE_CREATE,\r\n     16                         instance_type='ml.t2.medium',\r\n---> 17                         instance_count=1)\r\n     18 \r\n\r\n~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/mlflow\/sagemaker\/__init__.py in deploy(app_name, model_uri, execution_role_arn, bucket, image_url, region_name, mode, archive, instance_type, instance_count, vpc_config, flavor, synchronous, timeout_seconds)\r\n    353         prefix=model_name,\r\n    354         region_name=region_name,\r\n--> 355         s3_client=s3_client,\r\n    356     )\r\n    357 \r\n\r\n~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/mlflow\/sagemaker\/__init__.py in _upload_s3(local_model_path, bucket, prefix, region_name, s3_client)\r\n    660             obj.upload_fileobj(fobj)\r\n    661             response = s3_client.put_object_tagging(\r\n--> 662                 Bucket=bucket, Key=key, Tagging={\"TagSet\": [{\"Key\": \"SageMaker\", \"Value\": \"true\"}]}\r\n    663             )\r\n    664             _logger.info(\"tag response: %s\", response)\r\n\r\n~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/botocore\/client.py in _api_call(self, *args, **kwargs)\r\n    355                     \"%s() only accepts keyword arguments.\" % py_operation_name)\r\n    356             # The \"self\" in this scope is referring to the BaseClient.\r\n--> 357             return self._make_api_call(operation_name, kwargs)\r\n    358 \r\n    359         _api_call.__name__ = str(py_operation_name)\r\n\r\n~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/botocore\/client.py in _make_api_call(self, operation_name, api_params)\r\n    674             error_code = parsed_response.get(\"Error\", {}).get(\"Code\")\r\n    675             error_class = self.exceptions.from_code(error_code)\r\n--> 676             raise error_class(parsed_response, operation_name)\r\n    677         else:\r\n    678             return parsed_response\r\n\r\nClientError: An error occurred (AccessDenied) when calling the PutObjectTagging operation: Access Denied\r\n\r\n```\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [x] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","467":"\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ x No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nWe need to ship all MLFlow logs to remote log analytics servers such as Logstash. Is there a way to do this without modifying MLFlow code base which will affect our upgrades? \r\n\r\n## Motivation\r\n- What is the use case for this feature? Ship MLFlow logs to remote servers without modifying MLflow code base. \r\n- Why is this use case valuable to support for MLflow users in general? Re-direct logs to files and make use of handlers such as logstash. \r\n- Why is this use case valuable to support for your project(s) or organization? For debugging and production monitoring of deployed models and docker creation process. \r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient) We are having to modify the MLFlow code which is affecting our upgrades to a newer  version of MLflow\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","468":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04\r\n- **MLflow installed from (source or binary)**: pip\r\n- **MLflow version (run ``mlflow --version``)**:1.11.0\r\n- **Python version**: 3.8.3\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: \r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\nI have built and saved a pytorch model by running this example https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/examples\/pytorch\/mnist_tensorboard_artifact.py\r\nAfter saving the model, I tried to load the model in a separate notebook. \r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\nimport argparse\r\nimport os\r\nimport mlflow\r\nimport mlflow.pytorch\r\nimport pickle\r\nimport tempfile\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\nimport torch.optim as optim\r\nfrom torchvision import datasets, transforms\r\nfrom torch.autograd import Variable\r\nfrom tensorboardX import SummaryWriter\r\nfrom  mlflow.tracking import MlflowClient\r\n\r\nwith mlflow.start_run(run_id=<run_id>,experiment_id=<exp_id>):\r\n    print(mlflow.get_artifact_uri(\"pytorch-model\"))\r\n    loaded_model = mlflow.pytorch.load_model(mlflow.get_artifact_uri(\"pytorch-model\"))\r\n    eval_data, eval_labels = next(iter(test_loader))\r\n    predictions = loaded_model(eval_data).data.max(1)[1]\r\n    template = 'Sample {} : Ground truth is \"{}\", model prediction is \"{}\"'\r\n    print(\"\\nSample predictions\")\r\n    for index in range(5):\r\n        print(template.format(index, eval_labels[index], predictions[index]))\r\nmlflow.end_run()\r\n```\r\nI see the following errors:\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-2-66c1fe24f3f2> in <module>\r\n      1 with mlflow.start_run(run_id=\"3f95c840379b476fb0386cc33c76d294\",experiment_id=2):\r\n      2     print(mlflow.get_artifact_uri(\"pytorch-model\"))\r\n----> 3     loaded_model = mlflow.pytorch.load_model(mlflow.get_artifact_uri(\"pytorch-model\"))\r\n      4     eval_data, eval_labels = next(iter(test_loader))\r\n      5     predictions = loaded_model(eval_data).data.max(1)[1]\r\n\r\n\/opt\/conda\/lib\/python3.8\/site-packages\/mlflow\/pytorch\/__init__.py in load_model(model_uri, **kwargs)\r\n    449         )\r\n    450     torch_model_artifacts_path = os.path.join(local_model_path, pytorch_conf[\"model_data\"])\r\n--> 451     return _load_model(path=torch_model_artifacts_path, **kwargs)\r\n    452 \r\n    453 \r\n\r\n\/opt\/conda\/lib\/python3.8\/site-packages\/mlflow\/pytorch\/__init__.py in _load_model(path, **kwargs)\r\n    391         model_path = path\r\n    392 \r\n--> 393     return torch.load(model_path, **kwargs)\r\n    394 \r\n    395 \r\n\r\n\/opt\/conda\/lib\/python3.8\/site-packages\/torch\/serialization.py in load(f, map_location, pickle_module, **pickle_load_args)\r\n    527             with _open_zipfile_reader(f) as opened_zipfile:\r\n    528                 return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\r\n--> 529         return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\r\n    530 \r\n    531 \r\n\r\n\/opt\/conda\/lib\/python3.8\/site-packages\/torch\/serialization.py in _legacy_load(f, map_location, pickle_module, **pickle_load_args)\r\n    700     unpickler = pickle_module.Unpickler(f, **pickle_load_args)\r\n    701     unpickler.persistent_load = persistent_load\r\n--> 702     result = unpickler.load()\r\n    703 \r\n    704     deserialized_storage_keys = pickle_module.load(f, **pickle_load_args)\r\n\r\nAttributeError: Can't get attribute 'Net' on <module '__main__'>\r\n```\r\nWhat is the procedure to save the network architecture to use the model? Also, is there a way to do a REST API call on a Pytorch model that is served as a REST API endpoint?\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n","469":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community: The R hooks.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nI propose to use the [pre-commit](https:\/\/pre-commit.com) framework to the developer workflow in order to enhance git commit quality.\r\n\r\n## Motivation\r\n\r\n**What is the use case for this feature?**\r\n\r\n* Automatic linting \/ formatting for Python, Java and R code, yaml, json, Docker, and other file types, \r\n* doc source correspondence with rst derivatives.\r\n* import ordering\r\n* warn on large file commits.\r\n* many more [supported hooks](https:\/\/pre-commit.com).\r\n\r\n**Why is this use case valuable to support for MLflow users in general?**\r\n\r\nNone, it's pure developer infra.\r\n\r\n**Why is this use case valuable to support for your project(s) or organization?**\r\n\r\nI can't speak for reviewers because I don't review a lot of mlflow code but in general it would speed up the review process, increase quality, consistency.\r\n\r\n**Why is it currently difficult to achieve this use case?**\r\n\r\nThe cognitive burden on the code reviewer is high as he has to manually check some things pre-commit hooks can automate.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nI don't have a very detailed understanding of which hooks would be used here, I just listed a few possibilities. And there are configuration options. But the framework is very popular and has reached a mature state. There is also the prospect of using https:\/\/pre-commit.ci and enforce all hooks via GitHub Actions. Note that without running pre-commits on CI\/CD, the hooks can be skipped manually when committing locally.","470":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nThe build-docker functionality should be supported in R\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nThe MLflow R package should maintain its feature parity with Python. Also, build-docker is clearly useful for containerization of ML models.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [x] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n","471":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.11.0\r\n- **Python version**: 3.8.5\r\n- **npm version, if running the dev UI**: -\r\n- **Exact command to reproduce**: p = subprocess.Popen(\r\n            [\"mlflow\", \"models\", \"serve\", \"-m\", remote_model_uri, \"-h\", host, \"-p\",\r\n             port, \"--no-conda\"])\r\n\r\n### Describe the problem\r\nI'm trying to serve a model locally within a unittest test case using subprocess.Popen() and to terminate the serving process at the end of the test. I'm able to start the subprocess and get predictions from the served model, but unable to terminate the process that runs the served model, i.e., after the test completes the model serving gunicorn process as well as the worker process it spawns stay alive and can be queried for predictions.\r\n\r\nI've tried to terminate the process with all of the following\r\n\r\np.terminate()\r\np.kill()\r\nos.kill(p.pid, signal.SIGTERM)\r\nos.kill(p.pid, signal.SIGKILL)\r\n\r\nas well as calling different combinations of\r\n\r\np.wait()\r\np.poll()\r\np.communicate(timeout=20)\r\ndel p\r\n\r\nafter the termination attempt.\r\n\r\nHowever, the two gunicorn processes never get killed and persist after the tests end. \r\n\r\nI'm looking for a way to run model serving from Python script and to terminate the model serving processes when the script finishes.\r\n\r\n### Code to reproduce issue\r\n\r\np = subprocess.Popen(\r\n            [\"mlflow\", \"models\", \"serve\", \"-m\", remote_model_uri, \"-h\", host, \"-p\",\r\n             port, \"--no-conda\"])\r\n\r\n### Other info \/ logs\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","472":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nAdd input validation to `mlflow.search_runs`, in particular for `experiment_ids`.\r\n\r\n## Motivation\r\nI accidentally passed the Experiment object instead of the experiment ID to `mlflow.search_runs`:\r\n```python\r\nexperiment = mlflow.get_experiment_by_name(\"experiment\")\r\nmlflow.search_runs(experiment_ids=[experiment])\r\n```\r\n\r\nFrom the client side I did not receive any error message, besides having 3 tries with error code 500, internal server error.\r\nWhen investigating the MLFlow server logs, I found out that a serialized string of the experiment object was passed as experiment ID, with error message on the server\r\n```ptb\r\nsycopg2.errors.InvalidTextRepresentation: invalid input syntax for type integer: \"<Experiment: artifact_location='\/path\/to\/mlflow\/artifacts\/207', experiment_id='207', lifecycle_stage='active', name='experiment', tags={}>\"\r\n```\r\n\r\nSince not every user of the MLFlow client may have access to the server logs, it would be good to have a more informative error message from the client side.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nA check whether all passed arguments are string representations of an integer could be sufficient.\r\n```python\r\nimport re\r\nif not all (re.match(r\"^\\d+$\", i) for i in experiment_ids):\r\n    raise ValueError(f\"Invalid experiment_ids: {experiment_ids}\")\r\n```\r\n\r\nI am not familiar with the MLFLow code base, but here seems to be a suitable place\r\n\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/8fb419fb109d72446a869f3d1c002cdfd8610f92\/mlflow\/tracking\/_tracking_service\/client.py#L367-L368","473":"When I type mlflow ui on jupyterhub  I get  the  http:\/\/127.0.0.1:5000 link which doesn't redirect me to the ui part of mlflow.\r\nIs there any way to get over this problem ?\r\n","474":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this documentation issue template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages documentation fix contributions. Would you or another member of your organization be willing to contribute a fix for this documentation issue to the MLflow code base?\r\n\r\n- [ X ] Yes. I can contribute a documentation fix independently.\r\n- [ ] Yes. I would be willing to contribute a document fix with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a documentation fix at this time.\r\n\r\n### URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry in question.\r\n\r\n[https:\/\/www.mlflow.org\/docs\/latest\/plugins.html](https:\/\/www.mlflow.org\/docs\/latest\/plugins.html)\r\n\r\n### Description of proposal (what needs changing):\r\nProvide a clear description. Why is the proposed documentation better?\r\n\r\nWhen writing a plugin for MLFlow it is not clear that you need to configure your logging separately for the plugin. (At least it wasn't to me.)\r\n\r\nThe issue is that MLFlow currentl sets the logging at the level of `mlflow`. When you define a plugin without configuring your own logging it reverts to the root logger, which still has the default configuration. \r\n\r\nMaybe this is obvious behaviour to some, but it wasn't to me personally. I think it would help to highlight this point in the documentation. My current solution is to call `_configure_mlflow_loggers(__name__)` in the plugin.\r\n","475":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [X] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nRefactoring `mlflow ui` code to make it easy for changing the UI theme (mostly colors)\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nmlflow is one of many services in the project I am working with. I need to make the UI consistent across all services, and for that need to change colors in mlflow ui.\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\nUser will be able to change the theme of UI to more closely match other apps they might be integrating mlflow with.\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nIt is critical for UI to be consistent across different services to give a polished experience to users.\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n`mlflow ui` provides no way of changing the theme of the UI. It uses ant.design, but does not exposes its theming support. The CSS also have colors hard coded across different components, which make it difficult to change the theme with minimal changes to the codebase.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [X] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nI am up for making these changes to mlflow ui code:\r\n1. Refactor CSS files to LESS, and use colors from ant.design where possible, or create new LESS variables where needed\r\n2. Create a `theme.less` file which overrides ant.design's theme. Users can then fork mlflow, and change just this file to change the UI's theme. This will allow them to keep the ability to upgrade mlflow codebase with minimal intervention. As an alternative, I am also open to accept a less file as CLI argument for `mlflow ui`, so users won't need to fork the repo just to change the theme. \r\n\r\nWould this be an acceptable approach to solve the theming problem? ","476":"\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows Server 2019 (or whichever distribution `windows-latest` gets you in Github Workflow)\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: 1.2\r\n- **Python version**: 3.6\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: see https:\/\/github.com\/mlflow\/mlflow\/runs\/1513241231?check_suite_focus=true\r\n\r\n### Describe the problem\r\nmlflow_cli is not working well on Windows -- Both issues below are the ones I have run into while attempting to enable GitHub CI workflow for MLflow R client on Windows in https:\/\/github.com\/mlflow\/mlflow\/runs\/1513241231?check_suite_focus=true\r\n\r\nCurrently MLflow R client still depends on mlflow_cli for some of its functionalities, which is why Windows interop issues in mlflow_cli affects MLflow R client.\r\n\r\nThere are at least 2 problems:\r\n\r\n- Almost all calls to `os.path.join()` are not handling mixture of forward slashes and backward slashes well. Having both types of slashes in a file path will not work.\r\n-- Proposed solution: replace `os.path.join()` with `os.path.normpath(os.path.join())` (unless the resulting path is then passed to `os.path.abspath()` which internally calls `os.path.normpath()` already) so that the resulting path will only contain back slashes on Windows\r\n\r\n- \"ValueError: close_fds is not supported on Windows platforms if you redirect stdin\/stdout\/stderr\"\r\n-- Solution: TBD. I still need to look into what exactly causes this error on Windows.\r\n\r\n### Code to reproduce issue\r\nsee https:\/\/github.com\/mlflow\/mlflow\/runs\/1513241231?check_suite_focus=true\r\n### Other info \/ logs\r\nsee https:\/\/github.com\/mlflow\/mlflow\/runs\/1513241231?check_suite_focus=true\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [x] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","477":"## What changes are proposed in this pull request?\r\n\r\nA new exported function `mlflow_log_text()` to log text, to make the R API match Python's (compare with #3678). I moved the artifact logging out of the tracking source and test file, as these have grown quite large and with future support for `log_figure()` and others that are supported experimentally in Python, the code related to logging will only grow.\r\n\r\nThe documentation, examples and API closely follows #3678.  ~I am not sure why the file path argument was named `artifact_file`, as my impression is that `path` and `artifact_path` are far more common in the source code (1400+ vs 80+ matches). I think the argument `artifact_file` in the Python API should be renamed to `artifact_path` or `path` for consistency with `mlflow.log_artifacts()` \/ `list_artifacts()` and the rest of the API. I think this is still possible without breaking the released API, as this change was not yet released. Might also be it was deliberately named `artifact_file`, I don't know.~ Explanation: https:\/\/github.com\/mlflow\/mlflow\/pull\/3890#discussion_r547318219 ~Please let me know what you think, then I can open a separate issue for this if you think it should be re-named.~\r\n\r\nI'd be happy to later add support for `mlflow_log_figure()` and friends.\r\n\r\n## How is this patch tested?\r\n\r\nUnit tests\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nSupport logging text from R with `mlflow_log_text()`.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [x] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n\r\ncc: @yitao-li ","478":"## MLflow Roadmap Item\r\n\r\nThis is an MLflow Roadmap item that has been prioritized by the MLflow maintainers. We're seeking help with the implementation of roadmap items tagged with the `help wanted` label.\r\n\r\nFor requirements clarifications and implementation questions, or to request a PR review, please tag @WeichenXu123 in your communications related to this issue.\r\n\r\n### System information\r\n- Linux Ubuntu 18.04\r\n- MLflow installed from pip\r\n- MLFlow version 1.11:\r\n- Python version 3.8.3\r\n\r\n### Describe the problem\r\nThis might not be true for other dialects, but Postgres doesn't automatically index on FKs. It makes something as simple as querying all run details extremely slow, as the number of experiments \/ runs (the UI only allows to fetch results 100 at  time).\r\n\r\n\r\n### Code to reproduce issue\r\nThe following has about 10k rows but essentially times out.\r\n```\r\nSELECT * \r\nFROM runs\r\nJOIN params on params.run_uuid = runs.run_uuid\r\nJOIN metrics on metrics.run_uuid = params.run_uuid\r\nWHERE runs.experiment_id = 30\r\n```\r\n\r\n\r\n### Other info \/ logs\r\nQuery to get all the missing FKs ([credit](https:\/\/www.cybertec-postgresql.com\/en\/index-your-foreign-key\/))\r\n```\r\nSELECT c.conrelid::regclass AS \"table\",\r\n       \/* list of key column names in order *\/\r\n       string_agg(a.attname, ',' ORDER BY x.n) AS columns,\r\n       pg_catalog.pg_size_pretty(\r\n          pg_catalog.pg_relation_size(c.conrelid)\r\n       ) AS size,\r\n       c.conname AS constraint,\r\n       c.confrelid::regclass AS referenced_table\r\nFROM pg_catalog.pg_constraint c\r\n   \/* enumerated key column numbers per foreign key *\/\r\n   CROSS JOIN LATERAL\r\n      unnest(c.conkey) WITH ORDINALITY AS x(attnum, n)\r\n   \/* name for each key column *\/\r\n   JOIN pg_catalog.pg_attribute a\r\n      ON a.attnum = x.attnum\r\n         AND a.attrelid = c.conrelid\r\nWHERE NOT EXISTS\r\n        \/* is there a matching index for the constraint? *\/\r\n        (SELECT 1 FROM pg_catalog.pg_index i\r\n         WHERE i.indrelid = c.conrelid\r\n           \/* the first index columns must be the same as the\r\n              key columns, but order doesn't matter *\/\r\n           AND (i.indkey::smallint[])[0:cardinality(c.conkey)-1]\r\n               OPERATOR(pg_catalog.@>) c.conkey)\r\n  AND c.contype = 'f'\r\nGROUP BY c.conrelid, c.conname, c.confrelid\r\nORDER BY pg_catalog.pg_relation_size(c.conrelid) DESC;\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","479":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nI propose the implementation of publishing the mlflow docker container to a registry.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n\r\nStarting mlflow without having to worry about the os and setup.\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\n\r\nSetting up mlflow with the docker container is the easiest way to get it running.\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n\r\nI run all the software on my server as docker containers. Unofficial builds exist, but none is up-to-date. Instead of building the container myself I want to contribute directly to the project, so other can profit as well.\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nBuilding containers from another repo on push without the event is difficult and requires constant polling.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [x] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nThere is already an old issue #826 from 2019 , where the problem was labled as important-longterm.\r\nBut it doesnt follow the template and an issue over a year old without any implementation, which makes me think, that it has been forgotten.\r\nSo I thought of creating a new one, to bring it back on the agenda.\r\nThe dockerfile already exist, the only step missing is the actual publishing.\r\nPossible solution can be found here #3709\r\n","480":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nAdd the `--synchronized` option flag to the `mlflow run` cli, having a default value of `False`.\r\n\r\n## Motivation\r\nWe are using the MLFlow CLI to run projects with a databricks backend via Airflow. Currently, it is not possible to specify that the `mlflow run` command should only return if the job is finished. To facilitate this I would like to make it possible to pass the `--synchronized` flag to the `mlflow run` command. That way it becomes possible to also use the `mlflow run` cli in e.g. CI pipelines or in Airflow dags.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [x] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nI'm happy to implement this feature. The change should be minimal and non-breaking since we can set a default of `False` in the next `--synchronized` option to add in https:\/\/github.com\/mlflow\/mlflow\/blob\/1d7d09b2c9bd6b4f87ef0b6de3d7870697e67f35\/mlflow\/cli.py#L42.  This maintains all current functionality of the cli.\r\n","481":"### Willingness to contribute\r\nThe MLflow Community encourages documentation fix contributions. Would you or another member of your organization be willing to contribute a fix for this documentation issue to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a documentation fix independently.\r\n- [ ] Yes. I would be willing to contribute a document fix with guidance from the MLflow community.\r\n- [X] No. I cannot contribute a documentation fix at this time.\r\n\r\n### URL(s) with the issue:\r\n\r\nhttps:\/\/mlflow.org\/docs\/latest\/rest-api.html\r\n\r\n### Description of proposal (what needs changing):\r\n\r\nI have found a number of references to the transition-requests API, but it is not listed in the REST API documentation. \r\nI have managed to figure out how to make it work for some simple use cases by testing and playing around with curl, but it would be nice to have this included in the documentation.\r\n","482":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [X] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nUsers may supply important comments when a request to transition a model to a different stage is made. This information could be invaluable to those making the determination whether or not to approve the request. While the comments are listed in the \"Activities\" section, they should be displayed alongside other aspects of the pending request. It would be relatively easy to add an additional column to the pending request UI table that would display the comments.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nTo assist in reviewing pending stage transition requests.\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\nIt facilitates the good communication of different team members in an MLOps workflow\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nIt facilitates the good communication of different team members in an MLOps workflow\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nComments are not displayed in a way that obviously ties them to the pending request under consideration.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [X] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [X] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n","483":"Signed-off-by: Yitao Li <yitao@rstudio.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nThis PR enables GitHub CI workflow for the MLflow R package and fixes a number of issues affecting MLflow on Windows:\r\n\r\n- `python_mlflow_bin()` should return <python_bin_dir>\/Scripts\/mlflow.exe on Windows\r\n- When extracting a file path from MLflow CLI output, both `\\r` and `\\n`  must be removed on Windows, not just `\\n`\r\n- Prefixing local file paths with `file:\/\/` whenever necessary, as otherwise paths like \"C:\/dir1\/dir2\" gets interpreted as some invalid URI with scheme `C:` in Python\r\n- Taking into account the fact that currently `waitress-serve` (the equivalent of `gunicorn` for Windows) cannot support `--workers` specification of MLflow server, so `mlflow::mlflow_server()` must omit the `--workers` flag with a warning if running on Windows\r\n- Replacing `os.path.join(...)` with `os.path.normpath(os.path.join(...))` whenever necessary so that in case part of the path contains back slashes and other parts contain forward slashes, the resulting path will still only contain back slashes on Windows (in fact this will only be not necessary when within if branches that are UNIX-only or when `os.path.join()` is wrapped with `os.path.abspath()` which calls `os.path.normpath()` internally)\r\n- Replacing `if os.name != \"nt\":` with `if platform.system() != \"Windows\":` everywhere -- Because checking `os.name` is clearly a rookie mistake, as it could return `\"nt\"` or `\"ce\"` or possibly some other value in some future version of Windows, whereas `platform.system()` is the most portable and future-proof way to check whether we are running on Windows or not\r\n \r\ncloses #1009\r\ncloses #3206\r\ncloses #3319\r\ncloses #3393\r\ncloses #3430\r\n\r\n \r\n## How is this patch tested?\r\n\r\nUnit test\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nSeveral Windows-related platform-specific issues were addressed in this release\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [x] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [x] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [x] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [x] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","484":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n- [x] Maybe. I would be willing to try to contribute this feature, but I wouldn't know where to start.\r\n\r\n## Proposal Summary\r\n\r\nWhen comparing runs, the parameters that _differ_ from one run to another, are far more important than all the parameters that are the same for all runs in the comparison. \r\n\r\nRight now, in the comparison ui, the rows with these changing parameters are easily identified, because they're highlighted in orange. This is great, but it would be even better if all other rows could be hidden (by default, or after a single click). Similarly, for the Parallel Coordinates Plot, it would be great if only these features would be selected by default, because the ones that do not change from run to run, merely make the chart unreadable.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nWith my workflow I tend to track just about anything that is trackable. However, when doing experiments, I tend to be focused on only a small subset of these parameters. This means that when I'm comparing runs, most of the parameters are not changed between the runs, but they do completely clutter the ui\/chart.\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\nGenerally speaking, when doing comparisons, that which is _different_ is of interest. There is also no reason to have the unchanged parameters in the Parallel Coordinates Plot at all.\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nGives a better overview, and saves lots of time\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nComparing runs in the table now requires lots of scrolling to find the few relevant rows, and lots of manual deselecting irrelevant parameters for the chart.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n\r\n","485":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nSupports aggregating some runs to provide nicer visualizations.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n\r\nIn Hyper Parameter Optimization, it is common to run on the same set of hyper parameters several times (in deep learning), so it will be nice to support aggregating these runs (e.g. through tags) to provide a mean-std visualization of each metric (which [aim](https:\/\/github.com\/aimhubio\/aim) has already supported).\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\n\r\nBeing able to aggregate the 'same' runs can provide us a more general view of the model (e.g. bias-variance analysis).\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n\r\nIt can help us choose hyper parameters better.\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nI've searched for hours and could not get a near solution. As far as I know is the nested run, but it did not provide statistics (e.g. mean, std) of the child runs.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nI'm expecting something like this:\r\n\r\n![mean-std](https:\/\/user-images.githubusercontent.com\/15677328\/100879917-04598f00-34e7-11eb-93ec-a722b70bbcc4.png)\r\n\r\nIf this feature is supported, it will be so cool!","486":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [X] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**:\r\n- **Python version**:\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nAfter setting MLFLOW_EXPERIMENT_NAME as environment variable, `python <filename>.py` run produces an experiment run in the UI with the specified RUN Name as shown below:\r\n![issue_ankan](https:\/\/user-images.githubusercontent.com\/51693147\/100780999-791dc200-3430-11eb-8c1e-6721e2a8d720.JPG)\r\n\r\n\r\n\r\nHowever, while running the same script as a project with `mlflow run .` , the Run Name is logged as parameter.\r\n\r\n![issue_ankan_2](https:\/\/user-images.githubusercontent.com\/51693147\/100781275-d31e8780-3430-11eb-9177-3e0321883c4f.JPG)\r\n\r\n\r\n### Code to reproduce issue\r\n`import mlflow`\r\n`import os`\r\n\r\n`experiment_name = os.environ[\"MLFLOW_EXPERIMENT_NAME\"]`\r\n\r\n`mlflow.set_experiment(experiment_name)`\r\n\r\n`mlflow.start_run(run_name=\"BaselineModel\")`\r\n     ` mlflow.log_param(\"abc\",\"yes\")`\r\n      `mlflow.log_metric(\"score\",100)`\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [X] `language\/Python`: Python APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","487":"### System information\r\n- **OS Platform and Distribution**: macOS\r\n- **MLflow version**:  mlflow version 1.9.1\r\n- **Python version**: 3.9\r\n\r\n### Describe the problem\r\nI save my model and run MLflow UI like this\r\n'''\r\n    mlflow.set_tracking_uri(\"file:\/models\")\r\n    mlflow.xgboost.autolog()\r\n    mlflow.set_experiment(\"model\")\r\n    \u2026\u2026\r\n    mlflow.xgboost.save_model(model,\".\/models\/mymodel-%s\" % run_name)\r\n    mlflow.xgboost.log_model(model,artifact_path='1')\r\n'''\r\nthen I get error\r\n\r\nTraceback (most recent call last):\r\n  File \"\/Users\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/store\/tracking\/file_store.py\", line 197, in list_experiments\r\n    experiment = self._get_experiment(exp_id, view_type)\r\n  File \"\/Users\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/store\/tracking\/file_store.py\", line 260, in _get_experiment\r\n    meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\r\n  File \"\/Users\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/utils\/file_utils.py\", line 167, in read_yaml\r\n    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\r\nmlflow.exceptions.MissingConfigException: Yaml file '\/Path\/to\/mymodel\/meta.yaml' does not exist.\r\nMalformed experiment 'mymodel'. Detailed error Yaml file \r\n","488":"Signed-off-by: harupy <17039389+harupy@users.noreply.github.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nSee this comment: https:\/\/github.com\/mlflow\/mlflow\/pull\/3731#discussion_r532318129\r\n\r\n## How is this patch tested?\r\n\r\n(Details)\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","489":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **MLflow installed from (source or binary)**: Binary (pip)\r\n- **MLflow version (run ``mlflow --version``)**: 1.12.0\r\n- **Python version**: 3.6\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n```python\r\nmlflow.log_artifact(\"\/path\/to\/file\", artifact_path=\"<<Azure Blob Storage URI>>\")\r\n```\r\n\r\n### Describe the problem\r\nSimilar to issue  #3478 (except this is referring to the Python version), the Azure Blob Storage Python SDK causes a timeout if the upload takes too long. This can be solved by setting the `timeout` keyword when uploading a file, but MLFlow does not provide a way to set this value. I have implemented [solution](https:\/\/github.com\/ismailuddin\/mlflow\/commit\/e0e9148ea8a7e19ecb060de750bd3c5e02d71b34) in a fork of my own, which uses an environment value that can be set. If this approach is suitable, I can make a PR for it.\r\n\r\n### Code to reproduce issue\r\n```python\r\nmlflow.log_artifact(\"\/path\/to\/file\", artifact_path=\"<<Azure Blob Storage URI>>\")\r\n```\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [x] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","490":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nSeveral Sciki-learn models has attributes that can be an `int` or a `None` for example in `sklearn.ensemble.RandomForestClassifier` the parameter `max_depth`. \r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- Why is this use case valuable to support for MLflow users in general? Because many sklearn models and other libraries allows some parameters to be an `int`, `float` ... or a None.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","491":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nRight now for MLflow Projects just `string`, `float`, `path` and `uri` types are supported.\r\nI would like to have `int`, `bool`, `list`, `dict` and `set` types as well.\r\n\r\nI think that adding `int` and `bool` would be easy. \r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","492":"## What changes are proposed in this pull request?\r\n\r\nPatch for https:\/\/github.com\/mlflow\/mlflow\/issues\/3741\r\n\r\n## How is this patch tested?\r\n\r\nTested manually using our K8S cluster\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [* ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nThis patch introduces an env named as 'SKIP_DOCKER_IMAGE_BUILD' for the kubernetes backend. If this env is defined, the kubernetes backend will not build and push a new docker image to run the experiment. Instead, the backend will use the values associated with 'repository-uri' and 'image-digest' defined in kubernetes_config.json to compose the docker image uri when launching K8S jobs.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ *] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","493":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [* ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nThe current 'kubernetes' backend requires users to rebuild and push docker images for every run. However, this makes it difficult to launch mlflow from a pod inside a Kubernetes cluster, as one normally cannot build docker image inside a pod. We should provide an option to users to launch mlflow runs with existing docker images, which could be built by some other tools or processes.\r\n\r\n## Motivation\r\nTo my understanding, the reason why we need to build a new docker image for each mlflow run is to package code and data in the working directory into the image. But \r\n1. Ideally this packaging should only happen once when the source code or runtime dependency changes. We may run the experiments multiple times using various arguments but these runs do not require new images. \r\n2. It is not always necessary to package everything into a new docker, since we normally have CI pipelines to build docker images and distribute code via git or data volumes in K8S.\r\n\r\nMoreover, rebuilding and pushing images for each run is also a blocker to deploy the entire mlflow stack into a Kubernetes cluster. We prefer to develop mlflow projects in K8S Pods and launch multiple runs directly using the kubernetes backend. However, we won't allow user to build and push docker images inside a Pod for security reasons. \r\n\r\nSo it would be nice if we allows mlflow users to use a flag to skip docker image building\/pushing when start runs with the 'kubernetes' backend. \r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [* ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","494":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 10.15.7\r\n- **MLflow installed from (source or binary)**: binary (pip)\r\n- **MLflow version (run ``mlflow --version``)**: 1.12.1\r\n- **Python version**: 3.7.7\r\n- **npm version, if running the dev UI**: \r\n- **Exact command to reproduce**: Register a model from a run including a \"\/\" in the model name\r\n\r\n### Describe the problem\r\nIf a model name contains a \"\/\", e.g. \"my-namespace\/my-model\", then it is interpreted as a path when building the URL to that model and clicking on it will return a 404 error.\r\n\r\n### Code to reproduce issue\r\nNo code necessary. UI issue.\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","495":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\nIt would be helpful to support pagination for experiment listing. A list request would come back with a subset of results and a continuation token. That token could then be passed in with a next request to get the subsequent subset of results and a second token, etc.\r\n\r\n## Motivation\r\n- What is the use case for this feature? For workspaces with many experiments, it can be too much to get a list of all experiments at once, but a user may still want a way to go through all experiments. Pagination is the standard way to make that possible.\r\n- Why is this use case valuable to support for MLflow users in general? Introducing pagination gives users more levers directly, but also enables downstream scenarios like UIs built on MLflow APIs to improve their performance.\r\n- Why is this use case valuable to support for your project(s) or organization? Some of our key scenarios are failing because pagination is currently unsupported for ListExperiments from the MLflow side.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient) If we need to search through every experiment in a workspace right now, there's no way to do that other than to get the full list of experiments all at once.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n\r\nThe plan would be to base this work on [this PR](https:\/\/github.com\/mlflow\/mlflow\/pull\/1542) which added similar support to SearchRuns.","496":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\n\r\n## Motivation\r\n- What is the use case for this feature? It is hard to work with exported csv without Date columns\r\n- Why is this use case valuable to support for MLflow users in general? It is hard to work with exported csv without Date columns\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","497":"File \"train_mlflow.py\", line 407, in train_keras\r\n    callbacks=callbacks,initial_epoch=latest_epoch)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/mlflow\/tensorflow.py\", line 1031, in fit_generator\r\n    result = original(self, *args, **kwargs)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/tensorflow\/python\/keras\/engine\/training.py\", line 1433, in fit_generator\r\n    steps_name='steps_per_epoch')\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/tensorflow\/python\/keras\/engine\/training_generator.py\", line 331, in model_iteration\r\n    callbacks.on_epoch_end(epoch, epoch_logs)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/tensorflow\/python\/keras\/callbacks.py\", line 311, in on_epoch_end\r\n    callback.on_epoch_end(epoch, logs)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/tensorflow\/python\/keras\/callbacks_v1.py\", line 401, in on_epoch_end\r\n    self._write_custom_summaries(step, logs)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/tensorflow\/python\/keras\/callbacks_v1.py\", line 342, in _write_custom_summaries\r\n    self.writer.add_summary(summary, step)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/mlflow\/tensorflow.py\", line 1049, in add_summary\r\n    _flush_queue()\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/mlflow\/tensorflow.py\", line 583, in _flush_queue\r\n    client = mlflow.tracking.MlflowClient()\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/mlflow\/tracking\/client.py\", line 54, in __init__\r\n    self._tracking_client = TrackingServiceClient(final_tracking_uri)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 38, in __init__\r\n    self.store = utils._get_store(self.tracking_uri)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/mlflow\/tracking\/_tracking_service\/utils.py\", line 155, in _get_store\r\n    return _tracking_store_registry.get_store(store_uri, artifact_uri)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/mlflow\/tracking\/_tracking_service\/registry.py\", line 38, in get_store\r\n    return builder(store_uri=store_uri, artifact_uri=artifact_uri)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/mlflow\/tracking\/_tracking_service\/utils.py\", line 117, in _get_sqlalchemy_store\r\n    return SqlAlchemyStore(store_uri, artifact_uri)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/mlflow\/store\/tracking\/sqlalchemy_store.py\", line 116, in __init__\r\n    inspected_tables = set(sqlalchemy.inspect(self.engine).get_table_names())\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/sqlalchemy\/inspection.py\", line 64, in inspect\r\n    ret = reg(subject)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/reflection.py\", line 139, in _insp\r\n    return Inspector.from_engine(bind)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/reflection.py\", line 134, in from_engine\r\n    return bind.dialect.inspector(bind)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/sqlalchemy\/dialects\/postgresql\/base.py\", line 2401, in __init__\r\n    reflection.Inspector.__init__(self, conn)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/reflection.py\", line 108, in __init__\r\n    bind.connect().close()\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/base.py\", line 2263, in connect\r\n    return self._connection_cls(self, **kwargs)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/base.py\", line 104, in __init__\r\n    else engine.raw_connection()\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/base.py\", line 2370, in raw_connection\r\n    self.pool.unique_connection, _connection\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/base.py\", line 2340, in _wrap_pool_connect\r\n    e, dialect, self\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/base.py\", line 1584, in _handle_dbapi_exception_noconnection\r\n    sqlalchemy_exception, with_traceback=exc_info[2], from_=e\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/sqlalchemy\/util\/compat.py\", line 182, in raise_\r\n    raise exception\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/base.py\", line 2336, in _wrap_pool_connect\r\n    return fn()\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/sqlalchemy\/pool\/base.py\", line 304, in unique_connection\r\n    return _ConnectionFairy._checkout(self)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/sqlalchemy\/pool\/base.py\", line 778, in _checkout\r\n    fairy = _ConnectionRecord.checkout(pool)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/sqlalchemy\/pool\/base.py\", line 495, in checkout\r\n    rec = pool._do_get()\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/sqlalchemy\/pool\/impl.py\", line 140, in _do_get\r\n    self._dec_overflow()\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/sqlalchemy\/util\/langhelpers.py\", line 70, in __exit__\r\n    with_traceback=exc_tb,\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/sqlalchemy\/util\/compat.py\", line 182, in raise_\r\n    raise exception\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/sqlalchemy\/pool\/impl.py\", line 137, in _do_get\r\n    return self._create_connection()\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/sqlalchemy\/pool\/base.py\", line 309, in _create_connection\r\n    return _ConnectionRecord(self)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/sqlalchemy\/pool\/base.py\", line 440, in __init__\r\n    self.__connect(first_connect_check=True)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/sqlalchemy\/pool\/base.py\", line 661, in __connect\r\n    pool.logger.debug(\"Error on connect(): %s\", e)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/sqlalchemy\/util\/langhelpers.py\", line 70, in __exit__\r\n    with_traceback=exc_tb,\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/sqlalchemy\/util\/compat.py\", line 182, in raise_\r\n    raise exception\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/sqlalchemy\/pool\/base.py\", line 656, in __connect\r\n    connection = pool._invoke_creator(self)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/strategies.py\", line 114, in connect\r\n    return dialect.connect(*cargs, **cparams)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/default.py\", line 493, in connect\r\n    return self.dbapi.connect(*cargs, **cparams)\r\n  File \"\/home\/ubuntu\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.7\/site-packages\/psycopg2\/__init__.py\", line 127, in connect\r\n    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)\r\nsqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  remaining connection slots are reserved for non-replication superuser and rds_superuser connections\r\n(Background on this error at: http:\/\/sqlalche.me\/e\/13\/e3q8)\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nthis issue i am facing on postgresql database,plzz give me solution other than increase connection slot in database.\r\nthanx","498":"Hi\r\nI am wondering if paramiko should be listed in  requirements,txt?\r\nAs we can see, paramiko is used in the following screenshot as a must. But when I use \"pip install mlflow\", it seems that paramiko will not be installed automatically. So should paramiko be listed as dependency? If not, why?\r\n![image](https:\/\/user-images.githubusercontent.com\/27858725\/99873920-6defb880-2c1e-11eb-94a0-1abbd2689c1e.png)\r\n","499":"## What changes are proposed in this pull request?\r\n\r\nAdding an sklearn gridsearch example to show how to log metrics, best parameters, and best model to MLflow.\r\n\r\n## How is this patch tested?\r\n\r\nTested in both Databricks and a Jupyter notebook\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [x] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","500":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [X] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: 1.11.0\r\n- **Python version**: 3.7\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI was not able to change the artifacts URI for an existing experiment. I was running mlflow with local files system as artifacts location and then later tried to use Azure. However, the files were still getting stored at local only. Once I changed the MLFlow experiment name it started logging in Azure. There was no warning or error. I couldn't find any documentation around this as well.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [X] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n","501":"The paramers are stored as strings. But when you have numeric values as strings the sorting is not optimal. See screenshot below.\r\n\r\n<img width=\"155\" alt=\"MLflow_sorting\" src=\"https:\/\/user-images.githubusercontent.com\/229382\/99562332-44d5ea80-29c8-11eb-97d4-9ff51170c7f1.PNG\">\r\n\r\nIf parameters are integer only they should be sorted by numerical order.\r\n","502":"Hi\uff0cI fine tune BERT with hugging face(https:\/\/github.com\/huggingface\/transformers) and save the result model to disk, therefore the result model is like\uff1a\r\n![image](https:\/\/user-images.githubusercontent.com\/10300313\/99502434-046e7080-29b8-11eb-8393-9b424f9cf281.png)\r\nIs there any example show how to deploy my result model ? Thanks a lot !","503":"### Willingness to contribute\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes, see the reproduction code below\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10  (&Ubuntu 18.04)\r\n- **MLflow installed from (source or binary)**: pip install mlflow\r\n- **MLflow version (run ``mlflow --version``)**: 1.12.0\r\n- **Python version**: 3.8.5\r\n- **npm version, if running the dev UI**: \r\n- **Exact command to reproduce**: run reproduction code\r\n\r\n### Describe the problem\r\nBecause python on Windows has a different mechanism for multiprocessing (spawn, not fork), mlflow.start_run assigns new run_id-s as many as the number of processes. This does not happen on Linux. I'd like to have the same result on Windows as on Linux. \r\n\r\nMaybe if I can assign run_id manually before `mlflow.start_run()`, it might be a workaround.\r\n\r\n### Code to reproduce issue\r\n\r\n```\r\nfrom multiprocessing import Process\r\nimport mlflow\r\n\r\nimport random\r\n\r\ndef worker(id):\r\n    for i in range(10):\r\n        mlflow.log_metric(\"i\", i+id*100)\r\n        mlflow.log_metric(\"random\", random.random())\r\n\r\ndef main():\r\n    ps = [Process(target=worker, args=(idx, )) for idx in range(10)]\r\n\r\n    with mlflow.start_run():\r\n        mlflow.log_param(\"test\", 0)\r\n        for p in ps:\r\n            p.start()\r\n        for p in ps:\r\n            p.join()\r\n\r\nif __name__ == \"__main__\":\r\n   main() \r\n```\r\n\r\n### Other info \/ logs\r\nOn Windows, \r\n```\r\nmlruns\r\n\u2514\u2500\u2500 0\r\n    \u251c\u2500\u2500 0923090c0e8a48c1ad2806eda88eaab5\r\n    \u251c\u2500\u2500 169e98c4aee045268f0c7fe69badc3f2\r\n    \u251c\u2500\u2500 204b344b0f6c4f5c85614ab2708ffae5\r\n    \u251c\u2500\u2500 8329fa81732f4d09a4f54bde9059e445\r\n    \u251c\u2500\u2500 86d15c82cf16405aa80f855f317c659e\r\n    \u251c\u2500\u2500 992bb9a789cd4abeb898941162493170\r\n    \u251c\u2500\u2500 9dc6ac9fc8724e6986b53579e5caa6a4\r\n    \u251c\u2500\u2500 ad78ec27aec74ae9a66002cae1b9d152\r\n    \u251c\u2500\u2500 cdde35adc1ec46f287d6460927fb482a\r\n    \u251c\u2500\u2500 d7275185463447ad95d3d2caa0510d80\r\n    \u251c\u2500\u2500 f60e899f099c496ca35843fd5f34ea73\r\n    \u2514\u2500\u2500 meta.yaml\r\n```\r\n\r\nOn Linux\r\n```\r\nmlruns\r\n\u2514\u2500\u2500 0\r\n    \u251c\u2500\u2500 abcad6f993b54344b8c541b523a8b628\r\n    \u2514\u2500\u2500 meta.yaml\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [x] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","504":"The logging client automaticaly logs the source file. It works fine for python scripts. But when logging from Jupyter Notebooks (Jupyter Lab in my case) it detects: ipykernel_launcher.py \r\n\r\nThat should detect the notebook (.ipynb file).","505":"When I have nested runs and delete the parent run the child runs are not deleted. Instead they are changed to top level runs.\r\n\r\nIMO this should be changed so that child runs are deleted together with the parents.","506":"You seem to display only 3 digits after the \".\" when displaying metrics. Could you please extend that to all digits? If the column is small when displayed on the GUI it will be shortened anyway...\r\n\r\n![grafik](https:\/\/user-images.githubusercontent.com\/229382\/99186559-5feaf500-2751-11eb-9a1a-a944127f11cc.png)\r\n","507":"This is the same FR as #3691 (Persist state of \"Hide Experiment List\".) but with persistence of the \"Columns Selection\".\r\n\r\nAlso see mlflow-mailing list topic: \"How to either memorize column selection, or use sql to query mlflow?\"","508":"The Tracking Server GUI has a sidebar at the left. It has an \"Hide Experiment List\" button. The state is not persisted. When reloading the page or changing into a run and back to the experiment the bar is visible again if you did hide it before. It would be very nice if the state of the sidebar would be persisted.","509":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.04\r\n- **MLflow installed from (source or binary)**: Binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.11 and 1.12\r\n- **Python version**: 3.6.9 Anaconda\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nCalling `mlflow.pytorch.log_model` yields a warning about being unable to log model metadata and suggests the MLFlow sever may be out of date even though Python package and server are the same version and both are either v1.11.0 or v1.12.0. Removing the try catch generating the warning reveals the length limit of a REST call is being violated.\r\n\r\n### Code to reproduce issue\r\n1. Clone retinanet-examples repo: https:\/\/github.com\/NVIDIA\/retinanet-examples\r\n2. Instrument to save model using `mlflow.pytorch.log_model` to a Postgres backend store and FTP artifact store.\r\n3. Execute `ODTK train`\r\n\r\n### Other info \/ logs\r\nThe exact error is:\r\n`2020\/11\/13 20:54:21 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under ftp:\/\/mlflow:mlflow@localhost\/4\/0bb3d83deea74868bb0bf2a838460223\/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the  tracking store. If logging to a mlflow server via REST, consider  upgrading the server version to MLflow 1.7.0 or above.`.\r\n\r\nRemoving the `try-catch` from `def log` in `mlflow\/models\/model.py` reveals the stack trace:\r\n```\r\nTraceback (most recent call last):\r\n  File \"\/opt\/conda\/bin\/odtk\", line 11, in <module>\r\n    load_entry_point('odtk', 'console_scripts', 'odtk')()\r\n  File \"\/home\/repos\/retinanet-examples\/retinanet\/main.py\", line 251, in main\r\n    worker(0, args, 1, model, state)\r\n  File \"\/home\/repos\/retinanet-examples\/retinanet\/main.py\", line 186, in worker\r\n    regularization_l2=args.regularization_l2, rotated_bbox=args.rotated_bbox, absolute_angle=args.absolute_angle)\r\n  File \"\/home\/repos\/retinanet-examples\/retinanet\/train.py\", line 241, in train\r\n    mlflow.pytorch.log_model(model, state['path'])\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/pytorch\/__init__.py\", line 193, in log_model\r\n    **kwargs\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/models\/model.py\", line 163, in log\r\n    mlflow.tracking.fluent._record_logged_model(mlflow_model)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/tracking\/fluent.py\", line 333, in _record_logged_model\r\n    MlflowClient()._record_logged_model(run_id, mlflow_model)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/tracking\/client.py\", line 299, in _record_logged_model\r\n    self._tracking_client._record_logged_model(run_id, mlflow_model)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 255, in _record_logged_model\r\n    self.store.record_logged_model(run_id, mlflow_model)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 288, in record_logged_model\r\n    self._call_endpoint(LogModel, req_body)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 52, in _call_endpoint\r\n    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/utils\/rest_utils.py\", line 155, in call_endpoint\r\n    response = verify_rest_response(response, endpoint)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/utils\/rest_utils.py\", line 117, in verify_rest_response\r\n    raise RestException(json.loads(response.text))\r\nmlflow.exceptions.RestException: INVALID_PARAMETER_VALUE: Tag value '[{\"run_id\": \"4f65dbd571364b3483d8cf155d7fa325\", \"artifact_path\": \"test.pth\", \"utc_time_created\": \"2020-11-13 21:01:50.210020\", \"flavors\": {\"pytorch\": {\"model_data\": \"data\", \"pytorch_version\": \"1.5.0a0+8f84ded\"}, \"python_function\": {\"pickle_module_nam' had length 5031, which exceeded length limit of 5000\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","510":"AFAIK MLflow must store artifacts in an Artifact Store:\r\n- Amazon S3 and S3-compatible storage\r\n- Azure Blob Storage\r\n- Google Cloud Storage\r\n- FTP server\r\n- SFTP Server\r\n- NFS\r\n- HDFS\r\n\r\nIt would be nice if the Artifact can just be transfered by HTTP and REST to the tracking server and there stored in locale file system. That seems to be unpossible at the moment.","511":"It is possible to wite notes to runs. When looking at the overview table at experiment level it would be nice\r\nif the runs with a note would be marked with an icon. That way I would better find my notes...\r\n\r\nLike this:\r\n![grafik](https:\/\/user-images.githubusercontent.com\/229382\/99112547-2057c800-25ee-11eb-89cb-673d5e43b340.png)\r\n","512":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nRight now the stages in model registry is fixed, would be useful to allow user define their own.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nAllow users to customize their CI\/CD pipeline, e.g. we relying on mlflow stage to build our CI\/CD pipeline, but there are cases the current list of stages can't cover, like model shadowing before go production.\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\nMake mlflow easier to extend \r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nWe will use this feature to improve our existing CI\/CD pipeline and capture different stages of the models better.\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","513":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **MLflow installed from (source or binary)**: Binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.12\r\n- **Python version**: 3.6\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n\r\nModels that make use of np.datetime64 objects cannot have their signatures inferred. One can convert the column to a np.int64, but that introduces a processing step. Could we automatically infer them as `long`? The scoring server seems to already do this (see below). If not, some documentation for best practices with this behaviour would be good (which I can contribute). \r\n\r\n### Code to reproduce issue\r\n\r\n```python\r\nIn [25]: import pandas as pd\r\n\r\nIn [26]: import numpy as np\r\n\r\nIn [27]: dates = pd.date_range('1\/1\/2000', periods=8)\r\n\r\nIn [28]: df = pd.DataFrame(dates, columns=['timestamps'])\r\n\r\nIn [29]: df\r\nOut[29]:\r\n  timestamps\r\n0 2000-01-01\r\n1 2000-01-02\r\n2 2000-01-03\r\n3 2000-01-04\r\n4 2000-01-05\r\n5 2000-01-06\r\n6 2000-01-07\r\n7 2000-01-08\r\n\r\nIn [30]: from mlflow.models import infer_signature\r\n\r\nIn [33]: infer_signature(df)\r\n---------------------------------------------------------------------------\r\nMlflowException                           Traceback (most recent call last)\r\n<ipython-input-33-290f50834d60> in <module>\r\n----> 1 infer_signature(df)\r\n\r\n~\\anaconda3\\envs\\mlflow\\lib\\site-packages\\mlflow\\models\\signature.py in infer_signature(model_input, model_output)\r\n    121     :return: ModelSignature\r\n    122     \"\"\"\r\n--> 123     inputs = _infer_schema(model_input)\r\n    124     outputs = _infer_schema(model_output) if model_output is not None else None\r\n    125     return ModelSignature(inputs, outputs)\r\n\r\n~\\anaconda3\\envs\\mlflow\\lib\\site-packages\\mlflow\\types\\utils.py in _infer_schema(data)\r\n     60     elif isinstance(data, pd.DataFrame):\r\n     61         return Schema(\r\n---> 62             [ColSpec(type=_infer_numpy_array(data[col].values), name=col) for col in data.columns]\r\n     63         )\r\n     64     elif isinstance(data, np.ndarray):\r\n\r\n~\\anaconda3\\envs\\mlflow\\lib\\site-packages\\mlflow\\types\\utils.py in <listcomp>(.0)\r\n     60     elif isinstance(data, pd.DataFrame):\r\n     61         return Schema(\r\n---> 62             [ColSpec(type=_infer_numpy_array(data[col].values), name=col) for col in data.columns]\r\n     63         )\r\n     64     elif isinstance(data, np.ndarray):\r\n\r\n~\\anaconda3\\envs\\mlflow\\lib\\site-packages\\mlflow\\types\\utils.py in _infer_numpy_array(col)\r\n    162             )\r\n    163     else:\r\n--> 164         return _infer_numpy_dtype(col.dtype)\r\n    165\r\n    166\r\n\r\n~\\anaconda3\\envs\\mlflow\\lib\\site-packages\\mlflow\\types\\utils.py in _infer_numpy_dtype(dtype)\r\n    115             \"_map_numpy_array instead.\"\r\n    116         )\r\n--> 117     raise MlflowException(\"Unsupported numpy data type '{0}', kind '{1}'\".format(dtype, dtype.kind))\r\n    118\r\n    119\r\n\r\nMlflowException: Unsupported numpy data type 'datetime64[ns]', kind 'M'\r\n```\r\n\r\nWorkaround, convert timestamps to np.int64 and signature will be of type `long`: \r\n\r\n```\r\ndf['timestamps'] = df['timestamps'].astype(np.int64)\r\n```\r\n\r\n### Other info \/ logs\r\n\r\nThere is some subtlety here with how this interacts with the prediction server. If you have the signature use the `np.int64` type, then the signature will have type `long`. The prediction server will then happily accept datetimes serialized from pandas as either timestamps or iso format. In the following toy example, a simple pyfunc server accepts `np.int64` types, which are correctly converted:\r\n\r\n```python\r\nIn [1]: import numpy as np\r\n\r\nIn [2]: import pandas as pd\r\n\r\nIn [3]: dates = pd.date_range('1\/1\/2000', periods=6)\r\n   ...: x = [5,-1,11,10.0,0,0]\r\n   ...: data = pd.DataFrame({'timestamps': dates, 'X':x})\r\n   ...: data.head()\r\nOut[3]:\r\n  timestamps     X\r\n0 2000-01-01   5.0\r\n1 2000-01-02  -1.0\r\n2 2000-01-03  11.0\r\n3 2000-01-04  10.0\r\n4 2000-01-05   0.0\r\n\r\n# use iso formatting\r\nIn [4]: data_json = data.to_json(orient='split', date_format='iso')\r\n   ...: data_json\r\nOut[4]: '{\"columns\":[\"timestamps\",\"X\"],\"index\":[0,1,2,3,4,5],\"data\":[[\"2000-01-01T00:00:00.000Z\",5.0],[\"2000-01-02T00:00:00.000Z\",-1.0],[\"2000-01-03T00:00:00.000Z\",11.0],[\"2000-01-04T00:00:00.000Z\",10.0],[\"2000-01-05T00:00:00.000Z\",0.0],[\"2000-01-06T00:00:00.000Z\",0.0]]}'\r\n\r\nIn [6]: import requests\r\n\r\nIn [7]: reply = requests.post('http:\/\/localhost:5000\/invocations',data=data_json, headers={\"Content-Type\": \"application\r\n   ...: \/json; format=pandas-split\"})\r\n\r\nIn [8]: reply.json()\r\nOut[8]:\r\n[{'Y': False},\r\n {'Y': True},\r\n {'Y': True},\r\n {'Y': False},\r\n {'Y': False},\r\n {'Y': False}]\r\n\r\n# this time serialize to ns timestamps\r\nIn [9]: data_json = data.to_json(orient='split')\r\n   ...: data_json\r\nOut[9]: '{\"columns\":[\"timestamps\",\"X\"],\"index\":[0,1,2,3,4,5],\"data\":[[946684800000,5.0],[946771200000,-1.0],[946857600000,11.0],[946944000000,10.0],[947030400000,0.0],[947116800000,0.0]]}'\r\n\r\nIn [10]: reply = requests.post('http:\/\/localhost:5000\/invocations',data=data_json, headers={\"Content-Type\": \"applicatio\r\n    ...: n\/json; format=pandas-split\"})\r\n\r\nIn [11]: reply.json()\r\nOut[11]:\r\n[{'Y': False},\r\n {'Y': True},\r\n {'Y': True},\r\n {'Y': False},\r\n {'Y': False},\r\n {'Y': False}]\r\n```\r\n\r\nIn both cases, the dataframe is read in correctly:\r\n\r\n```\r\n           timestamps     X\r\n0  946684800000000000   5.0\r\n1  946771200000000000  -1.0\r\n2  946857600000000000  11.0\r\n3  946944000000000000  10.0\r\n4  947030400000000000   0.0\r\n5  947116800000000000   0.0\r\n```\r\n\r\nOn the flip side, if one converts the column to an ISO formatted string, so the signature has type `string`, then it doesn't work for numeric inputs. So I think `long` type does make the most sense. \r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","514":"Model serving for a Scikit-learn Linear Regression Model deployed through MLFLOW'S PyFunc works normally only for up to 75 records per request. If the input exceeds this threshold, we receive an empty reply from server, with error code 52. The error is based on the size of the request and not on a specific data\/data quality.\r\n\r\n# Expected behavior\r\n\r\nThe served model implementation does not make any assumptions about input size and thus mlflow should allow to process an arbitrary number of rows in the input via the served endpoint.\r\n\r\n## How to reproduce?\r\n\r\n```\r\nHOSTNAME=localhost\r\n\r\n## prepare model (See attached python script prepare_mlflow_model.py)\r\nexport MODEL_NAME=test_model\r\npython3 prepare_mlflow_model.py\r\n\r\n## Serve the model\r\nmlflow models serve -m ${MODEL_NAME} --host 0.0.0.0 --port 5110  &\r\n\r\n## Consume the model with a simple one-row record \r\ncurl http:\/\/${HOSTNAME}:5110\/invocations -H 'Content-Type: application\/json' -d '{\"columns\":[\"Operation\",\"-7\",\"-6\",\"-5\",\"-4\",\"-3\",\"-2\",\"-1\",\"0\"],\"data\":[[\"A0208\",24.0,24.0,24.0,24.0,24.0,24.0,24.0,4.6]]}'\r\n\r\n## consume same model but with many records --> this fails\r\ncat 480_api_record_example.json | curl http:\/\/${HOSTNAME}:5110\/invocations -H 'Content-Type: application\/json' -d @-\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\n\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.04 LTS\r\n- **MLflow installed from (source or binary)**: source\r\n\r\n\r\n\r\n- **MLflow version (run ``mlflow --version``)**: 1.10\r\n- **Python version**: 3.8.5\r\n[JSON INPUT.txt](https:\/\/github.com\/mlflow\/mlflow\/files\/5536400\/JSON.INPUT.txt)\r\n[mlflow model py script.txt](https:\/\/github.com\/mlflow\/mlflow\/files\/5536407\/mlflow.model.py.script.txt)\r\n\r\n","515":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this installation issue template to ensure a timely and thorough response.**\r\n\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian GNU\/Linux 10 - [a GCP Deep Learning VM](https:\/\/cloud.google.com\/deep-learning-vm)\r\n- **MLflow installed from (source or binary)**: `pip install mlflow`\r\n- **MLflow version (run ``mlflow --version``)**: `mlflow, version 1.11.0`\r\n- **Python version**: Python 3.7.8\r\n- **Exact command to reproduce**: N\/A\r\n\r\n### Describe the problem\r\nProvide the exact sequence of commands \/ steps that you executed before running into the problem.\r\n\r\nStart the mlflow server on the remote VM like so:-\r\n\r\n```\r\npwigg@mlflow:~$ mlflow server --host 0.0.0.0\r\n[2020-11-11 19:30:02 +0000] [10327] [INFO] Starting gunicorn 20.0.4\r\n[2020-11-11 19:30:02 +0000] [10327] [INFO] Listening at: http:\/\/0.0.0.0:5000 (10327)\r\n[2020-11-11 19:30:02 +0000] [10327] [INFO] Using worker: sync\r\n[2020-11-11 19:30:02 +0000] [10330] [INFO] Booting worker with pid: 10330\r\n[2020-11-11 19:30:02 +0000] [10332] [INFO] Booting worker with pid: 10332\r\n[2020-11-11 19:30:02 +0000] [10333] [INFO] Booting worker with pid: 10333\r\n[2020-11-11 19:30:02 +0000] [10334] [INFO] Booting worker with pid: 10334\r\n```\r\n\r\nI am using the `host` option because I want to connect to the UI using an [GCP IAP tunnel](https:\/\/cloud.google.com\/iap\/docs\/using-tcp-forwarding) from my local machine.\r\n\r\nI start an IAP tunnel like so:-\r\n\r\n```gcloud compute start-iap-tunnel mlflow 5000   --local-host-port=localhost:5000   --zone=europe-west3-a   --project my-gcp-project```\r\n\r\nI can now browse to the UI on http:\/\/localhost:5000 from my local machine. The problem is that various of the static assets don't load and fail with ERR_CONTENT_LENGTH_MISMATCH.\r\n\r\n<img width=\"1409\" alt=\"Screenshot 2020-11-11 at 19 40 05\" src=\"https:\/\/user-images.githubusercontent.com\/244059\/98856817-0d11f480-2456-11eb-88d2-1564ac8ef1d1.png\">\r\n\r\nI'm not sure if it's the IAP tunnel here that's causing the issue? It seems strange that no-one else seems to have encountered this and I guess the combination of a GCP IAP tunnel and mlflow is fairly rare.\r\n\r\nI have discovered that moving from the 'sync' worker to the 'gevent' worker fixes it. The gunicorn [docs](https:\/\/docs.gunicorn.org\/en\/stable\/design.html#choosing-a-worker-type) state that, \"[..] we require a buffering proxy in front of a default configuration Gunicorn\" which obviously I don't have in this scenario.\r\n\r\nSwitching to the `gevent` type of worker by adding `--gunicorn-opts \"-k gevent\"` does the trick.\r\n\r\nI'm logging this a) in case it helps anyone else (I spent ages troubleshooting this) but also I'm wondering why `sync` is the default worker type? Are there any drawbacks to using `gevent` that I might encounter?\r\n\r\n","516":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.11.0\r\n\r\n### Describe the problem\r\n\r\n`MlflowClient.list_run_infos()` loads params, metrics, and tags for each run, even though they are not needed. This slows it down dramatically on slow backends with lots of long runs.\r\n\r\n### Code to reproduce issue\r\n\r\n```python\r\nimport mlflow\r\nclient = mlflow.tracking.MlflowClient('file:\/some\/path\/to\/store')\r\ninfos = client.list_run_infos('0')\r\n```\r\n\r\n### Other info \/ logs\r\n\r\nThis function is implemented via `AbstractStore.list_run_infos()`, which calls `AbstractStore.search_runs()`. The latter function loads all run details, even though they are immediately discarded in `list_run_infos()`.\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","517":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\nI can contribute the R part (if any of the implementation is specific to R), ideally someone else implements this for the other language clients. Maybe I can support for Python too.\r\n\r\n## Proposal Summary\r\n\r\nI suggest to allow specifying parameters in MLprojects globally in addition to per entry-point to reduce code duplication.\r\n\r\n## Motivation\r\n\r\nI am using MLflow in my daily workflows and I came across the following problem: MLprojects can grow big in terms of entry points and parameters. Some entry points share parameters, e.g. how to treat missing values. It would be great if these could be defined globally in MLproject instead of by entry point because this would reduce duplication and cognitive burden for the user. In particular if a user wants to change the value of the parameter, it has to be updated in multiple places, which is error prone. Building on the [example](https:\/\/mlflow.org\/docs\/latest\/projects.html#mlproject-file) from the doc, here is how I imagine this to be implemented:\r\n\r\n\r\n```yaml\r\nname: My Project\r\nparameters: # <- This is a new key\r\n  on_missing: {type: string, default: \"error\"}\r\n\r\n\r\nconda_env: my_env.yaml\r\n# Can have a docker_env instead of a conda_env, e.g.\r\n# docker_env:\r\n#    image:  mlflow-docker-example\r\n\r\nentry_points:\r\n  main:\r\n    parameters:\r\n       regularization: {type: float, default: 0.1}\r\n  command: \"python train.py -r {regularization} --on_missing={on_missing}\"\r\n  validate:\r\n    parameters:\r\n      data_file: path\r\n    command: \"python validate.py {data_file} --on_missing={on_missing}\"\r\n```\r\n\r\nI suggest that the parameters defined in an entry point take precedence over the ones defined globally in case both are defined. This is a non-breaking API change and would benefit everyone who uses MLprojects with entry points that share at least one parameter. I think the benefit of this relative to the implementation effort is small. \r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","518":"Signed-off-by: sephi berry <js.berry@gmail.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nFix bug #3595 \r\n\r\n## How is this patch tested?\r\n\r\ntest_local_artifact_repo.py\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [X] No. You can skip the rest of this section.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [X] `area\/artifacts`: Artifact stores and artifact logging\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [X] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","519":"## What changes are proposed in this pull request?\r\n\r\nIf `MLFLOW_EXPERIMENT_NAME` is set, but the experiment referred to in the the env doesn't exist then MLflow uses the `default` experiment name. \r\nThese changes change behaviour so that MLflow creates an experiment with the env var, and then sets that as the experiment name. \r\n\r\n## How is this patch tested?\r\n\r\nThere is an additional test for this function in \r\n`tests\/tracking\/fluent\/test_fluent::test_get_experiment_id_when_with_new_experiment_returns_active_experiment_id`\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nSetting `MLFLOW_EXPERIMENT_NAME` will create the named experiment if it doesn't already exist (previously this value was ignored and `default` was used). \r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n\r\nWith reference to https:\/\/github.com\/mlflow\/mlflow\/issues\/3656","520":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nSetting `MLFLOW_EXPERIMENT_NAME` will create the named experiment if it doesn't already exist (previously this value was ignored and `default` was used). \r\n\r\n## Motivation\r\n\r\nWhen running MLflow as part of an automated process, we expect setting `MLFLOW_EXPERIMENT_NAME` to create experiments with the expected name - updating in code with `mflow.set_experiment()` or on the CLI is less preferable. \r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n","521":"Also  Can someone help me with documentation for using mlflow with system environment with example. There is no much info about mlflow usage in system environment.","522":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- Windows 10:\r\n- **MLflow installed from source\r\n- **MLflow version 1.11.0\r\n- **Python version :3.7.7\r\n\r\n### Describe the problem\r\nI have imported both the mlflow as well as the mlflow.sklearn modules.\r\nWhen calling mlflow.sklearn.autlog(), I am getting the error \"AttributeError: module 'mlflow.sklearn' has no attribute 'autolog'\"\r\n\r\n### Code to reproduce issue\r\nmlflow.sklearn.autolog()\r\nwith mlflow.start_run(nested=True,run_name = \"RF Run\") as child_run:\r\n    #Build Model\r\n    print(\"Training Model\")\r\n    classifier = RandomForestClassifier(max_depth=space['max_depth'],criterion=space['criterion'],\r\n                                            n_estimators=space['n_estimators'],\r\n                                            max_leaf_nodes=space['max_leaf_nodes'],min_samples_split=space['min_samples_split'],\r\n                                            min_samples_leaf=space['min_samples_leaf'])\r\n\r\n### Other info \/ logs\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-13-bb618b130a98> in <module>\r\n      6             algo=tpe.suggest,\r\n      7             max_evals=2,\r\n----> 8             trials=trials)\r\n      9     mlflow.set_tag(\"best params\", str(best))\r\n     10     print(\"Best: \", best)\r\n\r\n~\\.conda\\envs\\myenv\\lib\\site-packages\\hyperopt\\fmin.py in fmin(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\r\n    520             show_progressbar=show_progressbar,\r\n    521             early_stop_fn=early_stop_fn,\r\n--> 522             trials_save_file=trials_save_file,\r\n    523         )\r\n    524 \r\n\r\n~\\.conda\\envs\\myenv\\lib\\site-packages\\hyperopt\\base.py in fmin(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\r\n    697             show_progressbar=show_progressbar,\r\n    698             early_stop_fn=early_stop_fn,\r\n--> 699             trials_save_file=trials_save_file,\r\n    700         )\r\n    701 \r\n\r\n~\\.conda\\envs\\myenv\\lib\\site-packages\\hyperopt\\fmin.py in fmin(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\r\n    551 \r\n    552     # next line is where the fmin is actually executed\r\n--> 553     rval.exhaust()\r\n    554 \r\n    555     if return_argmin:\r\n\r\n~\\.conda\\envs\\myenv\\lib\\site-packages\\hyperopt\\fmin.py in exhaust(self)\r\n    354     def exhaust(self):\r\n    355         n_done = len(self.trials)\r\n--> 356         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)\r\n    357         self.trials.refresh()\r\n    358         return self\r\n\r\n~\\.conda\\envs\\myenv\\lib\\site-packages\\hyperopt\\fmin.py in run(self, N, block_until_done)\r\n    290                 else:\r\n    291                     # -- loop over trials and do the jobs directly\r\n--> 292                     self.serial_evaluate()\r\n    293 \r\n    294                 self.trials.refresh()\r\n\r\n~\\.conda\\envs\\myenv\\lib\\site-packages\\hyperopt\\fmin.py in serial_evaluate(self, N)\r\n    168                 ctrl = base.Ctrl(self.trials, current_trial=trial)\r\n    169                 try:\r\n--> 170                     result = self.domain.evaluate(spec, ctrl)\r\n    171                 except Exception as e:\r\n    172                     logger.error(\"job exception: %s\" % str(e))\r\n\r\n~\\.conda\\envs\\myenv\\lib\\site-packages\\hyperopt\\base.py in evaluate(self, config, ctrl, attach_attachments)\r\n    905                 print_node_on_error=self.rec_eval_print_node_on_error,\r\n    906             )\r\n--> 907             rval = self.fn(pyll_rval)\r\n    908 \r\n    909         if isinstance(rval, (float, int, np.number)):\r\n\r\n<ipython-input-9-7ee39e40337d> in train_model(space)\r\n      2 \r\n      3     #With Autolog, all paramters, metrics and artifacts will be automatically logged\r\n----> 4     mlflow.sklearn.autolog()\r\n      5     with mlflow.start_run(nested=True,run_name = \"RF Run\") as child_run:\r\n      6         #Build Model\r\n\r\nAttributeError: module 'mlflow.sklearn' has no attribute 'autolog'\r\n\r\n\r\n\r\n","523":"python env: \r\npython- 3.7.7\r\nmlflow- 1.10.0\r\n\r\nmlflow project folder created successfully with all the required files.\r\ngetting the following error while tried to deploy the model. \r\n\r\n(custom_ml_env) C:\\Users\\644947\\CSAT\\custom_model_templates\\mlflow_impl_guide\\classification>mlflow models serve -m runs:\/92c6059bbea54c378bf1320f1a5632d1\/artifacts\/model -p 1234 --no-conda\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\644947\\python3.7.7\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"C:\\Users\\644947\\python3.7.7\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\644947\\custom_ml_env\\Scripts\\mlflow.exe\\__main__.py\", line 9, in <module>\r\n  File \"c:\\users\\644947\\custom_ml_env\\lib\\site-packages\\click\\core.py\", line 829, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"c:\\users\\644947\\custom_ml_env\\lib\\site-packages\\click\\core.py\", line 782, in main\r\n    rv = self.invoke(ctx)\r\n  File \"c:\\users\\644947\\custom_ml_env\\lib\\site-packages\\click\\core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"c:\\users\\644947\\custom_ml_env\\lib\\site-packages\\click\\core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"c:\\users\\644947\\custom_ml_env\\lib\\site-packages\\click\\core.py\", line 1066, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"c:\\users\\644947\\custom_ml_env\\lib\\site-packages\\click\\core.py\", line 610, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"c:\\users\\644947\\custom_ml_env\\lib\\site-packages\\mlflow\\models\\cli.py\", line 58, in serve\r\n    install_mlflow=install_mlflow).serve(model_uri=model_uri, port=port,\r\n  File \"c:\\users\\644947\\custom_ml_env\\lib\\site-packages\\mlflow\\models\\cli.py\", line 165, in _get_flavor_backend\r\n    append_to_uri_path(underlying_model_uri, MLMODEL_FILE_NAME), output_path=tmp.path())\r\n  File \"c:\\users\\644947\\custom_ml_env\\lib\\site-packages\\mlflow\\tracking\\artifact_utils.py\", line 74, in _download_artifact_from_uri\r\n    artifact_path=artifact_path, dst_path=output_path)\r\n  File \"c:\\users\\644947\\custom_ml_env\\lib\\site-packages\\mlflow\\store\\artifact\\runs_artifact_repo.py\", line 116, in download_artifacts\r\n    return self.repo.download_artifacts(artifact_path, dst_path)\r\n  File \"c:\\users\\644947\\custom_ml_env\\lib\\site-packages\\mlflow\\store\\artifact\\local_artifact_repo.py\", line 67, in download_artifacts\r\n    return super(LocalArtifactRepository, self).download_artifacts(artifact_path, dst_path)\r\n  File \"c:\\users\\644947\\custom_ml_env\\lib\\site-packages\\mlflow\\store\\artifact\\artifact_repo.py\", line 130, in download_artifacts\r\n    return download_file(artifact_path)\r\n  File \"c:\\users\\644947\\custom_ml_env\\lib\\site-packages\\mlflow\\store\\artifact\\artifact_repo.py\", line 90, in download_file\r\n    self._download_file(remote_file_path=fullpath, local_path=local_file_path)\r\n  File \"c:\\users\\644947\\custom_ml_env\\lib\\site-packages\\mlflow\\store\\artifact\\local_artifact_repo.py\", line 95, in _download_file\r\n    shutil.copyfile(remote_file_path, local_path)\r\n  File \"C:\\Users\\644947\\python3.7.7\\lib\\shutil.py\", line 120, in copyfile\r\n    with open(src, 'rb') as fsrc:\r\nFileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\644947\\\\CSAT\\\\custom_model_templates\\\\mlflow_impl_guide\\\\classification\\\\mlruns\\\\0\\\\92c6059bbea54c378bf1320f1a5632d1\\\\artifacts\\\\artifacts\\\\model\\\\MLmodel'","524":"Hi all. I am new to mlflow and just installed v 1.11.0 for python 3.8 using `pip3 install mlflow` and this on an Ubuntu 20.04 machine.  I am doing the tutorial at [here](https:\/\/mlflow.org\/docs\/latest\/tutorials-and-examples\/tutorial.html).  After git cloning and training a few models with examples\/sklearn_elasticnet_wine\/train.py, I get to part where you are supposed to do `mlflow ui` to visualize the different models.  Instead I get the full error message within my browser after visiting http:\/\/127.0.0.1:5000\r\n\r\n> Unable to display MLflow UI - landing page (index.html) not found.\r\n\r\n>You are very likely running the MLflow server using a source installation of the Python MLflow\r\npackage.\r\n\r\n>If you are a developer making MLflow source code changes and intentionally running a source\r\ninstallation of MLflow, you can view the UI by running the Javascript dev server:\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#running-the-javascript-dev-server\r\n\r\n>Otherwise, uninstall MLflow via 'pip uninstall mlflow', reinstall an official MLflow release\r\nfrom PyPI via 'pip install mlflow', and rerun the MLflow server.\r\n\r\nIs the pip version not the official release or do I have an incorrect version of something?  I don't think I have a source installation\r\n\r\n","525":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Databricks Runtime Version 6.6\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.11.0\r\n- **Python version**: \r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: \r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\n**Some existing models do not appear in the selection list in the UI when trying to register a model from an existing run. I can however register the model through the API (mlflow.register_model). There seems to be a limit of 100 models that are displayed.**\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Register a model in the UI from an existing run when there are more than 100 models already registered.**\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","526":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nDon't require conda if I specify the MLFLOW_PYTHON_BIN & MLFLOW_BIN. Don't treat R different from python\r\n\r\nI noticed that it is possible to install and run mlflow in python in any type of python environment. I created an environment with pyenv-virtualenv for instance. This is nice, lightweight and works just fine with python and I wanted to use this environment for my R session as well. And so I set the environ vars MLFLOW_PYTHON_BIN, and MLFLOW_BIN and restart the project to use mlflow. But that fails because: the R package is explicitly looking for a conda environment. I would think that setting the two vars, one to the python interpreter and one to the mlflow binary would be enough to run this program. Why does it need to be conda? \r\n \r\n\r\n\r\n## Motivation\r\n- What is the use case for this feature? separate pyton environments and python versions. \r\n- Why is this use case valuable to support for MLflow users in general? don't need to install entire conda ecosystem just to use mlflow\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient) \r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [x] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","527":"## Willingness to contribute\r\n- [x] Yes. I can contribute this feature independently.\r\n\r\n## Proposal Summary\r\nHi! I had a problem with a long param (len > 250). And I've got the exception (MlflowException). Do we need this specific length?\r\nI've tried to cover it with try\/except and understood that I can't find exception as just mlflow.MlflowException.\r\nCurrently It is in the mlflow.tracking.fluent.MlflowException. \r\nCould we move it? \r\nMay I contribute this?\r\n\r\n## Motivation\r\n- Cover mlflow exceptions easily\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging","528":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nWhen I want to build an image on AzureML using mlflow.azureml.build_mage, I can use in the model_uri parameter the format:\r\n\r\n```models:\/<model_name>\/<model_version>```\r\n\r\nWhich imply that my model is already registered.\r\n\r\nWould it be possible then not to re-register it?\r\n\r\n## Motivation\r\nThis would ensure that the model I register \"manually\" is the one that goes into the container.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [x] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nN\/A\r\n","529":"I would like to log files (code and images \/ plots) to Experiments and not just runs. This is because they belong to an automated hyperparameter optimization and not to each single trial (run).\r\n\r\nNow you might say \"just use nested runs and log your files to the root run\". But this is no good option for me:\r\n\r\nSince I do not have an easy to use function to only select and compare all child runs of a root run and do not have a function to sort only child runs by an metric. ","530":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**:\r\n- **Python version**:\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","531":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nSome time ago, Google proposed Model Cards as a way to document models. In words of the author of the paper:\r\n\r\n\"Model cards are short documents accompanying trained machine learning models that provide benchmarked evaluation in a variety of conditions, such as across different cultural, demographic, or phenotypic groups (e.g., race, geographic location, sex, Fitzpatrick skin type) and intersectional groups (e.g., age and race, or sex and Fitzpatrick skin type) that are relevant to the intended application domains. Model cards also disclose the context in which models are intended to be used, details of the performance evaluation procedures, and other relevant information.\"\r\n\r\nI believe it would be a good idea to have a piece of the JS UI dedicated to model documentation, where not only scientists but also stakeholders or other engineers can know the purpose of the model, limitations, type and dimension of inputs\/outputs, inference time, etc. I'm also aware that Model Registry has a description field, but I think it could be extended to a more sophisticated component. See examples of Model Cards from Google here: https:\/\/modelcards.withgoogle.com\/object-detection.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nThis is applicable to users that want to integrate detailed technical and non-technical documentation of models as part of the ML lifecycle.\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\nDocumentation is a vital part of the development and productioning of ML models. It is useful for users of the model as they know what inputs and outputs are expected, as well as its limitations. It is also valuable to stakeholders as they can visualize easily the model performance on the evaluation tests. And finally, documenting the model is a good way to reflect on its behavior and assess fairness and bias.\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n\r\nWe are currently working with a pipeline of 8-10 different ML models, and it is difficult for us to find a single source of truth for documentation that keeps up to date with the continuous improvement of models.\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nBeing completely honest, I haven't dig deep into the Model Registry documentation features, but I feel that having a markdown field for the model description could be insufficient for detailed documentation. I would appreciate a richer interface or set of components. I think it'd be interesting to have some fields where we can play around with the model, upload a dataset for evaluation, etc. (Some of the things that Google Model Cards support).\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nThis proposal would introduce several changes to the codebase. Those changes are mainly focused on the UI part, where the main goal would be to create a richer documentation editor. But some features proposed need changes on the core of MLFlow. For example, if we want to have a field where we can play around with the model, eg. submit inputs and show predictions, we would need to deploy a model for that. Another alternative I'm thinking of is embedding a swagger API REST doc page (#2948) (https:\/\/github.com\/Redocly\/redoc).\r\n\r\nIt would also be great if some of the model metadata, like input\/output type, could be extracted automatically. Google released a toolkit for creating model cards as simple HTML pages, and they use TFX to extract some metadata. I know it is not applicable for the rest of the frameworks supported, but there may be some way to infer that information automatically. \r\n\r\nI apologize in advance for not being very specific, I just wanted to share my idea and get some feedback from the community and see where we can go from here.\r\n\r\nThanks!\r\n\r\n\r\n\r\n","532":"### Willingness to contribute\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Suse\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.10\r\n- **Python version**:\r\n- **Exact command to reproduce**:\r\nmlflow gc --backend-store-uri \"sqlite:\/\/\/\/path\/to\/sqlit3.db\"\r\n\r\n### Describe the problem\r\nWhen run [gc](https:\/\/www.mlflow.org\/docs\/latest\/cli.html#mlflow-gc) - if some of the runs were manually deleted from the artifact folder\/location then the entire gc command fails (or until the 'ghosted' run is encountered).\r\n\r\n### Other info \/ logs\r\nA possible workaround\/solution is to add a try and except to [local_artifact_repo](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/store\/artifact\/local_artifact_repo.py#L110)   \r\n```python\r\ntry:\r\n    shutil.rmtree(local_file_uri_to_path(artifact_path))\r\nexcept OSError as e:\r\n    print(e)\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n\r\nInterface \r\n- [X] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n\r\n","533":"First of all, thanks for the amazing work. This is such a helpful library. \r\n\r\nThis is probably due to sleep deprivation, but I'm stumped by a BAD_REQUEST error after using `mlflow models docker_build` to serve a model. My custom mlflow (pyfunc) models are served with `mlflow models serve` without a problem inside the Docker container where they were originally created with the standard\r\n\r\n`curl http:\/\/127.0.0.1:5002\/invocations -H 'Content-Type: application\/json' -d @df_head.json`\r\n\r\nHowever, when I step outside the container to build a new image with `mlflow models docker_build` and use exactly the same json-file, I get \r\n\r\n\r\n`{\"error_code\": \"BAD_REQUEST\", \"message\": \"Encountered an unexpected error while evaluating the model. Verify that the serialized input Dataframe is compatible with the model for inference.\", \"stack_trace\": \"Traceback (most recent call last):\\n  File \\\"\/miniconda\/envs\/custom_env\/lib\/python3.6\/site-packages\/mlflow\/pyfunc\/scoring_server\/__init__.py\\\", line 213, in transformation\\n    raw_predictions = model.predict(data)\\n  File \\\"\/miniconda\/envs\/custom_env\/lib\/python3.6\/site-packages\/mlflow\/pyfunc\/__init__.py\\\", line 425, in predict\\n    return self._model_impl.predict(data)\\n  File \\\"\/miniconda\/envs\/custom_env\/lib\/python3.6\/site-packages\/mlflow\/pyfunc\/model.py\\\", line 254, in predict\\n    return self.python_model.predict(self.context, model_input)\\n  File \\\"<ipython-input-91-8795afeda7be>\\\", line 32, in predict\\n  File \\\"\/miniconda\/envs\/custom_env\/lib\/python3.6\/site-packages\/pandas\/core\/series.py\\\", line 4200, in apply\\n    mapped = lib.map_infer(values, f, convert=convert_dtype)\\n  File \\\"pandas\/_libs\/lib.pyx\\\", line 2402, in pandas._libs.lib.map_infer\\n  File \\\"<ipython-input-91-8795afeda7be>\\\", line 32, in <lambda>\\n  File \\\"\/miniconda\/envs\/custom_env\/lib\/python3.6\/s `\r\n\r\n\r\nAny thoughts? Yeah, it's probably obvious, but I can't see it \r\n","534":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Custom code for model training and stock code from documentation for deployment to Azure\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.6\r\n- **MLflow installed from (source or binary)**: Source (pip)\r\n- **MLflow version (run ``mlflow --version``)**: 1.11.0\r\n- **Python version**: Tried with 3.6 as well as 3.7.9\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: mlflow.azureml.build_image(model_uri=<my_mlrun_uri>, workspace=ws, synchronous=True)\r\n\r\n### Describe the problem\r\nMLflow deployment on AzureML fails because of a previous version of Numpy.\r\n\r\nI have developed a custom code that I am trying to deploy to Azure using MLFlow. I have used the deployment script multiple times over last couple of months so I know that nothing is wrong there.\r\n\r\nAnyway, I let the image build using the command ```mlflow.azureml.build_image(model_uri=<my_mlrun_uri>, workspace=ws, synchronous=True)``` and build succeeds, but when I deploy the Image as a webservice using Azure Container Instances, the \r\ncode fails with a Timeout Error and the following error:\r\n\r\n```\r\nWebserviceException: WebserviceException:\r\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Unhealthy\r\nOperation ID: 5bcee0af-35b7-45ae-8be3-ff3a610afa2a\r\nMore information can be found using '.get_logs()'\r\nError:\r\n{\r\n  \"code\": \"DeploymentTimedOut\",\r\n  \"statusCode\": 504,\r\n  \"message\": \"The deployment operation polling has TimedOut. The service creation is taking longer than our normal time. We are still trying to achieve the desired state for the web service. Please check the webservice state for the current webservice health. You can run print(service.state) from the python SDK to retrieve the current state of the webservice.\r\nPlease refer to https:\/\/aka.ms\/debugimage#dockerlog for more information.\",\r\n  \"details\": [\r\n    {\r\n      \"code\": \"AciDeploymentFailed\",\r\n      \"message\": \"Your container application crashed. Please follow the steps to debug:\r\n1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https:\/\/aka.ms\/debugimage#dockerlog for more information.\r\n2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https:\/\/aka.ms\/debugimage#debug-locally for more information.\r\n3. View the diagnostic events to check status of container, it may help you to debug the issue. \r\n{\"restartCount\":7,\r\n\"currentState\": {\"state\":\"Waiting\",\"startTime\":null,\"exitCode\":null,\"finishTime\":null,\"detailStatus\":\"CrashLoopBackOff: Back-off 5m0s restarting failed\"},\r\n\"previousState\":{\"state\":\"Terminated\",\"startTime\":\"2020-10-22T18:53:39Z\",\"exitCode\":111,\"finishTime\":\"2020-10-22T18:54:02Z\",\"detailStatus\":\"Error\"},\r\n\"events\":[\r\n{\"count\":3,\"firstTimestamp\":\"2020-10-22T18:28:19Z\",\"lastTimestamp\":\"2020-10-22T18:40:40Z\",\"name\":\"Pulling\",\"message\":\"pulling image \\\\\\\"<IMAGE_NAME>\\\\\\\" \", \"type\":\"Normal\"},\r\n{\"count\":3,\"firstTimestamp\":\"2020-10-22T18:39:31Z\",\"lastTimestamp\":\"2020-10-22T18:40:41Z\",\"name\":\"Pulled\",\"message\":\"Successfully pulled image \\\\\\\"<IMAGE_NAME>\\\\\\\" \",\"type\":\"Normal\"},\r\n{\"count\":3,\"firstTimestamp\":\"2020-10-22T18:39:35Z\",\"lastTimestamp\":\"2020-10-22T18:40:41Z\",\"name\":\"Created\",\"message\":\"Created container\",\"type\":\"Normal\"},\r\n{\"count\":3,\"firstTimestamp\":\"2020-10-22T18:39:35Z\",\"lastTimestamp\":\"2020-10-22T18:40:41Z\",\"name\":\"Started\",\"message\":\"Started container\",\"type\":\"Normal\"},\r\n{\"count\":50,\"firstTimestamp\":\"2020-10-22T18:40:28Z\",\"lastTimestamp\":\"2020-10-22T18:53:23Z\",\"name\":\"BackOff\",\"message\":\"Back-off restarting failed container\",\"type\":\"Warning\"}]}\"\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\n\r\nI pulled up the logs from the Azure Container Instances Services and it is as follows:\r\n```\r\n2020-10-22T06:58:49,020260384+00:00 - iot-server\/run \r\n2020-10-22T06:58:49,019574380+00:00 - rsyslog\/run \r\n2020-10-22T06:58:49,117097008+00:00 - gunicorn\/run \r\n2020-10-22T06:58:49,118285816+00:00 - nginx\/run \r\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\r\n2020-10-22T06:58:51,222442674+00:00 - iot-server\/finish 1 0\r\n2020-10-22T06:58:51,322087216+00:00 - Exit code 1 is normal. Not restarting iot-server.\r\nStarting gunicorn 19.6.0\r\nListening at: http:\/\/127.0.0.1:31311 (12)\r\nUsing worker: sync\r\nworker timeout is set to 300\r\nBooting worker with pid: 41\r\nException in worker process\r\nTraceback (most recent call last):\r\n  File \"\/opt\/miniconda\/lib\/python3.6\/site-packages\/gunicorn\/arbiter.py\", line 557, in spawn_worker\r\n    worker.init_process()\r\n  File \"\/opt\/miniconda\/lib\/python3.6\/site-packages\/gunicorn\/workers\/base.py\", line 126, in init_process\r\n    self.load_wsgi()\r\n  File \"\/opt\/miniconda\/lib\/python3.6\/site-packages\/gunicorn\/workers\/base.py\", line 136, in load_wsgi\r\n    self.wsgi = self.app.wsgi()\r\n  File \"\/opt\/miniconda\/lib\/python3.6\/site-packages\/gunicorn\/app\/base.py\", line 67, in wsgi\r\n    self.callable = self.load()\r\n  File \"\/opt\/miniconda\/lib\/python3.6\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 65, in load\r\n    return self.load_wsgiapp()\r\n  File \"\/opt\/miniconda\/lib\/python3.6\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 52, in load_wsgiapp\r\n    return util.import_app(self.app_uri)\r\n  File \"\/opt\/miniconda\/lib\/python3.6\/site-packages\/gunicorn\/util.py\", line 357, in import_app\r\n    __import__(module)\r\n  File \"\/var\/azureml-server\/wsgi.py\", line 1, in <module>\r\n    import create_app\r\n  File \"\/var\/azureml-server\/create_app.py\", line 3, in <module>\r\n    from app import main\r\n  File \"\/var\/azureml-server\/app.py\", line 31, in <module>\r\n    import main as user_main\r\n  File \"\/var\/azureml-app\/main.py\", line 12, in <module>\r\n    driver_module_spec.loader.exec_module(driver_module)\r\n  File \"\/var\/azureml-app\/execution_script.py\", line 2, in <module>\r\n    import pandas as pd\r\n  File \"\/opt\/miniconda\/lib\/python3.6\/site-packages\/pandas\/__init__.py\", line 22, in <module>\r\n    from pandas.compat.numpy import (\r\n  File \"\/opt\/miniconda\/lib\/python3.6\/site-packages\/pandas\/compat\/numpy\/__init__.py\", line 21, in <module>\r\n    \"this version of pandas is incompatible with numpy < 1.15.4\\n\"\r\nImportError: this version of pandas is incompatible with numpy < 1.15.4\r\nyour numpy version is 1.14.2.\r\nPlease upgrade numpy to >= 1.15.4 to use this pandas version\r\nWorker exiting (pid: 41)\r\nShutting down: Master\r\nReason: Worker failed to boot.\r\n2020-10-22T06:59:16,624645953+00:00 - gunicorn\/finish 3 0\r\n2020-10-22T06:59:16,717989455+00:00 - Exit code 3 is not normal. Killing image.\r\n```\r\n\r\nI checked and my development venv (Py3.7.9) has the numpy version - 1.19.2 and even the base python (3.6.6) has 1.18.2\r\n\r\nInitially the error was that the numpy version is 1.14.2. To mitigate that I explicitly passed ```numpy==1.16.1``` as a dependency and as a result the error now asks me to uninstall the previous versions of numpy. \r\n\r\n**DOUBT 01 of 02 : How do I uninstall this previous version? Is that even possible.**\r\n\r\nWhile investigating it, I went back to the logs generated by MLflow while building the image and I noticed that it is installing a number of additional packages while building the base image (including Numpy version 1.14.2) that is subsequently overwritten using packages from my mlflow_env.yml file.\r\n\r\nA snippet of logs while building the image is as follows:\r\n\r\n```\r\nStep 36\/38 : RUN CONDA_ROOT_DIR=$(conda info --root) && if [ -n \"$AZUREML_CONDA_ENVIRONMENT_PATH\" ]; then conda env update -p \"$AZUREML_CONDA_ENVIRONMENT_PATH\" -f '\/var\/azureml-app\/mlflow_env.yml'; else conda env update -n base -f '\/var\/azureml-app\/mlflow_env.yml'; fi && conda clean -aqy && rm -rf \/root\/.cache\/pip && rm -rf \"$CONDA_ROOT_DIR\/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} +\r\n ---> Running in fe3b3c665339\r\nWarning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\r\nCollecting package metadata: ...working... \r\ndone\r\nSolving environment: ...working... \r\ndone\r\n\r\nDownloading and Extracting Packages\r\n\r\n<Random packages being installed>\r\n<Random packages being installed>\r\n<Random packages being installed>\r\nnumpy-1.14.2         | 4.0 MB    |            |   0% \r\nnumpy-1.14.2         | 4.0 MB    | #######6   |  76% \r\nnumpy-1.14.2         | 4.0 MB    | #########  |  91% \r\nnumpy-1.14.2         | 4.0 MB    | ########## | 100% \r\n\r\nPreparing transaction: ...working... done\r\nVerifying transaction: ...working... done\r\nExecuting transaction: ...working... \r\ndone\r\nRan pip subprocess with arguments:\r\n['\/opt\/miniconda\/bin\/python', '-m', 'pip', 'install', '-U', '-r', '\/var\/azureml-app\/condaenv.kscafao_.requirements.txt']\r\nPip subprocess output:\r\nCollecting torch==1.3.0\r\n  Downloading torch-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (773.1 MB)\r\nCollecting numpy==1.16.1\r\n  Downloading numpy-1.16.1-cp36-cp36m-manylinux1_x86_64.whl (17.3 MB)\r\nInstalling collected packages: numpy, torch,\r\n  Attempting uninstall: numpy\r\n    Found existing installation: numpy 1.19.2\r\n    Uninstalling numpy-1.19.2:\r\n      Successfully uninstalled numpy-1.19.2\r\n  Attempting uninstall: torch\r\n    Found existing installation: torch 0.4.1\r\n    Uninstalling torch-0.4.1:\r\n      Successfully uninstalled torch-0.4.1\r\nSuccessfully installed numpy-1.16.1  torch-1.3.0 \r\n```\r\n\r\n**Doubt 02 of 02: As you can see, my system has a different numpy (1.19) and in my yml file I'm asking for numpy (1.16) to be installed, then where is this numpy (1.14.2) coming from?**\r\n\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [X] `area\/build`: Build and test infrastructure for MLflow\r\n\r\nInterface \r\n- [X] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n\r\n\r\nIntegrations\r\n- [X] `integrations\/azure`: Azure and Azure ML integrations","535":"getting below error in UI console:\r\n\r\nDevTools failed to load SourceMap: Could not load content for http:\/\/10.74.58.147:8753\/static-files\/bootstrap\/bootstrap.min.css.map: HTTP error: status code 404, net::ERR_HTTP_RESPONSE_CODE_FAILURE\r\nreact-dom.production.min.js:3282 DOMException: Blocked a frame with origin \"http:\/\/10.74.58.147:8753\" from accessing a cross-origin frame.\r\n    at Function.value (http:\/\/10.74.58.147:8753\/static-files\/static\/js\/main.8790c2d7.chunk.js:1:9610)\r\n    at t.value (http:\/\/10.74.58.147:8753\/static-files\/static\/js\/main.8790c2d7.chunk.js:1:189202)\r\n    at commitLifeCycles (http:\/\/10.74.58.147:8753\/static-files\/static\/js\/2.04e2d2ac.chunk.js:1:4043867)\r\n    at C (http:\/\/10.74.58.147:8753\/static-files\/static\/js\/2.04e2d2ac.chunk.js:1:4031668)\r\n    at w (http:\/\/10.74.58.147:8753\/static-files\/static\/js\/2.04e2d2ac.chunk.js:1:4030478)\r\n    at _ (http:\/\/10.74.58.147:8753\/static-files\/static\/js\/2.04e2d2ac.chunk.js:1:4030009)\r\n    at b (http:\/\/10.74.58.147:8753\/static-files\/static\/js\/2.04e2d2ac.chunk.js:1:4029846)\r\n    at v (http:\/\/10.74.58.147:8753\/static-files\/static\/js\/2.04e2d2ac.chunk.js:1:4029225)\r\n    at u (http:\/\/10.74.58.147:8753\/static-files\/static\/js\/2.04e2d2ac.chunk.js:1:4028687)\r\n    at Object.enqueueSetState (http:\/\/10.74.58.147:8753\/static-files\/static\/js\/2.04e2d2ac.chunk.js:1:4017873)\r\n_r @ react-dom.production.min.js:3282\r\ncommitErrorLogging @ react-dom.production.min.js:3619\r\nC @ react-dom.production.min.js:4395\r\nw @ react-dom.production.min.js:4296\r\n_ @ react-dom.production.min.js:4263\r\nb @ react-dom.production.min.js:4254\r\nv @ react-dom.production.min.js:4213\r\nu @ react-dom.production.min.js:4164\r\nenqueueSetState @ react-dom.production.min.js:2267\r\ny.setState @ react.production.min.js:71\r\na.onStateChange @ connectAdvanced.js:245\r\nv @ createStore.js:174\r\n(anonymous) @ index.js:114\r\n(anonymous) @ index.js:11\r\ndispatch @ applyMiddleware.js:46\r\n(anonymous) @ index.js:202\r\nPromise.then (async)\r\n(anonymous) @ index.js:228\r\n(anonymous) @ index.js:11\r\n(anonymous) @ bindActionCreators.js:3\r\nvalue @ ExperimentPage.js:49\r\nvalue @ ExperimentPage.js:113\r\ncommitLifeCycles @ react-dom.production.min.js:3558\r\nC @ react-dom.production.min.js:4394\r\nw @ react-dom.production.min.js:4296\r\n_ @ react-dom.production.min.js:4263\r\nb @ react-dom.production.min.js:4254\r\nv @ react-dom.production.min.js:4213\r\nu @ react-dom.production.min.js:4164\r\nenqueueSetState @ react-dom.production.min.js:2267\r\ny.setState @ react.production.min.js:71\r\na.onStateChange @ connectAdvanced.js:245\r\nv @ createStore.js:174\r\n(anonymous) @ index.js:114\r\n(anonymous) @ index.js:11\r\ndispatch @ applyMiddleware.js:46\r\n(anonymous) @ index.js:202\r\nPromise.then (async)\r\n(anonymous) @ index.js:228\r\n(anonymous) @ index.js:11\r\ndispatchListExperimentsApi @ HomePage.js:49\r\nvalue @ HomePage.js:22\r\nmountClassInstance @ react-dom.production.min.js:2327\r\nbeginWork @ react-dom.production.min.js:2912\r\no @ react-dom.production.min.js:4051\r\ni @ react-dom.production.min.js:4068\r\nw @ react-dom.production.min.js:4296\r\n_ @ react-dom.production.min.js:4263\r\nb @ react-dom.production.min.js:4254\r\nv @ react-dom.production.min.js:4213\r\nu @ react-dom.production.min.js:4164\r\nt @ react-dom.production.min.js:4601\r\nupdateContainer @ react-dom.production.min.js:4636\r\nwo.render @ react-dom.production.min.js:5513\r\n(anonymous) @ react-dom.production.min.js:5849\r\nunbatchedUpdates @ react-dom.production.min.js:4519\r\nko @ react-dom.production.min.js:5848\r\nrender @ react-dom.production.min.js:5871\r\n2145 @ index.js:18\r\ni @ (index):1\r\n963 @ no-experiments.svg:1\r\ni @ (index):1\r\na @ (index):1\r\ne @ (index):1\r\n(anonymous) @ main.8790c2d7.chunk.js:1\r\nAppErrorBoundary.js:19 DOMException: Blocked a frame with origin \"http:\/\/10.74.58.147:8753\" from accessing a cross-origin frame.\r\n    at Function.value (http:\/\/10.74.58.147:8753\/static-files\/static\/js\/main.8790c2d7.chunk.js:1:9610)\r\n    at t.value (http:\/\/10.74.58.147:8753\/static-files\/static\/js\/main.8790c2d7.chunk.js:1:189202)\r\n    at commitLifeCycles (http:\/\/10.74.58.147:8753\/static-files\/static\/js\/2.04e2d2ac.chunk.js:1:4043867)\r\n    at C (http:\/\/10.74.58.147:8753\/static-files\/static\/js\/2.04e2d2ac.chunk.js:1:4031668)\r\n    at w (http:\/\/10.74.58.147:8753\/static-files\/static\/js\/2.04e2d2ac.chunk.js:1:4030478)\r\n    at _ (http:\/\/10.74.58.147:8753\/static-files\/static\/js\/2.04e2d2ac.chunk.js:1:4030009)\r\n    at b (http:\/\/10.74.58.147:8753\/static-files\/static\/js\/2.04e2d2ac.chunk.js:1:4029846)\r\n    at v (http:\/\/10.74.58.147:8753\/static-files\/static\/js\/2.04e2d2ac.chunk.js:1:4029225)\r\n    at u (http:\/\/10.74.58.147:8753\/static-files\/static\/js\/2.04e2d2ac.chunk.js:1:4028687)\r\n    at Object.enqueueSetState (http:\/\/10.74.58.147:8753\/static-files\/static\/js\/2.04e2d2ac.chunk.js:1:4017873)","536":"## What changes are proposed in this pull request?\r\n\r\nI'd like to propose adding Singularity containers as an option, akin to Docker! Singularity containers can be run on an HPC cluster, albeit we would need sudo for building from a base image (so perhaps the use case isn't quite right?) I'm opening this as a draft PR because I have several questions \/ things to discuss.\r\n\r\n### black\r\nWhat version of black do you use for formatting? I tried running black locally and most files were re-formatted, so I'm guessing I have a newer version.\r\n\r\n### options vs args\r\nakin to docker_args, singularity has base and command options, along with arguments you can add to the command itself. E.g.,\r\n\r\n```\r\nsingularity <client-options> exec <command-options> <container> <args>\r\n```\r\nHow should those map here, and do we need a different spec input?\r\n\r\n### fakeroot\r\nI'm wondering if [fakeroot]() should be used by default so that sudo is not needed. I'm also wondering what the purpose of having a base image is - is there any reason the user cannot provide an existing image under the `singularity_env.image` and use as is?\r\n\r\n### common class\r\nThere is quite a bit of redundancy between docker and singularity, and I'm wondering if you would be interested in a refactor to have a common ContainerProject class. Also, why is it called a project? In other workflow manager terms, I'd think of Singularity as an executor or just a runtime container environment.\r\n\r\n### testing\r\nHow would you like testing done? Singularity typically needs to be installed natively in the CI environment\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nUsers will be allowed to use singularity_env in their project files.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [x] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n\r\nSo - mostly just discussion for now! I'm especially interested in discussing some kind of common base, because there isn't any reason some other container technology (or similar) might come around, and it should be easy \/ non-redundant to plug in. ","537":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\n\r\n## Motivation\r\n- What is the use case for this feature? It's useful for downstream applications that only support certain model flavors to be able to filter down to only those in their requests.\r\n- Why is this use case valuable to support for MLflow users in general? This adds convenience for users of all kinds who work with more than one flavor of model.\r\n- Why is this use case valuable to support for your project(s) or organization? We have customers who have specifically requested to be able to do this because they only work with a certain type of models.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient) Right now, there's no way to do this besides doing something hacky with `name` or filtering on the client side.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","538":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nAfter the SkinnyClient work is done within the library. Deployment logic needs to be expanded to: make heavy depencies configurable and allow for two libraries to be shipped from one code baase.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nIn order to deliver the improvements of the Skinny client work, we need to update the release infra to release both packages with configurations for the desired differences between both packages.\r\n- Why is this use case valuable to support for MLflow users in general?\r\nThis allows mlflow users to install the skinny version of mlflow from pypi\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nSame skinny client motivation, smaller transitive closure for mlflow's base functionality\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nMLflow currently does not have this option with the original packaging structure\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [x] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","539":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nMLflow currently auto infers schema information. This functionality is introduced within mlflow.models, which is also exposed in TrackingClient classes through imports, even within the FileStore. Thus lazy loading of numpy and pandas is finnicky. The feature set is also hard to easily degrade since the base types are not currently supported in the type system used for Schema, Signature, and Inputs\/Outputs.\r\n\r\nA vendored approach to the dtypes section and a subset of pd.DataFrame would cover most of the functionality used for this feature set in MLflow. The vendored code can be used as\r\n\r\ntry:\r\n   import pandas as pd\r\nexcept ImportError:\r\n   from mlflow.vendor.pandas import pd  # where pd has a subset of the functionality\r\n                                                                  # testing for skinny client should catch breaks in usage of the vendored pd\/np\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nmlfow.models introduces a strong numpy and pandas dependency. Using vendoring for a smoother experience without numpy or pd can help improve the skinny client while not requiring a rewrite of many mlflow components around Model\r\n- Why is this use case valuable to support for MLflow users in general?\r\nSame skinny client motivation from other issues around improved usability in new environments\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nModel Schema features are a strong value add of mlflow, turning the features completely off may detract adoption of the skinny client\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nCurrently the model signature heavily uses numpy and pd and is also imported at the mlflow.model level, which causes early ImportErrors if the packages are not installed.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","540":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nIn preparation for an mlflow package with minimal dependencies, flavors should be updated to lazy load numpy and other dependencies. \r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nGiven mlflow\/__init__.py loads all flavors into the top level namespace, non lazy dependencies trickle to the top level of mlflow. In order to remove pandas and numpy from the skinny mlflow package, we need to lazy load those packages.\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\nThis will improve mlflow's resilience to not having pandas or numpy installed\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nDevelopers hoping to leverage mlflow will have more compatible environments going forward as we reduce the amount of dependencies that could possibly conflict with their environments.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nMLflow currently has many requirements brought in to the top level namespace, thus causing an immediate ImportError if numpy or pandas are not installed.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","541":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [X] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution**: MacOS 10.15.5\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: version 1.11.0\r\n- **Python version**: 3.7.4\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n\r\nmlflow.pyfunc.log_model(\"model\", python_model= model)\r\n\r\n### Describe the problem\r\nI would like to train register a custom Python model. I have an incremental learning model from Python library Creme trained, but am unable to register this model with MLFlow.\r\n\r\n### Code to reproduce issue\r\n\r\n```\r\nfrom creme import datasets, linear_model, metrics, optim, preprocessing, stream, compose, feature_extraction\r\nfrom creme import compose, feature_extraction, model_selection, stats, ensemble, tree, compat\r\nfrom creme.base import MultiClassifier\r\nfrom creme import neighbors\r\nfrom creme import compose\r\nfrom creme import linear_model\r\nfrom creme import metrics\r\nfrom creme import multiclass\r\nfrom creme import preprocessing\r\nimport pandas as pd\r\nimport numpy as np\r\nfrom sklearn.ensemble import RandomForestClassifier\r\nfrom sklearn import datasets\r\nimport mlflow.sklearn\r\nimport mlflow\r\nfrom sklearn.linear_model import LogisticRegression\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\r\n\r\niris = datasets.load_iris()\r\nX = pd.DataFrame(iris.data, columns=['C1', 'C2', 'C3', 'C4'])\r\nX['Target'] = iris.target\r\ny = X['Target']\r\ndel X['Target']\r\n\r\nmlflow.end_run()\r\nmlflow.set_tracking_uri(\"http:\/\/localhost:5000\")\r\nmlflow.set_experiment(\"path\")\r\n\r\n\r\ncreme_data = X.to_dict(orient='records')\r\nmodel = neighbors.KNeighborsClassifier(n_neighbors=3)\r\nwith mlflow.start_run():\r\n    model_selection.progressive_val_score(\r\n        X_y=zip(creme_data, y.values),\r\n        model=model,\r\n        metric=metrics.Accuracy(),\r\n        print_every=1)\r\nmlflow.pyfunc.log_model(\"model\", python_model= model)\r\n```\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [X] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [X] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [X] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [X] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [X] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","542":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.10\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.11.0\r\n- **Python version**: 3.7.9 and 3.8.6\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\nCopy the reproduction script below into `reproduction_script.py`\r\n```bash\r\nvirtualenv venv --python=python3\r\nsource venv\/bin\/activate\r\npip install gluoncv==0.8.0 mxnet==1.7.0.post1 mlflow==1.11.0 pandas==1.0.4 numpy==1.18.5 matplotlib==3.3.2\r\npython reproduction_script.py\r\n```\r\n### Describe the problem\r\n**TL;DR;** Models that require a high-dimensional input can't be invoked\r\n\r\nThe MLFlow `predict` method takes\/returns only `pd.DataFrame`s which are [by definition](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.html) two dimensional, this makes it impossible to use models that require high-dimensional (>2d) arrays as inputs\/outputs, see the reproduction script and the similar open\/closed issues \r\n\r\nIn fact, many issues were open to allow `predict` to accept\/return high-dimensional arrays:\r\n##### Open issues:\r\n* [[BUG] ONNX predict fails for high-dimensional models #3229](https:\/\/github.com\/mlflow\/mlflow\/issues\/3229)\r\n* [[BUG] Predict N-dimensional data with pyfunc from MLmodel #2830](https:\/\/github.com\/mlflow\/mlflow\/issues\/2830)\r\n* [[FR] Support tensor inputs to MLflow inference APIs #3159](https:\/\/github.com\/mlflow\/mlflow\/issues\/3159)\r\n\r\n##### Pull requests:\r\n* [Added support for high dimensional onnx models #3307](https:\/\/github.com\/mlflow\/mlflow\/pull\/3307\/)\r\n\r\n##### Closed issues:\r\n* [How to pass 2D array as an input to the MLFlow Model #1480](https:\/\/github.com\/mlflow\/mlflow\/issues\/1480)\r\n* [[FR]How to transfer the multi-dimensional pixel information of the image to the model after the model is deployed as docker\uff1f #1668](https:\/\/github.com\/mlflow\/mlflow\/issues\/1668)\r\n* [[BUG] Model predict with json input fails if the dataframe has multi-index #2412](https:\/\/github.com\/mlflow\/mlflow\/issues\/2412)\r\n* [[FR] Mlflow serve - sending an image #2452](https:\/\/github.com\/mlflow\/mlflow\/issues\/2452)\r\n* [Recommended handling of I\/O for pyfunc? #702](https:\/\/github.com\/mlflow\/mlflow\/issues\/702)\r\n* [TensorFlow wrapper ravels outputs on predict #1066](https:\/\/github.com\/mlflow\/mlflow\/issues\/1066)\r\n\r\nThis is clearly something that blocks so many users from using the models that require high-dimensional inputs\/outputs logged by MLFlow, I don't understand why MLFlow `predict` method is tightly coupled to `pd.DataFrame`s which clearly can't represent high-dimensional inputs\/outputs, why don't we just allow passing `numpy` arrays and return them?  \r\n\r\n### Code to reproduce issue\r\n```python\r\n# Run the following pip command to install the dependencies\r\n# ! pip install gluoncv==0.8.0 mxnet==1.7.0.post1 mlflow==1.11.0 pandas==1.0.4 numpy==1.18.5 matplotlib==3.3.2 pyqt5==5.15.1\r\nfrom gluoncv import model_zoo, data, utils\r\nfrom matplotlib import pyplot as plt\r\nimport pandas as pd\r\nimport numpy as np\r\nimport mlflow\r\nimport mxnet\r\nimport mlflow.gluon\r\nimport traceback\r\n\r\n# Load a pretrained model\r\nnet = model_zoo.get_model('yolo3_darknet53_voc', pretrained=True)\r\n\r\n# Pre-process an image\r\nim_fname = utils.download('https:\/\/raw.githubusercontent.com\/zhreshold\/' +\r\n                          'mxnet-ssd\/master\/data\/demo\/dog.jpg',\r\n                          path='dog.jpg')\r\nx, img = data.transforms.presets.yolo.load_test(im_fname, short=512)\r\nprint('Shape of pre-processed image:', x.shape)\r\n\r\n# Inference and display\r\nnet.hybridize()\r\nclass_IDs, scores, bounding_boxs = net(x)\r\n\r\nax = utils.viz.plot_bbox(img, bounding_boxs[0], scores[0],\r\n                         class_IDs[0], class_names=net.classes)\r\n\r\n\r\n# Log the model with MLFlow\r\nr = mlflow.start_run()\r\nmodel_name = 'net'\r\nmodel_path = r.info.artifact_uri + '\/' + model_name\r\nmlflow.gluon.log_model(net, model_name)\r\nmlflow.end_run()\r\n\r\n# Load the model\r\nm = mlflow.pyfunc.load_model(model_path)\r\n\r\n\r\nprint('-------------------------------------------------------------------------------------------')\r\nprint('Using the input as it is')\r\nprint('-------------------------------------------------------------------------------------------')\r\ntry:\r\n    print(m.predict(x))\r\nexcept Exception:\r\n    traceback.print_exc()\r\n\r\n# Using numpy.ndarray raises AttributeError: 'numpy.ndarray' object has no attribute 'values'\r\nprint('-------------------------------------------------------------------------------------------')\r\nprint(\"Using numpy.ndarray raises AttributeError: 'numpy.ndarray' object has no attribute 'values'\")\r\nprint('-------------------------------------------------------------------------------------------')\r\ntry:\r\n    print(m.predict(x.asnumpy()))\r\nexcept Exception:\r\n    traceback.print_exc()\r\n\r\n# Can't construct pd.DataFrame with a >2d shaped array\r\nprint('-------------------------------------------------------------------------------------------')\r\nprint(\"Can't construct pd.DataFrame with a >2d shaped array\")\r\nprint('-------------------------------------------------------------------------------------------')\r\ntry:\r\n    print(m.predict(pd.DataFrame(x.asnumpy())))\r\nexcept Exception:\r\n    traceback.print_exc()\r\n\r\n\r\n# Flattening the input with np.ravel is not acceptable\r\nprint('-------------------------------------------------------------------------------------------')\r\nprint(\"Flattening the input with np.ravel is not acceptable\")\r\nprint('-------------------------------------------------------------------------------------------')\r\ntry:\r\n    print(m.predict(pd.DataFrame(np.ravel(x.asnumpy()))))\r\nexcept Exception:\r\n    traceback.print_exc()\r\n\r\n\r\n# Using pd.DataFrame after reshaping also don't work\r\nprint('-------------------------------------------------------------------------------------------')\r\nprint(\"Using pd.DataFrame after reshaping also don't work\")\r\nprint('-------------------------------------------------------------------------------------------')\r\ntry:\r\n    x_df = pd.DataFrame(x.reshape(0, -1).asnumpy())\r\n    print(m.predict(x_df))\r\nexcept Exception:\r\n    traceback.print_exc()\r\n```\r\n\r\n### Other info \/ logs\r\nHere's the output of the reproduction script\r\n```\r\n-------------------------------------------------------------------------------------------\r\nUsing the input as it is\r\n-------------------------------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"invoking_mlflow_model_that_requires_multidimensional_input.py\", line 45, in <module>\r\n    print(m.predict(x))\r\n  File \"\/home\/mohammedi\/Downloads\/venv\/lib\/python3.8\/site-packages\/mlflow\/pyfunc\/__init__.py\", line 425, in predict\r\n    return self._model_impl.predict(data)\r\n  File \"\/home\/mohammedi\/Downloads\/venv\/lib\/python3.8\/site-packages\/mlflow\/gluon.py\", line 78, in predict\r\n    ndarray = mx.nd.array(df.values)\r\nAttributeError: 'NDArray' object has no attribute 'values'\r\n-------------------------------------------------------------------------------------------\r\nUsing numpy.ndarray raises AttributeError: 'numpy.ndarray' object has no attribute 'values'\r\n-------------------------------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"invoking_mlflow_model_that_requires_multidimensional_input.py\", line 54, in <module>\r\n    print(m.predict(x.asnumpy()))\r\n  File \"\/home\/mohammedi\/Downloads\/venv\/lib\/python3.8\/site-packages\/mlflow\/pyfunc\/__init__.py\", line 425, in predict\r\n    return self._model_impl.predict(data)\r\n  File \"\/home\/mohammedi\/Downloads\/venv\/lib\/python3.8\/site-packages\/mlflow\/gluon.py\", line 78, in predict\r\n    ndarray = mx.nd.array(df.values)\r\nAttributeError: 'numpy.ndarray' object has no attribute 'values'\r\n-------------------------------------------------------------------------------------------\r\nCan't construct pd.DataFrame with a >2d shaped array\r\n-------------------------------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"invoking_mlflow_model_that_requires_multidimensional_input.py\", line 63, in <module>\r\n    print(m.predict(pd.DataFrame(x.asnumpy())))\r\n  File \"\/home\/mohammedi\/Downloads\/venv\/lib\/python3.8\/site-packages\/pandas\/core\/frame.py\", line 464, in __init__\r\n    mgr = init_ndarray(data, index, columns, dtype=dtype, copy=copy)\r\n  File \"\/home\/mohammedi\/Downloads\/venv\/lib\/python3.8\/site-packages\/pandas\/core\/internals\/construction.py\", line 169, in init_ndarray\r\n    values = prep_ndarray(values, copy=copy)\r\n  File \"\/home\/mohammedi\/Downloads\/venv\/lib\/python3.8\/site-packages\/pandas\/core\/internals\/construction.py\", line 295, in prep_ndarray\r\n    raise ValueError(\"Must pass 2-d input\")\r\nValueError: Must pass 2-d input\r\n-------------------------------------------------------------------------------------------\r\nFlattening the input with np.ravel is not acceptable\r\n-------------------------------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"invoking_mlflow_model_that_requires_multidimensional_input.py\", line 73, in <module>\r\n    print(m.predict(pd.DataFrame(np.ravel(x.asnumpy()))))\r\n  File \"\/home\/mohammedi\/Downloads\/venv\/lib\/python3.8\/site-packages\/mlflow\/pyfunc\/__init__.py\", line 425, in predict\r\n    return self._model_impl.predict(data)\r\n  File \"\/home\/mohammedi\/Downloads\/venv\/lib\/python3.8\/site-packages\/mlflow\/gluon.py\", line 79, in predict\r\n    return pd.DataFrame(self.gluon_model(ndarray).asnumpy())\r\n  File \"\/home\/mohammedi\/Downloads\/venv\/lib\/python3.8\/site-packages\/mxnet\/gluon\/block.py\", line 682, in __call__\r\n    out = self.forward(*args)\r\n  File \"\/home\/mohammedi\/Downloads\/venv\/lib\/python3.8\/site-packages\/mxnet\/gluon\/block.py\", line 1429, in forward\r\n    return self._call_cached_op(x, *args)\r\n  File \"\/home\/mohammedi\/Downloads\/venv\/lib\/python3.8\/site-packages\/mxnet\/gluon\/block.py\", line 1028, in _call_cached_op\r\n    out = self._cached_op(*cargs)\r\n  File \"\/home\/mohammedi\/Downloads\/venv\/lib\/python3.8\/site-packages\/mxnet\/_ctypes\/ndarray.py\", line 148, in __call__\r\n    check_call(_LIB.MXInvokeCachedOpEx(\r\n  File \"\/home\/mohammedi\/Downloads\/venv\/lib\/python3.8\/site-packages\/mxnet\/base.py\", line 246, in check_call\r\n    raise get_last_ffi_error()\r\nmxnet.base.MXNetError: MXNetError: Error in operator darknetv30_conv0_fwd: [14:32:19] src\/operator\/nn\/convolution.cc:152: Check failed: dshp.ndim() == 4U (2 vs. 4) : Input data should be 4D in batch-num_filter-y-x\r\n-------------------------------------------------------------------------------------------\r\nUsing pd.DataFrame after reshaping also don't work\r\n-------------------------------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"invoking_mlflow_model_that_requires_multidimensional_input.py\", line 84, in <module>\r\n    print(m.predict(x_df))\r\n  File \"\/home\/mohammedi\/Downloads\/venv\/lib\/python3.8\/site-packages\/mlflow\/pyfunc\/__init__.py\", line 425, in predict\r\n    return self._model_impl.predict(data)\r\n  File \"\/home\/mohammedi\/Downloads\/venv\/lib\/python3.8\/site-packages\/mlflow\/gluon.py\", line 79, in predict\r\n    return pd.DataFrame(self.gluon_model(ndarray).asnumpy())\r\n  File \"\/home\/mohammedi\/Downloads\/venv\/lib\/python3.8\/site-packages\/mxnet\/gluon\/block.py\", line 682, in __call__\r\n    out = self.forward(*args)\r\n  File \"\/home\/mohammedi\/Downloads\/venv\/lib\/python3.8\/site-packages\/mxnet\/gluon\/block.py\", line 1429, in forward\r\n    return self._call_cached_op(x, *args)\r\n  File \"\/home\/mohammedi\/Downloads\/venv\/lib\/python3.8\/site-packages\/mxnet\/gluon\/block.py\", line 1028, in _call_cached_op\r\n    out = self._cached_op(*cargs)\r\n  File \"\/home\/mohammedi\/Downloads\/venv\/lib\/python3.8\/site-packages\/mxnet\/_ctypes\/ndarray.py\", line 148, in __call__\r\n    check_call(_LIB.MXInvokeCachedOpEx(\r\n  File \"\/home\/mohammedi\/Downloads\/venv\/lib\/python3.8\/site-packages\/mxnet\/base.py\", line 246, in check_call\r\n    raise get_last_ffi_error()\r\nmxnet.base.MXNetError: MXNetError: Error in operator darknetv30_conv0_fwd: [14:32:19] src\/operator\/nn\/convolution.cc:152: Check failed: dshp.ndim() == 4U (2 vs. 4) : Input data should be 4D in batch-num_filter-y-x\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","543":"Use existing Environment Variable for S3 Upload File in Sagemaker Artifact Upload as per issue #3564\r\n\r\nSigned-off-by: Rumeshkrishnan Mohan <rumeshkrish@gmail.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nAdd Environment Variable for S3 Upload File ExtraArgs as per issue #3564 and AddOn to #1298\r\n\r\n## How is this patch tested?\r\n\r\nExisting Unit tests in test_s3_artifact_repo.py\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [X] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [X] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [X] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","544":"\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [X] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Feature Request\r\nAdd a way to pass `MAVEN_OPTS` argument into docker file to support proxy or custom maven opts configuration \r\n\r\n## Sample Proxy Setting\r\n\r\n1. Set the environment variable before model build and publish`MAVEN_OPTS=\"-Dhttp.proxyHost=localhost -Dhttp.proxyPort=2010 -Dhttps.proxyHost=localhost -Dhttps.proxyPort=2010\"`\r\n2. Modify the docker file to import environment variable `ARG MAVEN_OPTS`\r\n","545":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow codebase)?\r\n\r\n- [X] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Feature Request\r\nAdd a way to pass through Boto3 S3 Upload Extraargs to support varying requirements for storing S3 artifacts with MLFlow Sagemaker.\r\n\r\n## Sample Use Case\r\nStoring artifacts in S3 using KMS Encryption requires setting the ServerSideEncryption and SSEKMSKeyId ExtraArgs in the Boto3 S3 Client upload_file function.\r\n\r\n## Suggested Solution\r\nAdding an optional MLFLOW_S3_UPLOAD_EXTRA_ARGS environment variable. This similar to Issue #1298\r\n\r\nThis variable takes a JSON key\/value object containing the Boto3 Defined Extra Args which are passed through to the Boto3 upload_file call.\r\n","546":"Hi everyone, \r\n\r\nI would like to implement the user role permission on the tracking server.\r\nfor instance,\r\nthe some group of member can **view experiment and model only.** \r\nand another group can **edit the experiment and used the tracking API**. \r\n\r\nDoes MLflow have this feature? ","547":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nMany Deep Learning models need a 3 dimension input and REST API's input format doesn't allow it. It is limited to 1d or 2d input format.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","548":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ X ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Databricks runtime 7.1 and 7.3, also 7.3ML, as far as i know  Ubuntu 18.04.4 LTS. \r\n- **MLflow installed from (source or binary)**: Installed by pip MLflow\r\n- **MLflow version (run ``mlflow --version``)** :mlflow, version 1.11.0\r\n- **Python version**: Python 3.7.5\r\n- **Exact command to reproduce**: \r\n\r\n```\r\nmlflow.start_run()\r\nmlflow.log_param(\"featuresCol\", \"features\")\r\nmlflow.log_param(\"predictionCol\", \"prediction\")\r\nmlflow.log_param(\"maxBins\", \"38\")\r\n\r\nlr = GBTRegressor(featuresCol='features',labelCol='ligeros_total', predictionCol='prediction', maxBins=38)\r\n\r\n# # Fit the model\r\nlrModel = lr.fit(train)\r\n\r\nmlflow.spark.log_model(lrModel, \"Model name\")\r\n\r\nmlflow.end_run()\r\n```\r\n\r\n### Describe the problem\r\nThe expected behaviour was that the log_model directive would save the artifact in the MLflow server and reflect it in the models UI that works in databricks, this process works correctly with the databricks 6.4 runtime, right now the problem is that when running the code snipped above it stays in a constant execution  with the message \" determining location of dbio file fragments \" that seems to describe a message about delta cache regarding the table information as i understand it. It shows in the experiments tabs and the run experiments list in the UI, but  there are no artifacts recorded, it also stays in an \"UNFINISHED\" status for the run because the end_run never gets executed, this last thing can be forced but the artifact still won't appear. This may be related to the MLflow version, or something related to the system it runs in but are there are no error messages i am at a loss on how to proceed. \r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ X ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ X ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ X ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n\r\nInterface \r\nDatabricks\r\n\r\nIntegrations\r\n- [ X ] `integrations\/databricks`: Databricks integrations\r\n","549":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.04\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: 1.11.0\r\n- **Python version**: 3.8.5\r\n\r\n### Describe the problem\r\nA pyfunc model is created to store a GPyTorch model (gpytorch.ai). When saving the model using the mlflow.pyfunc.log_model() it raises an pickle error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"mlflow_issue.py\", line 45, in <module>\r\n    mlflow.pyfunc.log_model(artifact_path=\"gpmodel\", python_model=gpmodel, conda_env=conda_env)\r\n  File \"\/home\/erwin\/dev\/ds\/mlflow\/mlflow\/pyfunc\/__init__.py\", line 990, in log_model\r\n    return Model.log(\r\n  File \"\/home\/erwin\/dev\/ds\/mlflow\/mlflow\/models\/model.py\", line 172, in log\r\n    flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\r\n  File \"\/home\/erwin\/dev\/ds\/mlflow\/mlflow\/pyfunc\/__init__.py\", line 868, in save_model\r\n    return mlflow.pyfunc.model._save_model_with_class_artifacts_params(\r\n  File \"\/home\/erwin\/dev\/ds\/mlflow\/mlflow\/pyfunc\/model.py\", line 138, in _save_model_with_class_artifacts_params\r\n    cloudpickle.dump(python_model, out)\r\n  File \"\/home\/erwin\/dev\/ds\/charging_time\/.venv\/lib\/python3.8\/site-packages\/cloudpickle\/cloudpickle_fast.py\", line 55, in dump\r\n    CloudPickler(\r\n  File \"\/home\/erwin\/dev\/ds\/charging_time\/.venv\/lib\/python3.8\/site-packages\/cloudpickle\/cloudpickle_fast.py\", line 563, in dump\r\n    return Pickler.dump(self, obj)\r\n_pickle.PicklingError: Can't pickle <built-in function softplus>: import of module 'torch._C._nn' failed\r\n```\r\nCloudpickle is not able to serialize the gpytorch model. This is reported in https:\/\/github.com\/cloudpipe\/cloudpickle\/issues\/381 as well. The cloudpickle alternative dill does the serialization correct. \r\n\r\nI'm raising this issue here as I would like to contribute to a vendor neutral pickle module for `pyfunc` that allows a choice between cloudpickle and dill.\r\n\r\n### Code to reproduce issue\r\nThere are two examples to reproduce the error. First using `mlflow` and a second, even more minimalised version using cloudpickle only.\r\n\r\n```python\r\nimport mlflow\r\nimport torch\r\nimport gpytorch\r\n\r\nclass GPPythonModel(mlflow.pyfunc.PythonModel):\r\n\r\n    def __init__(self,\r\n                 input_example,\r\n                 output_example,\r\n                 ):\r\n\r\n        self.likelihood = gpytorch.likelihoods.GaussianLikelihood()\r\n        self.model = gpytorch.models.ExactGP(torch.tensor(input_example, dtype=torch.float32), torch.tensor(output_example, dtype=torch.float32), self.likelihood)\r\n\r\n    def predict(self, context, model_input):\r\n        pass\r\n\r\nconda_env = {\r\n    'name': 'mlflow-env',\r\n    'channels': ['defaults'],\r\n    'dependencies': [\r\n        'python=3.8.5', \r\n        {\r\n            'pip': [\r\n                'mlflow==1.11.0',\r\n                'cloudpickle',\r\n                'gpytorch',\r\n                'torch'\r\n            ]\r\n        }\r\n    ]\r\n}\r\n\r\ngpmodel = GPPythonModel(\r\n    input_example=[[0., 0., 0.]],\r\n    output_example=[[0.]],\r\n)\r\n\r\nmlflow.pyfunc.log_model(artifact_path=\"gpmodel\", python_model=gpmodel, conda_env=conda_env)\r\n```\r\nBare minimum example:\r\n```python\r\nimport cloudpickle\r\nimport gpytorch\r\n\r\nwith open('ww', 'wb') as f:\r\n    model = gpytorch.models.GP()\r\n    cloudpickle.dump(gpmodel, f)\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","550":"Hi everyone, \r\n\r\nI would like to setup the authenticaion to tracking server via Python. Which is I had read the this docs https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#logging-to-a-tracking-server\r\n\r\nAs I know that we have to assign the environment variables such as \r\n```\r\nMLFLOW_TRACKING_TOKEN\r\nMLFLOW_TRACKING_USERNAME\r\nMLFLOW_TRACKING_PASSWORD\r\n```\r\nto the both server and client right ? \r\n\r\nBut when I try it doesn't work.\r\n\r\nI still can use the tracking server without any env var authentication. \r\n\r\nSo I'm quite confure about how to setup this authentication \r\n\r\nDo anyone has recommend to me? which step or section that I was missing.\r\n\r\n\r\n","551":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.11\r\n- **Python version**: 2.7\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: \r\n\r\n### Describe the problem\r\nRunning the mlflow project with float parameter value in exponential format throws the INVALID_PARAMETER_VALUE exception - \"Changing param value is not allowed\":\r\n\r\n### Code to reproduce issue\r\nUsing the provided docker example in https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/docker, running it with \r\n`mlflow run examples\/docker -P alpha=0.5 -P alpha=0.00001`\r\n`mlflow run examples\/docker -P alpha=0.5 -P alpha=1e-1`\r\nthrows an INVALID_PARAMETER_VALUE exception. However the same with parameter in decimal format works until 4 decimal places, e.g:\r\n`mlflow run examples\/docker -P alpha=0.5 -P alpha=0.01`\r\n\r\nThe bug seems to be related to how floating parameter values are stored either in exponential format or decimal format. \r\n\r\n### Other info \/ logs\r\n```\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 65, in <module>\r\n    mlflow.log_param(\"alpha\", alpha)\r\n  File \"\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/tracking\/fluent.py\", line 214, in log_param\r\n    MlflowClient().log_param(run_id, key, value)\r\n  File \"\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/tracking\/client.py\", line 205, in log_param\r\n    self._tracking_client.log_param(run_id, key, value)\r\n  File \"\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 179, in log_param\r\n    self.store.log_param(run_id, param)\r\n  File \"\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 143, in log_param\r\n    self._call_endpoint(LogParam, req_body)\r\n  File \"\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 32, in _call_endpoint\r\n    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)\r\n  File \"\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/utils\/rest_utils.py\", line 137, in call_endpoint\r\n    response = verify_rest_response(response, endpoint)\r\n  File \"\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/utils\/rest_utils.py\", line 103, in verify_rest_response\r\n    raise RestException(json.loads(response.text))\r\nmlflow.exceptions.RestException: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Param with key='alpha' was already logged with value='1e-2' for run ID='a831272fa4f5498fb55e20e8a4116b5f'. Attempted logging new value '0.01'\r\n```\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","552":"Proof-read updated the CONTRIBUTING.rst file with several grammatical, punctuation corrections.\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nUpdated CONTRIBUTING.rst file with necessary grammatical, punctuation corrections. \r\n\r\n## How is this patch tested?\r\n\r\nThe changes do not impact the actual codebase and are entirely limited to the CONTRIBUTING.rst file.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","553":"Made several appropriate grammatical corrections to the README file for the sole purpose of improving readability and avoiding confusion stemming from inappropriate grammatical usage.\r\n\r\n## How is this patch tested?\r\n\r\nUpdate to the README text correcting the language usage and other appropriate grammatical corrections at several places.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","554":"# Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ X ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nWhen clicking back to the experiment from any of the comparison views (tabular or graph), the Runs are all unselected.  Instead, it would be great if the previously selected runs from the comparison views were pre-selected.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nWhen we are comparing our runs via the graph view, we often think about another run we want to compare.\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\nThis makes adding runs to an existing comparison plot easier.\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nSaves time.\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nToday, our workflow is not ideal:\r\n1. First, open up the comparison view.\r\n2. Open up the experiment in a new tab.\r\n3. Find the run.\r\n4. Click on it.\r\n5. From the URL, copy the MLFlow experiment ID.\r\n6. Go back to the comparison view.\r\n7. Manually edit the URL to add the new experiment.\r\n8. Hit enter.\r\n9. Reload the page.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ X ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ X ] `integrations\/databricks`: Databricks integrations","555":"Hi this is a bespoke issue specific to our env.\r\nMLFLOW doesnt currently support authentication and SSL certs.So I have implemented a reverse proxy infront using nginx to take care of those issues.\r\nAs per our security standards we dont want users to download the artefact from the UI and send it personal emails etc.So when I restrict the download using nginx it restricts the viewing as well.\r\nQuestion: Does viewing and downloading happen via the same API?\r\n![Screen Shot 2020-10-13 at 3 02 21 pm](https:\/\/user-images.githubusercontent.com\/16069726\/95814677-a6ba8900-0d66-11eb-9087-1e5ea9794b44.png)\r\nIs there way I can enable viewing but not physically downloading the files.\r\n","556":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nour team is working on combining the mlflow framework with the xgboost model. Previously, I use single-instance xgboost model to train, which works fine with mlflow to log all the model-related parameters by using \" mlflow.xgboost.autolog() \", but when i change to distributed xgboost version changing from python package to JVM package by including the xgboost4j.jar and xgboost4j-spark.jar files, and also include mlflow module into it, (\u201cmlflow.xgboost.autolog()\u201d). The mlflow cannot show all the parameters on the page. They are empty. enter image description here\r\nSo I looked at the source code in the mlflow.xgboost, in line 271, \u201cdef autolog(importance_types=[\u201cweight\u201d]):\u201d says it imports the xgboost package, which i think is the single-instance xgboost model, I wonder if it is support the distributed version? Or is there any other methods to solve the problem? Thanks!\r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","557":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [x] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**:\r\n- **Python version**:\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nour team is working on combining the mlflow framework with the xgboost model. Previously, I use single-instance xgboost model to train, which works fine with mlflow to log all the model-related parameters by using \" mlflow.xgboost.autolog() \", but when i change to distributed xgboost version changing from python package to JVM package by including the xgboost4j.jar and xgboost4j-spark.jar files, and also include mlflow module into it, (\u201cmlflow.xgboost.autolog()\u201d). The mlflow cannot show all the parameters on the page. They are empty. enter image description here\r\n\r\nSo I looked at the source code in the mlflow.xgboost, in line 271, \u201cdef autolog(importance_types=[\u201cweight\u201d]):\u201d says it imports the xgboost package, which i think is the single-instance xgboost model, I wonder if it is support the distributed version? Or is there any other methods to solve the problem? Thanks!\r\n\r\n### Code to reproduce issue\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/56243512\/95747529-327ed780-0ccb-11eb-8c71-b61443fe46dd.png)\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\ndef autolog(importance_types=[\"weight\"]):\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","558":"**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Nope\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Catalina 10.15.7\r\n- **MLflow installed from (source or binary)**: `pip3 install mlflow`\r\n- **MLflow version (run ``mlflow --version``)**: `mlflow, version 1.11.0`\r\n- **Python version**: Python 3.8.3\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: run `mlflow --version` or `mlflow --help`\r\n\r\n### Describe the problem\r\n\r\nRunning `mlflow --help` and `mlflow --version` takes about 1 second instead of running instantly, despite very fast hardware (2019 16\" Macbook Pro with 2.4 GHz Core i9 processor, 32 GB of ram).\r\n\r\n### Code to reproduce issue\r\n\r\n```\r\n!#\/bin\/zsh\r\ntime mlflow --version\r\ntime mlflow --help\r\n```\r\n\r\n### Other info \/ logs\r\n\r\n```\r\n> time mlflow --version\r\nmlflow, version 1.11.0\r\nmlflow --version  0.99s user 0.31s system 99% cpu 1.300 total\r\n> time mlflow --help\r\nUsage: mlflow [OPTIONS] COMMAND [ARGS]...\r\n\r\nOptions:\r\n  --version  Show the version and exit.\r\n  --help     Show this message and exit.\r\n\r\nCommands:\r\n  artifacts    Upload, list, and download artifacts from an MLflow artifact...\r\n  azureml      Serve models on Azure ML.\r\n  db           Commands for managing an MLflow tracking database.\r\n  deployments  Deploy MLflow models to custom targets.\r\n  experiments  Manage experiments.\r\n  gc           Permanently delete runs in the `deleted` lifecycle stage.\r\n  models       Deploy MLflow models locally.\r\n  run          Run an MLflow project from the given URI.\r\n  runs         Manage runs.\r\n  sagemaker    Serve models on SageMaker.\r\n  server       Run the MLflow tracking server.\r\n  ui           Launch the MLflow tracking UI for local viewing of run...\r\nmlflow --help  1.00s user 0.30s system 99% cpu 1.312 total\r\n```\r\nAs you can see it takes 1 second. And it consistently takes 1 second no matter how many times you run it. \r\n\r\nFor good measure I also ensured that this checkbox is checked:\r\n\r\n<img width=\"780\" alt=\"Screen Shot 2020-10-09 at 4 35 23 PM\" src=\"https:\/\/user-images.githubusercontent.com\/14482624\/95639487-719ff500-0a4d-11eb-9964-d2007bc53997.png\">\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","559":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [X] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**:\r\n- **Python version**:\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nWhen I call the get_metric_history endpoint of the mlf flow tracking API with less than 100 steps, the array is sorted ascending from step 1 to X. As soon as I have 100 or more steps, the array is mixed.\r\n\r\n### Code to reproduce issue\r\n\r\n### Other info \/ logs\r\n\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","560":"Hi Team,\r\n\r\n         I have created the conda environment with help of **_mlflow prepare-env_** command , after that i am trying to launch\/serve the model manually with the command that being used by **_mlflow models serve_**   i.e., ` gunicorn --timeout=60 -b 0.0.0.0:8080 -w 1 ${GUNICORN_CMD_ARGS} -- mlflow.pyfunc.scoring_server.wsgi:app` \r\n\r\n      As per my analysis i understand that for serving the models the artifacts should be available some where in temporary location, so mlflow model serve command is helping to download the artifacts and saving into temp location.\r\n    \r\n     If we run manually the gunicorn command doesn't know about the temporary artifacts location. So please let me know how to server the model manually after preparing the environment. Thanks\r\n\r\nRegards,\r\nSiva ","561":"I was working with the Pycaret library to log models to mlflow. The models were logged to the a workspace experiment and the artifacts were save to an Azure datalake mount point. However, I received this warning. Note: I am running Databricks Runtime 7.3ML\r\n\r\n\"WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under\"\r\n\r\nEverything appear fine. I can see all of my logged runs and I can see my sklearn artifacts from the workspace experiment UI. However, when I go to register the the model to the Model Registry I get this message:\r\n\r\n\"Failed registration. The given source path does not exist.\"\r\n\r\nI thought maybe this was a Pycaret issue so I ran some sample code from the Mlflow documentation. The below code seems to work and logs the model under the Notebook experiment.\r\n\r\n> import mlflow\r\n> import mlflow.sklearn\r\n> from sklearn.datasets import load_iris\r\n> from sklearn import tree\r\n> \r\n> iris = load_iris()\r\n> sk_model = tree.DecisionTreeClassifier()\r\n> sk_model = sk_model.fit(iris.data, iris.target)\r\n> \r\n> mlflow.log_param(\"criterion\", sk_model.criterion)\r\n> mlflow.log_param(\"splitter\", sk_model.splitter)\r\n> \r\n> mlflow.sklearn.log_model(sk_model, \"sk_models\")\r\n\r\nBut, if I use mlflow.set_experiment() to log my parameters and model to a Workspace experiment I do not receive the earlier warning but I get the same error when attempting to register the model. \r\n\r\nI would like to be able to save my model artifacts to my mount point and be able to register them from that path. However, it appears I cannot do that.","562":"Hi there, \r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **MLflow installed from (source or binary)**: pip\r\n- **MLflow version (run ``mlflow --version``)**: try both 0.9.0 and 1.11.0\r\n- **Python version**: 3.6.6\r\n- **npm version, if running the dev UI**: -\r\n- **Exact command to reproduce**: `mlflow ui`\r\n\r\n### Describe the problem\r\n\r\nI work with my regular ML pipeline, which log the results using `mlflow`, previously on `0.9.0`. I update recently to `1.11.0`, do several changes in code accordingly (replace run_uuid with run_id in mlflow.start_run and so far this is all), but now I fail to open the table with results. I try with both `0.9.0` and `1.11.0` without success and even without a clue what is going on. For `0.9.0` there is an additional info in console, that *WARNING:root:Experiment ID mismatch for exp 0. ID recorded as '0' in meta data. Experiment will be ignored. NoneType: None*, but I assume that is because of changes still 0.9 release. There is no additional info about error or warning in console for `1.11.0`.\r\n\r\nI will attach my `mlruns` directory and screenshot of Chrome Dev Console below. Thanks\r\n\r\n### Code to reproduce issue\r\n\r\n`mlflow ui` in dir with given mlruns\r\n\r\n### Other info \/ logs\r\n\r\n[mlruns.zip](https:\/\/github.com\/mlflow\/mlflow\/files\/5317488\/mlruns.zip)\r\n\r\n![Screenshot from 2020-10-02 13-49-12](https:\/\/user-images.githubusercontent.com\/1048312\/94916980-57e43800-04b8-11eb-988c-f16f214d1f7a.png)\r\n\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","563":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [X] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nUpgrade proto files to use proto3 to enable the generation of .NET, Go, Dart code. The changes are relatively minor, but there may be some breaking changes. See this PR for reference on the changes that would need to be done. Make note of the proto files. \r\n\r\nThe required changes include:\r\n\r\n- Remove `optional` keyword.\r\n- Default values are based on primitive types, not as defined by user in proto file (potentially breaking)\r\n- Enums have to start at 0 (potentially breaking)\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n\r\n.NET, Go, Dart developers can access rich MLFLow lifecycle management features.\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\n\r\nMeet customers in the platforms they're working on.\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nCompilation of .NET, Go, Dart requires proto3.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [X] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [X] `area\/docs`: MLflow documentation pages\r\n- [X] `area\/examples`: Example code\r\n- [X] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [X] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [X] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [X] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","564":"## What changes are proposed in this pull request?\r\n\r\nThis change allows for using a Azure blob storage where AAD is used as authentication as described in #3483 \r\n\r\nThe main idea is that it allows for using a service principal that only has access to the blob container. It futhermore\r\nallows for controlling access to the Artifact Store through AAD as user\/developers\/model-builders can login with Azure CLI locally through the Azure Activate Directory login flow. This means that the normal Azure login flow can be used for model-builders to get access to the Artifact store.\r\n\r\n## How is this patch tested?\r\n\r\nThe current unit-test has been extended, and I have tried connecting to a AAD enabled blob container.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nAzure Activate Directory authentication when using Azure blob as storage for artifact store.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [x] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","565":"## Willingness to contribute\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nAllow users to authenticate to Azure Blob storage with AAD instead of storage key\r\n\r\n\r\n## Motivation\r\n- Moving all access management to deployer of MLflow and not user\r\n- Limiting what access is given to storage account\r\n- Won't have to make sure users roll their storage key as it is renewed.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [x] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nRight now the way to authenticate when using azure blob as artifact story is by using AZURE_STORAGE_CONNECTION_STRING or AZURE_STORAGE_ACCESS_KEY. However Azure Blob storage has the ability to use Azure Activate Directory for giving access. This would mean that you wouldn't have to distribute the key to the users (which also give them access to the whole storage account and not only the blob container.) and a system admin would just give the user access. To do this one can use the [azure-identity](https:\/\/github.com\/Azure\/azure-sdk-for-python\/tree\/master\/sdk\/identity\/azure-identity) package. \r\n\r\nThis would also have the benefit when deploying MLflow in AKS can use the service principal of your pod.\r\n\r\nAnother benefit is that you can have some users only have read access to the store.\r\n\r\nThis cloud easily be done by extending the  `AzureBlobArtifactRepository` class without any breaking changes (as far as I can see).\r\n https:\/\/github.com\/mlflow\/mlflow\/blob\/4f700b56cf0e389b31b67388947725da99221ef6\/mlflow\/store\/artifact\/azure_blob_artifact_repo.py#L12\r\n","566":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this installation issue template to ensure a timely and thorough response.**\r\n\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: latest master branch\r\n- **Python version**: 3.6\r\n- **Exact command to reproduce**:\r\n\r\nOn a Windows PC, make a commit\r\n\r\n```bash\r\ngit commit -s -m \"my commit message\"\r\n```\r\n\r\n### Describe the problem\r\nProvide the exact sequence of commands \/ steps that you executed before running into the problem.\r\n\r\nWhen making a commit, the following error appears:\r\n\r\n```bash\r\nerror: cannot spawn hooks\/prepare-commit-msg: No such file or directory\r\n```\r\n\r\nI was able to fix it by adding `#!\/bin\/sh` at the top of the file. Contributors guide may need to be updated. \r\n\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#common-prerequisites-and-dependencies\r\n\r\nI'd be happy to make the fix.\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n","567":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this installation issue template to ensure a timely and thorough response.**\r\n\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: latest maste branch\r\n- **Python version**: 3.6\r\n- **Exact command to reproduce**:\r\n\r\nInstalled test requirements by following the contributor's guide.\r\n\r\n```bash\r\npip install -r test-requirements.txt\r\n```\r\n\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#common-prerequisites-and-dependencies\r\n\r\n### Describe the problem\r\n\r\nWhen installing test-requirements (even after installing `cmake`) I get the following error:\r\n\r\n```text\r\nERROR: Could not find a version that satisfies the requirement torch==1.4.0 (from -r dev\/large-requirements.txt (line 22)) (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2)\r\nERROR: No matching distribution found for torch==1.4.0 (from -r dev\/large-requirements.txt (line 22))\r\n```\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n","568":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this installation issue template to ensure a timely and thorough response.**\r\n\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: latest master branch\r\n- **Python version**: 3.6\r\n- **Exact command to reproduce**:\r\n\r\nInstalled dev requirements by following the contributor's guide.\r\n\r\n```bash\r\npip install -r dev-requirements.txt\r\n```\r\n\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#common-prerequisites-and-dependencies\r\n\r\n### Describe the problem\r\n\r\nReceived the error message below. Not sure if it's an actual error or just a warning, but considering it's October 2020, it may be something to keep track of.  \r\n\r\n```text\r\nERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\r\n\r\nWe recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\r\n\r\npypi-publisher 0.0.4 requires gitpython==0.3.6, but you'll have gitpython 3.1.9 which is incompatible.\r\n```\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n","569":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ x ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\nyes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nMacOS Catalina 10.15.6, Docker with python:3.8.5-buster as base image\r\n- **MLflow installed from (source or binary)**:\r\npip install\r\n- **MLflow version (run ``mlflow --version``)**:\r\n1.10.0\r\n- **Python version**:\r\n3.8.5\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\nSee below.\r\n\r\n### Describe the problem\r\nWhen logging a single large (~500mb) artifact to an MLflow tracking server with a GCS artifact store hosted on GKE, MLflow times out. The cluster the server is running on seems to be large enough: 3 nodes, each with 3.75GB memory. No other experiments are being run at the same time.\r\n\r\n### Code to reproduce issue\r\n\r\nR script `train.R`:\r\n```\r\nlibrary(mlflow) # 1.10.0\r\nlibrary(tibble) \r\nlibrary(readr)\r\n\r\nwith(mlflow_start_run(), {\r\n  test_df <- as.tibble(replicate(300, sample(letters, 1000000, rep=TRUE)))\r\n  write_csv(test_df, 'test.csv') # ~500mb\r\n  mlflow_log_artifact(path='test.csv')\r\n})\r\n```\r\n\r\nCommand:\r\n```\r\nmlflow run --experiment-name big-file-test --entry-point train.R --no-conda .\r\n```\r\n\r\n### Other info \/ logs\r\n```\r\nTraceback (most recent call last):\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 670, in urlopen\r\n    httplib_response = self._make_request(\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 392, in _make_request\r\n    conn.request(method, url, **httplib_request_kw)\r\n  File \"\/usr\/local\/lib\/python3.8\/http\/client.py\", line 1255, in request\r\n    self._send_request(method, url, body, headers, encode_chunked)\r\n  File \"\/usr\/local\/lib\/python3.8\/http\/client.py\", line 1301, in _send_request\r\n    self.endheaders(body, encode_chunked=encode_chunked)\r\n  File \"\/usr\/local\/lib\/python3.8\/http\/client.py\", line 1250, in endheaders\r\n    self._send_output(message_body, encode_chunked=encode_chunked)\r\n  File \"\/usr\/local\/lib\/python3.8\/http\/client.py\", line 1049, in _send_output\r\n    self.send(chunk)\r\n  File \"\/usr\/local\/lib\/python3.8\/http\/client.py\", line 971, in send\r\n    self.sock.sendall(data)\r\n  File \"\/usr\/local\/lib\/python3.8\/ssl.py\", line 1204, in sendall\r\n    v = self.send(byte_view[count:])\r\n  File \"\/usr\/local\/lib\/python3.8\/ssl.py\", line 1173, in send\r\n    return self._sslobj.write(data)\r\nsocket.timeout: The write operation timed out\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 439, in send\r\n    resp = conn.urlopen(\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 726, in urlopen\r\n    retries = retries.increment(\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/urllib3\/util\/retry.py\", line 403, in increment\r\n    raise six.reraise(type(error), error, _stacktrace)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/urllib3\/packages\/six.py\", line 734, in reraise\r\n    raise value.with_traceback(tb)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 670, in urlopen\r\n    httplib_response = self._make_request(\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/urllib3Traceback (most recent call last):\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 670, in urlopen\r\n    httplib_response = self._make_request(\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 392, in _make_request\r\n    conn.request(method, url, **httplib_request_kw)\r\n  File \"\/usr\/local\/lib\/python3.8\/http\/client.py\", line 1255, in request\r\n    self._send_request(method, url, body, headers, encode_chunked)\r\n  File \"\/usr\/local\/lib\/python3.8\/http\/client.py\", line 1301, in _send_request\r\n    self.endheaders(body, encode_chunked=encode_chunked)\r\n  File \"\/usr\/local\/lib\/python3.8\/http\/client.py\", line 1250, in endheaders\r\n    self._send_output(message_body, encode_chunked=encode_chunked)\r\n  File \"\/usr\/local\/lib\/python3.8\/http\/client.py\", line 1049, in _send_output\r\n    self.send(chunk)\r\n  File \"\/usr\/local\/lib\/python3.8\/http\/client.py\", line 971, in send\r\n    self.sock.sendall(data)\r\n  File \"\/usr\/local\/lib\/python3.8\/ssl.py\", line 1204, in sendall\r\n    v = self.send(byte_view[count:])\r\n  File \"\/usr\/local\/lib\/python3.8\/ssl.py\", line 1173, in send\r\n    return self._sslobj.write(data)\r\nsocket.timeout: The write operation timed out\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 439, in send\r\n    resp = conn.urlopen(\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 726, in urlopen\r\n    retries = retries.increment(\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/urllib3\/util\/retry.py\", line 403, in increment\r\n    raise six.reraise(type(error), error, _stacktrace)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/urllib3\/packages\/six.py\", line 734, in reraise\r\n    raise value.with_traceback(tb)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 670, in urlopen\r\n    httplib_response = self._make_request(\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 392, in _make_request\r\n    conn.request(method, url, **httplib_request_kw)\r\n  File \"\/usr\/local\/lib\/python3.8\/http\/client.py\", line 1255, in request\r\n    self._send_request(method, url, body, headers, encode_chunked)\r\n  File \"\/usr\/local\/lib\/python3.8\/http\/client.py\", line 1301, in _send_request\r\n    self.endheaders(body, encode_chunked=encode_chunked)\r\n  File \"\/usr\/local\/lib\/python3.8\/http\/client.py\", line 1250, in endheaders\r\n    self._send_output(message_body, encode_chunked=encode_chunked)\r\n  File \"\/usr\/local\/lib\/python3.8\/http\/client.py\", line 1049, in _send_output\r\n    self.send(chunk)\r\n  File \"\/usr\/local\/lib\/python3.8\/http\/client.py\", line 971, in send\r\n    self.sock.sendall(data)\r\n  File \"\/usr\/local\/lib\/python3.8\/ssl.py\", line 1204, in sendall\r\n    v = self.send(byte_view[count:])\r\n  File \"\/usr\/local\/lib\/python3.8\/ssl.py\", line 1173, in send\r\n    return self._sslobj.write(data)\r\nurllib3.exceptions.ProtocolError: ('Connection aborted.', timeout('The write operation timed out'))\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"\/usr\/local\/bin\/mlflow\", line 8, in <module>\r\n    sys.exit(cli())\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/click\/core.py\", line 829, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/click\/core.py\", line 782, in main\r\n    rv = self.invoke(ctx)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/click\/core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/click\/core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/click\/core.py\", line 1066, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/click\/core.py\", line 610, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-pack\/connectionpool.py\", line 392, in _make_request\r\n    conn.request(method, url, **httplib_request_kw)\r\n  File \"\/usr\/local\/lib\/python3.8\/http\/client.py\", line 1255, in request\r\n    self._send_request(method, url, body, headers, encode_chunked)\r\n  File \"\/usr\/local\/lib\/python3.8\/http\/client.py\", line 1301, in _send_request\r\n    self.endheaders(body, encode_chunked=encode_chunked)\r\n  File \"\/usr\/local\/lib\/python3.8\/http\/client.py\", line 1250, in endheaders\r\n    self._send_output(message_body, encode_chunked=encode_chunked)\r\n  File \"\/usr\/local\/lib\/python3.8\/http\/client.py\", line 1049, in _send_output\r\n    self.send(chunk)\r\n  File \"\/usr\/local\/lib\/python3.8\/http\/client.py\", line 971, in send\r\n    self.sock.sendall(data)\r\n  File \"\/usr\/local\/lib\/python3.8\/ssl.py\", line 1204, in sendall\r\n    v = self.send(byte_view[count:])\r\n  File \"\/usr\/local\/lib\/python3.8\/ssl.py\", line 1173, in send\r\n    return self._sslobj.write(data)\r\nurllib3.exceptions.ProtocolError: ('Connection aborted.', timeout('The write operation timed out'))\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"\/usr\/local\/bin\/mlflow\", line 8, in <module>\r\n    sys.exit(cli())\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/click\/core.py\", line 829, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/click\/core.py\", line 782, in main\r\n    rv = self.invoke(ctx)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/click\/core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/click\/core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/click\/core.py\", line 1066, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/click\/core.py\", line 610, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/store\/artifact\/cli.py\", line 42, in log_artifact\r\n    artifact_repo.log_artifact(local_file, artifact_path)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/store\/artifact\/gcs_artifact_repo.py\", line 56, in log_artifact\r\n    blob.upload_from_filename(local_file)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/google\/cloud\/storage\/blob.py\", line 2334, in upload_from_filename\r\n    self.upload_from_file(\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/google\/cloud\/storage\/blob.py\", line 2220, in upload_from_file\r\n    created_json = self._do_upload(\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/google\/cloud\/storage\/blob.py\", line 2067, in _do_upload\r\n    response = self._do_resumable_upload(\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/google\/cloud\/storage\/blob.py\", line 1946, in _do_resumable_upload\r\n    response = upload.transmit_next_chunk(transport, timeout=timeout)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/google\/resumable_media\/requests\/upload.py\", line 495, in transmit_next_chunk\r\n    response = _request_helpers.http_request(\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/google\/resumable_media\/requests\/_request_helpers.py\", line 136, in http_request\r\n    return _helpers.wait_and_retry(func, RequestsMixin._get_status_code, retry_strategy)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/google\/resumable_media\/_helpers.py\", line 165, in wait_and_retry\r\n    response = func()\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/google\/auth\/transport\/requests.py\", line 464, in request\r\n    response = super(AuthorizedSession, self).request(\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 530, in request\r\n    resp = self.send(prep, **send_kwargs)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 643, in send\r\n    r = adapter.send(request, **kwargs)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 498, in send\r\n    raise ConnectionError(err, request=request)\r\nrequests.exceptions.ConnectionErrages\/mlflow\/store\/artifact\/cli.py\", line 42, in log_artifact\r\n    artifact_repo.log_artifact(local_file, artifact_path)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/store\/artifact\/gcs_artifact_repo.py\", line 56, in log_artifact\r\n    blob.upload_from_filename(local_file)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/google\/cloud\/storage\/blob.py\", line 2334, in upload_from_filename\r\n    self.upload_from_file(\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/google\/cloud\/storage\/blob.py\", line 2220, in upload_from_file\r\n    created_json = self._do_upload(\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/google\/cloud\/storage\/blob.py\", line 2067, in _do_upload\r\n    response = self._do_resumable_upload(\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/google\/cloud\/storage\/blob.py\", line 1946, in _do_resumable_upload\r\n    response = upload.transmit_next_chunk(transport, timeout=timeout)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/google\/resumable_media\/requests\/upload.py\", line 495, in transmit_next_chunk\r\n    response = _request_helpers.http_request(\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/google\/resumable_media\/requests\/_request_helpers.py\", line 136, in http_request\r\n    return _helpers.wait_and_retry(func, RequestsMixin._get_status_code, retry_strategy)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/google\/resumable_media\/_helpers.py\", line 165, in wait_and_retry\r\n    response = func()\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/google\/auth\/transport\/requests.py\", line 464, in request\r\n    response = super(AuthorizedSession, self).request(\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 530, in request\r\n    resp = self.send(prep, **send_kwargs)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 643, in send\r\n    r = adapter.send(request, **kwargs)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 498, in send\r\n    raise ConnectionError(err, request=request)\r\nrequests.exceptions.ConnectionError: ('Connection aborted.', timeout('The write operation timed out'))\r\nor: ('Connection aborted.', timeout('The write operation timed out'))\r\nError in run(mlflow_bin, args = unlist(args), echo = echo, echo_cmd = verbose, : System command 'mlflow' failed, exit status: 1, stdout & stderr were printed\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ x ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ x  ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","570":"Hi,\r\n\r\nThis seems to be a popular topic and I've read through a lot of tickets, but haven't found an answer, so I am not sure if this is impossible or just tricky to set up. \r\n\r\nMy use-case is that I have a Windows computer that runs some experiments locally, then tries to log metrics and artifacts to a remote server (Linux). The metrics are stored and work very well. However, it's not clear how to set up the remote artifact store using NFS. The documentation states that the paths must be identical on the client and the server, but I'm not sure how this can be done in Windows - everything has backspaces or has drive letters in the path. Can this be done right now?","571":"Hi everyone,\r\n\r\n### Willingness to contribute\r\n- [X] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes, custom code\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: CentOS Linux 7 (Core)\r\n- **MLflow installed from (source or binary)**: pip\r\n- **MLflow version (run ``mlflow --version``)**: 1.8 or later\r\n- **Python version**: 3.7\r\n- **npm version, if running the dev UI**: --\r\n- **Exact command to reproduce**: mlflow ui --port=5001\r\n\r\n### Describe the problem\r\nAs we are several users working on the same machine, we often use different ports for the server so that each user can display his own mlflow tracking UI.\r\nBut after updating mlflow from version 1.7.2 to 1.8 or later, we experienced a bug in the metric display interface : the line graphs are not displayed, there is only a blank pane instead. This bug appears only when launching the server on ports different than the usual 5000.\r\n\r\n\r\nMetric display for mlflow version 1.7.2 on every port:\r\n![CaptureMlflow172](https:\/\/user-images.githubusercontent.com\/19271957\/94706698-d323dd80-0342-11eb-815f-5fbb74508d2b.PNG)\r\n\r\nMetric doesn't display for mlflow version 1.8 or later when port != 5000:\r\n![CaptureMlflow19-2](https:\/\/user-images.githubusercontent.com\/19271957\/94706775-eafb6180-0342-11eb-9591-5e96fca91853.PNG)\r\n\r\nHowever when there is only one value for a metric, the bar plot is correctly displayed.\r\nOther than that, the interface works fine.\r\n\r\n### Code to reproduce issue\r\n```\r\nimport mlflow\r\n\r\nwith mlflow.start_run(run_name='Test'):\r\n    for i in range(10):\r\n        mlflow.log_metric('metric',i, step=i)\r\n```\r\n\r\n### Other info \/ logs\r\nOur web navigator is Firefox v79.0. We work behind the proxy of our company.\r\n\r\nThere isn't any error displayed in the mlflow terminal when this bug happens.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nThank you for your help,\r\nLea","572":"## What changes are proposed in this pull request?\r\n\r\nThis PR addresses #3175 . Please note that this is a **Draft**, and as such does not contain any additional tests yet.\r\n\r\nThis PR adds an option to the server to disable a number of possibly destructive actions on a given run if that run is associated with a registered model version that is currently in the 'production' stage. The thinking is that a production model should not be changed while it is in production. The methods that are protected by this functionality are:\r\n- `log_artifact`\r\n- `log_metric`\r\n- `log_param`\r\n- `delete_run`\r\n- `delete_registered_model`\r\n- `delete_registered_model_version`\r\nThe functionality is disabled by default but can be enabled on server side to enforce this, regardless of a client's configuration.\r\n\r\n## How is this patch tested?\r\n\r\nTests are still to come.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nThis PR adds an additional CLI parameter to the server that can be used to protect registered production models from modification.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [x] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","573":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time. It might change.\r\n\r\n## Proposal Summary\r\n\r\nAdd a _mlflow.set_artifact_uri_ to update artifact uri which change in my workflow. \r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nIn my workflow I want to change where the model is stored based on some results. I have a local artifactory. When I think that my models need to be shared, I want to push them to a served instance of **MLFLOW**.\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\nFor now, i set it with **mlflow.create_experiment** with _artifact_location_ arguments.\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nHelp a smoother worflow setup.\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nI don't see another way of doing diffently, with _mlflow.create_experiment_\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [x] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n","574":"Hi, I have been trying to to use mlflow for storing params, metrics and artifacts(models) for my deep learning experiments. Till now, I have able to achieve following things:\r\n 1) Setting up mlflow server on a remote machine and running the python script from another client machine\r\n 2) Able to successfully store the params and metrics on the remote server, but `log_artifacts()` is not saving the artifacts remotely, in fact it stores locally in .\/mlrun folder. \r\n\r\nNow, I just want to figure out a way to log artifacts remotely, which I have been struggling with since a day. On reading github issues, it seems that using NFS, SFTP and HDFS could help. However, I couldn't find a proper documentation for using NFS server with mlflow, and hence request anyone who has used NFS or other method to successfully store the artifacts.\r\n\r\n I look forward to a solution at the earliest. Thanks in advance.\r\n\r\nRegards,\r\nNakul \r\n","575":"## What changes are proposed in this pull request?\r\n\r\nThis fixes #3460 by describing correct maven coordinates for installing of `mlflow-spark`\r\n\r\n## How is this patch tested?\r\n\r\nNo need to test\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [X] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [X] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [X] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","576":"### Willingness to contribute\r\nThe MLflow Community encourages documentation fix contributions. Would you or another member of your organization be willing to contribute a fix for this documentation issue to the MLflow code base?\r\n\r\n- [X] Yes. I would be willing to contribute a document fix with guidance from the MLflow community.\r\n\r\n### URL(s) with the issue:\r\n\r\nhttps:\/\/mlflow.org\/docs\/latest\/tracking.html#spark-experimental\r\n\r\n### Description of proposal (what needs changing):\r\n\r\nExample of the code that adds the `mlflow-spark` package is incorrect\r\n\r\n```SparkSession.builder.config(\"spark.jars.packages\", \"org.mlflow.mlflow-spark\")```\r\n\r\nit should be\r\n\r\n```\r\nSparkSession.builder.config(\"spark.jars.packages\", \"org.mlflow:mlflow-spark:1.11.0\")\r\n```\r\n\r\nthis was already fixed in the source code: https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/spark.py#L665","577":"## What changes are proposed in this pull request?\r\n\r\nClarifies that MLflow requires Python >= 3.5 in the README and quickstart\r\n\r\n## How is this patch tested?\r\n\r\nManually\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","578":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [*] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**:\r\n\r\n- **Python version**: from azureml.core.webservice import AciWebservice, Webservice\r\n\r\n```\r\n(**Webservice**, model) = mlflow.azureml.deploy(model_uri= model_uri,\r\n                                            workspace= workspace,\r\n                                            model_name=\"<model_name>\",\r\n                                            service_name='<service_name>',\r\n                                            deployment_config=aci_config)\r\n```\r\n**webservice requires to start with small letter \"w\" in DBFS but required to start with capital letter \"W\" in pycharm or other python IDEs**\r\n\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [* ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [* ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [* ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [* ] `integrations\/azure`: Azure and Azure ML integrations\r\n\r\n- [* ] `integrations\/databricks`: Databricks integrations\r\n","579":"So mlflow has a function set_tracking_uri(), where we can pass http\/https URL of the tracking server as an argument. However, I dont have clue from the mlflow documents of the proper steps to start the tracking server. I am using mlflow with Nvidia's odth retinanet repository ```https:\/\/github.com\/NVIDIA\/retinanet-examples\/```\r\n\r\n Here are the commands I use:\r\n\r\n  1) `In terminal 1`:  mlflow server --host 0.0.0.0\r\n  2) `In terminal 2`:  python main.py train --args1 --args2 -- \r\n\r\nHowever, I end up getting this issue .\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 244, in <module>\r\n    main()\r\n  File \"main.py\", line 238, in main\r\n    worker(0, args, 1, model, state)\r\n  File \"main.py\", line 180, in worker\r\n    regularization_l2=args.regularization_l2, rotated_bbox=args.rotated_bbox, absolute_angle=args.absolute_angle)\r\n  File \"\/home\/nakul\/retinanet_pytorch\/retinanet\/train.py\", line 33, in train\r\n    with mlflow.start_run():\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/tracking\/fluent.py\", line 159, in start_run\r\n    active_run_obj = MlflowClient().create_run(experiment_id=exp_id_for_run, tags=tags)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/tracking\/client.py\", line 137, in create_run\r\n    return self._tracking_client.create_run(experiment_id, start_time, tags)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 95, in create_run\r\n    tags=[RunTag(key, value) for (key, value) in iteritems(tags)],\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 145, in create_run\r\n    response_proto = self._call_endpoint(CreateRun, req_body)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 52, in _call_endpoint\r\n    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/utils\/rest_utils.py\", line 153, in call_endpoint\r\n    host_creds=host_creds, endpoint=endpoint, method=method, json=json_body\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/utils\/rest_utils.py\", line 78, in http_request\r\n    max_rate_limit_interval, url=url, headers=headers, verify=verify, **kwargs\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/utils\/rest_utils.py\", line 57, in request_with_ratelimit_retries\r\n    response = requests.request(**kwargs)\r\n  File \"\/home\/nakul\/.local\/lib\/python3.6\/site-packages\/requests\/api.py\", line 61, in request\r\n    return session.request(method=method, url=url, **kwargs)\r\n  File \"\/home\/nakul\/.local\/lib\/python3.6\/site-packages\/requests\/sessions.py\", line 530, in request\r\n    resp = self.send(prep, **send_kwargs)\r\n  File \"\/home\/nakul\/.local\/lib\/python3.6\/site-packages\/requests\/sessions.py\", line 643, in send\r\n    r = adapter.send(request, **kwargs)\r\n  File \"\/home\/nakul\/.local\/lib\/python3.6\/site-packages\/requests\/adapters.py\", line 516, in send\r\n    raise ConnectionError(e, request=request)\r\nrequests.exceptions.ConnectionError: HTTPSConnectionPool(host='10.1.20.152', port=5000): Max retries exceeded with url: \/api\/2.0\/mlflow\/runs\/create (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f83bc22ceb8>: Failed to establish a new connection: [Errno 111] Connection refused',))\r\n\r\n\r\nI kindly request to post step-by-step guide about\r\n1) What modifications to make in files other than setting set_tracking_uri()\r\n2)  what commands to use to start the tracking server\r\n\r\nLooking forward to seeing the solution soon. Thanks\r\n\r\n","580":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 10.14.5 (18F203)\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.11.0\r\n- **Python version**: Python 3.8.5\r\n- **npm version, if running the dev UI**: Not using UI\r\n- **Exact command to reproduce**: `MLFLOW_TRACKING_URI=https:\/\/xxxx.xxxxx.com MLFLOW_TRACKING_USERNAME=xxxx MLFLOW_TRACKING_PASSWORD=xxxxx mlflow run -P alpha=0.5  . --backend kubernetes --backend-config kubernetes_config.json --experiment-name test1`\r\n\r\n### Describe the problem\r\n**MLflow not picking up environment variables when run with --backend kubernetes**\r\n\r\nI'm trying to get MLProject to run inside Kubernetes following this https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/docker with the below command\r\n\r\nThe describe pod however only show MLFLOW_TRACKING_URI being picked up not the other two env variables, see below\r\n\r\n```\r\nName:         tutorial-2020-09-22-11-17-54-381954-mgptt\r\nNamespace:    mlflow\r\nPriority:     0\r\nNode:         kind-worker\/172.19.0.3\r\nContainers:\r\n  tutorial:\r\n    Container ID:  containerd:\/\/7de7124f96ea83da474e66bc7b2119cba4d4e0ab7188e135e3ed190dde5c8df4\r\n    State:          Terminated\r\n      Reason:       Error\r\n      Exit Code:    1\r\n      Started:      Tue, 22 Sep 2020 11:17:55 +0200\r\n      Finished:     Tue, 22 Sep 2020 11:17:56 +0200\r\n    Ready:          False\r\n    Restart Count:  0\r\n    ...\r\n    Environment:\r\n      MLFLOW_RUN_ID:         1a83aa6a16704883a775ad50bc94c7e9\r\n      MLFLOW_TRACKING_URI:   https:\/\/xxxx.xxxxx.com\r\n      MLFLOW_EXPERIMENT_ID:  73\r\n    ...\r\n```\r\n\r\nThe env variables are described in the MLproject file as below, to note the volume mentioned below also is also not mounted as expected\r\n\r\n```\r\ndocker_env:\r\n  image: somaupday\/mlflow-sklearn:latest\r\n  environment: [[\"MLFLOW_TRACKING_URI\", \"https:\/\/xxxx.xxxxx.com\"], [\"MLFLOW_TRACKING_USERNAME\", \"mlflow\"], [\"MLFLOW_TRACKING_PASSWORD\", \"xxxxxxx\"]]\r\n  volumes: [\"${HOME}\/.aws:\/root\/.aws\"]\r\n```\r\n\r\nother relevant files for reference \r\n**kubernetes_config.json**\r\n```\r\n{\r\n  \"kube-context\": \"kind-kind\",\r\n  \"repository-uri\": \"xxxxx\/mlflow-sklearn\",\r\n  \"kube-job-template-path\": \".\/kubernetes_job_template.yaml\"\r\n}\r\n```\r\n\r\n**kubernetes_job_template.yaml**\r\n```\r\napiVersion: batch\/v1\r\nkind: Job\r\nmetadata:\r\n  name: \"{replaced with MLflow Project name}\"\r\n  namespace: mlflow\r\nspec:\r\n  ttlSecondsAfterFinished: 100\r\n  backoffLimit: 0\r\n  template:\r\n    spec:\r\n      containers:\r\n      - name: \"{replaced with MLflow Project name}\"\r\n        image: \"{replaced with URI of Docker image created during Project execution}\"\r\n        command: [\"{replaced with MLflow Project entry point command}\"]\r\n      resources:\r\n        limits:\r\n          memory: 512Mi\r\n        requests:\r\n          memory: 256Mi\r\n      restartPolicy: Never\r\n```\r\n\r\nAdditionally I also don't see the volumes are not mounted as expected.. \r\n\r\nPS: This is based on one of the MLproject that already runs in docker for us, we just want to run it in Kubernetes instead\r\n\r\n\r\n### Code to reproduce issue\r\n```\r\nMLFLOW_TRACKING_URI=https:\/\/xxxx.xxxxx.com MLFLOW_TRACKING_USERNAME=xxxx MLFLOW_TRACKING_PASSWORD=xxxxx mlflow run -P alpha=0.5  . --backend kubernetes --backend-config kubernetes_config.json --experiment-name test1\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [x] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","581":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.11.0\r\n- **Python version**: 3.7.9\r\n- **npm version, if running the dev UI**: 6.5.0\r\n- **Exact command to reproduce**: \r\n\r\n### Describe the problem\r\nI'm using `mlflow.tracking.MlflowClient` as a way of running and tracking experiments. When I try to log my PyTorch model as an artifact using `mlflow.pytorch.log_model`, it doesn't show up in the artifact list for the the specific experiment run. I dug through the codebase a little bit, and it seems that `mlflow.pytorch.log_model` work on the level of `mlflow.tracking.fluent` while `mlflow.tracking.MlflowClient` is working in a lower API level (but I'm not entirely sure). What is the best approach for saving PyTorch models while using `mlflow.tracking.MlflowClient`?\r\n\r\n### Code to reproduce issue\r\n```\r\nimport mlflow\r\n\r\nclient = mlflow.tracking.MlflowClient(tracking_uri)\r\nclient.create_run(experiment_id)\r\n...\r\nmlflow.pytorch.log_model(model, \"model\")\r\n```\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","582":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nProvide an interface for opening full-size images from Artefacts view.\r\n\r\n## Motivation\r\n\r\nWorking with computer vision or generative models, one often needs to inspect logged images. Especially in the case of generative models, it is crucial to see pixel-perfect renditions of the produced images, in full size, unperturbed by rescaling or cropping.\r\n\r\nUsing Tensorboard, I can click an image saved in the Images tab and see it in the original size. I would like to request a similar feature to be added to MLFlow.\r\n\r\nCurrently, the Artefacts view in MLFlow uses Plotly to render saved images. While this is a powerful interface for panning or zooming, it seems to have no option to render images in full size, without cropping or rescaling.\r\n\r\nA caveat: this change would need to play well with https:\/\/github.com\/mlflow\/mlflow\/issues\/2696 (comparing images between different runs).\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nA possible solutions is to partly mimic Tensorboard's interface and add a button to toggle between showing the image in the original size and the standard resized and cropped version. Mimicking it fully and implementing this functionality via a click on the image is unlikely to work well, since it would conflict with Plotly.","583":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n### The proposal is to expand arguments in calls to internal clients as kwargs to allow for easier plugin backward\/forward compatibility.\r\n\r\nExample for MlflowClient.list_run_infos:\r\n```\r\n    def list_run_infos(\r\n        self,\r\n        experiment_id,\r\n        run_view_type=ViewType.ACTIVE_ONLY,\r\n        max_results=SEARCH_MAX_RESULTS_DEFAULT,\r\n        order_by=None,\r\n        page_token=None,\r\n    ):\r\n        \"\"\":return: List of :py:class:`mlflow.entities.RunInfo`\"\"\"\r\n        return **self._tracking_client.list_run_infos(\r\n            experiment_id=experiment_id, run_view_type=run_view_type, max_results=max_results, order_by=order_by, page_token=page_token**\r\n        )\r\n```\r\n\r\n### MlflowClient currently calls the internal store with positional arguments for list_run_infos and a few other functions:\r\n```\r\n\r\n    def list_run_infos(\r\n        self,\r\n        experiment_id,\r\n        run_view_type=ViewType.ACTIVE_ONLY,\r\n        max_results=SEARCH_MAX_RESULTS_DEFAULT,\r\n        order_by=None,\r\n        page_token=None,\r\n    ):\r\n        \"\"\":return: List of :py:class:`mlflow.entities.RunInfo`\"\"\"\r\n        return **self._tracking_client.list_run_infos(\r\n            experiment_id, run_view_type, max_results, order_by, page_token**\r\n        )\r\n```\r\n#### current plugin requirement:\r\n```\r\ndef list_run_infos(self, *args, **kwargs):\r\n     custom code that uses args[0]\r\n     return super().list_run_infos(self, *args, **kwargs)\r\n```\r\n\r\nif args is not passed there is a failure for extra parameters. If kwargs is passed, there is also a failure for extra parameters.\r\n\r\nThis requires that plugins pass *args through function calls to avoid new parameters causing failures in function calls.\r\n\r\n\r\n#### future plugin requirement:\r\n```\r\ndef list_run_infos(self, experiment_id=None, **kwargs):\r\n     custom code that uses experiment_id\r\n     return super().list_run_infos(self, experiment_id=experiment_id, **kwargs)\r\n\r\n```\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nReduce surface area for plugins to break for newly introduced functionality.\r\n- Why is this use case valuable to support for MLflow users in general?\r\nThis allows users of plugins to have a more stable experience with new mlflow releases while also expanding the flexibility of plugin implementations.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nOur plugin broke on the August 31st release because of the new parameters passed to list_run_infos and a few other model registry functions. We were passing kwargs for thelist_run_infos call but it did not protect us against the break which caused our model registry and search runs functions to fail before reaching our service.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nCurrently plugins need to expand both args and maintain their order if they utilize super methods. This programming paradigm is more fickle than kwargs passing for extras since positional arguments can be interleaved incorrectly unlike kwargs.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","584":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**:\r\n- **Python version**:\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nRunning mlflow projects commands with a full path fails with\r\nstderr: 'fatal: 'C:\/Users\/eddeleon\/path\/to\/project' does not appear to be a git repository\r\nfatal: Could not read from remote repository.\r\n\r\nHowever passing relative paths like \".\" or \".\/to\/project\" works as expected.\r\n\r\n### Code to reproduce issue\r\n\r\ngit clone https:\/\/github.com\/mlflow\/mlflow-example\r\npip install mlflow\r\npwd\r\nmlflow run {abs path from pwd}\/mlflow-examples\r\n\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [x] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","585":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: yes\r\n\r\nAll versions are irrelevant, since the problem is in current `master`.\r\n\r\n- **Exact command to reproduce**:\r\n\r\n1. `mkdir \/tmp\/mlruns`\r\n2. Run the following script:\r\n\r\n```python\r\nimport mlflow\r\n\r\nmlflow.set_tracking_uri(f'file:\/tmp\/mlruns')\r\nmlflow.log_param(\"my int param\", 6)\r\n```\r\n\r\n### Describe the problem\r\n\r\n`FileStore` [creates a default experiment](https:\/\/github.com\/mlflow\/mlflow\/blob\/d743a40426d5dedbde395a4e6bbdeebadbccd4dc\/mlflow\/store\/tracking\/file_store.py#L138-L142) only if `self.root_directory` does not exist yet. However, if it does exist but is empty, this leads to an exception, which is difficult to interpret for those who encounter MLFlow for the first time:\r\n\r\n```python\r\nTraceback (most recent call last):\r\n  File \"test_mlflow.py\", line 4, in <module>\r\n    mlflow.log_param(\"my int param\", 6)\r\n  File \"\/home\/ser\/.miniconda3\/envs\/mlflow\/lib\/python3.8\/site-packages\/mlflow\/tracking\/fluent.py\", line 175, in log_param\r\n    run_id = _get_or_start_run().info.run_id\r\n  File \"\/home\/ser\/.miniconda3\/envs\/mlflow\/lib\/python3.8\/site-packages\/mlflow\/tracking\/fluent.py\", line 416, in _get_or_start_run\r\n    return start_run()\r\n  File \"\/home\/ser\/.miniconda3\/envs\/mlflow\/lib\/python3.8\/site-packages\/mlflow\/tracking\/fluent.py\", line 141, in start_run\r\n    active_run_obj = MlflowClient().create_run(\r\n  File \"\/home\/ser\/.miniconda3\/envs\/mlflow\/lib\/python3.8\/site-packages\/mlflow\/tracking\/client.py\", line 84, in create_run\r\n    return self.store.create_run(\r\n  File \"\/home\/ser\/.miniconda3\/envs\/mlflow\/lib\/python3.8\/site-packages\/mlflow\/store\/file_store.py\", line 360, in create_run\r\n    experiment = self.get_experiment(experiment_id)\r\n  File \"\/home\/ser\/.miniconda3\/envs\/mlflow\/lib\/python3.8\/site-packages\/mlflow\/store\/file_store.py\", line 270, in get_experiment\r\n    experiment = self._get_experiment(experiment_id)\r\n  File \"\/home\/ser\/.miniconda3\/envs\/mlflow\/lib\/python3.8\/site-packages\/mlflow\/store\/file_store.py\", line 245, in _get_experiment\r\n    raise MlflowException(\"Could not find experiment with ID %s\" % experiment_id,\r\nmlflow.exceptions.MlflowException: Could not find experiment with ID 0\r\n```\r\n\r\nPerhaps `FileStore.__init__()` should create a default experiment if it is not present yet, instead of only creating it if the directory itself does not exist?\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\nGuys, your issue template is really long, this somewhat discourages reporting and contributions :\/","586":"\r\n## Willingness to contribute\r\n\r\n- [ x ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nThe autolog function is great! However, is consuming a lot of memory resources because is saving the h5 model without an option to disable this feature. It would be very useful to have the possibility to disable the model save option.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nWhen someone works with huge models it can be impossible to save all h5 files for each experiment. This situation is worse when the teamwork uses a centralized logging server.\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\nEasily log function with some user control or options.\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nBetter resource management.\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\n## Details\r\n\r\nIn the @experimental mlflow.keras.autolog() function, on_train_end method it always tries to log the model. This situation triggers automatically a functionality to save the h5 file. There are situations it could be useful to avoid saving this file because of disk space management or transfer data to servers.\r\n\r\n","587":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nTo provide a way for adding a filter on some column+value in a single click\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\nThis would improve productivity with MLflow, making the UI more efficient to use.\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nIt's a nice feature in Kibana, which while not high-value, seems low-effort.\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nCurrently one needs to manually type a filter expression.  We could instead allow a simple equality filter to be added in a single click (if using a Kibana-style button in the list) or right-click+left-click if using context-menu.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n\r\nI was originally trying to decide how to nest runs where we have periodic retraining of some set of models (one model per e.g. product family).  Nest the runs as `date\/family\/` or as `family\/date\/`?\r\n\r\nBut if filtering was slightly more efficient to use (no manual text entry required) then this wouldn't even be an issue.\r\n\r\nI'm happy to implement it myself.","588":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nWe are training then saving our ML models using `with mlflow.start_run():` and `mlflow.sklearn.log_model()` methods. During the training steps, we want to import some private Python libraries. We are wondering what is the best way to include those libraries in the MLflow model?\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n\r\n## Details\r\nCurrently, we specify all public dependencies in the conda.yaml, such as sklearn, pip. Then, we deploy our model as a tar.gz file in AWS Sagemaker. In our case, we'd like to install some private Python libraries. More specifically, our artifacts are stored in Jfrog. We are wondering about, is the conda.yaml the only place that we can specify the dependencies (either public or private)? \r\nFor example, we are using a private model library to train my ML model. \r\n`import MyPrivateModel`\r\n`my_model=MyPrivateModel().fit(x_train, y_train)`\r\nWhat would my conda.yml look like? We are wondering do you provide any solution of securely passing in my private artifactory credentials?\r\n\r\nThank you so much!","589":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n* Implement new R flavours to support the `tidymodels` framework.\r\n* Implement autologging for these flavours.\r\n\r\n## Motivation\r\n\r\nCurrently, three flavours are supported in R: `keras`, `xgboost`, and `crate`. While `crate` supports arbitrary functions, it is difficult to use, requiring careful declarations of dependencies and methods. There remains no easy way to implement common machine learning techniques, such as random forests and k-nearest-neighbours.\r\n\r\n[The `tidymodels` metapackage\/framework](https:\/\/www.tidymodels.org\/) provides a unified interface for various machine learning packages in R. Rather than directly implementing machine learning techniques, it calls on other packages as _engines_. With the same syntax, a user can train a random forest with either the `randomForest` package or the `ranger` package. By supporting `tidymodels` flavours, MLflow can indirectly support [the wide variety of engines with which `tidymodels` interfaces](https:\/\/www.tidymodels.org\/find\/parsnip\/).\r\n\r\nMoreover, the unified interface also opens up the possibility of introducing autologging for R.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [x] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [x] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nThree `tidymodels` packages are relevant here:\r\n\r\n* `parsnip` interfaces with the various machine learning packages (engines).\r\n* `recipes` is used for data pre-processing.\r\n* `workflows` combines the above into single objects. This is somewhat analogous to `sklearn` pipelines.\r\n\r\nSince the models are single objects, we can implement `parsnip` and `workflow` flavours that save and load these as `RDS` files. This would involve extending the S3 generics `mlflow_save_model` and `mlflow_load_flavor`. For example, the below S3 method would work for `parsnip` models (with the \"model_fit\" class):\r\n\r\n```r\r\nmlflow_save_model.model_fit <- function(model,\r\n                                        path,\r\n                                        model_spec = list(),\r\n                                        ...) {\r\n  if (dir.exists(path)) unlink(path, recursive = TRUE)\r\n  dir.create(path)\r\n\r\n  saveRDS(model, file.path(path, \"parsnip_model.rds\"))\r\n\r\n  spec <- model$spec\r\n  model <- class(spec)[[1]] # adapted from workflows:::print_header\r\n  engine <- spec$engine\r\n  mode <- spec$mode\r\n\r\n  model_spec$flavors <- append(model_spec$flavors, list(\r\n    parsnip = list(\r\n      data = \"parsnip_model.rds\",\r\n      model = model,\r\n      engine = engine,\r\n      mode = mode\r\n    )\r\n  ))\r\n  mlflow_write_model_spec(path, model_spec)\r\n  model_spec\r\n}\r\n```\r\n\r\nThe `model` and `engine` attributes are particularly useful here: they can be used to check that the required packages for a particular `parsnip` model are available:\r\n\r\n```r\r\nget_parsnip_dependencies <- function(model, engine) {\r\n  dependencies <- parsnip::get_dependency(model)\r\n  if (!(engine %in% dependencies$engine)) {\r\n    stop(engine, \" is not a valid engine for \", model)\r\n  }\r\n  engine_dependencies <- dependencies[which(dependencies$engine == engine), ]\r\n  engine_dependencies$pkg[[1]]\r\n}\r\n\r\nrequire_parsnip_dependencies <- function(model, engine) {\r\n  required_packages <- get_parsnip_dependencies(model, engine)\r\n  for (package in required_packages) {\r\n    require_package(package)\r\n  }\r\n  invisible(required_packages)\r\n}\r\n```\r\n\r\nThis check is performed when the model is loaded back in:\r\n\r\n```r\r\nmlflow_load_flavor.mlflow_flavor_parsnip <- function(flavor, model_path) {\r\n  require_package(\"parsnip\")\r\n  model_spec <- mlflow_read_model_spec(\"model\")\r\n  model <- model_spec$flavors$parsnip$model\r\n  engine <- model_spec$flavors$parsnip$engine\r\n  require_parsnip_dependencies(model, engine)\r\n  readRDS(file.path(model_path, \"parsnip_model.rds\"))\r\n}\r\n```\r\n\r\nSomething similar is required for `workflow`s.\r\n\r\n`parsnip`'s unified interface also means that we can implement autologging for R models. A function that fits in with `magrittr`'s pipes would make sense here. In the example below, `mlflow_autolog_params` returns the model unaltered, but logs the arguments to `linear_model` as parameters. It's implemented as an S3 method, to leave the door open for autologging other flavours:\r\n\r\n```r\r\nlibrary(mlflow)\r\nlibrary(parsnip)\r\nlibrary(magrittr)\r\nidx <- sample(nrow(mtcars))\r\ntrain <- mtcars[idx[1:25], ]\r\ntest <- mtcars[idx[26:32], ]\r\nlinear_model <- linear_reg(penalty = 0.2, mixture = 0.5) %>% set_engine(\"lm\")\r\nwith(mlflow_start_run(),\r\n  linear_model %>%\r\n    mlflow_autolog_params() %>%\r\n    fit(mpg ~ ., train) %>%\r\n    mlflow_save_model(\"model\")\r\n)\r\n# Will log parameters \"penalty\" = 0.2 and \"mixture\" = 0.5\r\n# Default values are not logged\r\n```\r\n\r\nThere's also the possibilty of autologging metrics with the `yardstick` package, also a part of `tidymodels`, although I haven't yet explored this.\r\n\r\nI've drafted a bit of code to support the new flavours and autologging of parameters but, in line with the MLflow contributing guidelines, I'll hold off on submitting a pull request for now. Apart from design matters, I still need to do the following:\r\n\r\n- [ ] Request that the `tidymodels` team expose `workflows:::predict.workflow`, as CRAN will not be happy with using an internal function like this (`parsnip::predict.parsnip` looks fine)\r\n- [ ] Incorporate the new flavours into the MLflow CLI (I might need help with this)\r\n- [ ] Implement autologging of metrics, if desired\r\n- [ ] Update documentation and examples\r\n\r\nI hope I can help out! I really like MLflow --- this is a great tool, and I'm grateful for the work of all of the contributors.","590":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ x ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nPlugins currently require a tracking_uri with a registered schema. However, if the tracking_uri is only the schema, it is registered as a FileStore(\"plugin_schema\"). \r\n\r\nTo circumvent this plugin providers need to use a uri \"plugin_schema:\" to avoid this issue. However, users are then susceptible to forgetting the extra \":\" and losing some of their log calls to .\/mlruns\/.\r\n\r\nThe proposal is for mlflow.set_tracking_uri(\"plugin_schema\")  to validate as the specified plugin instead of FileStore(\"plugin_schema\").\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nThis allows plugin writers to have a more seamless user experience since users would only have to remember the plugin name in prepared environments. It also allows plugins to be more consistent with the databricks plugin's user experience.\r\n- Why is this use case valuable to support for MLflow users in general?\r\nIt provides a more robust code path for users that try to leverage a schema based tracking_uri.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nOur organization would like to have a tracking uri of \"azureml\", however, currently our plugin is not reached by mlflow so we are unable to do so.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nWe would need to have \"azureml:\", however, that solution is not consistent with other plugins and, as mentioned before has a failure mode that tracks to a local FileStore when \":\" is omitted.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ x ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","591":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.11.0\r\n- **Python version**: 3.6.8\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: calling `mlflow.pyfunc.load_model()`\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\nIm not sure if this was introduced as a feature or not, but here is the description:\r\n\r\nI have a python function model that wraps around an sklearn model, a class that looks like this:\r\n```\r\nclass GenericModel(mlflow.pyfunc.PythonModel):\r\n\r\n  def __init__(self, model):\r\n    self.model = model\r\n\r\n  def predict(self, input):\r\n    return self.model.predict_proba(input)[:, 1][0]\r\n\r\n  def get_model(self):\r\n    return self.model\r\n```\r\n\r\nMy `_load_pyfunc()` function returns an instance of this class above.\r\n\r\nIn version `mlflow==1.7.2` when I call `mlflow.pyfunc.load_model` I get back the correct instance and I can call `get_model()` on the returned object. However in recent updates, like `mlflow==1.11.0`, this method is no longer available on the class.\r\n\r\nI looked through the code and it seems that all that is happening is calling this `_load_pyfunc()` method which should return an instance of this class, but it seems that something is strongly typing it and removing the other custom instance methods I have written on it. \r\n\r\nAm I just missing some information on how python classes work or how the import_module is working? Not entirely sure if this is an feature with MLFlow or just some python stuff.\r\n\r\nThank you for any help!!\r\n\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\nCreate a generic PyfuncModel with additional instance methods and see if they are available when calling mlflow.pyfunc.load_model()\r\n```\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n","592":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [X] No. I cannot contribute a bug fix at this time.\r\n\r\n\r\n### Describe the problem\r\nThere is a bug in the current pandas==1.1.2 that incorrectly parses json strings. MLFlow serving uses `pandas.read_json(string)`, which currently creates an error for any request satisfying `\":\/\/\" in string`, see https:\/\/github.com\/pandas-dev\/pandas\/issues\/36271 . This problem does not exist in pandas==1.0.5 . This may affect all deployments with MLFlow.\r\n\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [X] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n","593":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Catalina 10.15.4\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: 1.10.0\r\n- **Python version**: 3.7.6\r\n- **npm version, if running the dev UI**: - \r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI would like to use the kubernetes deployment functionality for running training jobs. For this I have a `MLproject` file in my python package that looks something like this (I omitted details to make the mlflow tracking run properly, this works for now):\r\n```\r\nname: my-mlflow-project\r\n\r\ndocker_env:\r\n  image: eu.gcr.io\/my-gcloud-project\/project_container_gpu\r\n\r\nentry_points:\r\n  main:\r\n    command: \"python trainer.py\"\r\n```\r\n\r\nI would like to be able to run training locally as well as in kubernetes, just by changing the mlflow command arguments:\r\n1. `mlflow run .``\r\n2. `mlflow run . --backend kubernetes --backend-config ...`\r\n\r\nEvery time I run one of those commands, a docker image with the current code is build based on the base image provided in the `MLproject` file. The only difference is the resulting image repository name:\r\n\r\n```\r\n\u00bb docker images                                                                                                                               \r\nREPOSITORY                                                  TAG                             IMAGE ID            CREATED             SIZE\r\nmy-mlflow-project                                    9d6d7a3                         e535a8039eec        2 hours ago         5.85GB\r\neu.gcr.io\/my-gcloud-project\/project_container_gpu    9d6d7a3                         e535a8039eec        2 hours ago         5.85GB\r\n```\r\n\r\nNote, that the TAG and IMAGE ID is exactly the same in both cases (because it's the same commit and I did not change any code locally).\r\n\r\nOnce I ran the command locally and try to run it with the kubernetes backend **after**, the pushing of the image to the container registry fails with this error:\r\n```\r\n2020\/09\/11 16:04:33 INFO mlflow.projects: === Building docker image eu.gcr.io\/mxlabs-adem-pytorch-test\/project_container_gpu:9d6d7a3 ===\r\n2020\/09\/11 16:04:38 INFO mlflow.projects.kubernetes: === Pushing docker image mxlabs-adem-pytorch-test:9d6d7a3 ===\r\n2020\/09\/11 16:04:41 ERROR mlflow.cli: === Error while pushing to docker registry: denied: requested access to the resource is denied ===\r\n```\r\n\r\n**I can work around this by deleting the image with the REPOSITORY name of `my_package_name` (so only one image exists with the same docker IMAGE ID).**\r\n\r\nI looked into it a bit, and I am pretty sure that the reason for this is the usage of the first found image tag [in this line](https:\/\/github.com\/mlflow\/mlflow\/blob\/e34dbf236f7c19e9774365d03c87bc1b746d932f\/mlflow\/projects\/__init__.py#L154) where the first found image repository is chosen with `image.tag[0]`.\r\n\r\nThis leads to it trying to push the image repository `my_package_name` and failing to \"get access\" to the non existent repository.\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","594":"###Willingness to contribute\r\n- [x ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows Server 2016 Standard 64 bit \r\n- **MLflow installed from (source or binary)**: Installed with Anaconda GUI\r\n- **MLflow version (run ``mlflow --version``)**:  \r\nTrying this, but getting this error message: \r\nFatal error in launcher: Unable to create process using '\"d:\\bld\\mlflow_1599218365944\\_h_env\\python.exe\"  \"C:\\ProgramData\\Anaconda3\\envs\\UtvPy_38_MLFlow\\Scripts\\mlflow.exe\" --version': The system cannot find the file specified.\r\nBut Anaconda says mlflow & mlflow-ui-dbg 1.11.0\r\n- **Python version**: 3.8\r\n- **npm version, if running the dev UI**: ? \r\n- **Exact command to reproduce**: See below\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\nWhen running the train() function of the train.ipnb in https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/sklearn_elasticnet_wine , the tracking API returns an error message when trying to log to the tracking server set up with a mssql database. This issue does not happen when logging to a local sqlite database. \r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nInitialize mlflow tracking server, using local artifact store and mssql server: \r\npython \"C:\\ProgramData\\Anaconda3\\envs\\UtvPy_38_MLFlow\\Scripts\\mlflow.exe\" server --backend-store-uri mssql+pymssql:\/\/@<mssql> --default-artifact-root file:\/\/E:\/MyFolder\/MLFlow\/ --host 0.0.0.0\r\n\r\nUse the train.ipynb in https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/sklearn_elasticnet_wine\r\nSet the mlflow.set_tracking_uri('http:\/\/<local-computer-name>:5000')\r\nRun train(0.3, 0.7)\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nError message in the notebook: \r\nElasticnet model (alpha=0.300000, l1_ratio=0.700000):\r\n  RMSE: 0.774713648356711\r\n  MAE: 0.6079678532556209\r\n  R2: 0.14961391810397706\r\n2020\/09\/07 16:10:01 ERROR mlflow.utils.rest_utils: API request to http:\/\/<local-computer-name>:5000\/api\/2.0\/mlflow\/runs\/get failed with code 500 != 200, retrying up to 2 more times. API response body: <!DOCTYPE HTML PUBLIC \"-\/\/W3C\/\/DTD HTML 3.2 Final\/\/EN\">\r\n<title>500 Internal Server Error<\/title>\r\n<h1>Internal Server Error<\/h1>\r\n<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.<\/p>\r\n\r\n(...)\r\n\r\nMessages in the Tracking server terminal: \r\nServing on http:\/\/<local-computer-name>:5000\r\nC:\\ProgramData\\Anaconda3\\envs\\UtvPy_38_MLFlow\\lib\\site-packages\\sqlalchemy\\dialects\\mssql\\pymssql.py:61: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working\r\n  module = __import__(\"pymssql\")\r\n2020\/09\/07 12:16:01 ERROR mlflow.server: Exception on \/api\/2.0\/mlflow\/runs\/get [GET]\r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\UtvPy_38_MLFlow\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\", line 713, in field_setter\r\n    new_value = type_checker.CheckValue(new_value)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\UtvPy_38_MLFlow\\lib\\site-packages\\google\\protobuf\\internal\\type_checkers.py\", line 171, in CheckValue\r\n    raise TypeError(message)\r\nTypeError: Decimal('1599473751897') has type <class 'decimal.Decimal'>, but expected one of: (<class 'int'>,)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\UtvPy_38_MLFlow\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\r\n    response = self.full_dispatch_request()\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\UtvPy_38_MLFlow\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\r\n    rv = self.handle_user_exception(e)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\UtvPy_38_MLFlow\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\r\n    reraise(exc_type, exc_value, tb)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\UtvPy_38_MLFlow\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\r\n    raise value\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\UtvPy_38_MLFlow\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\r\n    rv = self.dispatch_request()\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\UtvPy_38_MLFlow\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\r\n    return self.view_functions[rule.endpoint](**req.view_args)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\UtvPy_38_MLFlow\\lib\\site-packages\\mlflow\\server\\handlers.py\", line 213, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\UtvPy_38_MLFlow\\lib\\site-packages\\mlflow\\server\\handlers.py\", line 445, in _get_run\r\n    response_message.run.MergeFrom(_get_tracking_store().get_run(run_id).to_proto())\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\UtvPy_38_MLFlow\\lib\\site-packages\\mlflow\\entities\\run.py\", line 39, in to_proto\r\n    run.info.MergeFrom(self.info.to_proto())\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\UtvPy_38_MLFlow\\lib\\site-packages\\mlflow\\entities\\run_info.py\", line 146, in to_proto\r\n    proto.start_time = self.start_time\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\UtvPy_38_MLFlow\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\", line 715, in field_setter\r\n    raise TypeError(\r\nTypeError: Cannot set mlflow.RunInfo.start_time to Decimal('1599473751897'): Decimal('1599473751897') has type <class 'decimal.Decimal'>, but expected one of: (<class 'int'>,)\r\n2020\/09\/07 12:16:05 ERROR mlflow.server: Exception on \/api\/2.0\/mlflow\/runs\/get [GET]\r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\UtvPy_38_MLFlow\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\", line 713, in field_setter\r\n    new_value = type_checker.CheckValue(new_value)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\UtvPy_38_MLFlow\\lib\\site-packages\\google\\protobuf\\internal\\type_checkers.py\", line 171, in CheckValue\r\n    raise TypeError(message)\r\nTypeError: Decimal('1599473751897') has type <class 'decimal.Decimal'>, but expected one of: (<class 'int'>,)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n(...)\r\nThis issue seems a bit similar to https:\/\/github.com\/mlflow\/mlflow\/issues\/1165 \r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [? ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [? ] `area\/windows`: Windows support\r\n","595":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this documentation issue template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages documentation fix contributions. Would you or another member of your organization be willing to contribute a fix for this documentation issue to the MLflow code base?\r\n\r\n- [x] Yes. I can contribute a documentation fix independently.\r\n- [ ] Yes. I would be willing to contribute a document fix with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a documentation fix at this time.\r\n\r\n### URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry in question.\r\n\r\n### Description of proposal (what needs changing):\r\nProvide a clear description. Why is the proposed documentation better?\r\n\r\n\r\n[numpydoc](https:\/\/numpydoc.readthedocs.io\/en\/latest\/format.html#overview) has a more readable and structured format than reStructuredText.\r\n\r\nreStructuredText\r\n\r\n```python\r\ndef func(foo, bar, baz):\r\n    \"\"\"\r\n    foo bar baz\r\n\r\n    :param foo: foo\r\n    :type foo: str\r\n    :param bar: bar\r\n    :type bar: int\r\n    :return: baz\r\n    :rtype: str\r\n    \"\"\"\r\n```\r\n\r\nnumpydoc:\r\n\r\n```python\r\ndef func(foo, bar, baz):\r\n    \"\"\"\r\n    foo bar baz\r\n\r\n    Parameters\r\n    ----------\r\n    foo: int\r\n        foo\r\n    bar: str\r\n        bar\r\n\r\n    Returns\r\n    -------\r\n    str:\r\n        baz\r\n    \"\"\"\r\n```\r\n","596":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**:\r\n- **Python version**:\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [x] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [x] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [x] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n\r\n\r\nI tried to run the test codes after my installation both of mlflow 1.10.0 and 1.11.0 and encountered the error message:\"Error in wait_for(function() mlflow_rest(\"experiments\", \"list\", client = client), : Operation failed after waiting for 10 seconds\" with using r on Windows 10. Any idea what happened?\r\n\r\nThe test codes are:\r\n```\r\nlibrary(mlflow)\r\nmlflow_set_experiment(\"Test\")\r\n```\r\n\r\nMy session info is as the following:\r\nR version 4.0.2 (2020-06-22)\r\nPlatform: x86_64-w64-mingw32\/x64 (64-bit)\r\nRunning under: Windows 10 x64 (build 19042)\r\n\r\nMatrix products: default\r\n\r\nlocale:\r\n[1] LC_COLLATE=Chinese (Traditional)_Taiwan.950  LC_CTYPE=Chinese (Traditional)_Taiwan.950   \r\n[3] LC_MONETARY=Chinese (Traditional)_Taiwan.950 LC_NUMERIC=C                                \r\n[5] LC_TIME=Chinese (Traditional)_Taiwan.950    \r\n\r\nattached base packages:\r\n[1] stats     graphics  grDevices utils     datasets  methods   base     \r\n\r\nother attached packages:\r\n[1] mlflow_1.10.0   reticulate_1.16\r\n\r\nloaded via a namespace (and not attached):\r\n [1] Rcpp_1.0.5         lubridate_1.7.9    lattice_0.20-41    forge_0.2.0        tidyr_1.1.1        ps_1.3.3          \r\n [7] class_7.3-17       zeallot_0.1.0      assertthat_0.2.1   ipred_0.9-9        R6_2.4.1           plyr_1.8.6        \r\n[13] hardhat_0.1.4      httr_1.4.1         pillar_1.4.6       rlang_0.4.7        curl_4.3           parsnip_0.1.2     \r\n[19] rstudioapi_0.11    data.table_1.12.8  DiceDesign_1.8-1   rpart_4.1-15       Matrix_1.2-18      splines_4.0.2     \r\n[25] gower_0.2.2        munsell_0.5.0      compiler_4.0.2     httpuv_1.5.4       xfun_0.15          askpass_1.1       \r\n[31] pkgconfig_2.0.3    base64enc_0.1-3    dials_0.0.8        nnet_7.3-14        openssl_1.4.2      tidyselect_1.1.0  \r\n[37] tibble_3.0.3       prodlim_2019.11.13 fansi_0.4.1        crayon_1.3.4       dplyr_1.0.0        withr_2.2.0       \r\n[43] later_1.1.0.1      MASS_7.3-51.6      recipes_0.1.13     rappdirs_0.3.1     grid_4.0.2         jsonlite_1.7.0    \r\n[49] lifecycle_0.2.0    magrittr_1.5       pROC_1.16.2        scales_1.1.1       cli_2.0.2          stringi_1.4.6     \r\n[55] swagger_3.9.2      fs_1.4.2           promises_1.1.1     timeDate_3043.102  ini_0.3.1          ellipsis_0.3.1    \r\n[61] generics_0.0.2     vctrs_0.3.2        xgboost_1.1.1.1    lava_1.6.7         yardstick_0.0.7    tools_4.0.2       \r\n[67] glue_1.4.1         purrr_0.3.4        yaml_2.2.1         processx_3.4.3     survival_3.2-3     colorspace_1.4-1  \r\n[73] knitr_1.29        \r\n\r\n\r\n ","597":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time. <- happy to help with design\/code review\r\n\r\n## Proposal Summary\r\n\r\n[SHAP](https:\/\/github.com\/slundberg\/shap) is a popular library for model explanability. These explanations are useful for both:\r\n* Understanding feature importance during model training (e.g. to guide further improvements to the model)\r\n* Understanding the predictions made by the model on fresh data (e.g. for providing post-hoc justification for\/insight into a prediction)\r\n\r\nWe should consider an extension to the MLflow APIs that simplifies logging model explanations with SHAP. \r\n\r\n## Motivation\r\nSee above\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n\r\n### Initial Investigation [WIP]\r\nSHAP provides an API for generating a \"model explainer\" given a fitted model, which can then be applied to an input dataset (`explainer.shap_values(input_dataset)`) to explain the model's predictions. For each data point, the \"shap value\" of each of its features is a coefficient illustrating the impact of that feature value in increasing or decreasing the model output.\r\n\r\nFor certain model types, e.g. trees ([link](https:\/\/github.com\/slundberg\/shap#tree-ensemble-example-with-treeexplainer-xgboostlightgbmcatboostscikit-learnpyspark-models)), SHAP is able to compute explanations using only the fitted model and model input:\r\n\r\n```\r\nmodel = xgboost.train({\"learning_rate\": 0.01}, xgboost.DMatrix(X, label=y), 100)\r\n\r\n# explain the model's predictions using SHAP\r\n# (same syntax works for LightGBM, CatBoost, scikit-learn and spark models)\r\nexplainer = shap.TreeExplainer(model)\r\nshap_values = explainer.shap_values(X)\r\n\r\n# visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\r\nshap.force_plot(explainer.expected_value, shap_values[0,:], X.iloc[0,:])\r\n```\r\n\r\nIn other cases, e.g. deep learning, more robust explanations can be generated by passing \"background\" data constructing a model explainer ([link](https:\/\/github.com\/slundberg\/shap#deep-learning-example-with-deepexplainer-tensorflowkeras-models)):\r\n\r\n```\r\n# select a set of background examples to take an expectation over\r\nbackground = x_train[np.random.choice(x_train.shape[0], 100, replace=False)]\r\n\r\n# explain predictions of the model on four images\r\ne = shap.DeepExplainer(model, background)\r\nshap_values = e.shap_values(x_test[1:5])\r\n\r\n# plot the feature attributions\r\nshap.image_plot(shap_values, -x_test[1:5])\r\n```\r\n\r\nThe same holds for SHAP's generic [KernelExplainer](https:\/\/github.com\/slundberg\/shap#model-agnostic-example-with-kernelexplainer-explains-any-function). Note that in the example below we pass a function to represent the model (``svm.predict_proba``):\r\n\r\n```\r\n# use Kernel SHAP to explain test set predictions\r\nexplainer = shap.KernelExplainer(svm.predict_proba, X_train, link=\"logit\")\r\nshap_values = explainer.shap_values(X_test, nsamples=100)\r\n\r\n# plot the SHAP values for the Setosa output of the first instance\r\nshap.force_plot(explainer.expected_value[0], shap_values[0][0,:], X_test.iloc[0,:], link=\"logit\")\r\n```\r\n\r\nIn general, it seems that constructing an explainer always requires the fitted model (or some attribute thereof) and often also an input dataset, while computing and plotting explanations requires the explainer and an input dataset. Thus in the future, we could autogenerate an explainer at model fit time (e.g. in our autologging integrations) and persist it alongside the model, so that users can later load it back and compute explanations on fresh data.\r\n\r\nAs a stepping stone, we could provide  ``mlflow.shap.log_explainer(explainer, path)`` and ``mlflow.shap.load_explainer(path)`` APIs that persist a user-constructed ``explainer`` to a specified artifact subpath and load it back for future use. Note that SHAP doesn't appear to have any built-in persistence APIs (TODO investigate, but [see docs](https:\/\/shap.readthedocs.io\/en\/latest\/#plots)), so we may have to e.g. just pickle the explainer","598":"I would be willing to contribute, but I'll need guidance, and it is possible that I won't have a lot of time for this.\r\n\r\n## Proposal Summary\r\n\r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n\r\nUnderstanding *why* a job has failed is frequently more important than understanding that it failed.  Getting the stack trace and any error messages would really help with debugging or understanding failures.\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\n\r\nLong runs that fail towards the end are the bane of deep learning researchers.  It can make debugging very difficult.  A stack trace could really help with debugging.\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nThe logging of a failed run stack trace should really be automatic, rather than something that is manually done.\r\n\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\n## Details\r\n\r\nThis should be fairly simple: wrap the run in a \"try\/except\" block, and then have a \"log_failure\" method that is automatically called when an exception is caught.","599":"Hi all, thanks for creating such a great open source project!\r\n\r\nI'm reaching out on behalf of the Ray team, and I was wondering if you would be interested in some form of integration in Ray Tune?\r\n\r\n[Ray Tune](http:\/\/tune.io\/) is an open source project for distributed hyperparameter tuning. We recently announced a [W&B integration](https:\/\/medium.com\/distributed-computing-with-ray\/ray-tune-weights-and-biases-simple-developer-tools-for-scaling-machine-learning-1c3f24f8ba83) and was wondering if you all would be interested in doing something similar. \r\n\r\nHistorically, we've actually received a number of users asking about how to integrate with MLflow.\r\n\r\nLet me know if you have any questions and happy to jump on a call + discuss further!\r\n\r\n","600":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: N\/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Chrome on Amazon Linux 2\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: 1.10.0\r\n- **Python version**: 3.6.10\r\n- **npm version, if running the dev UI**: N\/A\r\n- **Exact command to reproduce**: Log a large (~10MB) JSON artifact and attempt to preview through Chrome\r\n\r\n### Describe the problem\r\nWhenever I accidentally click on an **large** artefact (i.e. 10MB) that's in a previewable file format in the web UI, the page becomes unresponsive. I would prefer it if these files were truncated or not considered previewable.\r\n\r\n### Code to reproduce issue\r\nN\/A\r\n\r\n### Other info \/ logs\r\nI'm unfortunately not able to export logs or files from the machine.\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","601":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n<br>\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu18.04\r\n- **MLflow installed from (source or binary)**: Binary (pip)\r\n- **MLflow version (run ``mlflow --version``)**: 1.10.0\r\n- **Python version**: 3.6.5\r\n- **npm version, if running the dev UI**: N\/A\r\n- **Exact command to reproduce**: `mlflow run --docker-args runtime=nvidia https:\/\/github.com\/TaikiInoue\/MLProjects.git#SSAD`\r\n\r\n<br>\r\n\r\n### Describe the problem\r\nMy mlflow run command `mlflow run --docker-args runtime=nvidia https:\/\/github.com\/TaikiInoue\/MLProjects.git#SSAD` works correctly. However, there is no `--docker-args` option in MLflow UI \r\n\r\n<br>\r\n\r\n### Code to reproduce issue\r\nThis is my MLproject file\r\n```\r\nname: ssad\r\n\r\ndocker_env:\r\n    image: ssad:latest\r\n    environment: [\"MLFLOW_TRACKING_URI\", \"DATABRICKS_HOST\", \"DATABRICKS_TOKEN\", \"AZURE_STORAGE_CONNECTION_STRING\"]\r\n\r\nentry_points:\r\n    main:\r\n        parameters:\r\n            data_repo: {type: str, default: \"https:\/\/github.com\/TaikiInoue\/DVC.git\"}\r\n            data_commid_hash: {type: str, default: \"a6e3c2288e7808162d46d9f998eb7c674ad90384\"}\r\n            code_repo: {type: str, default: \"https:\/\/github.com\/TaikiInoue\/SSAD.git\"}\r\n            code_commit_hash: {type: str, default: \"18013875df1da233f25bf38d8751d100033a4cda\"}\r\n        command: \"sh entry_points.sh --data_repo={data_repo} --data_commid_hash={data_commid_hash} --code_repo={code_repo} --code_commit_hash={code_commit_hash}\"\r\n```\r\n\r\n<br>\r\n\r\n`runtime=nvidia` was specified to train my model with GPU, and this command works correctly.\r\n```\r\nmlflow run --docker-args runtime=nvidia https:\/\/github.com\/TaikiInoue\/MLProjects.git#SSAD\r\n```\r\n\r\n<br>\r\n\r\nThis is my MLflow UI. As you can see, there is no `--docker-args` option, and I can't reproduce the experiment with this command. Of course, it works correctly when I add `--docker-args` option manually.\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/29189728\/92127974-db205880-ee3c-11ea-93a7-5361904bd011.png)\r\n\r\n<br>\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","602":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n<br>\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu18.04\r\n- **MLflow installed from (source or binary)**: Binary (pip)\r\n- **MLflow version (run ``mlflow --version``)**: 1.10.0\r\n- **Python version**: 3.6.5\r\n- **npm version, if running the dev UI**: N\/A\r\n- **Exact command to reproduce**: mlflow run --docker-args runtime=nvidia .\r\n\r\n<br>\r\n\r\n### Describe the problem\r\n`mlflow run` doesn't work when copying the environment variables containing semi-colon `;` from the host to the docker container. \r\n\r\n<br>\r\n\r\n### Code to reproduce issue\r\nThis is my `MLproject` file. The problem is `AZURE_STORAGE_CONNECTION_STRING`. It contains semi-colon `;`. Don't worry, all the values (e.g. github repo and commit_hash) are dummies.\r\n```\r\nname: hoge\r\n\r\ndocker_env:\r\n    image: hoge\r\n    environment: [\"MLFLOW_TRACKING_URI\", \"DATABRICKS_HOST\", \"DATABRICKS_TOKEN\", \"AZURE_STORAGE_CONNECTION_STRING\"]\r\n\r\nentry_points:\r\n    main:\r\n        parameters:\r\n            data_repo: {type: str, default: \"https:\/\/github.com\/hoge\/hoge.git\"}\r\n            data_commid_hash: {type: str, default: \"974hj06p45;higghc8351\"}\r\n            code_repo: {type: str, default: \"https:\/\/github.com\/hoge\/hoge.git\"}\r\n            code_commit_hash: {type: str, default: \"hhjd8hasy8751d9gljlgej\"}\r\n        command: \"sh entry_points.sh\"\r\n```\r\n\r\n<br>\r\n\r\nI run the command, and then I got the following error. These values (e.g. environment variables and RUN ID) are dummies as well.\r\n\r\n```\r\nmlflow run --docker-args runtime=nvidia .\r\n```\r\n\r\n```\r\n2020\/09\/03 15:46:58 INFO mlflow.projects: === Building docker image ssad:129739b ===\r\n2020\/09\/03 15:46:59 INFO mlflow.projects: === Created directory \/tmp\/tmpczukugoy for downloading remote URIs passed to arguments of type 'path' ===\r\n2020\/09\/03 15:46:59 INFO mlflow.projects: === Running command 'docker run --rm --runtime nvidia -e MLFLOW_RUN_ID=1t3trg57dbfewbvfweb -e MLFLOW_TRACKING_URI=databricks -e MLFLOW_EXPERIMENT_ID=626262052256456 -e DATABRICKS_HOST=https:\/\/adb-997587567985267467.0.azuredatabricks.net -e DATABRICKS_TOKEN=gfvfbwgg4rgrvg14b3tbtrnbrt50a1232 -e AZURE_STORAGE_CONNECTION_STRING=DefaultEndpointsProtocol=https;AccountName=hoge;AccountKey=hgKGljLK+Uwg3vadvsdavsdAl1i7ERR2vsavds\/tgAJMG9\/IvavsamHGsavdaBERfdbd==;EndpointSuffix=core.windows.net hoge:12r35b sh entry_points.sh' in run with ID 'ehkg31435bdfglhkgg35j4fg4' === \r\n\"docker run\" requires at least 1 argument.\r\nSee 'docker run --help'.\r\n\r\nUsage:  docker run [OPTIONS] IMAGE [COMMAND] [ARG...]\r\n\r\nRun a command in a new container\r\nbash: ssad:129739b: command not found\r\n2020\/09\/03 15:47:01 ERROR mlflow.cli: === Run (ID '1484357d5b3f42a4a512945941e7e656') failed ===\r\n```\r\n\r\n<br>\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","603":"## What changes are proposed in this pull request?\r\n\r\nCurrently Artifacts view on Run page does not tool like a best viewer for .py and other text files content:\r\n- There is no enough space between a left border of content area and the content itself. That leads to difficulties with file content reading.\r\n- Instead of scrolling file content the entire artifact view panel is scrolling, and that does not look OK. Due to that you need to scroll down the file content panel to see the horizontal scrollbar, and this is not convenient.\r\n- Scrollbars are always on the screen even if there is no need to show them. In some cases these scrollbars are attached to each other, and that's is really ugly.\r\n- The file content goes off the panel border. You can open file with long lines and try horizontal scroll to see that.\r\n- This panel has a rounded border. Sometimes the background of selected file in the left panel is overlapping with this border. This causes the strange sharp angles appearance in the right angles-based interface.\r\n\r\nExamples:\r\n![scroll_files_old](https:\/\/user-images.githubusercontent.com\/4661021\/92036879-94b5f580-ed79-11ea-8535-1e46cd1e1df0.gif)\r\n![scroll_content_old](https:\/\/user-images.githubusercontent.com\/4661021\/92036868-8ff14180-ed79-11ea-8a37-c3e875a7bae0.gif)\r\n\r\nThis pull request fixes all these cases:\r\n- The file list panel and the content panel now have separated scrollbars\r\n- They are hidden if nothing is going off the drawing area\r\n- The left padding of file content panel increased\r\n- The horizontal scroll of file content panel does not cause strange appearance effects\r\n- The file list panel, the file info panel and the file content panel have their own borders now\r\n- No rounded borders anymore, just right angles\r\n\r\nExamples:\r\n![scroll_files_new](https:\/\/user-images.githubusercontent.com\/4661021\/92036904-9da6c700-ed79-11ea-92e2-9597de968b65.gif)\r\n\r\n![scroll_content_new](https:\/\/user-images.githubusercontent.com\/4661021\/92036892-9a134000-ed79-11ea-9710-08d87b2e003d.gif)\r\n\r\n## How is this patch tested?\r\n\r\nMLflow UI was browsed using Firefox 80.0b8 and Chrome 86.0.4240.22.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [X] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nFixed some small artifacts panel UI issues.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [X] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [X] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","604":"Signed-off-by: Arpan Bhattacharya <tell.arpan.bhattacharya@gmail.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nIn the \"Compare Runs\" section - display end time and run duration. \r\nAddresses [this](https:\/\/github.com\/mlflow\/mlflow\/issues\/2029) issue.\r\n\r\n## How is this patch tested?\r\n\r\nStill trying to figure out the automated test suite. \r\nScreenshot:\r\n![image](https:\/\/user-images.githubusercontent.com\/37980914\/91980679-7e0d9100-ecdc-11ea-8b6f-d7ac85e353d5.png)\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\nIt is. In the \"Compare Runs\" section of the tracking UI, the end timestamp, and the duration of the experiment will be shown upon pushing this patch.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\n\r\nInterface \r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n","605":"## What changes are proposed in this pull request?\r\n\r\nAdd support for pip only projects (not using conda or docker)\r\n\r\n## How is this patch tested?\r\n\r\nTested with mlflow projects local backend and mlflow-yarn backend.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\nAdd support for pip only projects.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","606":"\r\nThe field `version_num` in `alembic_version` table is also used by applications other than MLflow, such as Optuna. This causes MLflow to overwrite these applications' version numbers, making them unusable and upgrade-resistant. Manually creating a separate database for each application and granting db user read\/write access to each database is currently required to avoid this problem.\r\n\r\nMore details:\r\nhttps:\/\/github.com\/mlflow\/mlflow\/issues\/2923#issuecomment-684808578","607":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Linux Ubuntu 18.04\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.10.0\r\n- **Python version**: 3.7.3\r\n- **Tensorflow version**: 2.2.0\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: mlflow.tensorflow.autolog()\r\n\r\n### Describe the problem\r\nWhat I want to do - Log metrics generated by my experiments in tensorflow object detection (using TF2.x API). \r\nWhat happens - metrics are not logged when using mlflow.tensorflow.autolog()\r\nAdditional information - A previous PR https:\/\/github.com\/mlflow\/mlflow\/pull\/2396 lists the changes required to log metrics for TF Object Detection using TF1.x API. Since, TF1.x uses estimators, changes were made in corresponding patches in tensorflow.py file. However, with TF2.x, estimators are not used anymore. Instead, `train_loop` and `evaluate_continuously` is used for launching an a train (and eval job). You can find related code [here](https:\/\/github.com\/tensorflow\/models\/blob\/master\/research\/object_detection\/model_main_tf2.py). Using `mlflow.keras.autolog()` didn't work either. \r\n\r\nWhere do the changes need to be made to log metrics when using TF Object Detection 2.x ?\r\n\r\n### Other info \/ logs\r\nAn mlflow experiment is created correctly and files logged with mlflow.log_artifact() function as expected. Only the metrics are not recorded.\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [x ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.","608":"## System Details\r\npython_version: 3.6.10\r\npython_build: ('default', 'May  7 2020 19:46:08')\r\nmachine: AMD64\r\nplatform: Windows-10-10.0.18362-SP0\r\nmlflow==1.10.0\r\n\r\n## Issue\r\nWhen using `infer_signature` from `mlflow.models.signature` facing this error (see below traceback). Here is how you can reproduce the error.\r\n\r\n```\r\nimport pandas as pd\r\ndata = pd.read_csv('train.csv') \r\nfrom mlflow.models.signature import infer_signature\r\ninfer_signature(data)\r\n```\r\nDataset: https:\/\/www.kaggle.com\/c\/titanic\/data?select=train.csv\r\n\r\n**The exception is only thrown when there are `NULL` values in the dataset. Should it really matter for `infer_signature`? Can this function be edited to tolerate missing values?**\r\n\r\n**Traceback**\r\n----> 1 infer_signature(data)\r\n\r\n~\\Anaconda3\\envs\\pycaret21\\lib\\site-packages\\mlflow\\models\\signature.py in infer_signature(model_input, model_output)\r\n    109     :return: ModelSignature\r\n    110     \"\"\"\r\n--> 111     inputs = _infer_schema(model_input)\r\n    112     outputs = _infer_schema(model_output) if model_output is not None else None\r\n    113     return ModelSignature(inputs, outputs)\r\n\r\n~\\Anaconda3\\envs\\pycaret21\\lib\\site-packages\\mlflow\\types\\utils.py in _infer_schema(data)\r\n     57     elif isinstance(data, pd.DataFrame):\r\n     58         return Schema([ColSpec(type=_infer_numpy_array(data[col].values), name=col)\r\n---> 59                        for col in data.columns])\r\n     60     elif isinstance(data, np.ndarray):\r\n     61         if len(data.shape) > 2:\r\n\r\n~\\Anaconda3\\envs\\pycaret21\\lib\\site-packages\\mlflow\\types\\utils.py in <listcomp>(.0)\r\n     57     elif isinstance(data, pd.DataFrame):\r\n     58         return Schema([ColSpec(type=_infer_numpy_array(data[col].values), name=col)\r\n---> 59                        for col in data.columns])\r\n     60     elif isinstance(data, np.ndarray):\r\n     61         if len(data.shape) > 2:\r\n\r\n~\\Anaconda3\\envs\\pycaret21\\lib\\site-packages\\mlflow\\types\\utils.py in _infer_numpy_array(col)\r\n    143             return DataType.double\r\n    144         else:\r\n--> 145             raise MlflowException(\"Unable to map 'np.object' type to MLflow DataType. np.object can\"\r\n    146                                   \"be mapped iff all values have identical data type which is one \"\r\n    147                                   \"of (string, (bytes or byterray),  int, float).\")\r\n\r\nMlflowException: Unable to map 'np.object' type to MLflow DataType. np.object canbe mapped iff all values have identical data type which is one of (string, (bytes or byterray),  int, float).","609":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Any\r\n- **MLflow installed from (source or binary)**: Binary (pip)\r\n- **MLflow version (run ``mlflow --version``)**: Latest (1.10.0)\r\n- **Python version**: 3.7\r\n- **npm version, if running the dev UI**: N\/A\r\n- **Exact command to reproduce**: `mlflow server` with a database backend store with primary keys enforced (see below)\r\n\r\n### Describe the problem\r\nMLflow server Alembic migrations fail silently if primary keys are enforced on the backend store database (e.g. via `--innodb-force-primary-key`). This is due to the migration dropping and re-creating the key as two separate steps.\r\n\r\n### Code to reproduce issue\r\n1. Download docker-compose version of bitnami MariaDB Galera image\r\n\r\n`curl -sSL https:\/\/raw.githubusercontent.com\/bitnami\/bitnami-docker-mariadb-galera\/master\/docker-compose.yml > docker-compose.yml`\r\n\r\n\r\n2. Create mlflow Dockerfile\r\n\r\n```\r\nFROM python:3.7-slim-buster\r\n\r\nRUN apt update && apt install -y build-essential libmariadbclient-dev default-libmysqlclient-dev wait-for-it && \\\r\n  pip install --no-cache-dir mlflow boto3 mysqlclient\r\n\r\nENTRYPOINT wait-for-it -t 0 mariadb:3306 -- mlflow server --host=0.0.0.0 \\\r\n  --backend-store-uri mysql:\/\/root@mariadb:3306\/mlflow \\\r\n  --default-artifact-root \/tmp\r\n```\r\n\r\n3. Build mlflow docker container\r\n\r\n`docker build . --tag mlflow`\r\n\r\n4. Update docker-compose.yml to mlflow service\r\n\r\n```\r\nversion: '2.1'\r\n\r\nservices:\r\n  mariadb-galera:\r\n    image: 'docker.io\/bitnami\/mariadb-galera:10.5-debian-10'\r\n    ports:\r\n      - '3306:3306'\r\n      - '4444:4444'\r\n      - '4567:4567'\r\n      - '4568:4568'\r\n    volumes:\r\n      - 'mariadb_galera_data:\/bitnami\/mariadb'\r\n    environment:\r\n      # ALLOW_EMPTY_PASSWORD is recommended only for development.\r\n      - ALLOW_EMPTY_PASSWORD=yes\r\n      - MARIADB_DATABASE=mlflow\r\n      - MARIADB_EXTRA_FLAGS=--innodb-force-primary-key\r\n    networks: \r\n      - mlflow\r\n  mlflow:\r\n    image: 'mlflow:latest'\r\n    depends_on:\r\n      - mariadb-galera\r\n    links:\r\n      - \"mariadb-galera:mariadb\"\r\n    networks: \r\n      - mlflow\r\n\r\nnetworks:\r\n  mlflow:\r\n    driver: bridge\r\n\r\nvolumes:\r\n  mariadb_galera_data:\r\n    driver: local\r\n```\r\n\r\n5. Bring up containers\r\n\r\n`docker-compose up -d`\r\n\r\n6. MLflow fails silently\r\n\r\n### Other info \/ logs\r\n\r\nMLflow container logs:\r\n\r\n```\r\nwait-for-it: waiting for mariadb:3306 without a timeout\r\nwait-for-it: mariadb:3306 is available after 9 seconds\r\n2020\/08\/29 05:27:09 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\r\n2020\/08\/29 05:27:09 INFO mlflow.store.db.utils: Updating database tables\r\nINFO  [alembic.runtime.migration] Context impl MySQLImpl.\r\nINFO  [alembic.runtime.migration] Will assume non-transactional DDL.\r\nINFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\r\n```\r\n\r\nTo view the exact error message (as it isn't captured in the container logs), run `alembic upgrade 451aebb31d03` from inside the MLflow container:\r\n\r\n```\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/mlflow\/store\/db_migrations\/versions\/451aebb31d03_add_metric_step.py\", line 28, in upgrade\r\n    columns=['key', 'timestamp', 'step', 'run_uuid', 'value'])\r\n  File \"\/usr\/local\/lib\/python3.7\/contextlib.py\", line 119, in __exit__\r\n    next(self.gen)\r\n  ... (omitted for brevity)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/MySQLdb\/cursors.py\", line 315, in _query\r\n    db.query(q)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/MySQLdb\/connections.py\", line 231, in query\r\n    _mysql.connection.query(self, query)\r\nsqlalchemy.exc.OperationalError: (MySQLdb._exceptions.OperationalError) (1173, 'This table type requires a primary key')\r\n[SQL: ALTER TABLE metrics DROP PRIMARY KEY ]\r\n(Background on this error at: http:\/\/sqlalche.me\/e\/e3q8)\u200b\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [x] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","610":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**:\r\n- **Python version**:\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n\r\nThe MLflow scoring server returns a 500 HTTP status code when a bad request is submitted. This happens to servers launched as: \r\n* `mlflow models serve` \r\n* `mlflow sagemaker run-local`\r\n\r\nThe response body contains an error message but the HTTP status code is always 500. The status code should be 400 (BAD REQUEST) which indicates a client error. 5xx codes are reserved for server errors.\r\n\r\n### Code to reproduce issue\r\n```\r\ncurl  http:\/\/localhost:5001\/invocations  --verbose \\\r\n    -H \"Content-Type:application\/json\" \\\r\n    -d ' foo '\r\n```\r\n```\r\n HTTP\/1.1 500 INTERNAL SERVER ERROR\r\n```\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","611":"Signed-off-by: Stefano Padovan <ste.bioparco@gmail.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\n#3337\r\npass custom environment variables to sagemaker docker\r\n\r\n## How is this patch tested?\r\n\r\nunit test\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nIt's a new CLI param is added to mlflow sagemaker run-local\/deploy. It's self-documented with --help\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\n\r\nIntegrations\r\n- [x] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n","612":"**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\n- [x] Yes. I can contribute this feature independently.\r\n\r\n## Proposal Summary\r\n\r\nAllow an optional dict of environment variables to be passed on sagemaker (both run_local and deploy) docker image. \r\n\r\n\r\n\r\n## Motivation\r\nMy use case if to inject a pip extra-url that points to a private pypi repo with proprietary code.\r\nI think the modification will be generic enough to provide useful in other scenarios.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\n\r\nIntegrations\r\n- [x] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n\r\n","613":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: yes (cf. below)\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.04.1 LTS\r\n- **MLflow installed from (source or binary)**: binary (via pip)\r\n- **MLflow version (run ``mlflow --version``)**: mlflow, version 1.10.0\r\n- **Python version**: Python 3.8.2\r\n- **npm version, if running the dev UI**: n\/a\r\n- **Exact command to reproduce**: cf. code to reproduce\r\n\r\n### Describe the problem\r\nI use Mlflow to track results throughout the training of a model.\r\n\r\nThe Mlflow server uses a Postgres backend and is started via\r\n```console\r\n$ mlflow server --backend-store-uri postgresql:\/\/mlflow_user:mlflow@localhost\/mlflow_db --default-artifact-root \/path\/to\/artifacts --host HOSTNAME\r\n```\r\non a separate machine only used for tracking results. The actual training happens on workers which log to Mlflow via `http:\/\/HOSTNAME:5000`.\r\n\r\nTo analyse the training progress, I want to use `get_metric_history` to get the values of a metric of interest throughout the training. However, the number of tracked metrics (`32k`) seems to be large enough to cause a timeout during the HTTP request. This error also occurs when running the `get_metric_history` request directly on the tracking server. \r\n\r\nIn the web frontend I can view the metrics, although it takes a long time until the page finishes loading (`~80 sec`, Mozilla Firefox 79.0).\r\n\r\nWhen I directly issue the HTTP request taken from the browser's debug tools, the result comes back quickly\r\n\r\n```console\r\n$ time curl 'http:\/\/HOSTNAME:5000\/ajax-api\/2.0\/preview\/mlflow\/metrics\/get-history?run_uuid=bc82535154804601a1e1dcb91e9048b5&metric_key=eval.test.hits_at_1' -o \/dev\/null\r\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n                                 Dload  Upload   Total   Spent    Left  Speed\r\n100 90681  100 90681    0     0   147k      0 --:--:-- --:--:-- --:--:--  146k\r\n\r\nreal\t0m0,770s\r\nuser\t0m0,004s\r\nsys\t0m0,011s\r\n```\r\n\r\n\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```python-console\r\n>>> from mlflow.tracking import MlflowClient\r\n>>> client = MlflowClient(tracking_uri='http:\/\/HOSTNAME:5000')\r\n>>> history = client.get_metric_history(run_id='bc82535154804601a1e1dcb91e9048b5', key='eval.train.hits_at_1')\r\n```\r\n\r\n<details>\r\n<summary>Full traceback<\/summary>\r\n\r\n```python-traceback\r\nTraceback (most recent call last):\r\n  File \"\/path\/to\/venv\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 670, in urlopen\r\n    httplib_response = self._make_request(\r\n  File \"\/path\/to\/venv\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 426, in _make_request\r\n    six.raise_from(e, None)\r\n  File \"<string>\", line 3, in raise_from\r\n  File \"\/path\/to\/venv\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 421, in _make_request\r\n    httplib_response = conn.getresponse()\r\n  File \"\/usr\/lib\/python3.8\/http\/client.py\", line 1332, in getresponse\r\n    response.begin()\r\n  File \"\/usr\/lib\/python3.8\/http\/client.py\", line 303, in begin\r\n    version, status, reason = self._read_status()\r\n  File \"\/usr\/lib\/python3.8\/http\/client.py\", line 272, in _read_status\r\n    raise RemoteDisconnected(\"Remote end closed connection without\"\r\nhttp.client.RemoteDisconnected: Remote end closed connection without response\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"\/path\/to\/venv\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 439, in send\r\n    resp = conn.urlopen(\r\n  File \"\/path\/to\/venv\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 724, in urlopen\r\n    retries = retries.increment(\r\n  File \"\/path\/to\/venv\/lib\/python3.8\/site-packages\/urllib3\/util\/retry.py\", line 403, in increment\r\n    raise six.reraise(type(error), error, _stacktrace)\r\n  File \"\/path\/to\/venv\/lib\/python3.8\/site-packages\/urllib3\/packages\/six.py\", line 734, in reraise\r\n    raise value.with_traceback(tb)\r\n  File \"\/path\/to\/venv\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 670, in urlopen\r\n    httplib_response = self._make_request(\r\n  File \"\/path\/to\/venv\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 426, in _make_request\r\n    six.raise_from(e, None)\r\n  File \"<string>\", line 3, in raise_from\r\n  File \"\/path\/to\/venv\/lib\/python3.8\/site-packages\/urllib3\/connectionpool.py\", line 421, in _make_request\r\n    httplib_response = conn.getresponse()\r\n  File \"\/usr\/lib\/python3.8\/http\/client.py\", line 1332, in getresponse\r\n    response.begin()\r\n  File \"\/usr\/lib\/python3.8\/http\/client.py\", line 303, in begin\r\n    version, status, reason = self._read_status()\r\n  File \"\/usr\/lib\/python3.8\/http\/client.py\", line 272, in _read_status\r\n    raise RemoteDisconnected(\"Remote end closed connection without\"\r\nurllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"\/path\/to\/venv\/lib\/python3.8\/site-packages\/mlflow\/tracking\/client.py\", line 110, in get_metric_history\r\n    return self._tracking_client.get_metric_history(run_id, key)\r\n  File \"\/path\/to\/venv\/lib\/python3.8\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 60, in get_metric_history\r\n    return self.store.get_metric_history(run_id=run_id, metric_key=key)\r\n  File \"\/path\/to\/venv\/lib\/python3.8\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 187, in get_metric_history\r\n    response_proto = self._call_endpoint(GetMetricHistory, req_body)\r\n  File \"\/path\/to\/venv\/lib\/python3.8\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 32, in _call_endpoint\r\n    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)\r\n  File \"\/path\/to\/venv\/lib\/python3.8\/site-packages\/mlflow\/utils\/rest_utils.py\", line 139, in call_endpoint\r\n    response = http_request(\r\n  File \"\/path\/to\/venv\/lib\/python3.8\/site-packages\/mlflow\/utils\/rest_utils.py\", line 76, in http_request\r\n    response = request_with_ratelimit_retries(max_rate_limit_interval,\r\n  File \"\/path\/to\/venv\/lib\/python3.8\/site-packages\/mlflow\/utils\/rest_utils.py\", line 58, in request_with_ratelimit_retries\r\n    response = requests.request(**kwargs)\r\n  File \"\/path\/to\/venv\/lib\/python3.8\/site-packages\/requests\/api.py\", line 61, in request\r\n    return session.request(method=method, url=url, **kwargs)\r\n  File \"\/path\/to\/venv\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 530, in request\r\n    resp = self.send(prep, **send_kwargs)\r\n  File \"\/path\/to\/venv\/lib\/python3.8\/site-packages\/requests\/sessions.py\", line 643, in send\r\n    r = adapter.send(request, **kwargs)\r\n  File \"\/path\/to\/venv\/lib\/python3.8\/site-packages\/requests\/adapters.py\", line 498, in send\r\n    raise ConnectionError(err, request=request)\r\nrequests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\r\n```\r\n\r\n<\/details>\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n<details>\r\n  <summary>Full list of installed packages in venv<\/summary>\r\n  \r\n  ```console\r\nPackage                   Version\r\n------------------------- ---------\r\nalembic                   1.4.2\r\nazure-core                1.7.0\r\nazure-storage-blob        12.3.2\r\ncertifi                   2020.6.20\r\ncffi                      1.14.0\r\nchardet                   3.0.4\r\nclick                     7.1.2\r\ncloudpickle               1.5.0\r\ncryptography              2.9.2\r\ndatabricks-cli            0.11.0\r\ndocker                    4.2.2\r\nentrypoints               0.3\r\nFlask                     1.1.2\r\ngitdb                     4.0.5\r\nGitPython                 3.1.3\r\ngorilla                   0.3.0\r\ngunicorn                  20.0.4\r\nidna                      2.10\r\nisodate                   0.6.0\r\nitsdangerous              1.1.0\r\nJinja2                    2.11.2\r\nMako                      1.1.3\r\nMarkupSafe                1.1.1\r\nmlflow                    1.10.0\r\nmsrest                    0.6.17\r\nnumpy                     1.19.0\r\noauthlib                  3.1.0\r\npandas                    1.0.5\r\npip                       20.2.2\r\npkg-resources             0.0.0\r\nprometheus-client         0.8.0\r\nprometheus-flask-exporter 0.14.1\r\nprotobuf                  3.12.2\r\npsycopg2                  2.8.5\r\npycparser                 2.20\r\npython-dateutil           2.8.1\r\npython-editor             1.0.4\r\npytz                      2020.1\r\nPyYAML                    5.3.1\r\nquerystring-parser        1.2.4\r\nrequests                  2.24.0\r\nrequests-oauthlib         1.3.0\r\nsetuptools                49.6.0\r\nsix                       1.15.0\r\nsmmap                     3.0.4\r\nSQLAlchemy                1.3.13\r\nsqlparse                  0.3.1\r\ntabulate                  0.8.7\r\nurllib3                   1.25.9\r\nwebsocket-client          0.57.0\r\nWerkzeug                  1.0.1\r\nwheel                     0.35.1\r\n```\r\n<\/details>\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","614":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: NO\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **MLflow installed from (source or binary)**: Binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.10.0\r\n- **Python version**: 3.8.5\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: ``mlflow models serve -m runs:\/75614813307443a48a8c6fb80b9959d5\/model --no-conda``\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\nAdding switch `--no-conda` to `mlflow models serve` fails with error message.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nGenerate a trained model on Linux and copy it over to Windows 10 (see #3331 - ``mlflow run --no-conda`` works well on Windows 10, but the trained model is not saved with or without ``--no-conda`` switch):\r\n``mlflow run https:\/\/github.com\/mlflow\/mlflow-example.git -P alpha=5.0 --no-conda``\r\n\r\nServe trained model on Windows 10:\r\nmlflow models serve -m runs:\/75614813307443a48a8c6fb80b9959d5\/model --no-conda\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\n2020\/08\/26 09:40:47 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\r\n2020\/08\/26 09:40:47 INFO mlflow.pyfunc.backend: === Running command 'waitress-serve --host=127.0.0.1 --port=5000 --ident=mlflow mlflow.pyfunc.scoring_server.wsgi:app'\r\nTraceback (most recent call last):\r\n  File \"z:\\miniconda3\\envs\\autorouting_v1\\lib\\runpy.py\", line 195, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"z:\\miniconda3\\envs\\autorouting_v1\\lib\\runpy.py\", line 88, in _run_code\r\n    exec(code, run_globals)\r\n  File \"Z:\\miniconda3\\envs\\autorouting_v1\\Scripts\\mlflow.exe\\__main__.py\", line 7, in <module>\r\n  File \"z:\\miniconda3\\envs\\autorouting_v1\\lib\\site-packages\\click\\core.py\", line 829, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"z:\\miniconda3\\envs\\autorouting_v1\\lib\\site-packages\\click\\core.py\", line 782, in main\r\n    rv = self.invoke(ctx)\r\n  File \"z:\\miniconda3\\envs\\autorouting_v1\\lib\\site-packages\\click\\core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"z:\\miniconda3\\envs\\autorouting_v1\\lib\\site-packages\\click\\core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"z:\\miniconda3\\envs\\autorouting_v1\\lib\\site-packages\\click\\core.py\", line 1066, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"z:\\miniconda3\\envs\\autorouting_v1\\lib\\site-packages\\click\\core.py\", line 610, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"z:\\miniconda3\\envs\\autorouting_v1\\lib\\site-packages\\mlflow\\models\\cli.py\", line 55, in serve\r\n    return _get_flavor_backend(model_uri,\r\n  File \"z:\\miniconda3\\envs\\autorouting_v1\\lib\\site-packages\\mlflow\\pyfunc\\backend.py\", line 98, in serve\r\n    subprocess.Popen([command.split(\" \")], env=command_env).wait()\r\n  File \"z:\\miniconda3\\envs\\autorouting_v1\\lib\\subprocess.py\", line 854, in __init__\r\n    self._execute_child(args, executable, preexec_fn, close_fds,\r\n  File \"z:\\miniconda3\\envs\\autorouting_v1\\lib\\subprocess.py\", line 1247, in _execute_child\r\n    args = list2cmdline(args)\r\n  File \"z:\\miniconda3\\envs\\autorouting_v1\\lib\\subprocess.py\", line 549, in list2cmdline\r\n    for arg in map(os.fsdecode, seq):\r\n  File \"z:\\miniconda3\\envs\\autorouting_v1\\lib\\os.py\", line 818, in fsdecode\r\n    filename = fspath(filename)  # Does type-checking of `filename`.\r\nTypeError: expected str, bytes or os.PathLike object, not list\r\n```\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [x] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","615":"## What changes are proposed in this pull request?\r\n\r\nIntroducing tags support for filter_string ad order_by in searchRegisteredModels by extracting a vast amount of functions in search_utils.py and create new search_runs_utils and search_models_utils separately. Existing search logic in search_registered_models is also updated to allow tags as filter_string\r\n\r\n## How is this patch tested?\r\n\r\nUnit Tests, Manual Tests\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nThis PR allows user to search registered models based on tags attached to it, user can also order search results with tag values. (e.g. filter_string = \"name ILIKE '%neural net%' AND tag.algorithm = 'neural net'\", order_by = [\"name ASC\", \"tag.owner ASC\"])\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [x] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","616":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No \r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 Enterprise\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: 1.10.0\r\n- **R version**: 4.0.2\r\n- **npm version, if running the dev UI**: Not Applicable\r\n- **Exact command to reproduce**: please see the \"Code to reproduce issue\"\r\n\r\n### Describe the problem\r\nI am receiving an error when I run the \"mlflow_ui()\" command in R after installing the 'mlflow' package and also running 'install_mlflow()' command. Has any one encountered the same issue. I would highly appreciate your help\/tip to solve this problem. Thank you! \r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/66867619\/91091970-a4d22480-e657-11ea-8d91-1ce894035040.png)\r\n\r\n![image2](https:\/\/user-images.githubusercontent.com\/66867619\/91091990-aac80580-e657-11ea-93e2-a650157c8e41.png)\r\n\r\n### Code to reproduce issue\r\nPlease extract codes and error images from the URL of repo: https:\/\/github.com\/ghalibminhas\/mlflow-installation-issue \r\n","617":"## Willingness to contribute\r\nNo. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: yes\r\n- **OS Platform and Distribution**: Ubuntu 18.04\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: 1.8.0\r\n- **Python version**: 3.7.8\r\n\r\n### Describe the problem\r\nI built a sklearn pipeline that includes a FunctionTransformer. This FunctionTransformer is defined by a function that I created. I am able to log and save this sklearn pipeline in mlflow, however I am not able to serve it. There is an AttributeError message indicating that it cannot find the function that I created for the FunctionTransformer step in the pipeline. Here's an example below with the error message.\r\n\r\n### Code to reproduce issue\r\n```python\r\n\r\nimport mlflow\r\nimport mlflow.sklearn\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom sklearn.datasets import load_iris\r\nfrom sklearn import tree\r\nfrom sklearn.preprocessing import FunctionTransformer\r\nfrom sklearn.pipeline import Pipeline\r\n\r\niris = load_iris()\r\ndata = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\r\n                    columns= iris['feature_names'] + ['target'])\r\nX = data[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']]\r\ny = iris[\"target\"]\r\n\r\n\r\ndef custom_function(df):\r\n    dataframe = df.apply(np.sqrt, axis=0)\r\n    return dataframe\r\n\r\ntransformer = FunctionTransformer(custom_function)\r\nsk_model = tree.DecisionTreeClassifier()\r\npipeline = Pipeline(steps=[(\"preprocessor\", transformer), \r\n                           (\"classifier\", sk_model)])\r\n\r\nwith mlflow.start_run():\r\n    \r\n    pipeline.fit(X, y)\r\n\r\n    # log model\r\n    mlflow.sklearn.log_model(pipeline, \"sk_models\", serialization_format='pickle')\r\n```\r\n```python\r\nprint(mlflow.sklearn.load_model(\"mlruns\/0\/610244b8f9b1423c9d1c49a51958b872\/artifacts\/sk_models\"))\r\n----------------------------------------------------------------------------------------------------------------------------------------------\r\nPipeline(steps=[('preprocessor',\r\n                 FunctionTransformer(func=<function custom_function at 0x7f15599a28c0>)),\r\n                ('classifier', DecisionTreeClassifier())])\r\n```\r\n```python\r\n!mlflow models serve -m runs:\/610244b8f9b1423c9d1c49a51958b872\/sk_models -p 1234\r\n----------------------------------------------------------------------------------------------------------------------------------------------\r\n2020\/08\/24 14:43:24 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\r\n2020\/08\/24 14:43:25 INFO mlflow.pyfunc.backend: === Running command 'source \/opt\/conda\/bin\/..\/etc\/profile.d\/conda.sh && conda activate mlflow-10ac34ad0ee54ebbd0dc2d47e12f26a0de186e36 1>&2 && gunicorn --timeout=60 -b 127.0.0.1:1234 -w 1 ${GUNICORN_CMD_ARGS} -- mlflow.pyfunc.scoring_server.wsgi:app'\r\n[2020-08-24 14:43:25 +0000] [3510] [INFO] Starting gunicorn 20.0.4\r\n[2020-08-24 14:43:25 +0000] [3510] [INFO] Listening at: http:\/\/127.0.0.1:1234 (3510)\r\n[2020-08-24 14:43:25 +0000] [3510] [INFO] Using worker: sync\r\n[2020-08-24 14:43:25 +0000] [3519] [INFO] Booting worker with pid: 3519\r\n[2020-08-24 14:43:26 +0000] [3519] [ERROR] Exception in worker process\r\nTraceback (most recent call last):\r\n  File \"\/opt\/conda\/envs\/mlflow-10ac34ad0ee54ebbd0dc2d47e12f26a0de186e36\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py\", line 583, in spawn_worker\r\n    worker.init_process()\r\n  File \"\/opt\/conda\/envs\/mlflow-10ac34ad0ee54ebbd0dc2d47e12f26a0de186e36\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py\", line 119, in init_process\r\n    self.load_wsgi()\r\n  File \"\/opt\/conda\/envs\/mlflow-10ac34ad0ee54ebbd0dc2d47e12f26a0de186e36\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py\", line 144, in load_wsgi\r\n    self.wsgi = self.app.wsgi()\r\n  File \"\/opt\/conda\/envs\/mlflow-10ac34ad0ee54ebbd0dc2d47e12f26a0de186e36\/lib\/python3.7\/site-packages\/gunicorn\/app\/base.py\", line 67, in wsgi\r\n    self.callable = self.load()\r\n  File \"\/opt\/conda\/envs\/mlflow-10ac34ad0ee54ebbd0dc2d47e12f26a0de186e36\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 49, in load\r\n    return self.load_wsgiapp()\r\n  File \"\/opt\/conda\/envs\/mlflow-10ac34ad0ee54ebbd0dc2d47e12f26a0de186e36\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 39, in load_wsgiapp\r\n    return util.import_app(self.app_uri)\r\n  File \"\/opt\/conda\/envs\/mlflow-10ac34ad0ee54ebbd0dc2d47e12f26a0de186e36\/lib\/python3.7\/site-packages\/gunicorn\/util.py\", line 358, in import_app\r\n    mod = importlib.import_module(module)\r\n  File \"\/opt\/conda\/envs\/mlflow-10ac34ad0ee54ebbd0dc2d47e12f26a0de186e36\/lib\/python3.7\/importlib\/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"\/opt\/conda\/envs\/mlflow-10ac34ad0ee54ebbd0dc2d47e12f26a0de186e36\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/scoring_server\/wsgi.py\", line 6, in <module>\r\n    app = scoring_server.init(load_model(os.environ[scoring_server._SERVER_MODEL_PATH]))\r\n  File \"\/opt\/conda\/envs\/mlflow-10ac34ad0ee54ebbd0dc2d47e12f26a0de186e36\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py\", line 473, in load_model\r\n    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\r\n  File \"\/opt\/conda\/envs\/mlflow-10ac34ad0ee54ebbd0dc2d47e12f26a0de186e36\/lib\/python3.7\/site-packages\/mlflow\/sklearn.py\", line 332, in _load_pyfunc\r\n    serialization_format=serialization_format)\r\n  File \"\/opt\/conda\/envs\/mlflow-10ac34ad0ee54ebbd0dc2d47e12f26a0de186e36\/lib\/python3.7\/site-packages\/mlflow\/sklearn.py\", line 289, in _load_model_from_local_file\r\n    return pickle.load(f)\r\nAttributeError: Can't get attribute 'custom_function' on <module '__main__' from '\/opt\/conda\/envs\/mlflow-10ac34ad0ee54ebbd0dc2d47e12f26a0de186e36\/bin\/gunicorn'>\r\n[2020-08-24 14:43:26 +0000] [3519] [INFO] Worker exiting (pid: 3519)\r\n[2020-08-24 14:43:26 +0000] [3510] [INFO] Shutting down: Master\r\n[2020-08-24 14:43:26 +0000] [3510] [INFO] Reason: Worker failed to boot.\r\nTraceback (most recent call last):\r\n  File \"\/opt\/conda\/envs\/mlflow_test_env\/bin\/mlflow\", line 8, in <module>\r\n    sys.exit(cli())\r\n  File \"\/opt\/conda\/envs\/mlflow_test_env\/lib\/python3.7\/site-packages\/click\/core.py\", line 829, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\/opt\/conda\/envs\/mlflow_test_env\/lib\/python3.7\/site-packages\/click\/core.py\", line 782, in main\r\n    rv = self.invoke(ctx)\r\n  File \"\/opt\/conda\/envs\/mlflow_test_env\/lib\/python3.7\/site-packages\/click\/core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/opt\/conda\/envs\/mlflow_test_env\/lib\/python3.7\/site-packages\/click\/core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/opt\/conda\/envs\/mlflow_test_env\/lib\/python3.7\/site-packages\/click\/core.py\", line 1066, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\/opt\/conda\/envs\/mlflow_test_env\/lib\/python3.7\/site-packages\/click\/core.py\", line 610, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"\/opt\/conda\/envs\/mlflow_test_env\/lib\/python3.7\/site-packages\/mlflow\/models\/cli.py\", line 57, in serve\r\n    host=host)\r\n  File \"\/opt\/conda\/envs\/mlflow_test_env\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/backend.py\", line 92, in serve\r\n    command_env=command_env)\r\n  File \"\/opt\/conda\/envs\/mlflow_test_env\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/backend.py\", line 172, in _execute_in_conda_env\r\n    command, rc\r\nException: Command 'source \/opt\/conda\/bin\/..\/etc\/profile.d\/conda.sh && conda activate mlflow-10ac34ad0ee54ebbd0dc2d47e12f26a0de186e36 1>&2 && gunicorn --timeout=60 -b 127.0.0.1:1234 -w 1 ${GUNICORN_CMD_ARGS} -- mlflow.pyfunc.scoring_server.wsgi:app' returned non zero return code. Return code = 3\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- `area\/server-infra`: MLflow server\r\n","618":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nThe property of a run to be \"nested\", i.e. the child of a parent run, should be exposed in the the \"search_runs\" data frame. In addition, the filter string should allow querying for the \"nested\" property.\r\n\r\n## Motivation\r\n- _What is the use case for this feature?_ We're using the concept of nested runs to track intermediate models that generate hyperparameters of a main model. However, to promote only the main (non-nested) model to the model registry, we need a way to filter only the non-nested models (as a workaround, we're using tags).\r\n- _Why is this use case valuable to support for MLflow users in general?_ Consistency: Other attributes, properties and tags of a run are available for filtering as well.\r\n- _Why is this use case valuable to support for your project(s) or organization?_ It would make our code easier to maintain as there's no information duplication (tracking the nested property as an additional tag).\r\n- _Why is it currently difficult to achieve this use case?_ The current workaround isn't difficult, but introduces information duplication which is undesirable.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n","619":"## Proposal Summary\r\n\r\nCurrently, I can provide an S3 bucket for my artifact store as follows \r\n`--default-artifact-root s3:\/\/bucket-name`\r\nFor my use case, I have multiple MLFlow servers running, one for each team. I do not want to create a new S3 bucket for each of these servers as this number can be quite high.\r\nIs it possible to give S3 paths (within the same S3 bucket) as default artifact store? Something like\r\n`--default-artifact-root s3:\/\/bucket-name\/teeam-name`\r\n\r\nAlso, any good alternative to having a separate MLFlow server running for each team?\r\n\r\nThank you.\r\n\r\n## Motivation\r\nThis way, users can segregate their MLFlow servers within the same S3 bucket.","620":"## Willingness to contribute\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n\r\n## Proposal Summary\r\n\r\nAbility to custom configure SQLAlchemy engine\r\n\r\n## Motivation\r\nI'm using mlflow tracking server backed by an AWS RDS Serverless DB. Since the traffic is sporadic (both on read and write), I'd like to see no connections active when there is no ongoing activity, so that the DB can go in paused state.\r\n\r\nI can't find a proper configuration to achieve this, though.\r\n\r\nIf I tweak the _mlflow\/store\/db\/utils.py_ code using\r\n`pool_kwargs = {\"poolclass\":sqlalchemy.pool.NullPool}\r\n`\r\n, then I'm able to achieve what I want.\r\n\r\nI'd like to know if this feature could be added properly at server startup.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ x] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n","621":"## What changes are proposed in this pull request?\r\n\r\nFixes #3229 \r\n\r\n## How is this patch tested?\r\n\r\n(Details)\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x ] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [x ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","622":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nTensorFlow Serving (TFS) provides a convenient REST API for deploying Keras\/TensorFlow models and managing deployments. We should make it easy to deploy Keras\/TensorFlow models logged using MLflow to a TFS server. We should only focus on TensorFlow 2.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nWhile it's currently possible to locally deploy Keras models using mlflow models serve, TorchServe contains a number of additional useful features when deploying Keras models, e.g. instrumentation on request success\/error rates, configurable access logs, inference endpoints for different versions of a model, etc.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ x] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n### Links\r\n* https:\/\/www.tensorflow.org\/tfx\/guide\/serving\r\n* https:\/\/www.tensorflow.org\/tfx\/serving\/serving_basic\r\n* https:\/\/github.com\/tensorflow\/serving\r\n\r\n### Proposed Solutions\r\n\r\nSince this ticket is analogous to issue [3065](https:\/\/github.com\/mlflow\/mlflow\/issues\/3065) (Support serving Pytorch models via TorchServe), see that issue for general implementation approaches. Below we discuss the TFS-specific issues.\r\n\r\n### TensorFlow Serving Specific Observations\r\n\r\nObservations:\r\n* TFS expects the model to be in [SavedModel](https:\/\/www.tensorflow.org\/guide\/saved_model) format which is the default for saving Keras models in TensorFlow 2.\r\n* In MLflow the current default is to log Keras models in legacy HD5 format. Due to a bug, you can't log a KerasModel as SaveModel. \r\n* We need change the MLflow TF 2.0 default to SavedModel. Without this, you can't deploy a model to TFS from the model registry.\r\n\r\nRelated issues:\r\n* [3224](https:\/\/github.com\/mlflow\/mlflow\/issues\/3224) - Cannot save Keras\/TF_2.x model as SavedModel format using mlflow.keras.log_model with kwargs { \"save_format\": \"tf\" }\r\n* [3246]( https:\/\/github.com\/mlflow\/mlflow\/issues\/3246) - [FR] Serialization format for TensorFlow 2.x (Keras) model should be Save Model per TF 2.0 doc\r\n\r\n### Implementation\r\n\r\nThe TFS server is similar to the MLflow scoring server. It expects and returns a JSON format which is slightly different. It should be straightforward to create an MLflow TFS deployment API. \r\n\r\nRequest format:\r\n```\r\n{\"instances\": [\r\n  [ 7,   0.27, 0.36]\r\n  ]}\r\n```\r\nResponse format:\r\n```\r\n{\r\n  \"predictions\": [\r\n    [\r\n      0.998985946\r\n   ]}\r\n```\r\n\r\nTFS has several options to create docker container. See [TensorFlow Serving with Docker](https:\/\/www.tensorflow.org\/tfx\/serving\/docker) We should implement the variant where the model is baked into the container. See [Creating your own serving image](https:\/\/www.tensorflow.org\/tfx\/serving\/docker#creating_your_own_serving_image).\r\n\r\n### Example 1\r\n\r\nFrom https:\/\/github.com\/amesar\/mlflow-tools, see [Serve MLflow Keras model with TensorFlow Serving](https:\/\/github.com\/amesar\/mlflow-tools\/tree\/master\/mlflow_tools\/tensorflow_serving).\r\n\r\n```\r\npython launch_tensorflow_serving.py \\\r\n  --model-uri runs:\/774f1d5e4573499a8eb2043c397cd98a\/keras-model \\\r\n  --tfs-model-name keras_mnist\r\n  --container tfs_serving_keras_mnist\r\n```\r\n\r\nTo score:\r\n```\r\ncurl -X POST \\\r\n  http:\/\/localhost:8502\/v1\/models\/keras_mnist:predict  \\\r\n  -d @data\/mnist.json \r\n```\r\n\r\n### Example 2\r\n\r\nI have already proofed this with an MNIST model at https:\/\/github.com\/amesar\/mlflow-examples\/blob\/master\/python\/keras_tf_mnist\/README.md#tensorflow-serving-real-time-scoring.\r\n\r\nSince I couldn't use mlflow.keras.log_model, I converted the model to SavedModel format and logged it as an artifact. See [train.py](https:\/\/github.com\/amesar\/mlflow-examples\/blob\/master\/python\/keras_tf_mnist\/train.py#L52).\r\n\r\nSample code to deploy a TFS server.\r\n```\r\nHOST_PORT=8502\r\nMODEL=keras_mnist\r\nCONTAINER=tfs_serving_$MODEL\r\nDOCKER_MODEL_PATH=\/models\/$MODEL\/01\r\n\r\nRUN_ID=7e674524514846799310c41f10d6b99d\r\nHOST_MODEL_PATH=`mlflow artifacts download --run-id $RUN_ID --artifact-path tensorflow-model`\r\nBASE_CONTAINER=tfs_serving_base\r\ndocker run -d --name $BASE_CONTAINER tensorflow\/serving\r\ndocker cp $HOST_MODEL_PATH\/ $BASE_CONTAINER:\/tmp\r\ndocker exec -d $BASE_CONTAINER mkdir -p \/models\/$MODEL\r\ndocker exec -d $BASE_CONTAINER mv \/tmp\/tensorflow-model \/models\/$MODEL\/01\r\ndocker commit --change \"ENV MODEL_NAME $MODEL\" $BASE_CONTAINER $CONTAINER\r\ndocker rm -f $BASE_CONTAINER\r\ndocker run -d --name $CONTAINER -p $HOST_PORT:8501 $CONTAINER\r\n```\r\nTo score:\r\n```\r\ncurl -X POST \\\r\n  http:\/\/localhost:8502\/v1\/models\/keras_mnist:predict  \\\r\n  -d @..\/..\/data\/score\/mnist\/mnist-tf-serving.json \r\n```","623":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nI can delete permanently or update the experiment by the client.\r\n\r\n## Motivation\r\n\r\nI want to update or permanently delete the old experiment by the client when the artifact location of the experiment has changed. In addition, the name of the experiment is fixed.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nFor deleting an experiment, we can provide an optional bool parameter `permanently`. And for updating, we can refer `update_registered_model`.\r\n","624":"## Willingness to contribute\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nExtend the conda support in mlflow to also support spec files in addition to an environment.yml file. \r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nTo support more explicit environment specification through conda native features.\r\n- Why is this use case valuable to support for MLflow users in general?\r\nImproved environment reproducibility while still using conda. Faster first-time conda environment creation.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nI'd like environments created on different machines and\/or at different times to be consistent.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nThe docker environment requires a lot more external effort and tooling to set up vs. the conda environment. Currently mlflow creates conda env only via [the `conda env create -n <name> --file <env-file>` command](https:\/\/github.com\/mlflow\/mlflow\/blob\/67b09adcd276271aab81bbbfa638bc3aa7dfa7c4\/mlflow\/utils\/conda.py#L94), whereas if it could also use `conda create -n <name> --file <spec-file>`.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\nThe conda docs explain spec files here: https:\/\/docs.conda.io\/projects\/conda\/en\/latest\/user-guide\/tasks\/manage-environments.html#building-identical-conda-environments. These are generally produced by `conda list --explicit`, though [conda-lock](https:\/\/github.com\/mariusvniekerk\/conda-lock) is a tool that helps build them from environment files. The two main benefits are 1. fully explicit environments 2. avoid invoking the conda solver producing environments faster.\r\n\r\nTo implement this one could simply look at the extension of the file: \r\n\r\n```\r\nif ext in {\".yaml\", \".yml\"}:\r\n    conda env create -n name --file <env-file>  \r\nelse if ext in {\".txt\", \".lock\"}:  \r\n    conda create -n name --file <spec-file>\r\n```\r\n(note: the .lock extension is a conda-lock detail)\r\n\r\nThis would overload the meaning of the \"conda_env\" field in MLProject, which may require some extra documentation. A more explicit approach might be to define a \"conda_spec\" field for MLProject, though I'm not sure if that is much better\/clearer. \r\n\r\nIf the file extension based approach sounds like a good idea, I would be able to contribute it.","625":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nThe Search Runs bar that appears for each experiment lacks features such as the OR operator, the ability to search for parameters\/metrics in a certain range or in a list of values (Ex: `(metrics.rmse in [0.1, 0.2, 0.3]) or (metrics.rmse in range(0.7, 0.8)`). \r\n\r\nAdditionally, the [MLFlow search documentation](https:\/\/www.mlflow.org\/docs\/latest\/search-syntax.html) does not include references to or explain the usage of certain operators, such as the `LIKE` and `ILIKE` queries. \r\n\r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","626":"## What changes are proposed in this pull request?\r\n\r\nIntroducing tags support for filter_string ad order_by in searchRegisteredModels by extracting a vast amount of functions in `search_utils.py` and create new `search_runs_utils` and `search_models_utils` separately. Existing search logic in `search_registered_models` is also updated to allow tags as filter_string\r\n\r\n## How is this patch tested?\r\n\r\nUnit Tests, Manual Tests\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nThis PR allows user to search registered models based on tags attached to it, user can also order search results with tag values. (e.g. filter_string = \"name ILIKE '%neural net%' AND tag.algorithm = 'neural net'\", order_by = [\"name ASC\", \"tag.owner ASC\"])\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [x] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","627":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [X] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Centos 7\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: master\r\n- **Python version**: 3.6\r\n- **npm version, if running the dev UI**: 6.14.5\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nIn tracking server UI, columns are not resized to take all the tab width when the experiments list is minimized (see video)\r\n![sizecolumns](https:\/\/user-images.githubusercontent.com\/658597\/90495994-8d6dd580-e145-11ea-9f8a-90c2c0f77d54.gif)\r\n\r\n\r\n### Code to reproduce issue\r\nN\/A\r\n\r\n### Other info \/ logs\r\nN\/A\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [X] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","628":"## What changes are proposed in this pull request?\r\n\r\nShowing file content on the frontend is a quite useful feature because you don't need to go to S3 and search here for a file.\r\nBut unfortunately, list of file extensions which are shown here does not include some popular config formats, like `.ini`, `.toml`, `.properties` and `.xml`.\r\nI've just added them into this list.\r\n\r\n## How is this patch tested?\r\n\r\nNo tests are needed here.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [X] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nAdded support of showing more config formats on the interface, like `.ini`, `.toml`, `.properties` and `.xml`.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [X] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [X] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","629":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [X] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nOrder runs by tags from the UI (extend the order by feature from param or metrics to tags)\r\n\r\n## Motivation\r\n\r\nTags are the only columns that are not sortable. Backend seems able to sort them (it can sort run name or username for instance). Do you know why the `sortable` attribute is missing for tags columns ?\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [X] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nI think this FR is a one liner change in javascript code . IMO, it could be a nice first contribution...","630":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [X ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS 10.15.6 with Homebrew 2.4.12\r\n- **MLflow installed from (source or binary)**: pip3.8 (binary)\r\n- **MLflow version (run ``mlflow --version``)**: 1.10.0\r\n- **Python version**: 3.8.3\r\n- **npm version, if running the dev UI**: N\/A\r\n- **Exact command to reproduce**: mlflow run --no-conda sklearn_elasticnet_wine -P alpha=0.5\r\n\r\n### Describe the problem\r\n\r\nProblem 1: I didn't find a way to configure the Python interpreter for MLFlow, and it defaults to the \"python\" command which calls the Mac OS's Python 2 interpreter, rather than 3.8.3 installed with homebrew.\r\n\r\nProblem 2: After aliasing python as python3, the command still breaks with error:\r\nImportError: No module named pandas\r\nI have pandas installed in the global pip3 repo so this is very weird. I tried running other examples but getting similar errors for ImportError. Somehow MLFlow is not detecting my installed packages.\r\n\r\n### Code to reproduce issue\r\nN\/A\r\n\r\n### Other info \/ logs\r\nN\/A\r\n\r\n","631":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\ncurrently it's hard to check if the image build successed or not in python,something like in a script  I want to call ``PyFuncBeckend.build_image`` and wait it to end so I can do something based on these images,  the only way I can used  now is start another shell checker process to retrieve information about current images  in my system. so why not return the ``Popen `` result back, as these function calls are somewhat \"synchronous\".\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n","632":"\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n\r\n## Motivation\r\ncurrently mlflow build image with [_build_image](https:\/\/github.com\/mlflow\/mlflow\/blob\/5647490b4590b8860e8276360e636b67157db371\/mlflow\/models\/docker_utils.py#L80)  using ``ubuntu`` as base image and install all and only *mlflow*  required system utils then install dowload model required models. it introduce problems like image size to large #2426 also others like\r\nsomeone needs additional features in the build images, he donot have a properly way to perform it.  like repositories mirroring speeding up(maven pypi conda cran) in different regions , monitor tools  etc.  add a additional argument ``base_image`` to let people provide a image base with all required system utils alos extra tools they need will be a good start point to solve these quesetions.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\n","633":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this documentation issue template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages documentation fix contributions. Would you or another member of your organization be willing to contribute a fix for this documentation issue to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a documentation fix independently.\r\n- [x] Yes. I would be willing to contribute a document fix with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a documentation fix at this time.\r\n\r\n### URL(s) with the issue:\r\n\r\nAs suggested by Lorenz in https:\/\/github.com\/yitao-li\/mlflow\/pull\/1\r\n\r\n### Description of proposal (what needs changing):\r\nProvide a clear description. Why is the proposed documentation better?\r\n\r\nMarkdown syntax is more lightweight compared to Rd","634":"Signed-off-by: Stefan Kokov <stefan.kokov@fadata.eu>\r\n\r\n## What changes are proposed in this pull request?\r\nFix #2824 \r\n\r\n(Please fill in changes proposed in this fix)\r\n\r\n## How is this patch tested?\r\n\r\n(Details)\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","635":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [X] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Minimal\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.1 (`FROM python:3.7.0`)\r\n- **MLflow installed from (source or binary)**: source (with pip)\r\n- **MLflow version (run ``mlflow --version``)**: 1.9.0\r\n- **Python version**: 3.7.0\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: below..\r\n\r\n### Describe the problem\r\n\r\nWhen:\r\n* set environment variable for BACKEND_STORE\r\n* human deletes default experiment in UI\r\n* mlflow server is restarted\r\n* open mlflow UI in browser\r\n\r\nInstead of useful UI, observe stdout logged exception with `DETAIL:  Key (experiment_id)=(0) already exists.`\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\n# \/usr\/local\/bin\/python\r\nPython 3.7.0 (default, Oct 16 2018, 07:10:55)\r\n[GCC 6.3.0 20170516] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> from mlflow.store.tracking.sqlalchemy_store import *\r\n>>> import os\r\n>>> s = SqlAlchemyStore(os.environ['BACKEND_STORE'], os.environ['ARTIFACT_STORE'])\r\n>>> s.delete_experiment(0)\r\n>>> s = SqlAlchemyStore(os.environ['BACKEND_STORE'], os.environ['ARTIFACT_STORE'])\r\nTraceback (most recent call last):\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/base.py\", line 1246, in _execute_context\r\n    cursor, statement, parameters, context\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/default.py\", line 588, in do_execute\r\n    cursor.execute(statement, parameters)\r\npsycopg2.errors.UniqueViolation: duplicate key value violates unique constraint \"experiment_pk\"\r\nDETAIL:  Key (experiment_id)=(0) already exists.\r\n```\r\n\r\nThe logic around `SqlAlchemyStore._create_default_experiment()` mentions hacks. If I make it a no-op, I observe a successful connection and that `list_experiments()` returns a 0-length list. Maybe it should use `list_experiments(view_type=ViewType.ALL)`? Or force-recover experiment 0? CC @mparkhe @dbczumar this has been the case since PR #860 \r\n\r\n```\r\n>>> SqlAlchemyStore._create_default_experiment = print\r\n>>> s = SqlAlchemyStore(os.environ['BACKEND_STORE'], os.environ['ARTIFACT_STORE'])\r\n<sqlalchemy.orm.session.Session object at 0x7f540da22da0>\r\n>>> s.list_experiments()\r\n[]\r\n>>> [(e.name, e.experiment_id, e.lifecycle_stage) for e in s.list_experiments(view_type=ViewType.ALL)]\r\n[('Default', '0', 'deleted'), ('Default1', '2', 'deleted'), ('\/my-experiment', '4', 'deleted'), ('expected', '1', 'deleted'), ('foobar', '3', 'deleted'), ('tf-test', '5', 'deleted'), ('\/notebook-tf-test2', '6', 'deleted'), ('\/ALPHA', '7', 'deleted')]\r\n```\r\n\r\nRecovery:\r\n\r\n```\r\n>>> SqlAlchemyStore._create_default_experiment = print\r\n>>> s.restore_experiment(0)\r\n>>> [(e.name, e.experiment_id, e.lifecycle_stage) for e in s.list_experiments(view_type=ViewType.ALL)]\r\n[('Default1', '2', 'deleted'), ('\/my-experiment', '4', 'deleted'), ('expected', '1', 'deleted'), ('foobar', '3', 'deleted'), ('tf-test', '5', 'deleted'), ('\/notebook-tf-test2', '6', 'deleted'), ('\/ALPHA', '7', 'deleted'), ('Default', '0', 'active')]\r\n```\r\n\r\nThere *is* a delete button in the UI, letting someone nuke the default experiment. If that's used, we're back to the original state again. Presumably that's what someone did originally, though I can't prove that happened. I can do it myself though:\r\n\r\n```\r\n>>> [(e.name, e.experiment_id, e.lifecycle_stage) for e in s.list_experiments(view_type=ViewType.ALL)]\r\n[('Default1', '2', 'deleted'), ('\/my-experiment', '4', 'deleted'), ('expected', '1', 'deleted'), ('foobar', '3', 'deleted'), ('tf-test', '5', 'deleted'), ('\/notebook-tf-test2', '6', 'deleted'), ('\/ALPHA', '7', 'deleted'), ('Default', '0', 'deleted')]\r\n```\r\n\r\nThis is a POC, so nothing of importance was lost. But it's not an obvious state to diagnose from.\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\nazure-storage-blob==12.3.2\r\nmlflow==1.9.0\r\npsycopg2-binary==2.8.5\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [X] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n","636":"MflowClient._tracking_client is using a different env variable than the MLflow UI for tracking uri, this is causing a problem for users using MLflow UI and AzureML as backend store. Whereas part of the UI that is depending on MlflowClient is not loading.\r\n\r\n## What changes are proposed in this pull request?\r\n\r\n(Please fill in changes proposed in this fix)\r\n\r\n## How is this patch tested?\r\n\r\n(Details)\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","637":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [X] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Y\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Arch Linux\r\n- **MLflow installed from (source or binary)**: Binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.10.0\r\n- **Python version**: 3.7.6\r\n- **Exact command to reproduce**: mlflow models serve -m MODELPATH\r\n\r\n### Describe the problem\r\nI successfully trained a model. Now, when trying to serve it I run into:\r\n```\r\nzeth@master \/tmp> mlflow models serve -m \/tmp\/exploding_springfield\/mlruns\/0\/f7c632e43f93437280cc72b88f279a56\/artifacts\/models                                                         (base) \r\n2020\/08\/11 14:47:26 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\r\n2020\/08\/11 14:47:28 INFO mlflow.pyfunc.backend: === Running command 'source \/home\/zeth\/anaconda3\/bin\/..\/etc\/profile.d\/conda.sh && conda activate mlflow-dd325f076f6465c8205b2342fd8ab4531e905e1a 1>&2 && gunicorn --timeout=60 -b 127.0.0.1:5000 -w 1 ${GUNICORN_CMD_ARGS} -- mlflow.pyfunc.scoring_server.wsgi:app'\r\n[2020-08-11 14:47:28 +0200] [20429] [INFO] Starting gunicorn 20.0.4\r\n[2020-08-11 14:47:28 +0200] [20429] [INFO] Listening at: http:\/\/127.0.0.1:5000 (20429)\r\n[2020-08-11 14:47:28 +0200] [20429] [INFO] Using worker: sync\r\n[2020-08-11 14:47:28 +0200] [20435] [INFO] Booting worker with pid: 20435\r\n[2020-08-11 14:47:29 +0200] [20435] [ERROR] Exception in worker process\r\nTraceback (most recent call last):\r\n  File \"\/home\/zeth\/anaconda3\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py\", line 583, in spawn_worker\r\n    worker.init_process()\r\n  File \"\/home\/zeth\/anaconda3\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py\", line 119, in init_process\r\n    self.load_wsgi()\r\n  File \"\/home\/zeth\/anaconda3\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py\", line 144, in load_wsgi\r\n    self.wsgi = self.app.wsgi()\r\n  File \"\/home\/zeth\/anaconda3\/lib\/python3.7\/site-packages\/gunicorn\/app\/base.py\", line 67, in wsgi\r\n    self.callable = self.load()\r\n  File \"\/home\/zeth\/anaconda3\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 49, in load\r\n    return self.load_wsgiapp()\r\n  File \"\/home\/zeth\/anaconda3\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 39, in load_wsgiapp\r\n    return util.import_app(self.app_uri)\r\n  File \"\/home\/zeth\/anaconda3\/lib\/python3.7\/site-packages\/gunicorn\/util.py\", line 358, in import_app\r\n    mod = importlib.import_module(module)\r\n  File \"\/home\/zeth\/anaconda3\/lib\/python3.7\/importlib\/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"\/home\/zeth\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/scoring_server\/wsgi.py\", line 6, in <module>\r\n    app = scoring_server.init(load_model(os.environ[scoring_server._SERVER_MODEL_PATH]))\r\n  File \"\/home\/zeth\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py\", line 473, in load_model\r\n    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\r\n  File \"\/home\/zeth\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/pytorch\/__init__.py\", line 423, in _load_pyfunc\r\n    return _PyTorchWrapper(_load_model(path, **kwargs))\r\n  File \"\/home\/zeth\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/pytorch\/__init__.py\", line 331, in _load_model\r\n    import torch\r\nModuleNotFoundError: No module named 'torch'\r\n[2020-08-11 14:47:29 +0200] [20435] [INFO] Worker exiting (pid: 20435)\r\n[2020-08-11 14:47:29 +0200] [20429] [INFO] Shutting down: Master\r\n[2020-08-11 14:47:29 +0200] [20429] [INFO] Reason: Worker failed to boot.\r\nTraceback (most recent call last):\r\n  File \"\/home\/zeth\/anaconda3\/bin\/mlflow\", line 8, in <module>\r\n    sys.exit(cli())\r\n  File \"\/home\/zeth\/anaconda3\/lib\/python3.7\/site-packages\/click\/core.py\", line 829, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\/home\/zeth\/anaconda3\/lib\/python3.7\/site-packages\/click\/core.py\", line 782, in main\r\n    rv = self.invoke(ctx)\r\n  File \"\/home\/zeth\/anaconda3\/lib\/python3.7\/site-packages\/click\/core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/home\/zeth\/anaconda3\/lib\/python3.7\/site-packages\/click\/core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/home\/zeth\/anaconda3\/lib\/python3.7\/site-packages\/click\/core.py\", line 1066, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\/home\/zeth\/anaconda3\/lib\/python3.7\/site-packages\/click\/core.py\", line 610, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"\/home\/zeth\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/models\/cli.py\", line 59, in serve\r\n    host=host)\r\n  File \"\/home\/zeth\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/backend.py\", line 92, in serve\r\n    command_env=command_env)\r\n  File \"\/home\/zeth\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/backend.py\", line 172, in _execute_in_conda_env\r\n    command, rc\r\nException: Command 'source \/home\/zeth\/anaconda3\/bin\/..\/etc\/profile.d\/conda.sh && conda activate mlflow-dd325f076f6465c8205b2342fd8ab4531e905e1a 1>&2 && gunicorn --timeout=60 -b 127.0.0.1:5000 -w 1 ${GUNICORN_CMD_ARGS} -- mlflow.pyfunc.scoring_server.wsgi:app' returned non zero return code. Return code = 3\r\n```\r\n\r\nThe conda.yml file is not broken:\r\n```\r\nzeth@master \/t\/e\/m\/0\/f\/a\/models> bat conda.yaml                                                                                                                                    (mlf-core) \r\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\r\n       \u2502 File: conda.yaml\r\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\r\n   1   \u2502 channels:\r\n   2   \u2502 - defaults\r\n   3   \u2502 - conda-forge\r\n   4   \u2502 - pytorch\r\n   5   \u2502 dependencies:\r\n   6   \u2502 - python=3.7.7\r\n   7   \u2502 - pytorch=1.6.0\r\n   8   \u2502 - torchvision=0.7.0\r\n   9   \u2502 - pip\r\n  10   \u2502 - pip:\r\n  11   \u2502   - mlflow\r\n  12   \u2502   - cloudpickle==1.5.0\r\n  13   \u2502 name: mlflow-env\r\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\r\n```\r\nAnd the Conda environment contains torch as well (verified).\r\n\r\nI expect the model to be serving without any issues.\r\n\r\n### Code to reproduce issue\r\nDifficult to share, but if required I can absolutely do so.\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/scoring`: Local serving, model deployment tools, spark UDFs","638":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nTensorFlow 2.0 documentation explicitly says the default model serialization format should be [SavedModel](https:\/\/www.tensorflow.org\/guide\/saved_model)  format (not HDF5). HDF5 was the default for older TensorFlow Keras 1.\r\n## Motivation\r\n- MLflow TensorFlow 2.0 functionality should be  compatible with TensorFlow 2.0 standards.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n\r\n\r\n##  Related Issues\r\n- https:\/\/github.com\/mlflow\/mlflow\/issues\/3224 - [BUG] Cannot save Keras\/TF_2.x model as SavedModel format using mlflow.keras.log_model with kwargs { \"save_format\": \"tf\" }\r\n\r\n","639":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this documentation issue template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages documentation fix contributions. Would you or another member of your organization be willing to contribute a fix for this documentation issue to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a documentation fix independently.\r\n- [ ] Yes. I would be willing to contribute a document fix with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a documentation fix at this time.\r\n\r\n### URL(s) with the issue:\r\n\r\n[Tracking](https:\/\/mlflow.org\/docs\/latest\/tracking.html#concepts) could be extended by a list.\r\n\r\n### Description of proposal (what needs changing):\r\n\r\nHey,\r\ni am fairly new to mlflow and was just wondering which file types are supported by mlflow artifacts viewer.\r\nI could only find [examples](https:\/\/mlflow.org\/docs\/latest\/tracking.html#concepts) in the documentation not a full list. (if I missed something please send me a link)\r\n\r\nI would suggest a short list of file types & file endings.\r\n\r\n- picture: .jpg, .png, ...\r\n- gif: .gif\r\n- pdf: .pdf\r\n- text: .txt, ...\r\n- ...\r\n\r\nExamples (pictures) would be awesome, but a list would be a good first step!\r\n\r\nThe list would make it easier for everyone to get a grasp of what mlflow artifact viewer is capable of visualizing.\r\n\r\nPS: I saw a [map visualizer component](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/server\/js\/src\/experiment-tracking\/components\/artifact-view-components\/ShowArtifactMapView.js), but have no clue what artifact file format is expected and what the outcome would look like.\r\n","640":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [X] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nConfidence intervals (most commonly 95%) can be considered a best practice when comparing metrics to determine which models are better than others, or that the estimation of the metrics are too uncertain to be able to conclude anything. Honestly it puzzles me why the support for confidence intervals is not more widespread in machine learning logging frameworks.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nThe results of any experiment can benefit by logging both point estimates of performance metrics along with confidence intervals to be able to interpret the uncertainty of the metrics.\r\n- Why is this use case valuable to support for MLflow users in general?\r\nSupport confidence intervals allows a good practice any mlflow user.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nWe routinely run experiments computing confidence intervals for the metrics. We also use mlflow, but it is quite frustrating that it does not support confidence intervals because we can't use mlflow to visualize the results that we get.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nConfidence intervals are best used when the are included in plots as error bars which allows easy comparison between different models. Including the low and high values of the intervals as different metrics is not useful because it makes the plots confusing. The error bars are actually important to ease the interpretation of the results.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [X] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nImplementing this feature would require:\r\n- Extend the log-metric functions in all APIs to support optional lower and upper limits of the confidence intervals.\r\n- Extend the storage of metrics so that it can optionally include the intervals.\r\n- Extend plotting functionalities in the ui so that if confidence intervals are available the user can choose to display them or not.","641":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time --> but happy to help review!\r\n\r\n## Proposal Summary\r\n\r\nIn #2087, we concluded that it's currently difficult to implement MLflow autologging for Pytorch directly due to the flexible structure of Pytorch training code (i.e. there's no Callback API for us to plug into, and users define training code via custom Python functions), opting instead for adding autologging for fastai, a higher-level framework built on top of Pytorch. In a similar vein, we should consider supporting autologging for other popular frameworks that build atop Pytorch, e.g. Pytorch Lightning.\r\n\r\n## Motivation\r\n- What is the use case for this feature? Users of Pytorch Lightning, a popular higher-level library that simply prescribes a structure for Pytorch code\r\n- Why is this use case valuable to support for MLflow users in general? Users of Pytorch Lightning will find it easier to onboard to using MLflow\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nIt's currently possible to manually log metrics, params, and models trained using Pytorch Lightning (& other higher-level frameworks based on Pytorch) to MLflow, but autologging support will make it easier & less intrusive to introduce MLflow tracking to training code.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nWe should consider putting this new API under a module namespace like `mlflow.pytorch.autolog` or `mlflow.pl.autolog` etc.","642":"\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [x] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: \r\n- **MLflow installed from (source or binary)**: Source \r\n- **MLflow version (run ``mlflow --version``)**: 1.10\r\n- **Python version**: 3.6\r\n- **npm version, if running the dev UI**:NA\r\n- **Exact command to reproduce**: \r\n\r\n### Describe the problem\r\nThe predict function in the onnx model fails for high-dimensional model inputs (e.g, image models). \r\nThe reason is that the data corresponding to each model input is represented as a pandas dataframe column\r\nand accessed though  `dataFrame[colName].values ` whose rank is always 1. This is because the column is of dtype(object)\r\nand does not recognize the high-dimensions of the object. Here is an example:\r\n\r\n>`df = pd.DataFrame([[1,2, [[3,4,5]]],[6,7,[[8,9,10]]]], columns=['a','b','c'])`\r\n\r\n>`df['c'].values`\r\narray([list([[3, 4, 5]]), list([[8, 9, 10]])], dtype=object)\r\n\r\n>`df['c'].values.shape`\r\n(2,)\r\n\r\nAs shown the 'c' column has rank 1 (shape = (2,)) whereas the data in the column is of rank 3 (shape=(1,2,3)).\r\n\r\nThe ONNXRuntime though expects a higher-rank object and as a result the prediction fails. The predict function should check the input model shape and bring the dataframe columns in the correct form before feeding them in the ONNXRuntime. Similarly, the output of predict (which is again a dataframe) should conform to the expected shape of the model output.\r\n\r\n### Code to reproduce issue\r\n \r\n   ```\r\n    import onnx\r\n    import mlflow.onnx\r\n    import tf2onnx\r\n    import tensorflow as tf\r\n```\r\n\r\n ```\r\n   graph = tf.Graph()\r\n    with graph.as_default():\r\n        t_in1 = tf.placeholder(tf.int32, (1, 2, 2), name=\"first_input\")\r\n        t_in2 = tf.placeholder(tf.int32, (1, 2, 2), name=\"second_input\")\r\n        t_out = tf.add(t_in1, t_in2)\r\n        t_out_named = tf.identity(t_out, name=\"output\")\r\n\r\n    sess = tf.Session(graph=graph)\r\n\r\n    onnx_graph = tf2onnx.tfonnx.process_tf_graph(\r\n        sess.graph,\r\n        input_names=[\"first_input:0\", \"second_input:0\",],\r\n        output_names=[\"output:0\"],\r\n    )\r\n    high_dim_model = onnx_graph.make_model(\"test\")\r\n```\r\n```\r\n    mlflow.onnx.save_model(high_dim_model, \"model\")\r\n    # Loading pyfunc model\r\n    pyfunc_loaded = mlflow.pyfunc.load_pyfunc(\"model\")\r\n\r\n     data_high_dim_inputs = pd.DataFrame(\r\n        {\r\n            \"first_input:0\": [np.arange(2 * 2, dtype=np.int32).reshape(2, 2)],\r\n            \"second_input:0\": [np.arange(2 * 2, dtype=np.int32).reshape(2, 2)],\r\n        },\r\n    )  \r\n    pyfunc_loaded.predict(data_high_dim_inputs)\r\n```\r\n\r\n\r\nThis test fails with error:\r\n\r\n`E       RuntimeError: Method run failed due to: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Unexpected input data type. Actual: (N11onnxruntime11NonOnnxTypeINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEEE) , expected: (N11onnxruntime11NonOnnxTypeIiEE)`\r\n\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\n\r\n\r\n","643":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this installation issue template to ensure a timely and thorough response.**\r\n\r\n### System information\r\n- **OS Platform and Distribution :Ubuntu 18.04\r\n- **MLflow installed from :source\r\n- **MLflow version :1.10\r\n\r\n\r\nI am trying to log the TensorFlow based Deeplab model using mlflow.tensorflow.log_model(). It takes the following 3 arguments.\r\n1-tf_saved_model_dir\r\n2-tf_meta_graph_tags\r\n3-tf_signature_def_key\r\n1-tf_saved_model_dir - For the first argument- deeplab models are saved in .ckpt format but mlflow.tensorflow.log_model() expects in .pb format.\r\nSo I used export_model.py https:\/\/github.com\/tensorflow\/models\/blob\/master\/research\/deeplab\/export_model.py to convert to pb format.\r\nCommand used-\r\npython3 deeplab\/export_model.py \\\r\n  --logtostderr \\\r\n  --model_variant=\"xception_65\" \\\r\n  --num_classes=151 \\\r\n  --atrous_rates=6 \\\r\n  --atrous_rates=12 \\\r\n  --atrous_rates=18 \\\r\n  --output_stride=16 \\\r\n  --crop_size=513 \\\r\n  --crop_size=513 \\\r\n  --checkpoint_path='\/home\/...\/training_dir\/model.ckpt-100' \\\r\n  --export_path='\/home\/...\/training_dir\/export_model\/saved_model.pb' \\\r\n  --save_inference_graph=True\r\n2-tf_meta_graph_tags -\r\nFor conversion of checkpoints to pb export_model.py uses freeze_graph_with_def_protos() function of \/tensorflow\/python\/tools\/freeze_graph.py. The arguments saved_model_tags is set to None.\r\nBut when I try\r\nmlflow.tensorflow.log_model(tf_saved_model_dir= tf_saved_model_dir ,tf_meta_graph_tags= None , tf_signature_def_key=None , artifact_path = export_path)\r\nI get the error -\r\nTypeError: 'NoneType' object is not iterable\r\nOr\r\nmlflow.tensorflow.log_model(tf_saved_model_dir= tf_saved_model_dir ,tf_meta_graph_tags= tag_constants.SERVING , tf_signature_def_key=None , artifact_path = export_path)\r\nRuntimeError: MetaGraphDef associated with tags serve could not be found in SavedModel.\r\nIs tf_meta_graph_tags and saved_model_tags different.\r\nhow to find tf_meta_graph_tags.\r\nI tried this\r\nfrom tensorflow.python.tools import freeze_graph\r\ntf_saved_model_dir = '\/home\/...\/deeplab\/training_dir\/export_model'\r\nprint(freeze_graph._parse_input_meta_graph_proto(tf_saved_model_dir+'\/inference_graph.pbtxt',input_binary= False))\r\nGot this error-\r\ngoogle.protobuf.text_format.ParseError: 1:1 : Message type \"tensorflow.MetaGraphDef\" has no field named \"node\"\r\n3-tf_signature_def_key- Please suggest how to find this argument. for eg- in few other codes other than deeplab it is tf_signature_def_key=\u2019serving_default\u2019.\r\nBut I am not sure it is the same for my model.\r\nWhat I have understood till now is that I have to use saved_model_cli to know tags and key from my model. Am i right?\r\nIf yes how to use saved_model_cli here.\r\nIf I am wrong please suggest ways to know tf_meta_graph_tags and tf_signature_def_key.\r\nI have also followed this https:\/\/medium.com\/analytics-vidhya\/mlflow-logging-for-tensorflow-37b6a6a53e3c approach.\r\nto log model checkpoints as artifacts which can be a workaround to mlflow.tensorflow.log_model().\r\n","644":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n## Proposal Summary\r\n\r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\nLog streaming for ongoing runs. A mechanism to view the logs of an ongoing run on the MLFlow UI.\r\n\r\n## Motivation\r\nFor use cases where users don't have access to the cloud node on which the experiment is running, this would be a helpful feature to view the logs and debug issues if any.","645":"Signed-off-by: Arjun DCunha <arjun.dcunha@databricks.com>\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nMLflow Projects provides the ability for users to specify project parameters referencing remote files using the `path` parameter. However, the path parameters does not support http:\/\/ URLs. This PR adds supports for http URLs.\r\n\r\n## How is this patch tested?\r\n\r\nUnit tests and manually tested.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nAdded support for `http` URLs in the path parameter for MLflow projects.\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","646":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ *] No. I cannot contribute this feature at this time.\r\n\r\nI not sure what to change\r\n\r\n## Proposal Summary\r\n\r\nShrink the size of the docker a bit with unnecessary conda pkg\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nSmaller container size less memory foot print\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [* ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nWhen I have built a docker container the size of it is quite large\r\n\r\nubuntu@:~\/$ docker images\r\nREPOSITORY                  TAG                 IMAGE ID            CREATED             SIZE\r\nbob_custom_model_payload    v2                  23397ab96ed4        5 seconds ago       3.48GB\r\n\r\nI logged into the container and ran 'conda clean --all'\r\n\r\nroot@8edad59620d7:\/# du -h --max-depth=1\r\n63M     .\/opt\r\n4.0K    .\/boot\r\n151M    .\/root\r\n13M     .\/lib\r\n12K     .\/tmp\r\n4.0K    .\/home\r\n20K     .\/run\r\n0       .\/dev\r\n15M     .\/var\r\n878M    .\/usr\r\n4.6M    .\/sbin\r\n5.5M    .\/bin\r\n0       .\/proc\r\n4.0K    .\/mnt\r\n4.0K    .\/srv\r\n4.0K    .\/lib64\r\n0       .\/sys\r\n4.0K    .\/media\r\n2.8M    .\/etc\r\n2.3G    .\/miniconda\r\n3.4G    .\r\nroot@8edad59620d7:\/# cd \/miniconda\/\r\nroot@8edad59620d7:\/miniconda# du -h --max-depth=1\r\n1.7G    .\/pkgs\r\n12K     .\/x86_64-conda_cos6-linux-gnu\r\n8.0K    .\/condabin\r\n250M    .\/lib\r\n263M    .\/envs\r\n628K    .\/conda-meta\r\n4.0K    .\/compiler_compat\r\n8.2M    .\/share\r\n17M     .\/bin\r\n56K     .\/ssl\r\n4.0K    .\/.empty\r\n12K     .\/shell\r\n2.3M    .\/include\r\n28K     .\/etc\r\n2.3G    .\r\nroot@8edad59620d7:\/miniconda# conda clean --all\r\nroot@8edad59620d7:\/miniconda# du -h --max-depth=1\r\n1.3G    .\/pkgs\r\n12K     .\/x86_64-conda_cos6-linux-gnu\r\n8.0K    .\/condabin\r\n250M    .\/lib\r\n263M    .\/envs\r\n628K    .\/conda-meta\r\n4.0K    .\/compiler_compat\r\n8.2M    .\/share\r\n17M     .\/bin\r\n56K     .\/ssl\r\n4.0K    .\/.empty\r\n12K     .\/shell\r\n2.3M    .\/include\r\n28K     .\/etc\r\n1.8G    .\r\n\r\nIt is only a reduction of 300M but for 3 containers that is 1G\r\n\r\nI don't know if there is anything else that can be done?\r\n\r\nThanks\r\n\r\nBob","647":"### System information\r\n- OS: Windows\r\n-source: library(mlflow)\r\n- version: 1.1\r\n- **Python version**:3.6\r\n- **Exact command to reproduce**:\r\nlibrary(mlflow)\r\ninstall_mlflow(python_version = \"3.6\")\r\nmlflow_log_param(\"param1\", 5)\r\n\r\n### Describe the problem\r\nAfter installing mlflow in rstudio and run any mlflow command such as mlflow_log_param(\"param1\", 5) i recieve the below error. I tried to manually copy mlflow.exe but this resulted in another problem where every mlflow command fails after 10s, see \r\nhttps:\/\/stackoverflow.com\/questions\/63174883\/using-mlflow-with-r-operation-failed-after-waiting-for-10-seconds\r\n\r\n### Other info \/ logs\r\nError in rethrow_call(c_processx_exec, command, c(command, args), stdin,  : \r\n  Command 'C:\/Users\/usr\/Anaconda3\/envs\/r-mlflow-1.10.0\/mlflow' not found @win\/processx.c:994 (processx_exec)\r\nType .Last.error.trace to see where the error occured\r\n","648":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nAdding more hooks to  RunContextProvider class would allow tracking plugins to add more functionality like slack\/email notifications based on run\/experiment start\/end events.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n> Start\/end run events can be be used to trigger extra actions using plugins.\r\n- Why is this use case valuable to support for MLflow users in general?\r\n> Yes.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n> Yes.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n> Yes.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","649":"## What changes are proposed in this pull request?\r\n\r\nAdds more actions to RunContextProvider class which can be used by tracking plugins to add more functionality like slack\/email notifications based on run\/experiment start\/end events.\r\n\r\n## How is this patch tested?\r\n\r\nManually\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nNow, tracking plugins can define `execute_start_run_actions`, `execute_end_run_actions`, `execute_create_experiment_actions`, `execute_delete_experiment_actions` functions to trigger actions when runs are started\/finished and experiments are created\/deleted.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","650":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Describe the problem\r\nI am training a pytorch model and trying to log it towards the end using the following command\r\n```\r\nmlflow.pytorch.log_model(model, \"model\")\r\n```\r\n\r\n### Code to reproduce issue\r\nhttps:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/pytorch\r\nI am using the exact same code by adding the log_model line at the bottom\r\n\r\n### Other info \/ logs\r\n```\r\nTraceback (most recent call last):\r\n  File \"mnist_tensorboard_artifact.py\", line 172, in <module>\r\n    mlflow.pytorch.log_model(model, \"model\")\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/site-packages\/mlflow\/pytorch\/__init__.py\", line 179, in log_model\r\n    signature=signature, input_example=input_example, **kwargs)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/site-packages\/mlflow\/models\/model.py\", line 154, in log\r\n    **kwargs)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/site-packages\/mlflow\/pytorch\/__init__.py\", line 300, in save_model\r\n    torch.save(pytorch_model, model_path, pickle_module=pickle_module, **kwargs)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/site-packages\/torch\/serialization.py\", line 328, in save\r\n    _legacy_save(obj, opened_file, pickle_module, pickle_protocol)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/site-packages\/torch\/serialization.py\", line 401, in _legacy_save\r\n    pickler.dump(obj)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/site-packages\/cloudpickle\/cloudpickle_fast.py\", line 540, in dump\r\n    return Pickler.dump(self, obj)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 409, in dump\r\n    self.save(obj)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 521, in save\r\n    self.save_reduce(obj=obj, *rv)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 605, in save_reduce\r\n    save(cls)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 463, in save\r\n    self.save_pers(pid)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 530, in save_pers\r\n    self.save(pid, save_persistent_id=False)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 751, in save_tuple\r\n    save(element)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/site-packages\/cloudpickle\/cloudpickle_fast.py\", line 705, in save_global\r\n    self._save_reduce_pickle5(*_dynamic_class_reduce(obj), obj=obj)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/site-packages\/cloudpickle\/cloudpickle_fast.py\", line 664, in _save_reduce_pickle5\r\n    save(state)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 736, in save_tuple\r\n    save(element)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 821, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 847, in _batch_setitems\r\n    save(v)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/site-packages\/cloudpickle\/cloudpickle_fast.py\", line 722, in save_function\r\n    *self._dynamic_function_reduce(obj), obj=obj\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/site-packages\/cloudpickle\/cloudpickle_fast.py\", line 664, in _save_reduce_pickle5\r\n    save(state)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 736, in save_tuple\r\n    save(element)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 821, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 847, in _batch_setitems\r\n    save(v)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 821, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 847, in _batch_setitems\r\n    save(v)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 521, in save\r\n    self.save_reduce(obj=obj, *rv)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 634, in save_reduce\r\n    save(state)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 821, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 847, in _batch_setitems\r\n    save(v)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 521, in save\r\n    self.save_reduce(obj=obj, *rv)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 634, in save_reduce\r\n    save(state)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 821, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 852, in _batch_setitems\r\n    save(v)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 521, in save\r\n    self.save_reduce(obj=obj, *rv)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 634, in save_reduce\r\n    save(state)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 821, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 847, in _batch_setitems\r\n    save(v)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/pickle.py\", line 496, in save\r\n    rv = reduce(self.proto)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/multiprocessing\/queues.py\", line 58, in __getstate__\r\n    context.assert_spawning(self)\r\n  File \"\/Users\/dshah\/Desktop\/local\/miniconda\/envs\/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419\/lib\/python3.6\/multiprocessing\/context.py\", line 356, in assert_spawning\r\n    ' through inheritance' % type(obj).__name__\r\nRuntimeError: Queue objects should only be shared between processes through inheritance\r\n2020\/07\/30 12:23:42 ERROR mlflow.cli: === Run (ID 'b7a5eed7f3a74219ac3d72c376f3edac') failed ===\r\n```\r\n\r\n","651":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this documentation issue template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages documentation fix contributions. Would you or another member of your organization be willing to contribute a fix for this documentation issue to the MLflow code base?\r\n\r\n- [x ] Yes. I can contribute a documentation fix independently.\r\n- [ ] Yes. I would be willing to contribute a document fix with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a documentation fix at this time.\r\n\r\n### URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry in question.\r\n\r\n### Description of the proposal (what needs changing):\r\nDevelopers using MLflow APIs expect good descriptions of the API interface as well as code snippets that show how\r\nto use a method. Adding code snippets to all Python MLflow APIs will be an ongoing effort\u2014to improve developer experience\u2014but let's start with the `mlflow` module first.\r\n","652":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n**Expanding functionality for Windows users**\r\n- Why is this use case valuable to support for MLflow users in general?\r\n**Provides a more uniform experience across OS**\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n**A large number of our users use Windows**\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n**Users are required to utilize relative paths even if their normal workflow uses absolute paths. While not impossible, it's an inconvenience we'd like to alleviate.**\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [x] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","653":"## What changes are proposed in this pull request?\r\n\r\nWhen loging any kind of supported model, mlflow is added as a pip dependency to the `conda.yaml`. The following change with fix the mlflow version to the one used to log the model.\r\n\r\nFixes: #2979 \r\n\r\n## How is this patch tested?\r\n```py\r\nimport numpy as np\r\nfrom sklearn.linear_model import LinearRegression\r\nimport mlflow\r\nimport mlflow.sklearn\r\n\r\nX = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\r\ny = np.dot(X, np.array([1, 2])) + 3\r\nreg = LinearRegression().fit(X, y)\r\nreg.score(X, y)\r\n\r\nwith mlflow.start_run():\r\n    mlflow.sklearn.log_model(sk_model=reg, artifact_path=\"model\")\r\n```\r\n\r\nresults in the following `conda.yaml`\r\n```yaml\r\nchannels:\r\n- defaults\r\n- conda-forge\r\ndependencies:\r\n- python=3.6.10\r\n- scikit-learn=0.20.2\r\n- pip\r\n- pip:\r\n  - mlflow==1.9.2.dev0\r\n  - cloudpickle==0.8.0\r\nname: mlflow-env\r\n```\r\n\r\nunit test added\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nWhen logging a model the `conda.yaml` file will an `mlflow` pip dependency with the version used to log the model\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [x] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","654":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [X] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nEditing\/updating of an experiment run should not be possible if the run has been registered in the model registry.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nCurrently you can edit\/update an existing experiment run after it has been registered as a model in the model registry. This makes it possible to break the traceability of registered models, making models possibly less reliable.\r\n- Why is this use case valuable to support for MLflow users in general?\r\nOnce a model is registered MLflow users should be able to assume that it is \"frozen\" in place, and cannot be changed anymore.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [X] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n\r\nMy 2cts on what the solution to this should be: once an experiment run is registered as a model, it should be marked as \"frozen\". This would allow non-registered experiment runs to still be updated, while protecting registered models from changing\/breaking. This would probably mean a change to the tracking API as it should reject changes to an experiment run that has a model registered to it.\r\nI think this issue is related to #3160. I'm happy to help out implementing this, if this is deemed a valid approach to resolving the problem.\r\n","655":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [X] Yes. I can contribute this feature independently.\r\n- [X] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nDeletion of experiment run should ideally not allowed if there is a model from the run registered in the model registry.\r\n\r\n## Motivation\r\n- What is the use case for this feature? \r\nData integrity\r\n- Why is this use case valuable to support for MLflow users in general? \r\nWould be bad to have a model where the run that generated it no longer exists, which potentially included non-existent model artifact if artifacts for deleted run are cleaned on a regular basis.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [X] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n\r\n[Happy to look into implementation details if this feature is deemed useful \/ likely to be incorporated]","656":"**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nMLflow's framework-agnostic inference APIs (e.g. `mlflow models serve` for RESTful inference, `mlflow.pyfunc.spark_udf` for batch scoring with Spark, `mlflow.pyfunc.load_model(...).predict(df)` are largely based around scoring DataFrame inputs (although they're capable of producing numpy-array output). In particular, it's difficult to score multidimensional input (e.g. tensors) with the `mlflow.pyfunc` API and related tools. We should investigate ways to make it easier to score such tensor input, either by extending the existing pyfunc flavor or by introducing a new flavor (e.g. tensorfunc? pytensorfunc?)\r\n\r\n## Motivation\r\n- What is the use case for this feature? Users of deep learning frameworks, e.g. PyTorch, TensorFlow, and Keras, often want to train and predict with models that accept multidimensional input (e.g. image or NLP models). It's currently not possible to score such models with MLflow\r\n- Why is this use case valuable to support for MLflow users in general? See above - we'd make MLflow models usable for a wide range of deep learning use cases\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n","657":"### Willingness to contribute\r\n\r\nNo. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- OS Platform and Distribution: Linux Ubuntu 16.04.6\r\n- MLflow version 1.10.0\r\n- Python version: 3.7.3\r\n\r\n### Describe the problem\r\n\r\nI need the newest version of MLflow due to some dependencies between MLFlow and Databricks platform releases.  However, importing mlflow.onnx results in an ImportError.  Specifically, the error is: \r\n\r\nImportError: cannot import name 'NumpyEncoder' from 'mlflow.utils.proto_json_utils'\r\n\r\nI'm able to import mlflow.onnx with version 1.8.0 and below.\r\n\r\n### Code to reproduce issue\r\n\r\n`import mlflow.onnx`\r\n\r\n### Other info \/ logs\r\n\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n<command-18347> in <module>\r\n      1 # newer versions of mlflow run into import error\r\n----> 2 import mlflow.onnx\r\n\r\n\/databricks\/python\/lib\/python3.7\/site-packages\/mlflow\/onnx.py in <module>\r\n     14 import pandas as pd\r\n     15 \r\n---> 16 from mlflow import pyfunc\r\n     17 from mlflow.models import Model\r\n     18 from mlflow.models.model import MLMODEL_FILE_NAME\r\n\r\n\/databricks\/python\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py in <module>\r\n    211 from typing import Any, Union\r\n    212 import mlflow\r\n--> 213 import mlflow.pyfunc.model\r\n    214 import mlflow.pyfunc.utils\r\n    215 from mlflow.models import Model, ModelSignature, ModelInputExample\r\n\r\n\/databricks\/python\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/model.py in <module>\r\n     15 import mlflow.utils\r\n     16 from mlflow.exceptions import MlflowException\r\n---> 17 from mlflow.models import Model\r\n     18 from mlflow.models.model import MLMODEL_FILE_NAME\r\n     19 from mlflow.protos.databricks_pb2 import INVALID_PARAMETER_VALUE\r\n\r\n\/databricks\/python\/lib\/python3.7\/site-packages\/mlflow\/models\/__init__.py in <module>\r\n     20 from .flavor_backend import FlavorBackend\r\n     21 from .signature import ModelSignature, infer_signature\r\n---> 22 from .utils import ModelInputExample\r\n     23 \r\n     24 __all__ = [\"Model\", \"ModelSignature\", \"infer_signature\", \"FlavorBackend\"]\r\n\r\n\/databricks\/python\/lib\/python3.7\/site-packages\/mlflow\/models\/utils.py in <module>\r\n      9 from mlflow.models import Model\r\n     10 from mlflow.types.utils import TensorsNotSupportedException\r\n---> 11 from mlflow.utils.proto_json_utils import NumpyEncoder, _dataframe_from_json\r\n     12 \r\n     13 ModelInputExample = Union[pd.DataFrame, np.ndarray, dict, list]\r\n\r\nImportError: cannot import name 'NumpyEncoder' from 'mlflow.utils.proto_json_utils' (\/databricks\/python\/lib\/python3.7\/site-packages\/mlflow\/utils\/proto_json_utils.py)\r\n\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\n\r\nModel Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n","658":"The following problem occurs when running the  mlflow run .   command.\r\n\r\n2020\/07\/22 18:07:31 INFO mlflow.projects: === Building docker image docker-example ===\r\n2020\/07\/22 18:07:31 INFO mlflow.projects: === Created directory \/tmp\/tmp20yr16p3 for downloading remote URIs passed to arguments of type 'path' ===\r\n2020\/07\/22 18:07:31 INFO mlflow.projects: === Running command 'docker run --rm -v \/home\/zyz\/cphm_mlflow_sklearn_docker\/mlruns:\/mlflow\/tmp\/mlruns -v \/home\/zyz\/cphm_mlflow_sklearn_docker\/mlruns\/0\/3d6b35ed5605417f9cbb18311944eede\/artifacts:\/home\/zyz\/cphm_mlflow_sklearn_docker\/mlruns\/0\/3d6b35ed5605417f9cbb18311944eede\/artifacts -e MLFLOW_RUN_ID=3d6b35ed5605417f9cbb18311944eede -e MLFLOW_TRACKING_URI=file:\/\/\/mlflow\/tmp\/mlruns -e MLFLOW_EXPERIMENT_ID=0 docker-example:latest python main.py --cphm-csv .\/datasets\/cd5_3x_curve_feayute_fixed.csv --split-prop 0.8 --n-neighbors 2' in run with ID '3d6b35ed5605417f9cbb18311944eede' === \r\nNo matching run has been found.\r\nLaunching new run for entrypoint=load_data and parameters={'cphm_csv': '.\/datasets\/cd5_3x_curve_feayute_fixed.csv'}\r\nTraceback (most recent call last):\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/projects\/__init__.py\", line 578, in _validate_docker_installation\r\n    process.exec_cmd([docker_path, \"--help\"], throw_on_error=False)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/utils\/process.py\", line 43, in exec_cmd\r\n    cwd=cwd, universal_newlines=True, **kwargs)\r\n  File \"\/opt\/conda\/lib\/python3.6\/subprocess.py\", line 709, in __init__\r\n    restore_signals, start_new_session)\r\n  File \"\/opt\/conda\/lib\/python3.6\/subprocess.py\", line 1344, in _execute_child\r\n    raise child_exception_type(errno_num, err_msg, err_filename)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'docker': 'docker'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 98, in <module>\r\n    workflow(cphm_csv, split_prop, n_neighbors)\r\n  File \"main.py\", line 86, in workflow\r\n    load_data_run = _get_or_run(\"load_data\", {\"cphm_csv\": cphm_csv}, git_commit)\r\n  File \"main.py\", line 62, in _get_or_run\r\n    submitted_run = mlflow.run(\".\", entrypoint, parameters=parameters)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/projects\/__init__.py\", line 281, in run\r\n    synchronous=synchronous)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/projects\/__init__.py\", line 134, in _run\r\n    _validate_docker_installation()\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/projects\/__init__.py\", line 580, in _validate_docker_installation\r\n    raise ExecutionException(\"Could not find Docker executable. \"\r\nmlflow.exceptions.ExecutionException: Could not find Docker executable. Ensure Docker is installed as per the instructions at https:\/\/docs.docker.com\/install\/overview\/.\r\n2020\/07\/22 18:07:33 ERROR mlflow.cli: === Run (ID '3d6b35ed5605417f9cbb18311944eede') failed ===\r\n\r\nThen I solved the above problem with docker -v command\uff0cbut the following problems occurred when running the mlflow run . command again\r\n\r\n2020\/07\/22 18:16:06 INFO mlflow.projects: === Building docker image docker-example ===\r\n2020\/07\/22 18:16:07 INFO mlflow.projects: === Created directory \/tmp\/tmpj8pfnsvn for downloading remote URIs passed to arguments of type 'path' ===\r\n2020\/07\/22 18:16:07 INFO mlflow.projects: === Running command 'docker run --rm -v \/home\/zyz\/cphm_mlflow_sklearn_docker\/mlruns:\/mlflow\/tmp\/mlruns -v \/home\/zyz\/cphm_mlflow_sklearn_docker\/mlruns\/0\/54904d42eefb4c5089371cc255a6009e\/artifacts:\/home\/zyz\/cphm_mlflow_sklearn_docker\/mlruns\/0\/54904d42eefb4c5089371cc255a6009e\/artifacts -v \/usr\/bin\/docker:\/usr\/bin\/docker -v \/var\/run\/docker.sock:\/var\/run\/docker.sock -e MLFLOW_RUN_ID=54904d42eefb4c5089371cc255a6009e -e MLFLOW_TRACKING_URI=file:\/\/\/mlflow\/tmp\/mlruns -e MLFLOW_EXPERIMENT_ID=0 docker-example:latest python main.py --cphm-csv .\/datasets\/cd5_3x_curve_feayute_fixed.csv --split-prop 0.8 --n-neighbors 2' in run with ID '54904d42eefb4c5089371cc255a6009e' === \r\nNo matching run has been found.\r\n2020\/07\/22 10:16:08 INFO mlflow.projects: === Building docker image docker-example ===\r\n2020\/07\/22 10:16:08 INFO mlflow.projects: === Created directory \/tmp\/tmp5__scuob for downloading remote URIs passed to arguments of type 'path' ===\r\n2020\/07\/22 10:16:08 INFO mlflow.projects: === Running command 'docker run --rm -v \/mlflow\/tmp\/mlruns:\/mlflow\/tmp\/mlruns -v \/home\/zyz\/cphm_mlflow_sklearn_docker\/mlruns\/0\/f4854d7936704a66bc4633e4d3035f2d\/artifacts:\/home\/zyz\/cphm_mlflow_sklearn_docker\/mlruns\/0\/f4854d7936704a66bc4633e4d3035f2d\/artifacts -v \/usr\/bin\/docker:\/usr\/bin\/docker -v \/var\/run\/docker.sock:\/var\/run\/docker.sock -e MLFLOW_RUN_ID=f4854d7936704a66bc4633e4d3035f2d -e MLFLOW_TRACKING_URI=file:\/\/\/mlflow\/tmp\/mlruns -e MLFLOW_EXPERIMENT_ID=0 docker-example:latest python load_data.py --cphm-csv .\/datasets\/cd5_3x_curve_feayute_fixed.csv' in run with ID 'f4854d7936704a66bc4633e4d3035f2d' === \r\nTraceback (most recent call last):\r\n  File \"load_data.py\", line 41, in <module>\r\n    load_data(cphm_csv)\r\n  File \"load_data.py\", line 30, in load_data\r\n    with mlflow.start_run() as mlrun:\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/tracking\/fluent.py\", line 119, in start_run\r\n    active_run_obj = MlflowClient().get_run(existing_run_id)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/tracking\/client.py\", line 96, in get_run\r\n    return self._tracking_client.get_run(run_id)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 49, in get_run\r\n    return self.store.get_run(run_id)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/store\/tracking\/file_store.py\", line 423, in get_run\r\n    run_info = self._get_run_info(run_id)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/store\/tracking\/file_store.py\", line 442, in _get_run_info\r\n    databricks_pb2.RESOURCE_DOES_NOT_EXIST)\r\nmlflow.exceptions.MlflowException: Run 'f4854d7936704a66bc4633e4d3035f2d' not found\r\nLaunching new run for entrypoint=load_data and parameters={'cphm_csv': '.\/datasets\/cd5_3x_curve_feayute_fixed.csv'}\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 98, in <module>\r\n    workflow(cphm_csv, split_prop, n_neighbors)\r\n  File \"main.py\", line 86, in workflow\r\n    load_data_run = _get_or_run(\"load_data\", {\"cphm_csv\": cphm_csv}, git_commit)\r\n  File \"main.py\", line 62, in _get_or_run\r\n    submitted_run = mlflow.run(\".\", entrypoint, parameters=parameters)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/projects\/__init__.py\", line 283, in run\r\n    _wait_for(submitted_run_obj)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/projects\/__init__.py\", line 300, in _wait_for\r\n    raise ExecutionException(\"Run (ID '%s') failed\" % run_id)\r\nmlflow.exceptions.ExecutionException: Run (ID 'f4854d7936704a66bc4633e4d3035f2d') failed\r\n2020\/07\/22 18:16:10 ERROR mlflow.cli: === Run (ID '54904d42eefb4c5089371cc255a6009e') failed ===\r\n\r\nCan you help me to solve this question?  Thanks!","659":"## What changes are proposed in this pull request?\r\n\r\nAdd a to_dictionary() method for mlflow.entities.model_registry.registered_model.RegisteredModel\r\n\r\n## How is this patch tested?\r\n\r\nCalled on various mlflow.entities.model_registry.registered_model.RegisteredModel objects.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [X] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nInclusion of to_dictionary() method that converts mlflow.entities.model_registry.registered_model.RegisteredModel contents into a python dictionary.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [X] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [X] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","660":"From time to time, the path to the _mlruns_ folder changes, e.g., when an experiment is moved to another folder. This also affects the _artifact_location_, which is currently only stored globally in the _meta.yaml_. What are the best practices to avoid this? Are there any efforts to only save a relative path to the artifacts?","661":"## What changes are proposed in this pull request?\r\n\r\nUse username from request's `authorization` header (if such exists), to fill in `Creator` field in model version page when create a new model version\r\n\r\n## How is this patch tested?\r\n\r\nUnit test + manual test\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [X] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n`Creator` field in model version page is extracted from request's `authorization` header (if such exists) when creating a new model version\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [X] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [X] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","662":"**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time. <-- but would be happy to provide guidance to someone interested in helping with this work - please comment if interested!\r\n\r\n## Proposal Summary\r\n\r\nAs per discussion in https:\/\/github.com\/mlflow\/mlflow\/pull\/3121, it'd save long-term maintenance cost if we can formalize and get community buy-in around a policy for which Python versions MLflow supports, and when we'll drop support for EOL'd Python versions.\r\n\r\n## Motivation\r\nSee above.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [x] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\nRelated: #2522, where we dropped Python 2 support in MLflow.\r\n\r\nWhen we look at formalizing our Python version policy, we should look at both what other ML libraries do (e.g. numpy\/sklearn have a [well-specified versioning policy](https:\/\/scikit-hep.org\/supported-python-versions)) and what other infrastructure tools do (e.g. Apache Airflow).\r\n\r\nThe difference is that in the infrastructure tool case, the common workflow may be to attempt to run e.g. airflow in a VM\/docker container using the system Python, which is likely to be older. For example, Ubuntu 16.04 is actually still not EOL and ships with Python 2.x out of the box, while Ubuntu 18.04 ships with Python 3.5 and is only [EOL in 2028](https:\/\/wiki.ubuntu.com\/Releases). But it may be that the common practice is to encourage running airflow in a conda environment etc - the point is we should investigate it.\r\n","663":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\nrunning on azure databricks 7.0 ML runtime\r\n\r\n### Describe the problem\r\nTried to  create a custom model subclass using the code in the documentation at https:\/\/www.mlflow.org\/docs\/latest\/models.html#custom-python-models\r\n\r\ngot the trace back below\r\n\r\nI believe this might have something to do with the use of yaml.safe_dump on line 57 of `mlflow\/models\/__init__.py` as mentioned in the following stack overflow https:\/\/stackoverflow.com\/questions\/21695705\/dump-an-python-object-as-yaml-file\r\n\r\np.s. it seems like a really strange design decision to require that a model has to be saved before the `predict()` method can be called\r\n\r\n### Code to reproduce issue\r\n```python\r\nimport mlflow.pyfunc\r\n\r\n# Define the model class\r\nclass AddN(mlflow.pyfunc.PythonModel):\r\n\r\n    def __init__(self, n):\r\n        self.n = n\r\n\r\n    def predict(self, context, model_input):\r\n        return model_input.apply(lambda column: column + self.n)\r\n\r\n# Construct and save the model\r\nmodel_path = \"add_n_model\"\r\nadd5_model = AddN(n=5)\r\nmlflow.pyfunc.save_model(path=model_path, python_model=add5_model)\r\n\r\n# Load the model in `python_function` format\r\nloaded_model = mlflow.pyfunc.load_model(model_path)\r\n\r\n# Evaluate the model\r\nimport pandas as pd\r\nmodel_input = pd.DataFrame([range(10)])\r\nmodel_output = loaded_model.predict(model_input)\r\nassert model_output.equals(pd.DataFrame([range(5, 15)]))\r\n```\r\n\r\n### Other info \/ logs\r\n```python\r\n---------------------------------------------------------------------------\r\nRepresenterError                          Traceback (most recent call last)\r\n<command-757720469349135> in <module>\r\n     14 add5_model = AddN(n=5)\r\n     15 \r\n---> 16 mlflow.pyfunc.log_model(add5_model, model_path)\r\n     17 \r\n     18 # Load the model in `python_function` format\r\n\r\n\/databricks\/python\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py in log_model(artifact_path, loader_module, data_path, code_path, conda_env, python_model, artifacts, registered_model_name)\r\n    697                      artifacts=artifacts,\r\n    698                      conda_env=conda_env,\r\n--> 699                      registered_model_name=registered_model_name)\r\n    700 \r\n    701 \r\n\r\n\/databricks\/python\/lib\/python3.7\/site-packages\/mlflow\/models\/__init__.py in log(cls, artifact_path, flavor, registered_model_name, **kwargs)\r\n     99             run_id = mlflow.tracking.fluent._get_or_start_run().info.run_id\r\n    100             mlflow_model = cls(artifact_path=artifact_path, run_id=run_id)\r\n--> 101             flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\r\n    102             mlflow.tracking.fluent.log_artifacts(local_path, artifact_path)\r\n    103             try:\r\n\r\n\/databricks\/python\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py in save_model(path, loader_module, data_path, code_path, conda_env, mlflow_model, python_model, artifacts, **kwargs)\r\n    603         return _save_model_with_loader_module_and_data_path(\r\n    604             path=path, loader_module=loader_module, data_path=data_path,\r\n--> 605             code_paths=code_path, conda_env=conda_env, mlflow_model=mlflow_model)\r\n    606     elif second_argument_set_specified:\r\n    607         return mlflow.pyfunc.model._save_model_with_class_artifacts_params(\r\n\r\n\/databricks\/python\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py in _save_model_with_loader_module_and_data_path(path, loader_module, data_path, code_paths, conda_env, mlflow_model)\r\n    747     mlflow.pyfunc.add_to_model(\r\n    748         mlflow_model, loader_module=loader_module, code=code, data=data, env=conda_env_subpath)\r\n--> 749     mlflow_model.save(os.path.join(path, 'MLmodel'))\r\n    750     return mlflow_model\r\n    751 \r\n\r\n\/databricks\/python\/lib\/python3.7\/site-packages\/mlflow\/models\/__init__.py in save(self, path)\r\n     63         \"\"\"Write the model as a local YAML file.\"\"\"\r\n     64         with open(path, 'w') as out:\r\n---> 65             self.to_yaml(out)\r\n     66 \r\n     67     @classmethod\r\n\r\n\/databricks\/python\/lib\/python3.7\/site-packages\/mlflow\/models\/__init__.py in to_yaml(self, stream)\r\n     55 \r\n     56     def to_yaml(self, stream=None):\r\n---> 57         return yaml.safe_dump(self.__dict__, stream=stream, default_flow_style=False)\r\n     58 \r\n     59     def to_json(self):\r\n\r\n\/databricks\/python\/lib\/python3.7\/site-packages\/yaml\/__init__.py in safe_dump(data, stream, **kwds)\r\n    304     If stream is None, return the produced string instead.\r\n    305     \"\"\"\r\n--> 306     return dump_all([data], stream, Dumper=SafeDumper, **kwds)\r\n    307 \r\n    308 def add_implicit_resolver(tag, regexp, first=None,\r\n\r\n\/databricks\/python\/lib\/python3.7\/site-packages\/yaml\/__init__.py in dump_all(documents, stream, Dumper, default_style, default_flow_style, canonical, indent, width, allow_unicode, line_break, encoding, explicit_start, explicit_end, version, tags, sort_keys)\r\n    276         dumper.open()\r\n    277         for data in documents:\r\n--> 278             dumper.represent(data)\r\n    279         dumper.close()\r\n    280     finally:\r\n\r\n\/databricks\/python\/lib\/python3.7\/site-packages\/yaml\/representer.py in represent(self, data)\r\n     25 \r\n     26     def represent(self, data):\r\n---> 27         node = self.represent_data(data)\r\n     28         self.serialize(node)\r\n     29         self.represented_objects = {}\r\n\r\n\/databricks\/python\/lib\/python3.7\/site-packages\/yaml\/representer.py in represent_data(self, data)\r\n     46         data_types = type(data).__mro__\r\n     47         if data_types[0] in self.yaml_representers:\r\n---> 48             node = self.yaml_representers[data_types[0]](self, data)\r\n     49         else:\r\n     50             for data_type in data_types:\r\n\r\n\/databricks\/python\/lib\/python3.7\/site-packages\/yaml\/representer.py in represent_dict(self, data)\r\n    205 \r\n    206     def represent_dict(self, data):\r\n--> 207         return self.represent_mapping('tag:yaml.org,2002:map', data)\r\n    208 \r\n    209     def represent_set(self, data):\r\n\r\n\/databricks\/python\/lib\/python3.7\/site-packages\/yaml\/representer.py in represent_mapping(self, tag, mapping, flow_style)\r\n    116         for item_key, item_value in mapping:\r\n    117             node_key = self.represent_data(item_key)\r\n--> 118             node_value = self.represent_data(item_value)\r\n    119             if not (isinstance(node_key, ScalarNode) and not node_key.style):\r\n    120                 best_style = False\r\n\r\n\/databricks\/python\/lib\/python3.7\/site-packages\/yaml\/representer.py in represent_data(self, data)\r\n     56                     node = self.yaml_multi_representers[None](self, data)\r\n     57                 elif None in self.yaml_representers:\r\n---> 58                     node = self.yaml_representers[None](self, data)\r\n     59                 else:\r\n     60                     node = ScalarNode(None, str(data))\r\n\r\n\/databricks\/python\/lib\/python3.7\/site-packages\/yaml\/representer.py in represent_undefined(self, data)\r\n    229 \r\n    230     def represent_undefined(self, data):\r\n--> 231         raise RepresenterError(\"cannot represent an object\", data)\r\n    232 \r\n    233 SafeRepresenter.add_representer(type(None),\r\n\r\nRepresenterError: ('cannot represent an object', <__main__.AddN object at 0x7fdbe88bf9d0>)\r\n```\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [x] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n","664":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nWhen using the `load_model` functionality I would like to have a persistent cache directory which is checked before the model is downloaded. For example:\r\n\r\n```python\r\n# download the model to \/my_cache and open it\r\nmodel = mlflow.pytorch.load_model('models:\/my_model\/4', cache='\/my_cache') \r\n# loads the model from the local directory\r\nmodel2 = mlflow.pytorch.load_model('models:\/my_model\/4', cache='\/my_cache')\r\n```\r\n\r\n## Motivation\r\n\r\nWe have large models stored on GCP which are referenced by tagging names in MLFlow. These take quite a while to download and experiment with each time they are used and are a major inconvenience. We have written some code to manually look up the artifact location, download and load models to get around this.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n","665":"## Willingness to contribute\r\nWould you or another member of your organization be willing to contribute an implementation of this feature?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n\r\n## Proposal Summary\r\n\r\nWhen running an MLFlow server, I would like to propose having the ability to specify the `BACKEND_STORE_URI` as an environment variable instead of a CLI option.\r\n\r\n## Motivation\r\n\r\nThe `backend-store-uri` will oftentimes contain sensitive information like database passwords. Some deployment options, like AWS ECS, won't allow you to interpolate secrets in CLI arguments at runtime.\r\n\r\nWorkarounds to this limitation of ECS include creating a custom docker image with an entrypoint that interpolates said secret, or overriding the entrypoint to use a shell.\r\n\r\nAlthough this limitation is not the responsibility of MLFlow, I would argue that giving people the option to specify values that contain secret information in multiple ways (env vars, files, ...) provides a better UX for systems engineers.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\n## Details\r\n\r\nIf you think this is a good idea, I was thinking of leveraging [Click's `envvar` argument for the `.option()` decorator](https:\/\/click.palletsprojects.com\/en\/7.x\/options\/#values-from-environment-variables).\r\n\r\n\r\n","666":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nWe should add support to reorder the columns by selecting and dragging columns on the runs table. We will also need to persist these settings in the browser.\r\n\r\nThis was initially implemented in #2251, but we decided to not include reordering since the orders would not persist.\r\n\r\nThe proposal here is to add back custom column orderings & persist the order.\r\n\r\n## Motivation\r\nRuns often have many associated parameters, only some of which are useful in viewing the Runs table. This is especially true when using autologging, and also sometimes occurs with metrics.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n","667":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [X] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Databricks 6.6 (Ubuntu 16.04.6 LTS)\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: 1.8.0\r\n- **Python version**: 3.7.3\r\n- **npm version, if running the dev UI**: N\/A\r\n- **Exact command to reproduce**: N\/A\r\n\r\n### Describe the problem\r\nI am using Databricks 6.6, but connecting to an external MLFlow server with a set tracking URI. When I run 'with mlflow.start_run():', an initial run is created. The run takes 1.7h to complete. About 1 hr in, a second run is created with a different job ID. When we run the same code using databricks as the tracking_uri, only one run is created throughout the entire process. Is there possibly a bug when connecting to external mlflow server from databricks that could cause a new run to be created during the initial run?\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n","668":"Looks like we might be missing support for custom pre\/post-processing for R models.\r\n\r\nFrom public Slack group:\r\n\r\n```\r\nNew to ML Flow here and I'm wondering how pre-processing\/post-processing of inputs\/outputs can be achieved for an ML flow deployed model. I have Tensorflow model I'm trying to deploy and I used the Tensorflow flavor to create the ML Flow model for it. For context, this model will be deployed for business users to test by sending inputs to an API. The actual model input is an array of token_ids from documents. But business users would provide english text to the API. So I'll need to somehow pre-process the input text by the users to suitable model input of token_ids and then serve the array to the model API. Also, the model output is a list of probabilities for ~60 classes. How do I pre-process and post-process the model inputs\/result so business users can simply submit text to the API and get in return the appropriate mapped class the model provides. Is this possible?\r\n\r\nDo you  have some example with R?\r\n\r\nI don't think the R models have the same support to add custom pre\/post-processing.\r\n```","669":"Hello. I'd love to be able to run experiments using `mlflow run --backend kubernetes` and have the container logs saved as an artifact in the artifact store. Today, I find myself having to search through pod logs through `kubectl`, which is a painstaking and highly technical task. Being able to read those logs from MLFlow UI would be of great help -- it'd help tremendously in debugging and tracking. \r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nUpon spinning up the container in the Kubernetes pod, start capturing stderr, stdout (or log). Then, store that log as an artifact (and send it along to the MLFlow UI server). The feature would save a lot of time and issues.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n-- Great for better debugging and tracking of experiments. Today, I find myself having to search through pod logs through `kubectl`, which is a painstaking task. Being able to read those logs from MLFlow UI would be of great help -- it'd help tremendously in debugging and tracking.\r\n- Why is this use case valuable to support for MLflow users in general?\r\n-- It is very likely that every user of MLFlow in K8s needs to go through logs, which is usually done through `kubectl`. This is a highly technical and time consuming task which would be greatly improved with MLFlow's capabilities.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n-- A lot of Data Scientists in my organization don't have the permissions\/technical abilities to check logs through `kubectl`. Having the ability to view logs within the MLFlow UI would be game-changer in using MLFlow within Kubernetes.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n-- As far as I know, there is no capability within MLFlow to easily check logs. The most informative approach is to check the K8s pod logs by using `kubectl` commands, which is technical and requires additional permissions. Another alternative I can think of is to do heavy logging of the process -- also painful for the user. The ability to save the logs as artifacts would make the process a breeze.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n\r\nUpon spinning up the container in the Kubernetes pod, start capturing stderr, stdout (or log) of the entry point described in MLProject (or the entire container run if possible). Then, store that log as an artifact and send it along to the MLFlow UI server, under the experiment and run_id.\r\n\r\nThe option could be implemented as a flag within `mlflow run` or as an env variable.\r\n\r\nI can foresee some difficulty in runs that log more than one run_id. Perhaps save the log to all of them?\r\n","670":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this documentation issue template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages documentation fix contributions. Would you or another member of your organization be willing to contribute a fix for this documentation issue to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a documentation fix independently.\r\n- [x] Yes. I would be willing to contribute a document fix with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a documentation fix at this time.\r\n\r\n### URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry in question.\r\n\r\n### Description of proposal (what needs changing):\r\nI am working on azure databricks. Due to network security restrictions of my company I must provide a list of URIs to be allowlist for mlflow usage.\r\n\r\n Is there any such list? I didn't find any yet. Would be of great help!\r\n","671":"Currenty when we try to run a sample code to log the experiment \r\nwe get the below error\r\n```Error in wait_for(function() mlflow_rest(\"experiments\", \"list\", client = client),  : \r\n  Operation failed after waiting for 10 seconds\r\n```\r\nCode we ran are:\r\n```with(mlflow_start_run(),{\r\n  run1= mlflow_start_run(experiment_id=52,client=client)\r\n  mlflow_log_param(\"parameter\", 5, run_id=run1$run_uuid, client=client)\r\n  mlflow_log_metric(\"metric\", 0, run_id=run1$run_uuid, client=client)\r\n```\r\nIs it possible to configure this on our side to have an increased timeOut?\r\nI see the reference [here](https:\/\/github.com\/mlflow\/mlflow\/blob\/4edf15a88d3792915fffee5f37257e2cbab87200\/mlflow\/R\/mlflow\/R\/tracking-server.R#L101)","672":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [X] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nI build the docker image by the this command:\r\n```bash\r\nmlflow models build-docker -m <mlrun>\/<run-ids>\/artifacts\/model -n mltest\r\n```\r\nbut it costs lots of time on this step\r\n```bash\r\n[INFO] Downloading from google-maven-central: https:\/\/maven-central.storage-download.googleapis.com\/repos\/central\/data\/org\/apache\/maven\/plugins\/maven-checkstyle-plugin\/3.0.0\/maven-checkstyle-plugin-3.0.0.pom\r\n```\r\n\r\nSo I hope that I can set `proxy` when building docker image, and this is what I wanted.\r\n```bash\r\nmlflow models build-docker -m <mlrun>\/<run-ids>\/artifacts\/model -n mltest --build-arg http_proxy=\"http::\/\/my-proxy\"  --build-arg https_proxy=\"http:\/\/my-proxy\"\r\n```\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [X] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","673":"We are trying to use MFLOW from RStudio.\r\nMLFLOW tracking server is hosted on a remote server[docker container] access over https served by an nginx.\r\nWe have noticed 2 errors \r\n\r\n- RUN ID missing.At times it complains that the run id generated its not found.However that run ID is existing on MLFLOWServer .However if we rename the run id on the tracking server and re run the code the run id is accepted by the API.\r\n```much existing on the mlflow tracking UI\r\nFile \"\/home\/ealiasbi\/.conda\/envs\/r-mlflow-1.0.0\/bin\/mlflow\", line 11, in <module>\r\nsys.exit(cli())\r\nFile \"\/home\/ealiasbi\/.conda\/envs\/r-mlflow-1.0.0\/lib\/python3.6\/site-packages\/click\/core.py\", line 829, in __call__\r\nreturn self.main(*args, **kwargs)\r\nFile \"\/home\/ealiasbi\/.conda\/envs\/r-mlflow-1.0.0\/lib\/python3.6\/site-packages\/click\/core.py\", line 782, in main\r\nrv = self.invoke(ctx)\r\nFile \"\/home\/ealiasbi\/.conda\/envs\/r-mlflow-1.0.0\/lib\/python3.6\/site-packages\/click\/core.py\", line 1259, in invoke\r\nreturn _process_result(sub_ctx.command.invoke(sub_ctx))\r\nFile \"\/home\/ealiasbi\/.conda\/envs\/r-mlflow-1.0.0\/lib\/python3.6\/site-packages\/click\/core.py\", line 1259, in invoke\r\nreturn _process_result(sub_ctx.command.invoke(sub_ctx))\r\nFile \"\/home\/ealiasbi\/.conda\/envs\/r-mlflow-1.0.0\/lib\/python3.6\/site-packages\/click\/core.py\", line 1066, in invoke\r\nreturn ctx.invoke(self.callback, **ctx.params)\r\nFile \"\/home\/ealiasbi\/.conda\/envs\/r-mlflow-1.0.0\/lib\/python3.6\/site-packages\/click\/core.py\", line 610, in invoke\r\nreturn callback(*args, **kwargs)\r\nFile \"\/home\/ealiasbi\/.conda\/envs\/r-mlflow-1.0.0\/lib\/python3.6\/site-packages\/mlflow\/store\/cli.py\", line 62, in log_artifacts\r\nartifact_uri = store.get_run(run_id).info.artifact_uri\r\nFile \"\/home\/ealiasbi\/.conda\/envs\/r-mlflow-1.0.0\/lib\/python3.6\/site-packages\/mlflow\/store\/file_store.py\", line 380, in get_run\r\nrun_info = self._get_run_info(run_id)\r\nFile \"\/home\/ealiasbi\/.conda\/envs\/r-mlflow-1.0.0\/lib\/python3.6\/site-packages\/mlflow\/store\/file_store.py\", line 396, in _get_run_info\r\ndatabricks_pb2.RESOURCE_DOES_NOT_EXIST)\r\nmlflow.exceptions.MlflowException: Run '61f82e624abe44d094dccb320e22a3aa' not found\r\n```\r\n-  issue with \"mlflow_log_artifact\"\r\n\r\n```Error in UseMethod(\"mlflow_id\") :\r\nno applicable method for 'mlflow_id' applied to an object of class \"c('tbl_df', 'tbl', 'data.frame')\"\r\n```\r\n\r\nBelow is the code and calls to MLFLOW server using R APIs listed here https:\/\/www.mlflow.org\/docs\/latest\/R-api.html#mlflow-log-artifact\r\n \r\n```Sys.setenv(PATH=paste0('\/opt\/conda\/bin:', Sys.getenv('PATH')))\r\nlibrary(reticulate)\r\nuse_condaenv('mlflowtest4')\r\n#mlflow::install_mlflow()\r\nlibrary(mlflow)\r\nlibrary(glmnet)\r\nlibrary(carrier)\r\n# install_mlflow()\r\nclient <- mlflow_client(tracking_uri = \"https:\/\/XXXX:4443\")\r\nmlflow_client(tracking_uri = \"https:\/\/XXXXXX:4443\")\r\nmlflow_create_experiment(\"bicky\/test_example66\", artifact_location = '\/home\/ealiasbi\/mlflow', client = client)\r\nwith(mlflow_start_run(),{\r\nrun1= mlflow_start_run(experiment_id=51,client=client)\r\nmlflow_log_param(\"parameter\", 5, run_id=run1$run_uuid, client=client)\r\nmlflow_log_metric(\"metric\", 0, run_id=run1$run_uuid, client=client)\r\nmlflow_log_artifact(\"wine-quality.csv\", artifact_path = '\/home\/ealiasbi\/mflow\/wine-quality.csv', run_id = run1$run_uuid, client = client)\r\n})\r\n```\r\n","674":"**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community <-- willing to help review contributions here!\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n[TorchServe](https:\/\/pytorch.org\/serve\/) provides a convenient REST API for deploying Pytorch models and managing deployments. We should make it easy to deploy Pytorch models logged using MLflow to a TorchServe server.\r\n\r\n## Motivation\r\n\r\nWhile it's currently possible to locally deploy Pytorch models using `mlflow models serve`, TorchServe contains a number of additional useful features when deploying Pytorch models, e.g. [instrumentation](https:\/\/pytorch.org\/serve\/metrics.html) on request success\/error rates, configurable access logs, inference endpoints for different versions of a model, etc.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n\r\n### Proposed Solutions\r\nThere are at least two high-level approaches.\r\n\r\n1. Use MLflow's pluggable [`mlflow.deployments` interface](https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.deployments.html#module-mlflow.deployments) for defining model-deployment logic to targets like Sagemaker, AzureML, etc\r\n2. Update `mlflow model serve` to delegate to TorchServe when serving a PyTorch model.\r\n\r\nNote that these approaches  are not mutually exclusive (i.e. we could do both) -  it'd be great for `mlflow models serve` to locally-serve Pytorch models in the recommended\/most-efficient way, and it would also be great to enable users to deploy models to a remote TorchServe server for the reasons above^.\r\n\r\n#### Approach 1: Write a deployment plugin for local\/remote deployment to TorchServe\r\nIn option 1, we'd write a deployment plugin [as described in the docs](https:\/\/mlflow.org\/docs\/latest\/plugins.html#writing-your-own-mlflow-plugins), so that users could deploy\/score PyTorch models with TorchServe via commands like:\r\n\r\n```\r\n# Deploy to local TorchServe server to test out model\r\nmlflow deployments run-local --target torchserve  --name spamclassifier --model-uri s3:\/my\/spam\/classifier\r\n# Deploy model to remote server\r\nmlflow deployments create --target torchserve  --name spamclassifier --model-uri s3:\/my\/spam\/classifier\r\n# Perform inference using our remote-deployed model endpoint\r\nmlflow deployments predict --target torchserve --name spamclassifier -f emails.json\r\n# Delete our remote endpoint\r\nmlflow deployments delete  --target torchserve --name spamclassifier\r\n```\r\n\r\n#### Option 2: Make `mlflow models serve` delegate to TorchServe when locally serving a PyTorch model\r\nIn option 2, we'd define and [register](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/models\/flavor_backend_registry.py) a new PytorchFlavorBackend defining a custom `serve` method that delegates to TorchServe when serving MLflow models via `mlflow models serve`, if TorchServe is installed locally. The PytorchFlavorBackend would implement this [FlavorBackend interface](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/pyfunc\/backend.py), and could generally extend the existing [PyfuncBackend implementation](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/pyfunc\/backend.py) with custom behavior for `serve`\r\n\r\n\r\n#### Observations\r\nOne apparent challenge with option 2 is that the TorchServe inference endpoint (POST to `\/predictions\/<model-name>`, see [docs](https:\/\/pytorch.org\/serve\/inference_api.html#id3)) and the endpoint exposed by `mlflow models serve` (POST to `\/invocations`, [see docs](https:\/\/mlflow.org\/docs\/latest\/cli.html#mlflow-models-serve)) are different. The expected input formats are also different - MLflow expects JSON-serialized records in pandas split or record-oriented formats, while TorchServe seems to support more general binary input (e.g. a jpg)","675":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: WSL 2, Ubuntu 16.04\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.9.0\r\n- **Python version**: 3.7.1\r\n\r\n### Describe the problem\r\nWhen running the docker example from mlflow\/examples\/docker in kubernetes it fails with the following error:\r\n![image](https:\/\/user-images.githubusercontent.com\/29867749\/86822429-87cf9b00-c083-11ea-83e8-894659910b85.png)\r\n\r\nInspecting the logs I get this error message:\r\n![image](https:\/\/user-images.githubusercontent.com\/29867749\/86822562-b2215880-c083-11ea-862e-47cfced357aa.png)\r\n\r\nHaving done some investigation, this seems to be due to the environment variable MLFLOW_RUN_ID being set at some point in the creation of the docker image from the base docker_env image. You can see this is the case by adding os.environ[\"MLFLOW_RUN_ID\"] = \"\"  before the mlflow.start_run() line in the train.py file. Doing so completes the run without any issues as per the screenshot below:\r\n![image](https:\/\/user-images.githubusercontent.com\/29867749\/86822075-10017080-c083-11ea-84b2-10e63002a1a5.png)\r\n\r\nNote that I get the same error with the mlflow\/python version specified in the original docker example and when I updated it to use the latest mlflow version (see Dockerfile attached).\r\n[Dockerfile.txt](https:\/\/github.com\/mlflow\/mlflow\/files\/4886458\/Dockerfile.txt)\r\n\r\nI've looked through the code to try to figure out where this is happening and how to fix it but no success so far. I'm happy to submit a bug fix with some help from the mlflow community.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ x] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n","676":"## What changes are proposed in this pull request?\r\nThe change allows for the user to only delete an experiment if there is more than one experiment. This is the fix to the issue number #2690.\r\n\r\n## How is this patch tested?\r\nThis patch was tested by creating a second experiment and being able to delete it. When trying to delete the default experiment, we get an error saying the experiment cannot be deleted.\r\n\r\n## Release Notes\r\nDon't allow user to delete the last experiment.\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nThe change allows for the user to only delete an experiment if there is more than one experiment. This is the fix to the issue number #2690.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","677":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\n\r\nTitle says pretty much everything: it is not visible which version of MLFlow is actually running. The pointer to the documentation should also go towards the proper version instead of 'latest' since there are regularly API changes.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\npoint to the correct documentation, easy check that an upgrade was succesful, ...\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\nNA\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nNA\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nNA\r\n\r\nyou need to go where the MLFlow UI is running and check manually which version is running\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","678":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary \/ Motivation\r\n\r\nWe store model fit plots (rendered as HTML) as artifacts. Sometimes these plots don't fit into the artifacts viewer (> 500px in height) in which case you need to scroll vertically, which makes for a bad user experience. It would be great if we could just increase the height of the artifacts viewer or make the height adjustable.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n\r\nPieces of code that govern the height of the (HTML) artifacts viewer at this point: [here](https:\/\/github.com\/mlflow\/mlflow\/blob\/9ec25f157a548fa8e60ee13e3be5c3d2d513a3d5\/mlflow\/server\/js\/src\/experiment-tracking\/components\/ArtifactView.css#L2), [here](https:\/\/github.com\/mlflow\/mlflow\/blob\/9ec25f157a548fa8e60ee13e3be5c3d2d513a3d5\/mlflow\/server\/js\/src\/experiment-tracking\/components\/ArtifactView.css#L56), [here](https:\/\/github.com\/mlflow\/mlflow\/blob\/9ec25f157a548fa8e60ee13e3be5c3d2d513a3d5\/mlflow\/server\/js\/src\/experiment-tracking\/components\/ArtifactView.js#L286), [here](https:\/\/github.com\/mlflow\/mlflow\/blob\/0f7393ec90745864b2beba9f91f684647c10e99d\/mlflow\/server\/js\/src\/experiment-tracking\/components\/artifact-view-components\/ShowArtifactHtmlView.js#L57)\r\n\r\nThe height of text areas can already be adjusted on the fly (within the bounds of the artifact viewer) via `resize: vertical`. Doing the same thing for the entire artifacts viewer is not quite as straightforward, because of all the places where the height is hardwired. And because it's difficult to extend the size of a box at the bottom of the screen (there's not much room for maneuver).","679":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n[Hydra](http:\/\/hydra.cc\/docs\/intro\/) is great for config management and I guess some helper functions to automatically track hyper logged parameters could be pretty useful.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [x ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n\r\nI suppose we could just implement a decorator function that can be used alongside hyrda's.\r\n","680":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04.3 LTS\r\n- **MLflow installed from (source or binary)**: from pip\r\n- **MLflow version (run ``mlflow --version``)**: mlflow, version 1.9.1\r\n- **Python version**: Python 3.7.7\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\nWhen using `mlflow.keras.log_model` with a keras model, I get the following error:\r\n\r\n```\r\n2020\/07\/01 14:49:45 ERROR mlflow.utils.rest_utils: API request to http:\/\/0.0.0.0:8765\/api\/2.0\/mlflow\/runs\/log-model failed with code 500 != 200, retrying up to 2 more times. API response body: {\"error_code\": \"INTERNAL_ERROR\", \"message\": \"Tag value '[{\\\"run_id\\\": \\\"862b8c024cf44623bca2c266f71519a1\\\", \\\"artifact_path\\\": \\\"best_model\\\", \\\"utc_time_created\\\": \\\"2020-07-01 14:47:40.934320\\\", \\\"flavors\\\": {\\\"keras\\\": {\\\"keras_module\\\": \\\"tensorflow.keras\\\", \\\"keras_version\\\": \\\"2.3.0-tf\\\", \\\"data\\\": \\\"data\\\"}, \\\"python_function\\\"' had length 5280, which exceeded length limit of 5000\"}\r\n2020\/07\/01 14:49:48 ERROR mlflow.utils.rest_utils: API request to http:\/\/0.0.0.0:8765\/api\/2.0\/mlflow\/runs\/log-model failed with code 500 != 200, retrying up to 1 more times. API response body: {\"error_code\": \"INTERNAL_ERROR\", \"message\": \"Tag value '[{\\\"run_id\\\": \\\"862b8c024cf44623bca2c266f71519a1\\\", \\\"artifact_path\\\": \\\"best_model\\\", \\\"utc_time_created\\\": \\\"2020-07-01 14:47:40.934320\\\", \\\"flavors\\\": {\\\"keras\\\": {\\\"keras_module\\\": \\\"tensorflow.keras\\\", \\\"keras_version\\\": \\\"2.3.0-tf\\\", \\\"data\\\": \\\"data\\\"}, \\\"python_function\\\"' had length 5280, which exceeded length limit of 5000\"}\r\n2020\/07\/01 14:49:51 ERROR mlflow.utils.rest_utils: API request to http:\/\/0.0.0.0:8765\/api\/2.0\/mlflow\/runs\/log-model failed with code 500 != 200, retrying up to 0 more times. API response body: {\"error_code\": \"INTERNAL_ERROR\", \"message\": \"Tag value '[{\\\"run_id\\\": \\\"862b8c024cf44623bca2c266f71519a1\\\", \\\"artifact_path\\\": \\\"best_model\\\", \\\"utc_time_created\\\": \\\"2020-07-01 14:47:40.934320\\\", \\\"flavors\\\": {\\\"keras\\\": {\\\"keras_module\\\": \\\"tensorflow.keras\\\", \\\"keras_version\\\": \\\"2.3.0-tf\\\", \\\"data\\\": \\\"data\\\"}, \\\"python_function\\\"' had length 5280, which exceeded length limit of 5000\"}\r\n2020\/07\/01 14:49:54 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under \/data\/mlflow-artifacts\/0\/862b8c024cf44623bca2c266f71519a1\/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the  tracking store. If logging to a mlflow server via REST, consider  upgrading the server version to MLflow 1.7.0 or above.\r\n```\r\n\r\nI run this function at every epoch in a keras callback. What is surprising it that I only get the error after several epochs. The first few times the model is saved without errors.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nRun mlflow server:\r\n```\r\nmlflow server -h 0.0.0.0 -p 8765 --backend-store-uri sqlite:\/\/\/\/data\/mlflow.db --default-artifact-root \/data\/mlflow-artifacts\/\r\n```\r\n\r\nCode (simple keras model on mnist):\r\n\r\n```python\r\nimport mlflow\r\nimport mlflow.keras\r\nimport mlflow.tensorflow\r\n\r\nimport numpy as np\r\nimport tensorflow\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense, Dropout\r\nfrom tensorflow.keras.optimizers import RMSprop\r\n\r\nmlflow.set_tracking_uri('http:\/\/0.0.0.0:8765')\r\n\r\n# -------------------------------------\r\n# Used to save the model after each epoch\r\n\r\nclass MlFlowModelCheckpoint(tensorflow.keras.callbacks.ModelCheckpoint):\r\n    def __init__(self, artifact_name, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        self.artifact_name = artifact_name\r\n\r\n    def _save_model(self, epoch, logs):\r\n        super()._save_model(epoch, logs)\r\n        mlflow.keras.log_model(self.model, self.artifact_name)\r\n\r\nmodel_checkpoint_callback = MlFlowModelCheckpoint(\r\n    artifact_name='best_model',\r\n    filepath='\/data\/checkpoints\/best_model.h5',\r\n    save_weights_only=False,\r\n    monitor='val_loss',\r\n    mode='min',\r\n    save_best_only=True)\r\n\r\n# -----------------------------------\r\n\r\nparams = dict(\r\n    batch_size = 128,\r\n    num_classes = 10,\r\n    epochs = 200,\r\n)\r\n\r\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\r\nx_train = x_train.reshape(60000, 784)\r\nx_test = x_test.reshape(10000, 784)\r\nx_train = x_train.astype('float32')\r\nx_test = x_test.astype('float32')\r\nx_train \/= 255\r\nx_test \/= 255\r\ny_train = tf.keras.utils.to_categorical(y_train, params['num_classes'])\r\ny_test = tf.keras.utils.to_categorical(y_test, params['num_classes'])\r\n\r\ndef make_model():\r\n    model = Sequential()\r\n    model.add(Dense(512, activation='relu', input_shape=(784,)))\r\n    model.add(Dropout(0.2))\r\n    model.add(Dense(512, activation='relu'))\r\n    model.add(Dropout(0.2))\r\n    model.add(Dense(params['num_classes'], activation='softmax'))\r\n    return model\r\n\r\n\r\nwith mlflow.start_run(run_name='mnist_keras_tutorial') as run:\r\n    mlflow.tensorflow.autolog(\r\n        every_n_iter=1\r\n    )\r\n    \r\n    model = make_model()\r\n    model.compile(loss='categorical_crossentropy',\r\n              optimizer=tf.keras.optimizers.SGD(\r\n                learning_rate=0.00001,\r\n              ),\r\n              metrics=['accuracy'])\r\n    \r\n    history = model.fit(\r\n        x_train,\r\n        y_train,\r\n        batch_size=params['batch_size'],\r\n        epochs=params['epochs'],\r\n        verbose=1,\r\n        validation_data=(x_test, y_test),\r\n        callbacks=[model_checkpoint_callback],\r\n    )\r\n```\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [?] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [?] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n","681":"Hello,\r\n\r\ni am not sure if this is considered a feature request or a bug, but this might be an particular issue based on the way I use mlflow.\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nChanges in mlflow 1.9 make it impossible to access the model context of a model saved and loaded using the pyfunc api directly.\r\n\r\nAn working example in mlflow 1.8 example would be \r\n```\r\nmodel = mlflow.pyfunc.load_model(package_folder)\r\n\r\n# Load package metadata\r\nwith open(model.context.artifacts[\"meta\"], 'rb') as handle:\r\n    meta = pickle.load(handle\r\n```\r\n\r\nSince mlflow 1.9 this is not possible anymore, as the object returned by mlflow.pyfunc.load_model() is not an instance of _PythonModelPyfuncWrapper anymore, but wrapped by a call of PyFuncModel.\r\n\r\nIn mlflow 1.8:\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/cf3b4e190612add14df99bb1036f1b5bfe775ba6\/mlflow\/pyfunc\/__init__.py#L296-L297\r\n\r\nIn mlflow 1.9:\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/29d61687b378dcb06154df4c4750bbe6cf1081bb\/mlflow\/pyfunc\/__init__.py#L465-L467\r\n\r\nFor mlflow >= 1.9 my current work around is to use the **_model_impl** reference as a helper.\r\n```\r\nmodel._model_impl.context\r\n```\r\n\r\nAm I abusing the API; I mean is this not the way to access meata information packaged with a model? \r\nI have a simple example [here](https:\/\/github.com\/mapa17\/air-de-jeux\/blob\/master\/mlflow\/pack.py)\r\n\r\nIf this is not good practise, one should obviously discard this issue.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n","682":"## What changes are proposed in this pull request?\r\n\r\nLogging multiple metrics via log_batch takes very long when using SQLAlchemy storage (as described here #3010). \r\n\r\nWith this pr, metrics are added batch-wise. In this way, only one session is opened which saved a lot of time. Additionally, storing the latest metrics is performed once at the end, so that only one database write is necessary.\r\n\r\nIt should be noted that metrics with the same run-id, step, timestamp, and value should be added only once. I assume that this conflict happens not that often. The check has originally been performed when adding the metric. However, it has turned out that this can be speed up by adding all metrics and catching possible integrity errors. If an integrity error appears, the metrics will be added in the slower mode (on after another).\r\n\r\nInserting 1000 new metrics now takes about 0.2 seconds instead of 9 seconds. If some metrics are duplicated, it takes about 2 seconds in the slower mode.\r\n\r\n## How is this patch tested?\r\n\r\nCovered by unit tests.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [x] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","683":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [X] Yes. I can contribute this feature independently.\r\n- [X] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nThe actual version of mlflow is heavily dependent on conda package, on the other hand the use of the default pip package is widely used by the community. Therefore, the native support to pip will encourage a lot of users that do not use the conda package to start using mlflow.\r\n\r\n## Motivation\r\n- What is the use case for this feature? Use of mlflow without needing to use conda environments.\r\n- Why is this use case valuable to support for MLflow users in general? It will allow to non-conda users to use features from mlflow without workarounds (like serve models).\r\n- Why is this use case valuable to support for your project(s) or organization? It will become a standard to use mlflow since we do not use conda.\r\n- Why is it currently difficult to achieve this use case? The user needs to install manually all the packages from a requirements.txt file, this process can be automated with the proposed feature.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [X] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n\r\nThe proposed feature request can be done by adding a new flag on MLproject files indicating the filename which contains all packages and their versions (pip freeze output). Then the mlflow can install those packages in the current environment, or create a local environment.\r\n","684":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [X] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nIn the Registered Models summary web page and the individual registered model's pages, it would be nice to be able to filter on or sort by model stage. For example, in the summary if I wanted to see all production models I could click on the Production column and only Production models would be shown (or shown first). Name and Last Modified already are sortable. Similarly for each model there is the ability to select \"Active\", but more fine grained filtering\/sorting would be nice\r\n\r\n## Motivation\r\n- What is the use case for this feature? Seeing at a glance all models in a stage\r\n- Why is this use case valuable to support for MLflow users in general? As you have more registered models, it becomes difficult to track which ones are in which stage (this affects this issue too: https:\/\/github.com\/mlflow\/mlflow\/issues\/3017).\r\n- Why is this use case valuable to support for your project(s) or organization? We have a lot of registered models in various stages. It would be helpful to be able to better see which ones are in each stage all at once.\r\n- Why is it currently difficult to achieve this use case? Pagination plus the lack of filter\/sort causes many clicks to determine the state of the system.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [X] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n\r\n","685":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [X] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nSubscription service for model registry changes. To use MLflow to drive deployment, we're currently querying MLflow periodically to determine if new versions were promoted to a different stage. It would probably be cleaner and simpler to register with MLflow and listen to an event stream (pub sub model).\r\n\r\n## Motivation\r\n- What is the use case for this feature? Automated model deployment. MLflow drives another system.\r\n- Why is this use case valuable to support for MLflow users in general? As MLflow is used more, the ability for it to easily interface with a production environment would be useful. Event based notifications are cleaner than time based querying with diff calculations.\r\n- Why is this use case valuable to support for your project(s) or organization? We currently query all registered models, filter them down to the ones we care about for each environment, and then compute what the diffs are from what is stored in the deployment environment.\r\n- Why is it currently difficult to achieve this use case? I wouldn't classify it as difficult, just non-optimal and requiring more code to interface with MLflow.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n\r\n","686":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS\r\n- **MLflow installed from (source or binary)**: No\r\n- **MLflow version (run ``mlflow --version``)**:1.9.1\r\n- **Python version**: 3.7.4\r\n- **npm version, if running the dev UI**: 6.14.4\r\n- **Exact command to reproduce**: `mlflow sagemaker build-and-push-container`\r\n\r\n### Describe the problem\r\nThere is an issue when trying to push the docker image to AWS ECR. It tries to run the command `$(aws ecr get-login --no-include-email)` but the operation `get-login`  is not available on [aws-cli V2](https:\/\/awscli.amazonaws.com\/v2\/documentation\/api\/latest\/reference\/ecr\/index.html), only in [aws cli V1](https:\/\/docs.aws.amazon.com\/cli\/latest\/reference\/ecr\/index.html)\r\n\r\n### Code to reproduce issue\r\n- Verify aws-cli has version >= 2\r\n- Run `mlflow sagemaker build-and-push-container`\r\n\r\n### Other info \/ logs\r\n```\r\n2020\/06\/28 14:50:40 INFO mlflow.sagemaker: Pushing image to ECR\r\n2020\/06\/28 14:50:40 INFO mlflow.sagemaker: Pushing docker image mlflow-pyfunc to xxxxxxxxxxx.dkr.ecr.us-west-1.amazonaws.com\/mlflow-pyfunc:1.9.1\r\nCreated new ECR repository: mlflow-pyfunc\r\n2020\/06\/28 14:50:42 INFO mlflow.sagemaker: Executing: $(aws ecr get-login --no-include-email);\r\ndocker tag mlflow-pyfunc xxxxxxxxxxx.dkr.ecr.us-west-1.amazonaws.com\/mlflow-pyfunc:1.9.1;\r\ndocker push xxxxxxxxxxx.dkr.ecr.us-west-1.amazonaws.com\/mlflow-pyfunc:1.9.1\r\nusage: aws [options] <command> <subcommand> [<subcommand> ...] [parameters]\r\nTo see help text, you can run:\r\n\r\n  aws help\r\n  aws <command> help\r\n  aws <command> <subcommand> help\r\naws: error: argument operation: Invalid choice, valid choices are:\r\n\r\nbatch-check-layer-availability           | batch-delete-image                      \r\nbatch-get-image                          | complete-layer-upload                   \r\ncreate-repository                        | delete-lifecycle-policy                 \r\ndelete-repository                        | delete-repository-policy                \r\ndescribe-image-scan-findings             | describe-images                         \r\ndescribe-repositories                    | get-authorization-token                 \r\nget-download-url-for-layer               | get-lifecycle-policy                    \r\nget-lifecycle-policy-preview             | get-repository-policy                   \r\ninitiate-layer-upload                    | list-images                             \r\nlist-tags-for-resource                   | put-image                               \r\nput-image-scanning-configuration         | put-image-tag-mutability                \r\nput-lifecycle-policy                     | set-repository-policy                   \r\nstart-image-scan                         | start-lifecycle-policy-preview          \r\ntag-resource                             | untag-resource                          \r\nupload-layer-part                        | get-login-password                      \r\nwait                                     | help                      `\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [x] `integrations\/sagemaker`: SageMaker integrations\r\n","687":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [X] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nI have launched MLFlow using a custom MLFlow operator which deploys a bunch of \"instances\" of MLFlow via kustomize. In order to provide a rough multi-tenancy all instances of MLFlow are behind Istio + Envoy using https:\/\/github.com\/ibm-cloud-security\/app-identity-and-access-adapter which works great. Now for each of the instances I can pass an Active Directory group (or other headers) and only that group will get access to a particular instance. The problem is when I want to grant programmatic access to an instance via say a jupyter notebook in kubeflow. \r\n\r\nI have this working in curl but unsure how this would work with the mlflow python sdk. I did notice that Azure Databricks does similar things and expects a header to be present so wondering if MLFlow would consider the ability to pass custom headers when it makes a request? The following is a successful curl command and just curious how could make this work with the MLFlow python sdk?\r\n\r\n```sh\r\ncurl -v --cookie \"oidc-cookie-XXXXX-XXXXX-XXXXX=XXXXXXXXXX\" https:\/\/mlflow-sample.example.ca\/api\/2.0\/preview\/mlflow\/experiments\/list\r\n```\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","688":"\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nLogging multiple metrics via log_batch takes very long when using SQLAlchemy storage. I did some experiments using a mysql database. For logging 1000 metrics it takes about 9 seconds on average (on a Intel(R) Core(TM) i7-7820X CPU @ 3.60GHz). The sample code is attached at the end.\r\n\r\nThe reason that the function is very slow is that each metric entry is handled individually. I think this can be speed up by introducing a batch-wise processing of the data. I did some tests and was able to speed up the processing to 2 seconds (factor 4.5) e.g. by initializing the session only once and updating the latest metric at the end.\r\n\r\n With some additional improvements (batch-wise insertion of the data and checking the integrity at the end), I was able to decrease the processing time to 0.13 seconds (factor 69).\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nSpeed up logging multiple metrics via log_batch when using SQLAlchemy storage.\r\n- Why is this use case valuable to support for MLflow users in general?\r\nMakes adding metrics in batch mode much faster.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nWe developed an import to mysql storage and notices that it takes a while. \r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nA couple of initializations and checks (e.g. session or check if is running) are performed multiple times. \r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [x] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n\r\ntest script for measuring the time log_batch need for inserting 1000 data points.\r\n```python\r\nimport mlflow\r\nimport time\r\nfrom mlflow.entities import Metric\r\n\r\ndst_uri = 'mysql:\/\/mlflow:XXXXX@localhost:3306\/mlflow'\r\n\r\nmlflow.set_tracking_uri(dst_uri)\r\nclient = mlflow.tracking.MlflowClient(dst_uri)\r\n\r\nwith mlflow.start_run():\r\n\r\n    run = mlflow.active_run()\r\n    run_id = run.info.run_id\r\n    mlflow.log_param(\"test\", 12)\r\n\r\n    metrics = []\r\n    metrics = [Metric('acc', i, i, i) for i in range(1000)]\r\n\r\n    start = time.time()\r\n    client.log_batch(run_id, metrics=metrics)\r\n    end = time.time()\r\n    print(end - start)\r\n\r\n```\r\n\r\nI'm looking forward what you think and I would be happy to submit a pull request.\r\n","689":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nIdeally, `pyfunc.log_model` would directly support passing kwargs that will be included in the MLmodel file while using the loader_module paradigm. The documentation suggests that this is the existing implementation. \r\n\r\nhttps:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.pyfunc.html#mlmodel-configuration\r\n\"Optionally, any additional parameters necessary for interpreting the serialized model in pyfunc format\"\r\n\r\nThe main request here is for a change to the pyfunc module, but an update to the documentation to explain addition of custom parameters would be very helpful as well.\r\n\r\n## Motivation\r\n- What is the use case for this feature? \r\nIn general, users with varied python function models may not want to or be able to use the PythonModel option and may have additional important information for rehydrating their models that should go into the MLmodel config.\r\n- Why is this use case valuable to support for MLflow users in general? \r\nIt expands the usability of pyfunc models to a greater diversity of model serialization formats.\r\n- Why is this use case valuable to support for your project(s) or organization? \r\nWe're working on logging model evaluations, which follow a similar format to models. In particular, they are collections of artifacts with metadata that is useful for efficient deserialization.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nTo start with, `pyfunc.log_model` just doesn't take kwargs to pass along to `Model.log`. Beyond that, even if trying to use `Model.log` directly with the `python_function` flavor, `Model.log` will pass those kwargs to `pyfunc.save_model`, but `pyfunc.save_model` throws away any kwargs other than `model`.\r\n\r\n``` python\r\nmlflow_model = kwargs.pop('model', mlflow_model)\r\n    if len(kwargs) > 0:\r\n        raise TypeError(\"save_model() got unexpected keyword arguments: {}\".format(kwargs))\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n\r\nThe main proposal is to add a `**kwargs` parameter to `pyfunc.log_model`, which would be passed through `Model.log` to the kwargs of `pyfunc.save_model`. `pyfunc.save_model` would then pass all kwargs other than `model` through to `_save_model_with_loader_module_and_data_path` (probably to the artifact-based function as well), which would in turn pass them to `pyfunc.add_to_model`. Once given as input there, they will automatically be added to the MLmodel config by existing code.\r\n\r\nIf changing the high-usage `log_model` function is considered too risky or might cause confusion for users, a compromise would be to at least update the function signatures from `pyfunc.save_model` and lower so that the useful pyfunc internals are still accessible from `Model.log` with kwargs. This would enable lower level development but leave the most visible piece unchanged.","690":"## What changes are proposed in this pull request?\r\n\r\nMotivation: we found that using a Dockerfile to build the Docker image for our experiment runs fits our workflow better than a pulling a built image from a registry.\r\n\r\nDescription: This PR enables `mlflow run` to optionally use a Dockerfile to build the image for an experiment run. Adds a `dockerfile` field to the MLproject yaml specifying the path to the dockerfile. If both an `image` and a `dockerfile` field are specified, then we raise an exception. Also adds a test and an example in the documentation for easier reference. \r\n\r\nSince we\u2019re building an image from a Dockerfile, there\u2019s no way to tell what the desired image tag is. So, added the option to either suffix the Dockerfile name `Dockerfile.image-name` and use the suffix as the image name, or automatically name the as `image_` + the hash of the Dockerfile if no suffix exists.\r\n\r\n## How is this patch tested?\r\n\r\nAdded a test named `test_dockerfile_project_execution` under `tests\/projects\/test_docker_projects.py` to test proper building. The test is (heavily) based on `test_docker_project_execution`. The main difference is that test first generates a new MLproject based on `tests\/resources\/example_docker_project\/MLproject_dockerfile` that specifies a `dockerfile` instead of an image. Then, the rest of the regular tests continues, where the image is built and an MLflow run is performed in the spirit of the original test.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nAdd ability to build Docker image for experiment run from Dockerfile\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","691":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **MLflow installed from (source or binary)**: source \r\n- **MLflow version (run ``mlflow --version``)**: 1.8.0\r\n- **Python version**: 3.7.5\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n`export MLFLOW_TRACKING_URI=mysql+pymysql:\/\/user:pwd@ip:port\/db && mlflow run git@github.com:Janus-Xu\/R-wine.git -P r-b=1`\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\nR_wine examples\uff0cwhen I add the env MLFLOW_TRACKING_URI using SQLAlchemy database URI as Backend Stores\uff0cError happens, can't log param\u3001metric to database\r\n \r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```bash\r\nLoading required package: Matrix\r\nLoading required package: foreach\r\nLoaded glmnet 2.0-16\r\n\r\nError in new_mlflow_client.default(tracking_uri) : \r\nUnsupported scheme: 'mysql+pymysql'\r\nCalls: with ... mlflow_client -> new_mlflow_client -> new_mlflow_client.default\r\nExecution halted\r\nERROR mlflow.cli: === Run (ID '1ce4d23709804a389548da3ca89211c7') failed ===\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [x] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [x] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [x] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n","692":"## What changes are proposed in this pull request?\r\n\r\n**Note**: We should hold off on merging this PR until the release of corresponding server-side changes in early August\r\n\r\nUpdates logic for remote MLflow project execution on Databricks to not shell-escape PyPI library version lower-bounds when running projects\r\n\r\n## How is this patch tested?\r\nAdded unit tests, plus manual tests\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","693":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows10\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.9.0\r\n- **Python version**: 3.7.3\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: mlflow server --backend-store-uri \\<postgresql-uri> --default-artifact-root file:C:\/users\/\\<user>\/mlruns -h 0.0.0.0 -p 5000\r\n\r\n### Describe the problem\r\nMy simple python program **start_run**, logs some random metrics values, then creates a file and saves it locally and calls **log_artifact(local_path)** \r\nI run on pycharm - I've set env: **MLFLOW_TRACKING_URI = file:C:\/users\/\\<user>\/mlruns**\r\n\r\n1. Mlflow Postgres tables are created, **but reflects only UI changes** (e.g. adding experiment). **UI displays only experiments and runs from DB**.\r\n2. Runs are saved actually in the specified artifact dir **but not in DB!**\r\n3. **Artifacts are saved under local mlrun tree** (e.g. python working dir) and not in MLFLOW_TRACKING_URI\r\n4. If I run the server without the **--backend-store-uri** flag, I can see the runs in the UI.\r\n\r\n### Code to reproduce issue\r\n```\r\ndef my_task():\r\n    with mlflow.start_run():\r\n        mlflow.log_metric(\"m1\", 10)  # some metrics like this\r\n        # ... process file and save it to local_path\r\n        mlflow.log_artifact(local_path=local_path)\r\n\r\n```\r\nThanks in advance :-)","694":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nCurrently, there are two ways of executing an MLflow project, with conda environment created\/changed into at runtime, or without conda, where the existing environment is used. There should be a way to specify what is the conda environment that is to be specified when starting a project. The reason for this is environment creation would be by the user, while MLflow would only activate the specified environment, rather than find and try to download the packages.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n  - Suppose there are multiple MLflow projects that are to be run, each having different requirements, but can be separated into 2 environments. As of right now, using conda to run the projects would create many new environments.\r\n- Why is this use case valuable to support for MLflow users in general?\r\n  - It adds another option for the user and allows environment setup from the user side.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n  - We cannot create environments at run time. We need them to be created and also maintained using our own names prior to any execution. Also, this makes it possible to use MLflow projects without internet, with separate environments for separate projects.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n  - The only two ways of running the MLflow project is to either set use_conda as True or False. There is no way of setting which exact conda environment is to be activated.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n","695":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [x] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS 10.15.2\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.5.0\r\n- **Python version**: 3.7\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: mlflow.sklearn.log_model(lr, \"model\")\r\n\r\n### Describe the problem\r\nWhen loging any kind of supported model, `mlflow` is added as a pip dependency to the `conda.yaml`. The issue is that it is added without any fixed version, which results in the conda env having the latest `mlflow` version even if the training environment had an older one.\r\n\r\n### Code to reproduce issue\r\nAny log model function uses `_mlflow_conda_env()` which adds the version less `mlflow` pip dependency.\r\n\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/10f336a0c86cbabab3089fdfc3943884d2f807ca\/mlflow\/utils\/environment.py#L13-L14\r\n\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/10f336a0c86cbabab3089fdfc3943884d2f807ca\/mlflow\/utils\/environment.py#L31-L32\r\n\r\nfor instance, the following code\r\n\r\n```python\r\nmlflow.sklearn.log_model(lr, \"model\")\r\n```\r\n\r\nwill results in the following `conda.yaml`\r\n```yaml\r\nchannels:\r\n- defaults\r\ndependencies:\r\n- python=3.6.10\r\n- scikit-learn=0.22.1\r\n- pip:\r\n  - mlflow\r\n  - cloudpickle==1.4.1\r\nname: mlflow-env\r\n```\r\n\r\na simple fix would be to infer `mlflow` version similar to what is done with other dependencies. for instance:\r\n\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/6e60e79a593fed2ff5a08aa637a79354bee1be0e\/mlflow\/sklearn.py#L46-L49\r\n\r\n\r\n","696":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nI have logged a tensorflow model in 'savedModel' format (directory of 'assets', 'variables' and .pb file).  I have also registered this model via the 'register model' button in the tracking UI.  I would like to download this model (the entire directory of files: assets, variables, .pb file).  However, I don't see any obvious way to do this.  I don't see any download option in the model registry UI, and the download option in the tracking UI is only available for individual files.  When I select a directory, the download icon is not visible, only the 'register model' icon is available.  How can I download a logged model \/ or directory of logged artifacts?   \r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nShare logged models with other team members via downloading models from mlflow UI \r\n- Why is this use case valuable to support for MLflow users in general?\r\nI had assumed this would be basic functionality.  The mlflow UI can facilitate communication between teams (e.g. modeling & deployment).  However, if the deployment team can't download models directly from the mlflow UI, additional workflows need to be established outside of mlflow.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nThe feature is needed to support deployment of models on edge devices by specific team members who have access to these devices.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nIt is apparently not possible to download a directory of artifacts (e.g. a tensorflow savedModel) via the UI.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\nCurrent [UI implementation](https:\/\/github.com\/mlflow\/mlflow\/blob\/0f7393ec90745864b2beba9f91f684647c10e99d\/mlflow\/server\/js\/src\/experiment-tracking\/components\/ArtifactView.js#L96-L100) only renders download link if selected artifact is a file.  When you select a directory, model registry button is rendered.  But model registry doesn't support model download. \r\n","697":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","698":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nExpose OpenAPI 2.0 specs when serving model as a webservice.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nThis makes it easier to integrate deployed model webservices with other infrastructure in the business.\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n\r\nThis feature could be as specifying a `swagger.yaml` file to go with the model when it is trained, and have something like [flasgger](https:\/\/github.com\/flasgger\/flasgger) snap that up and expose it in an endpoint. It could also be a separate layer in the dockerfile that can be optional.\r\n","699":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n\r\n## Proposal Summary\r\n\r\nToday, if I execute `mlflow run .` in a directory where an `MLProject` file does *not* exist but a `main.py` file does exist, MLflow does returns an error that it cannot find the default entry point \"main\" (since no entry points are defined anywhere).\r\n\r\nThus, I have to use the entry-point flag in this case, as in `mlflow run . --entry-point main.py`. \r\n\r\nI propose that if a file named `main.py` exists and one named `MLProject` does not, then MLflow run should run `python main.py` instead of returning an error.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n\r\nThis would make it easier to use the MLflow CLI to run projects that don't want to take the relatively heavy weight step of adding an MLProject file to their source repo.\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\n\r\nThis provides an extremely light weight path for folks to make their project\/git repo a runnable entity via MLflow: just add main.py to your project, or if you already have one, you're already done.\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n\r\nI'm writing a tool that treats directories as runnable things, and I'm using MLflow to do that but I don't want to force people who use my tool to learn about MLflow in order to start using it! So I don't want to force them to add an MLProject file to their project directory, I'd rather tell them they can simply create a main.py and then MLflow (and my tool) will run their project automatically. And then I can point to the parameter handling flags as the standard way to handle passing params.\r\n\r\nThis feature lowers the friction to having many more projects become runnable by MLflow, which might spread the word and adoption of MLflow!\r\n\r\nThen, since they are already using MLflow for the default case, they can upgrade to an MLProject file + conda or docker later when they need the extra power\/flexibility of those heavier weight options (e.g., when they want to benefit from MLflow automatically creating and re-using conda envs that have their requirements installed).\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nThis isn't much code, I think it would be a few lines of code [here](https:\/\/github.com\/mlflow\/mlflow\/blob\/4f576bbcb889275fda303fe531344ff6bb160c9d\/mlflow\/projects\/_project_spec.py#L99) plus some tweaks to the docs and CLI doc strings.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n","700":"## What changes are proposed in this pull request?\r\n\r\nCheck if the locally installed AzureML SDK is dev version, if it is, use the latest published AzureML SDK as dependency.\r\n\r\n## How is this patch tested?\r\n\r\n(Details)\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [X] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","701":"I've noticed that metrics and parameters which have been autoconverted to exponential notation via https:\/\/github.com\/mlflow\/mlflow\/pull\/2022 do not sort correctly in the main experiment table view.\r\n\r\n![Screen Shot 2020-06-17 at 3 42 44 PM](https:\/\/user-images.githubusercontent.com\/10052880\/84943102-de177280-b0b1-11ea-8af7-c8aa31b95176.png)\r\n\r\nThis bug makes it difficult to sort runs by fields that typically have small decimal values like learning rate. Is there an existing solution, or is that a bug that needs to be fixed?\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.4 LTS\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: 1.7.1\r\n- **Python version**: 3.6.6\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n","702":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nProvide a Swagger file so that users can generate clients with toolks like Swagger Codegen\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n\r\nEasier for users on non-supported languages\/platforms to create clients to interface with MLFlow\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nCan't find the Swagger file in docs or inside the project\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","703":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n\r\n### System information\r\n- **Stock example script provided in MLflow: github.com\/mlflow\/mlflow\/blob\/master\/examples\/sklearn_elasticnet_wine\/train.ipynb**\r\n- **Windows 10 Enterprise**\r\n- **MLflow installed from source**\r\n- **MLflow version 1.8.0**\r\n- **Python version 3.8.3**\r\n- **jupyterlab version 2.1.4**\r\n- **No npm**\r\n- **Launch cells in train.ipynb from jupyter lab and check the source of the run wether with the UI or the API**\r\n\r\n### Describe the problem\r\nThe source is REPLACE_WITH_%CONDA_PREFIX%\\lib\\site-packages\\ipykernel_launcher.py. Moreover the Run().data.tags['mlflow.source.type'] is LOCAL and not NOTEBOOK.\r\n\r\n### Code to reproduce issue\r\nCopy github.com\/mlflow\/mlflow\/blob\/master\/examples\/sklearn_elasticnet_wine\/train.ipynb file on your computer\r\nLaunch jupyter lab in the same folder\r\nOpen train.ipynb\r\nExecute cells of train.ipynb\r\nCheck mlflow.get_run('run_id').data.tags\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n\r\nLanguage \r\n- [ ] `language\/python`: Python APIs and clients\r\n","704":"I want to execute some code or script under the artifacts folder, like when I choose some better acc runs on the web browser, and I could execute `git commit -ma \"xxx\"; git push origin`\r\n","705":"## What changes are proposed in this pull request?\r\n\r\nThis PR follows https:\/\/github.com\/mlflow\/mlflow\/pull\/2566 (introduction of execution backend). This PR encapsulates local execution and Kubernetes submission code into a class that implements the AbstractBackend interface\r\n\r\n\r\n## How is this patch tested?\r\n\r\nUnit tests\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [X] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [X] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [X] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","706":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.8.0\r\n- **Python version**: 3.7.4\r\n- **npm version, if running the dev UI**: N\/A\r\n- **Exact command to reproduce**: `mlflow sagemaker run-local -m path\/to\/model -i local_image`\r\n\r\n### Describe the problem\r\nDeploying a model using sagemaker in `run-local` mode gives the following error:\r\n\r\n```\r\nmlflow sagemaker run-local -m mlruns\/1\/770cc8a11975451c984ff9445d764b01\/artifacts\/cc-classifier\/ -i testcc\r\nUsing the python_function flavor for local serving!\r\n2020\/06\/13 18:33:12 INFO mlflow.sagemaker: launching docker image with path \/home\/kiran\/Documents\/cc-net\/mlruns\/1\/770cc8a11975451c984ff9445d764b01\/artifacts\/cc-classifier\r\n2020\/06\/13 18:33:12 INFO mlflow.sagemaker: executing: docker run -v \/home\/kiran\/Documents\/cc-net\/mlruns\/1\/770cc8a11975451c984ff9445d764b01\/artifacts\/cc-classifier:\/opt\/ml\/model\/ -p 5000:8080 -e MLFLOW_DEPLOYMENT_FLAVOR_NAME=python_function --rm testcc serve\r\ndocker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused \"exec: \\\"serve\\\": executable file not found in $PATH\": unknown.\r\n```\r\n\r\nShould the docker image I'm using handle how to execute `serve`? Can't find in the documentation what specification the docker image should have. My Dockerfile to build the local image looks like:\r\n\r\n```\r\nFROM python:3.7.4-slim\r\nRUN apt-get update && \\ \r\n    pip install azure-storage-blob==12.3.0 && \\ \r\n    pip install cloudpickle\r\nCOPY requirements.txt \/tmp\/\r\nRUN pip install --requirement \/tmp\/requirements.txt\r\n```\r\nIs there anywhere that has an end-to-end `mlflow.sagemaker` example? Thanks!\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [x] `integrations\/sagemaker`: SageMaker integrations\r\n","707":"MLflow seems to have a length limit of 5000 when setting tags (see below).\r\n\r\n``` bash\r\n[...]\r\n  File \"\/home\/smay\/miniconda3\/envs\/py38\/lib\/python3.8\/site-packages\/mlflow\/utils\/validation.py\", line 136, in _validate_length_limit\r\n    raise MlflowException(\r\nmlflow.exceptions.MlflowException: Tag value '[0.8562690322984875, 0.8544098885636596, 0.8544098885636596, 0.8544098885636596, 0.8544098885636596, 0.859181214773054, 0.86273086038245, 0.86273086038245, 0.86273086038245, 0.86273086038245, 0.86273086038245, 0.8562690322984875, 0.8544098885636596, ' had length 5276, which exceeded length limit of 5000\r\n```\r\nSince you do not want to increase this limit (see #2892). What about an option to cut the strings if they are longer then 5000 characters and just log a warning instead of throwing an exception?\r\n\r\nWhat do you think? I am willing to contribute...","708":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\nFiling this issue to enable discussion :) - happy to help contribute\/review contributions once we've settled on a solution\r\n\r\n## Proposal Summary\r\n\r\nThe current `mlflow.pytorch.log_model` API uses a custom pickle pickle module (based on cloudpickle) to save models, which can cause failures when saving certain types of models. For example, it's currently not possible to log the model in our [Pytorch example](https:\/\/github.com\/mlflow\/mlflow\/blob\/7479f3518ffaf37e656e1505372e40655e936b90\/examples\/pytorch\/mnist_tensorboard_artifact.py) (see https:\/\/github.com\/mlflow\/mlflow\/issues\/2581), which uses unpicklable APIs from the third-party tensorboardX module to log metrics.\r\n\r\nWe should investigate alternative approaches for persisting pytorch models that avoid this class of issue, e.g. new Pytorch APIs for zipfile based serialization. We might also consider recommending use of torchscript (there's WIP support for a torchscript flavor in https:\/\/github.com\/mlflow\/mlflow\/pull\/2662) for persisting torch models with MLflow\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","709":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\nMaybe. I would need to discuss with my organisation.\r\n\r\n## Proposal Summary\r\n\r\nA way to search for missing values\/NAs using the `MlflowClient().search_runs()` parameter `filter_string`.\r\n\r\n## Motivation\r\n\r\nMy use case is searching for runs completed before a parameter was added.\r\n\r\nRuns completed before adding the parameter 'my_new_param' show a '-' under 'my_new_param' in the Parameters section of the UI. I would like to search for these runs programmatically. I cannot see a way to do it using https:\/\/github.com\/mlflow\/mlflow\/blob\/4ceeb45b3a72b6ae596a017d031cfa816098986b\/mlflow\/utils\/search_utils.py I have tried using a `filter_string` containing `\"params.my_new_param = '-'\"` and `\"params.my_new_param = ''\"` but they do not seem to work.\r\n\r\nMy current workaround is to export a CSV with `mlflow experiments csv`, read it back in and filter using `isna()` from pandas.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n\r\nApologies in advance if this is already possible and I have missed it, or if my 'use case' is actually the result of a bad MLflow workflow. In either of these cases, I'd be very pleased to hear what I should be doing instead!\r\n\r\nThank you.","710":"## Willingness to contribute\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [X] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nTorch's torch.save method currently allows you to pass the model instance as the first argument, _or_ a dictionary (see picture below). This dictionary is very important when multiple training sessions are required, since it is also of interest to save epoch number and optimizer configuration (particularly when using momentum\/decay). I suggest that this functionality be extended to mlflow.pytorch.log_model() or an additional function\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/59566611\/84154067-9c912280-aa34-11ea-80cc-6b93a8216730.png)\r\n\r\n source: https:\/\/pytorch.org\/tutorials\/beginner\/saving_loading_models.html\r\n## Motivation\r\nThe primary usage of this feature would be cases where multiple training sessions are required, and it is very important to keep track of the state_dict of the optimizer as well of the model. Currently, it is _possible_ to save the optimizer state_dict locally, and use log_artifact to move it to artifact file, but it can cause local files to accumulate and it is also somewhat difficult to later reference this artifact. If model state_dicts _and_ optimizer state_dicts could be stored as a dictionary in the same place, and could be loaded with mlflow.pytorch.load_model, it would remove lots of extra steps currently required to facilitate multiple training sessions accurately. \r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\nSince what i am suggesting is similar to the functionality of a torch function, here is a link to that function. Optionally passing a dictionary to save_model() should be backwards compatible and in general make it much easier to save certain artifacts.\r\n\r\nhttps:\/\/github.com\/pytorch\/pytorch\/blob\/4ec86ca5ba273dfc350446fc469e6a840c176351\/torch\/serialization.py#L330\r\n","711":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [X] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nProvide a way to upload a run, already done in the past, and for example stored in the local  `mlrun` directory, into a tracking server.\r\n\r\n\r\n## Motivation\r\n\r\nThe local `mlruns` tracking backend is very useful when the machine (let's call it the runner) that does the run is not connected to the internet. \r\nThis happens a lot in our company, Owkin, where we work with runners in Hospitals' datacenters that are not connected to the internet for security reasons.\r\nFor the same reasons, HPC machines in our datacenter are not connected to the internet and cannot upload their results to a tracking server.\r\nHowever, in both cases we have the possibility to manually transfer files from the non-internet-connected runner back to a machine with internet access, and do some analytics on the runs.\r\n\r\nIn this context, it would be very useful to be able to upload the runs created by the runner on a common tracking server, so that results are centralized.\r\n\r\n(While in our setup it's mainly an Internet access issue, this issue can also help in other cases, like to do a migration of runs from one tracking server to another, and thus is tightly related to https:\/\/github.com\/mlflow\/mlflow\/issues\/2382)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n\r\nA way to do this is to directly copy the run directory from the local `mlrun` of the runner into the `--backend-store-uri` dir of the tracking server and then restart the server.\r\nHowever, this is problematic:\r\n\r\n* It requires to restart the server\r\n* If the tracking server uses a database, this is not possible\n* This does not take into account artifcts\r\n\r\nA must would be a command to export\/import runs in a serialized format. Something like that:\r\n\r\n```\r\n# On worker withtout internet access\r\nmlflow run export my_run -o my_run.mlflow.zip\r\n\r\n# transfer the zip file to a machine with internet access\r\n# On the machine with internet access\r\nmlflow run import -i my_run.mlflow.zip --tracking \"http:\/\/YOUR-SERVER:4040\"\r\n# Now you can see your new run on the tracking server\r\n```\r\n\r\n","712":"Is it possible to read the metrics stored in the mlflow board as a numpy array or something else? I want to perform pythonic operations on them.","713":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n(In a few sentences, provide a clear, high-level description of the feature request)\r\n\r\nI have a xgboost model with 100+ features. I keep track of feature importance (gain and weight).\r\nI use mlflow in a standalone (localhost) mode with local storage (file).\r\nI have made a minor modification in mlflow\/xgboost.py to create higher resolutions pictures.\r\nThey are stored nicely in mlruns\/*\/artifacts directories.\r\nHowever in mlflow ui, the display is tiny. It would be nice to have it using all the width of my screen. \r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nergonomics mainly\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n\r\nHere is a screenshot to explain the need\r\n![artifact feature](https:\/\/user-images.githubusercontent.com\/2387408\/83736030-624d0d00-a651-11ea-9286-ccc5b92be25b.jpg)\r\n\r\n","714":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nAccording to https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/store\/db\/db_types.py it seems that only mysql, postgreSQL, MSSQL and sqlite are supported. It would be interesting to understand what it needs to be done to add snowflake as backend.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n\r\nSnowflake is a fully managed database server where you only pay by use. It would be very beneficial for many people to offload the maintainability of the MLFlow backend server infrastructure as well as more cost efficient.\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\n\r\nFor organizations with buy over build policies this could be used as a pitch to ensure that MLflow maintainability will be minor.\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n\r\nSnowflake is our main DBMS.\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nWe have not done any test yet.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [x] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","715":"### Willingness to contribute\r\n- [x] Yes. I can contribute a fix for this bug independently.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No, except for my own repo. I did not change mlflow.\r\n- **OS Platform and Distribution**: Windows 10\r\n- **MLflow installed from**: pip\r\n- **MLflow version (run ``mlflow --version``)**: 1.8.0\r\n- **Python version**: 3.6\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: mlflow run .\r\n\r\n### Describe the problem\r\nWhen running `mlflow run .` from the root dir of my repo, I get this error traceback:\r\n\r\n```shell\r\n2020\/05\/28 13:06:01 INFO mlflow.projects: === Creating conda environment mlflow-a3b54c00d1403b3356472de25fb33ec1ac36c1a0 ===\r\nCollecting package metadata (repodata.json): failed\r\n\r\nCondaHTTPError: HTTP 000 CONNECTION FAILED for url <https:\/\/repo.anaconda.com\/pkgs\/main\/win-64\/repodata.json>\r\nElapsed: -\r\n\r\nAn HTTP error occurred when trying to retrieve this URL.\r\nHTTP errors are often intermittent, and a simple retry will get you on your way.\r\n\r\nIf your current network has https:\/\/www.anaconda.com blocked, please file\r\na support request with your network engineering team.\r\n\r\nSSLError(MaxRetryError('HTTPSConnectionPool(host=\\'repo.anaconda.com\\', port=443): Max retries exceeded with url: \/pkgs\/main\/win-64\/repodata.json (Caused by SSLError(\"Can\\'t connect to HTTPS URL because the SSL module is not available.\"))'))\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\luiz\\anaconda3\\envs\\env_chamber_detector\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"c:\\users\\luiz\\anaconda3\\envs\\env_chamber_detector\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\Luiz\\Anaconda3\\envs\\env_chamber_detector\\Scripts\\mlflow.exe\\__main__.py\", line 7, in <module>\r\n  File \"c:\\users\\luiz\\anaconda3\\envs\\env_chamber_detector\\lib\\site-packages\\click\\core.py\", line 829, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"c:\\users\\luiz\\anaconda3\\envs\\env_chamber_detector\\lib\\site-packages\\click\\core.py\", line 782, in main\r\n    rv = self.invoke(ctx)\r\n  File \"c:\\users\\luiz\\anaconda3\\envs\\env_chamber_detector\\lib\\site-packages\\click\\core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"c:\\users\\luiz\\anaconda3\\envs\\env_chamber_detector\\lib\\site-packages\\click\\core.py\", line 1066, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"c:\\users\\luiz\\anaconda3\\envs\\env_chamber_detector\\lib\\site-packages\\click\\core.py\", line 610, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"c:\\users\\luiz\\anaconda3\\envs\\env_chamber_detector\\lib\\site-packages\\mlflow\\cli.py\", line 133, in run\r\n    run_id=run_id\r\n  File \"c:\\users\\luiz\\anaconda3\\envs\\env_chamber_detector\\lib\\site-packages\\mlflow\\projects\\__init__.py\", line 291, in run\r\n    synchronous=synchronous, run_id=run_id)\r\n  File \"c:\\users\\luiz\\anaconda3\\envs\\env_chamber_detector\\lib\\site-packages\\mlflow\\projects\\__init__.py\", line 164, in _run\r\n    conda_env_name = _get_or_create_conda_env(project.conda_env_path)\r\n  File \"c:\\users\\luiz\\anaconda3\\envs\\env_chamber_detector\\lib\\site-packages\\mlflow\\projects\\__init__.py\", line 456, in _get_or_create_conda_env\r\n    conda_env_path], stream_output=True)\r\n  File \"c:\\users\\luiz\\anaconda3\\envs\\env_chamber_detector\\lib\\site-packages\\mlflow\\utils\\process.py\", line 38, in exec_cmd\r\n    raise ShellCommandException(\"Non-zero exitcode: %s\" % (exit_code))\r\nmlflow.utils.process.ShellCommandException: Non-zero exitcode: 1\r\n```\r\n\r\nThe weird thing is that conda works perfectly fine otherwise. The same command, with the same repo version works fine on my Ubuntu machine.\r\n\r\n\r\n# Solution\r\n\r\nI installed [OpenSSL for Windows](https:\/\/wiki.openssl.org\/index.php\/Binaries) and this problem was solved. \r\nI thought it would be helpful to register it here.\r\n","716":"**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: y\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 18.04 Docker\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.80\r\n- **Python version**: 3.7\r\n- **Exact command to reproduce**: Run any docker mlflow example\r\n\r\n### Describe the problem\r\nIn my Docker container I am switching the user from root to a new user called 'user'. However, MLFlow creates all folders inside the Docker container as 'root'. Hence, I run into issues like:\r\n```\r\nGPU Run Time: 62.669366121292114 seconds\r\nLogging model to mlflow...\r\nTraceback (most recent call last):\r\n  File \"mnist_pytorch.py\", line 188, in <module>\r\n    start_training()\r\n  File \"\/home\/user\/miniconda\/envs\/pytorch\/lib\/python3.7\/site-packages\/click\/core.py\", line 829, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\/home\/user\/miniconda\/envs\/pytorch\/lib\/python3.7\/site-packages\/click\/core.py\", line 782, in main\r\n    rv = self.invoke(ctx)\r\n  File \"\/home\/user\/miniconda\/envs\/pytorch\/lib\/python3.7\/site-packages\/click\/core.py\", line 1066, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\/home\/user\/miniconda\/envs\/pytorch\/lib\/python3.7\/site-packages\/click\/core.py\", line 610, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"mnist_pytorch.py\", line 175, in start_training\r\n    mlflow.pytorch.log_model(model, 'models')\r\n  File \"\/home\/user\/miniconda\/envs\/pytorch\/lib\/python3.7\/site-packages\/mlflow\/pytorch\/__init__.py\", line 158, in log_model\r\n    registered_model_name=registered_model_name, **kwargs)\r\n  File \"\/home\/user\/miniconda\/envs\/pytorch\/lib\/python3.7\/site-packages\/mlflow\/models\/__init__.py\", line 102, in log\r\n    mlflow.tracking.fluent.log_artifacts(local_path, artifact_path)\r\n  File \"\/home\/user\/miniconda\/envs\/pytorch\/lib\/python3.7\/site-packages\/mlflow\/tracking\/fluent.py\", line 323, in log_artifacts\r\n    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)\r\n  File \"\/home\/user\/miniconda\/envs\/pytorch\/lib\/python3.7\/site-packages\/mlflow\/tracking\/client.py\", line 267, in log_artifacts\r\n    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)\r\n  File \"\/home\/user\/miniconda\/envs\/pytorch\/lib\/python3.7\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 268, in log_artifacts\r\n    artifact_repo.log_artifacts(local_dir, artifact_path)\r\n  File \"\/home\/user\/miniconda\/envs\/pytorch\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact\/local_artifact_repo.py\", line 50, in log_artifacts\r\n    mkdir(artifact_dir)\r\n  File \"\/home\/user\/miniconda\/envs\/pytorch\/lib\/python3.7\/site-packages\/mlflow\/utils\/file_utils.py\", line 110, in mkdir\r\n    raise e\r\n  File \"\/home\/user\/miniconda\/envs\/pytorch\/lib\/python3.7\/site-packages\/mlflow\/utils\/file_utils.py\", line 107, in mkdir\r\n    os.makedirs(target)\r\n  File \"\/home\/user\/miniconda\/envs\/pytorch\/lib\/python3.7\/os.py\", line 223, in makedirs\r\n    mkdir(name, mode)\r\nPermissionError: [Errno 13] Permission denied: '\/home\/zeth\/PycharmProjects\/mlflow_pytorch\/mlruns\/0\/fb257ba0821147898df402a23ee214c1\/artifacts\/models'\r\n```\r\n\r\nAnd when running `ls -la`:\r\n```\r\n(pytorch) user@3aabccf058b8:\/mlflow\/projects\/code\/mlruns\/0\/fb257ba0821147898df402a23ee214c1$ ls -la\r\ntotal 32\r\ndrwxr-xr-x 6 root root 4096 Jan  1  1970 .\r\ndrwxrwxrwx 1 root root 4096 Jan  1  1970 ..\r\ndrwxr-xr-x 2 root root 4096 Jan  1  1970 artifacts\r\n-rw-r--r-- 1 root root  396 Jan  1  1970 meta.yaml\r\ndrwxr-xr-x 2 root root 4096 Jan  1  1970 metrics\r\ndrwxr-xr-x 2 root root 4096 Jan  1  1970 params\r\ndrwxr-xr-x 2 root root 4096 Jan  1  1970 tags\r\n```\r\nI can see that everything is owned by root. \r\nHowever, to my mind everything should be created and owned by the current user!\r\n\r\nIs there a workaround for this? I already made a workaround for the models subdirectory, where I just run chmod -R 777 \/mlflowruns , however, this does not work for the artifacts, since this whole directory is created at runtime at the single code line.\r\n\r\n### Code to reproduce issue\r\nAny Docker example should suffice. I can share my custom code if you need it, but it's getting complex now.\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [X] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [X] `area\/docs`: MLflow documentation pages\r\n- [X] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [X] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n","717":"## What changes are proposed in this pull request?\r\n\r\nAdd support for Gensim Flavor\r\n\r\n## How is this patch tested?\r\n\r\nUnit tests\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nModel API support Gensim\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [x ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","718":"**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nI would like the option to specify a different environment for some or all of the entry points in my mlflow project.  Currently I can only specify a single environment per mlflow project.  \r\n\r\n## Motivation\r\n- What is the use case for this feature?  \r\nI have a multi-step workflow with at least two steps: 1) data prep and 2) model training.  Both steps are fairly complex, developed by different teams, and have different overlapping dependencies.  I would like the teams to be able to manage their conda environments independently without having to reach consensus on specific versions of overlapping dependencies.\r\n- Why is this use case valuable to support for MLflow users in general?\r\nI imagine this is a common pain point in developing multi-step workflows when there are multiple developers working on different parts of the workflow.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nIt would make our ml pipeline code more modular and easier to maintain.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nBest I can tell, the only way to achieve multiple environments per entry point is to set up multiple mlflow projects for each each step.  However this makes the code more complex to understand what is going on.  I would like to specify all of my entry points in a single MLProject file.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\nAllow user to specify conda_env or docker_env within an entry point in the MLProject file. Add env member variables ('docker_env', 'conda_env_path') to EntryPoint class.  In project._run() check for entry_point env variables.  If env variables are set, override project env before launching run.\r\n\r\n```yaml\r\nname: My Project\r\n\r\nconda_env: my_env.yaml\r\n\r\nentry_points:\r\n  main:\r\n    parameters:\r\n      data_file: path\r\n      regularization: {type: float, default: 0.1}\r\n    command: \"python train.py -r {regularization} {data_file}\"\r\n  validate:\r\n    conda_env: my_validate_env.yaml\r\n    parameters:\r\n      data_file: path\r\n    command: \"python validate.py {data_file}\"\r\n```\r\n\r\n","719":"\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nAdd autologging support for [XGBoost's Scikit-Learn API](https:\/\/xgboost.readthedocs.io\/en\/latest\/python\/python_api.html#module-xgboost.sklearn)\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n\r\nMake it easy to use MLflow with the Scikit-Learn API for XGBoost.\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\n\r\nThe Scikit-Learn API for XGBoost is a popular interface for training models with XGBoost. \r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nUsers of the Scikit-Learn API for XGBoost must instrument their own logging code. The auto-logging for `xgboost.train` has extensive support for parameters, metrics, feature importance, and the logging the model. \r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n\r\nBarring technical challenges, a good contribution would have feature parity with the existing autologging support for XGBoost's `xgboost.train`. This should include all regressors and classifiers in the Scikit-Learn APIs. This may require extending the XGBoost flavor for models to also support the Scikit-Learn APIs. \r\n","720":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [X] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nTo improve the ease of execution for ML Projects, I propose that the `mlflow run` CLI and `mlflow.projects.run` APIs should introduce support for resolving projects from external storage locations (S3, Azure WASBS, FTP, etc.). This will enable users to execute projects via commands such as:\r\n\r\n```\r\n$ mlflow run s3:\/\/bucket\/path\/to\/project\r\n```\r\n\r\n```\r\nmlflow.projects.run(\"ftp:\/\/hostname\/path\/to\/project\")\r\n```\r\n\r\n## Motivation\r\n- What is the use case for this feature? This feature will enable users to execute MLprojects that are stored in various external artifactories (e.g., AWS S3, Azure WASBS, ...)\r\n- Why is this use case valuable to support for MLflow users in general? This will enable MLflow users to store \/ load their projects in cloud storage locations, providing an alternative to GitHub storage\r\n- Why is this use case valuable to support for your project(s) or organization? NA\r\n- Why is it currently difficult to achieve this use case? `mlflow run ...` and `mlflow.projects.run()` are not compatible with cloud storage locations; projects must be manually downloaded using cloud-specific APIs before they can be executed, which is somewhat burdensome\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [X] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n\r\nWe should extend automatic unzipping support to these remote artifacts as well (i.e., when the remote project is a zip archive, we should unzip it)\r\n","721":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes, \r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Arch Linux latest, but using Docker here\r\n- **MLflow installed from (source or binary)**: Docker \r\n- **MLflow version (run ``mlflow --version``)**:  latest\r\n- **Python version**: 3.7 something\r\n- **Exact command to reproduce**: mlflow run .\r\n\r\n### Describe the problem\r\n\r\nMultistep workflow with Docker runs into `mlflow.exceptions.ExecutionException: Could not find Docker executable. `.\r\nDocker is clearly installed and should be available, since the run launched successfully and even reused the cached load_raw_data. However, subsequent entrypoints run into the exception.\r\n\r\n### Code to reproduce issue\r\n\r\nhttps:\/\/github.com\/Zethson\/mlflow_custom_ms_example\r\n\r\nThis is a very slightly adapted version of the custom multistep example. Please build the Docker container as `custom_ms_example` and then simply run the project with the usual `mlflow run .`\r\nPlease be aware, that you may run into subsequent errors such as missing JAVA_HOME or something, since the container may not be complete yet, but at this point it does not get to this stage!\r\n\r\n### Other info \/ logs\r\n\r\n```\r\nzeth@master ~\/P\/custom_multistep [1]> mlflow run .                                                                                                                                     (base) \r\n2020\/05\/18 16:50:38 INFO mlflow.projects: === Building docker image multistep_example ===\r\n2020\/05\/18 16:50:54 INFO mlflow.projects: === Created directory \/tmp\/tmpxwoywhi1 for downloading remote URIs passed to arguments of type 'path' ===\r\n2020\/05\/18 16:50:54 INFO mlflow.projects: === Running command 'docker run --rm -v \/home\/zeth\/PycharmProjects\/custom_multistep\/mlruns:\/mlflow\/tmp\/mlruns -v \/home\/zeth\/PycharmProjects\/mlflow\/examples\/multistep_workflow\/mlruns\/0\/d588d7bc4a174c8bb066748faeb88c5e\/artifacts:\/home\/zeth\/PycharmProjects\/mlflow\/examples\/multistep_workflow\/mlruns\/0\/d588d7bc4a174c8bb066748faeb88c5e\/artifacts -e MLFLOW_RUN_ID=d588d7bc4a174c8bb066748faeb88c5e -e MLFLOW_TRACKING_URI=file:\/\/\/mlflow\/tmp\/mlruns -e MLFLOW_EXPERIMENT_ID=0 multistep_example:latest python main.py --als-max-iter 10 --keras-hidden-units 20 --max-row-limit 100000' in run with ID 'd588d7bc4a174c8bb066748faeb88c5e' === \r\nRun matched, but has a different source version, so skipping (found=142abbbd6dbc3a9879854f8356f2d7e7d3270729, expected=None)\r\nNo matching run has been found.\r\nFound existing run for entrypoint=load_raw_data and parameters={}\r\nLaunching new run for entrypoint=etl_data and parameters={'ratings_csv': 'file:\/\/\/home\/zeth\/PycharmProjects\/mlflow\/examples\/multistep_workflow\/mlruns\/0\/ed8ba88063bc4ac8acd41a6ddf5bf8b7\/artifacts\/ratings-csv-dir', 'max_row_limit': 100000}\r\nTraceback (most recent call last):\r\n  File \"\/opt\/conda\/envs\/multistep\/lib\/python3.7\/site-packages\/mlflow\/projects\/__init__.py\", line 700, in _validate_docker_installation\r\n    process.exec_cmd([docker_path, \"--help\"], throw_on_error=False)\r\n  File \"\/opt\/conda\/envs\/multistep\/lib\/python3.7\/site-packages\/mlflow\/utils\/process.py\", line 43, in exec_cmd\r\n    cwd=cwd, universal_newlines=True, **kwargs)\r\n  File \"\/opt\/conda\/envs\/multistep\/lib\/python3.7\/subprocess.py\", line 800, in __init__\r\n    restore_signals, start_new_session)\r\n  File \"\/opt\/conda\/envs\/multistep\/lib\/python3.7\/subprocess.py\", line 1551, in _execute_child\r\n    raise child_exception_type(errno_num, err_msg, err_filename)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'docker': 'docker'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 105, in <module>\r\n    workflow()\r\n  File \"\/opt\/conda\/envs\/multistep\/lib\/python3.7\/site-packages\/click\/core.py\", line 829, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\/opt\/conda\/envs\/multistep\/lib\/python3.7\/site-packages\/click\/core.py\", line 782, in main\r\n    rv = self.invoke(ctx)\r\n  File \"\/opt\/conda\/envs\/multistep\/lib\/python3.7\/site-packages\/click\/core.py\", line 1066, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\/opt\/conda\/envs\/multistep\/lib\/python3.7\/site-packages\/click\/core.py\", line 610, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"main.py\", line 86, in workflow\r\n    git_commit)\r\n  File \"main.py\", line 67, in _get_or_run\r\n    submitted_run = mlflow.run(\".\", entrypoint, parameters=parameters)\r\n  File \"\/opt\/conda\/envs\/multistep\/lib\/python3.7\/site-packages\/mlflow\/projects\/__init__.py\", line 291, in run\r\n    synchronous=synchronous, run_id=run_id)\r\n  File \"\/opt\/conda\/envs\/multistep\/lib\/python3.7\/site-packages\/mlflow\/projects\/__init__.py\", line 150, in _run\r\n    _validate_docker_installation()\r\n  File \"\/opt\/conda\/envs\/multistep\/lib\/python3.7\/site-packages\/mlflow\/projects\/__init__.py\", line 702, in _validate_docker_installation\r\n    raise ExecutionException(\"Could not find Docker executable. \"\r\nmlflow.exceptions.ExecutionException: Could not find Docker executable. Ensure Docker is installed as per the instructions at https:\/\/docs.docker.com\/install\/overview\/.\r\n2020\/05\/18 16:50:56 ERROR mlflow.cli: === Run (ID 'd588d7bc4a174c8bb066748faeb88c5e') failed ===\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [x] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n","722":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nWould be very useful and for my use case mandatory, if both, a Conda environment and a Docker environment could be present in the project directory. The user can then pick which of the two environments to run mlflow with e.g. with flags: -with-conda or -with-docker\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n- Why is this use case valuable to support for MLflow users in general?\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nIt would allow us to build Docker containers based on the same present conda environment file. This would reduce duplicated implementation efforts. Furthermore, the user would gain the choice of which environment to run the mlflow run with. \r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [x] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n\r\nNextflow uses either flags for this (-with-conda or -with-docker) or predefined profiles for conda\/docker\/singularity environments such as -profile docker or -profile conda (they define run time parameters, which is another feature I would love to already have as configuration in the MLproject file, but that's another story)\r\n","723":"## What changes are proposed in this pull request?\r\n\r\n in spark 3.0, StructType return is added for pandas udf, this pr make a new feature, add support for StructType return in spark_udf\r\n\r\n## How is this patch tested?\r\n\r\nI tested it manually.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","724":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nWe can deployment model by command line `mlflow models serve [OPTIONS: --model-uri, --host, --port, --workers, --no-conda]`. We can't use raw gunicorn option like `--config`, so `access.log` or `error.log` can't be seen if we want.\r\n\r\n## Motivation\r\nI found out `mlflow models serve` use gunicorn to create models service in linux. Howere the options for users is limited. When I request the models service by api, I can't see access.log or error.log in  models service. If the `--config FILE` options is supported , we can define own 's gunicorn option more flexible.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n- add command line mlflow modes serve option\uff0cWhen use mlflow models serve --help`--config`option describe\uff1a\r\n ` -c, --config FILE    The Gunicorn config file is a .py file (default: None).\r\n                       You'd better add the file by absolute root. What can\r\n                       you write in this file reference:\r\n                       https:\/\/www.jianshu.com\/p\/260f18aa5462. This option has\r\n                       higher priority than any other gunicorn option.`\r\n- We contribute the raw gunicorn option to users. how to use gunicorn option, check the reference in gunicorn official website.\r\n- When users use config file, they can specify path of model service's log, log  format ect.\uff08fixed bug that users can't explore log, when request the  model service.\uff09\r\n\r\n","725":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution**: Darwin 18.5.0\r\n- **MLflow installed from (source or binary)**: pip install mlflow==1.8.0\r\n- **MLflow version (run ``mlflow --version``)**: 1.8.0\r\n- **Python version**: 3.7.5\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n\r\nMlflowClient.download_artifacts throws OSError if a run does not have aby artifacts. A run may often not have artifacts if an exception was thrown before it could log artifacts.\r\n\r\n### Code to reproduce issue\r\n\r\nimport mlflow\r\nclient = mlflow.tracking.MlflowClient()\r\nmlflow.set_experiment(\"test_download_artifacts\")\r\nwith mlflow.start_run() as run:\r\n    mlflow.log_param(\"version\",\"0\")\r\nlocal_path = client.download_artifacts(run.info.run_id,\"\")\r\n\r\n### Other info \/ logs\r\n```\r\nTraceback (most recent call last):\r\n  File \"test_download_artifacts.py\", line 6, in <module>\r\n    local_path = client.download_artifacts(run.info.run_id,\"\")\r\n  File \"\/Users\/andre\/miniconda3\/envs\/mlflow-examples\/lib\/python3.7\/site-packages\/mlflow\/tracking\/client.py\", line 303, in download_artifacts\r\n    return self._tracking_client.download_artifacts(run_id, path, dst_path)\r\n  File \"\/Users\/andre\/miniconda3\/envs\/mlflow-examples\/lib\/python3.7\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 301, in download_artifacts\r\n    return artifact_repo.download_artifacts(path, dst_path)\r\n  File \"\/Users\/andre\/miniconda3\/envs\/mlflow-examples\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact\/local_artifact_repo.py\", line 72, in download_artifacts\r\n    raise IOError('No such file or directory: \\'{}\\''.format(local_artifact_path))\r\nOSError: No such file or directory: '\/Users\/andre\/work\/mlflow\/server\/local_mlrun\/mlruns\/7\/7b8c4cc0c0a24a50944db9b84077803a\/artifacts\/.'\r\n```\r\n\r\n### Source code fix\r\n\r\nInstead of raising IOError, return None.\r\n\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/store\/artifact\/local_artifact_repo.py#L71\r\n```\r\n        if not os.path.exists(local_artifact_path):\r\n            raise IOError('No such file or directory: \\'{}\\''.format(local_artifact_path))\r\n```\r\n\r\nAlso update documentation to reflect this case.\r\nhttps:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.tracking.html#mlflow.tracking.MlflowClient\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n","726":"## Proposal Summary\r\n\r\nIn my work, I compare runs with large and **nested** configurations stored as python dictionaries. This results in the Run comparison page looking like this:\r\n![mlflow_comparison_nested_configs](https:\/\/user-images.githubusercontent.com\/7363758\/82066536-db4ee980-96cf-11ea-8f66-8de7663efa41.png)\r\n\r\nAs shown, the parameters that are themselves dictionaries are displayed in a single row of the table. I'm guessing this is because they are retrieved as plain strings when the page is loaded.\r\n\r\n\r\nThe visualization would be much more useful if each level of a nested configuration was displayed indented and in a new row, much like in a .yaml file. Maybe this can be done with a (recurrent) check if a param can be read as dictionary.\r\n\r\nIn case of deep nesting, there could be a fixed upper limit (e.g. 3) supported by mlflow.\r\nIdeally there would be a button in the UI, so the user can control the depth of nested params they want to see by expanding\/contracting these params.\r\n\r\nMoreover, since nested are not read as dictionaries, they are not searchable in order to filter runs.  \r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n","727":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for information on what types of issues we address.\r\n\r\n**Please fill in this documentation issue template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages documentation fix contributions. Would you or another member of your organization be willing to contribute a fix for this documentation issue to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a documentation fix independently.\r\n- [x] Yes. I would be willing to contribute a document fix with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a documentation fix at this time.\r\n\r\n### URL(s) with the issue:\r\nI'm honestly not sure where this should go\r\n\r\n### Description of proposal (what needs changing):\r\nProvide a clear description. Why is the proposed documentation better?\r\n\r\nFor python client, `pyarrow `is needed for ftp, `boto3 `for s3, etc. The dependencies are loaded at runtime in the code so it would be great to warn additional libs are needed depending on the backend you choose.","728":"## Proposal Summary\r\n\r\nMaybe this is already possible, but I cannot see how.\r\nI would like to be able to compare the metrics of runs while seeing the runs configurations. Since my runs have large (and nested) configurations, it is very tedious to go back and forth in the runs (configuration) comparison and runs metrics (comparison) page. Could these two pages be merged into one?\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n","729":"# Willingness to contribute\r\nThe MLflow Community encourages documentation fix contributions. Would you or another member of your organization be willing to contribute a fix for this documentation issue to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a documentation fix independently.\r\n- [x] Yes. I would be willing to contribute a document fix with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a documentation fix at this time.\r\n\r\n### URL(s) with the issue:\r\nSomewhere in [Tracking UI](https:\/\/mlflow.org\/docs\/latest\/tracking.html#tracking-ui)\r\n\r\n### Description of proposal (what needs changing):\r\nIt is far from being clear that, if you want to set up a remote MLFlow tracking server:\r\n- the artifact store needs to be accessible from both the client and the server\r\n- the client is the one actually pushing the artifacts to the artifact store, not the server\r\n- actual credentials for the artifact store are left for the installer to figure out. And in some cases are stored in plain text in the python code, which is not really best practice, especially if you version your code e.g. with GIT\r\n\r\nHere is a drawing of my understanding, I hope I understood things correctly\r\n![image](https:\/\/user-images.githubusercontent.com\/2760084\/82057370-86a57180-96c3-11ea-980c-11c4f351cfdc.png)\r\n","730":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Manjaro Kernel: 5.5.19-1-MANJARO\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.8.0\r\n- **Python version**: 3.8.2\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: \r\n\r\n### Describe the problem\r\nI have trained a model using `tensorflow.keras` and logged the training using `mlflow.tensorflow.autolog(every_n_iter=1)`. My training data and test data comes as `tf.Datasets`. I construct the model using the TensorFlow Functional API. The model is serialisable and I am saving it using `model.save('data\/exp-devtest\/unet.tf', save_format='tf')`. Mlflow successfully logs the model (see other info \/ logs). I noticed some irregularities while trying to load this model and predict with it.\r\nI tried the following things (see below):\r\n- using the pyfunc model to predict the data with shape (1, 3, 1)\u2192 problem: \"Must pass 2-d input\" \u2192 I guess since it expects a pandas DataFrame or similar. But this shape is not convertible to DataFrame (and I can not change that sadly...). \r\n- even if we reshape and give the pyfunc model data with shape (3, 1) \u2192 problem: the model was trained with (1, 3, 1), so we get a ValueError there.\r\n- I was actually able to load the model with `mlflow.keras.load_model()`. ~~While this works, at the same time `mlflow.keras.get_default_conda_env()` throws `ModuleNotFoundError: No module named 'keras'` - which is true, I don't have keras itself installed - but is that necessary to make this work, shouldn't `tensorflow.keras` be enough? If it is necessary, than it is confusing, that `mlflow.keras.load_model()` works.~~\r\n- could I just add a tensorflow flavour to the `MLmodel` file and load it with `mlflow.tensorflow.load_model`? Or does it actually make a difference to using `mlflow.keras.load_model` in this case, since the model class is already `<class 'tensorflow.python.keras.engine.sequential.Sequential'>`\r\n\r\n### Code to reproduce issue\r\nTrain a model\r\n```python\r\nimport sys\r\nimport mlflow\r\nimport mlflow.tensorflow\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nmlflow.tensorflow.autolog(every_n_iter=1)\r\n\r\ndata = np.array([[[5.1], [5.9], [6.9]], \r\n                 [[3.3], [3.0], [3.1]],\r\n                 [[1.7], [4.2], [5.4]],\r\n                 [[0.5], [1.5], [2.1]]])\r\nlabels = np.array([[[0], [1], [1]],\r\n                   [[1], [1], [0]],\r\n                   [[0], [1], [0]],\r\n                   [[0], [0], [1]]])\r\nprint(data.shape, labels.shape) # (4, 3, 1) (4, 3, 1)\r\n\r\ndata_tensor = tf.convert_to_tensor(value=data)\r\nlabels_tensor = tf.convert_to_tensor(value=labels)\r\nlabels_tensor = tf.cast(labels_tensor, tf.float32)\r\n\r\ndataset = tf.data.Dataset.from_tensor_slices((data_tensor, labels_tensor))\r\ndataset = dataset.shuffle(buffer_size=1000).repeat().batch(batch_size=2)\r\n\r\nmodel = tf.keras.models.Sequential([\r\n    tf.keras.layers.Dense(16, activation='relu', input_shape=(3, 1)),\r\n    tf.keras.layers.Dropout(0.2),\r\n    tf.keras.layers.Dense(3)\r\n])\r\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\r\nloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\n\r\nmodel.compile(loss=loss,\r\n              optimizer=optimizer,\r\n              metrics=['accuracy'])\r\nmodel.fit(x=x,\r\n          epochs=3,\r\n          steps_per_epoch=2)\r\n\r\nmodel.predict(data[0].reshape(1, -1, 1))\r\n# array([[[-0.9764497 , -1.236287  ,  0.59304774],\r\n#         [-1.1315356 , -1.4329386 ,  0.68833333],\r\n#         [-1.3253928 , -1.6787525 ,  0.8074404 ]]], dtype=float32)\r\n```\r\nThe model info can be seen below. We later load the model like this:\r\n```python\r\nclient = mlflow.tracking.MlflowClient(tracking_uri=mlflow.get_tracking_uri())\r\nrun_idx = 1\r\nmodel_path = client.download_artifacts(\r\n    run_id=runs.iloc[run_idx].run_id,\r\n    path='model')\r\nmodel_pyfunc = mlflow.pyfunc.load_model(model_path)\r\nprint(type(model_pyfunc)) \r\n# <class 'mlflow.keras._KerasModelWrapper'>\r\nmodel_pyfunc.predict(data[0].reshape(1, -1, 1))\r\n# ValueError: Must pass 2-d input \r\n# For log see below\r\nmodel_pyfunc.predict(data[0].reshape(-1, 1))\r\n# ValueError: Error when checking input: expected dense_2_input to have 3 dimensions, but got array with shape (3, 1)\r\n# For log see below\r\nmodel_keras = mlflow.keras.load_model(model_path)\r\nprint(type(model_keras))\r\n# <class 'tensorflow.python.keras.engine.sequential.Sequential'>\r\nmodel_keras.predict(data[0].reshape(1, -1, 1))\r\n# array([[[-0.9764497 , -1.236287  ,  0.59304774],\r\n#         [-1.1315356 , -1.4329386 ,  0.68833333],\r\n#         [-1.3253928 , -1.6787525 ,  0.8074404 ]]], dtype=float32)\r\n```\r\n\r\n### Other info \/ logs\r\nThese logs come from the test case code, which I executed on another machine - that's why the Python version is 3.7 here. But the tracebacks looked similar and I could not access the remote machine at the moment.\r\n\r\n```python\r\n>>> model.predict(data[0].reshape(1, -1, 1))\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-59-7cadbe6c606f> in <module>\r\n----> 1 model_pyfunc.predict(data[0].reshape(1, -1, 1))\r\n\r\n~\/Programme\/miniconda3\/envs\/tensorflow_env\/lib\/python3.7\/site-packages\/mlflow\/keras.py in predict(self, dataframe)\r\n    328         # In TensorFlow >= 2.0, we do not use a graph and session to predict\r\n    329         else:\r\n--> 330             predicted = pd.DataFrame(self.keras_model.predict(dataframe))\r\n    331         predicted.index = dataframe.index\r\n    332         return predicted\r\n\r\n~\/Programme\/miniconda3\/envs\/tensorflow_env\/lib\/python3.7\/site-packages\/pandas\/core\/frame.py in __init__(self, data, index, columns, dtype, copy)\r\n    438                 mgr = init_dict({data.name: data}, index, columns, dtype=dtype)\r\n    439             else:\r\n--> 440                 mgr = init_ndarray(data, index, columns, dtype=dtype, copy=copy)\r\n    441 \r\n    442         # For data is list-like, or Iterable (will consume into list)\r\n\r\n~\/Programme\/miniconda3\/envs\/tensorflow_env\/lib\/python3.7\/site-packages\/pandas\/core\/internals\/construction.py in init_ndarray(values, index, columns, dtype, copy)\r\n    169     # by definition an array here\r\n    170     # the dtypes will be coerced to a single dtype\r\n--> 171     values = prep_ndarray(values, copy=copy)\r\n    172 \r\n    173     if dtype is not None:\r\n\r\n~\/Programme\/miniconda3\/envs\/tensorflow_env\/lib\/python3.7\/site-packages\/pandas\/core\/internals\/construction.py in prep_ndarray(values, copy)\r\n    293         values = values.reshape((values.shape[0], 1))\r\n    294     elif values.ndim != 2:\r\n--> 295         raise ValueError(\"Must pass 2-d input\")\r\n    296 \r\n    297     return values\r\n\r\nValueError: Must pass 2-d input\r\n```\r\n\r\n```python\r\n>>> model_pyfunc.predict(data[0].reshape(-1, 1))\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-60-8cdf9d1f028f> in <module>\r\n----> 1 model_pyfunc.predict(data[0].reshape(-1, 1))\r\n\r\n~\/Programme\/miniconda3\/envs\/tensorflow_env\/lib\/python3.7\/site-packages\/mlflow\/keras.py in predict(self, dataframe)\r\n    328         # In TensorFlow >= 2.0, we do not use a graph and session to predict\r\n    329         else:\r\n--> 330             predicted = pd.DataFrame(self.keras_model.predict(dataframe))\r\n    331         predicted.index = dataframe.index\r\n    332         return predicted\r\n\r\n~\/Programme\/miniconda3\/envs\/tensorflow_env\/lib\/python3.7\/site-packages\/tensorflow_core\/python\/keras\/engine\/training.py in predict(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\r\n    907         max_queue_size=max_queue_size,\r\n    908         workers=workers,\r\n--> 909         use_multiprocessing=use_multiprocessing)\r\n    910 \r\n    911   def reset_metrics(self):\r\n\r\n~\/Programme\/miniconda3\/envs\/tensorflow_env\/lib\/python3.7\/site-packages\/tensorflow_core\/python\/keras\/engine\/training_arrays.py in predict(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\r\n    713     batch_size = model._validate_or_infer_batch_size(batch_size, steps, x)\r\n    714     x, _, _ = model._standardize_user_data(\r\n--> 715         x, check_steps=True, steps_name='steps', steps=steps)\r\n    716     return predict_loop(\r\n    717         model,\r\n\r\n~\/Programme\/miniconda3\/envs\/tensorflow_env\/lib\/python3.7\/site-packages\/tensorflow_core\/python\/keras\/engine\/training.py in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\r\n   2470           feed_input_shapes,\r\n   2471           check_batch_axis=False,  # Don't enforce the batch size.\r\n-> 2472           exception_prefix='input')\r\n   2473 \r\n   2474     # Get typespecs for the input data and sanitize it if necessary.\r\n\r\n~\/Programme\/miniconda3\/envs\/tensorflow_env\/lib\/python3.7\/site-packages\/tensorflow_core\/python\/keras\/engine\/training_utils.py in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)\r\n    563                            ': expected ' + names[i] + ' to have ' +\r\n    564                            str(len(shape)) + ' dimensions, but got array '\r\n--> 565                            'with shape ' + str(data_shape))\r\n    566         if not check_batch_axis:\r\n    567           data_shape = data_shape[1:]\r\n\r\nValueError: Error when checking input: expected dense_2_input to have 3 dimensions, but got array with shape (3, 1)\r\n```\r\n\r\nThese are from my 3.8.2 machine.\r\n```yaml\r\n>>> ls $model_path\r\n    conda.yaml  data\/  MLmodel\r\n\r\n>>> ls $model_path\/data\r\n    keras_module.txt  model.h5\r\n\r\n>>> cat $model_path\/MLmodel\r\n    artifact_path: model\r\n    flavors:\r\n      keras:\r\n        data: data\r\n        keras_module: tensorflow.keras\r\n        keras_version: 2.2.4-tf\r\n      python_function:\r\n        data: data\r\n        env: conda.yaml\r\n        loader_module: mlflow.keras\r\n        python_version: 3.8.2\r\n    run_id: 52764cca60c64d9bbdbf89293ef01f48\r\n    utc_time_created: '2020-05-14 14:36:15.881485'\r\n\r\n>>> cat $model_path\/conda.yaml\r\n    channels:\r\n    - defaults\r\n    dependencies:\r\n    - python=3.8.2\r\n    - pip\r\n    - pip:\r\n      - mlflow\r\n      - tensorflow==2.2.0-dev20200506\r\n    name: mlflow-env\r\n\r\n>>> cat $model_path\/data\/keras_module.txt\r\n    tensorflow.keras\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [X] `area\/docs`: MLflow documentation pages (maybe? I find little docs to N-dimensional data and wouldn't have thought that it will be a problem)\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [X] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [X] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging (maybe?)\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\nEDIT 22\/05\/20: removed the remarks regarding `mlflow.keras.get_default_conda_env(keras_module=tf.keras)` - it works, I just forgot the `keras_module` parameter.","731":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nRight now mlflow based scoring servers have a set of RESTful api endpoints that are quite generic, but for production model deployments, very often greater flexibility is required. Users may want to pass information to deployed models as well as retrieve certain types of data such as model version, or data that is very particular to certain types of use cases.\r\n\r\nMlflow right now obscures the backend flask architecture that could be used by end users to create their own API endpoints, but I was wondering if there is a set way to allow developers to create custom endpoints without replacing mlflow.\r\n\r\n\r\n## Motivation\r\n- What is the use case for this feature? Allow greater flexibility to end-users.\r\n\r\n- Why is this use case valuable to support for MLflow users in general? Passing data to things like PythonModels is currently limited to inference data (pandas dataframes and numpy arrays), but for non-inference data, engineers and software development teams expect adherence to RESTful API design patterns.\r\n\r\n- Why is this use case valuable to support for your project(s) or organization? Our organization can facilitate better communication and code reusability by communicating with deployed services using RESTful APIs.\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient) No documentation exists on how to swap out mlflow's default flask backend for something that can be modified to include additional api endpoints.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal for how to implement this feature, please include it here. For implementation guidelines, please refer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","732":"## What changes are proposed in this pull request?\r\n\r\nThis change adds a new command line option `--run-name` to provide name for run generated during project execution. Fix for https:\/\/github.com\/mlflow\/mlflow\/issues\/2804\r\n\r\n## How is this patch tested?\r\n\r\nManually\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","733":"## What changes are proposed in this pull request?\r\nQuick fix for #2824 . When checking if path is git repo ignore all paths beginning with less than two symbols followed by \":\". This is a quick fix which does not change the regex too much but allows running of projects on Windows with absolute paths.\r\n\r\n## How is this patch tested?\r\nlocally\r\n(Details)\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","734":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [x] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.7.2\r\n- **Python version**: Python 3.7.3\r\n- **npm version, if running the dev UI**: N\/A\r\n- **Exact command to reproduce**: python -c \"from mlflow import projects;projects.run('C:\\asd')\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\nGit uri regex matches absolute Windows path starting with drive (e.g. C:\\..). As a result running projects.run('C:\\...') results in the error:\r\n```\r\ngit.exc.GitCommandError: Cmd('git') failed due to: exit code(128)\r\n  cmdline: git fetch -v origin\r\n  stderr: 'fatal: 'C:\/asd' does not appear to be a git repository\r\nfatal: Could not read from remote repository.\r\n\r\nPlease make sure you have the correct access rights\r\nand the repository exists.'\r\n```\r\n\r\nThe git uri regex seemse to be too broad, matching any path containing `:`\r\n```\r\n_GIT_URI_REGEX = re.compile(r\"^[^\/]*:\")\r\n```\r\n\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\nfrom mlflow import projects\r\nprojects.run('C:\\\\asd')\r\n```\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\n>>> from mlflow import projects\r\n>>> projects.run('C:\\\\asd')\r\n2020\/05\/14 09:45:26 INFO mlflow.projects: === Fetching project from C:\\asd into C:\\Users\\USER_NAME\\AppData\\Local\\Temp\\tmpciv1cczr ===\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"D:\\miniconda3\\lib\\site-packages\\mlflow\\projects\\__init__.py\", line 288, in run\r\n    use_conda=use_conda, storage_dir=storage_dir, synchronous=synchronous, run_id=run_id)\r\n  File \"D:\\miniconda3\\lib\\site-packages\\mlflow\\projects\\__init__.py\", line 104, in _run\r\n    work_dir = _fetch_project(uri=uri, force_tempdir=False, version=version)\r\n  File \"D:\\miniconda3\\lib\\site-packages\\mlflow\\projects\\__init__.py\", line 342, in _fetch_project\r\n    _fetch_git_repo(parsed_uri, version, dst_dir)\r\n  File \"D:\\miniconda3\\lib\\site-packages\\mlflow\\projects\\__init__.py\", line 382, in _fetch_git_repo\r\n    origin.fetch()\r\n  File \"D:\\miniconda3\\lib\\site-packages\\git\\remote.py\", line 790, in fetch\r\n    res = self._get_fetch_info_from_stderr(proc, progress)\r\n  File \"D:\\miniconda3\\lib\\site-packages\\git\\remote.py\", line 674, in _get_fetch_info_from_stderr\r\n    proc.wait(stderr=stderr_text)\r\n  File \"D:\\miniconda3\\lib\\site-packages\\git\\cmd.py\", line 412, in wait\r\n    raise GitCommandError(self.args, status, errstr)\r\ngit.exc.GitCommandError: Cmd('git') failed due to: exit code(128)\r\n  cmdline: git fetch -v origin\r\n  stderr: 'fatal: 'C:\/asd' does not appear to be a git repository\r\nfatal: Could not read from remote repository.\r\n\r\nPlease make sure you have the correct access rights\r\nand the repository exists.'\r\n```\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [x] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n","735":"\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nThere's a popular community request to support running MLflow behind a reverse proxy, but it seems like there are some barriers to make that happen. This could be limitations of our documentation or actual issues within MLflow that prevent certain popular reverse proxies from working with MLflow. This feature request is to identify a popular reverse proxy, remove the barriers from using it, and document how to set it up.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n\r\nEnable teams running MLflow to run MLflow behind a reverse proxy would be useful for load balancing or setting up authentication. \r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\n\r\nMLflow is designed to help teams work together. A reverse proxy can help companies running MLflow on premise to secure their data. It could also allow them to scale up their service through putting replicas behind the reverse proxy.\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\nFor me this is a bit unclear, but I'm trying to collect together several related issues into a meta-issue we can use to collect and discuss this as a feature. At a minimum it is hard because we do not document how this could be done.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [x] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\n\r\nRelated issues:\r\n#2193 #597 #111\r\n","736":"## What changes are proposed in this pull request?\r\n(Please fill in changes proposed in this fix)\r\nIt solved problem with POST requests to Databricks. \r\nMore information here: https:\/\/github.com\/mlflow\/mlflow\/issues\/2821\r\n\r\n## How is this patch tested?\r\n\r\nOn my local computer\r\n\r\n(Details)\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","737":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [X] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**:\r\n- **Python version**:\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\nThe command:\r\n```\r\nmlflow run https:\/\/github.com\/mlflow\/mlflow-example.git -P alpha=5\r\n```\r\nThrows an exception\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\nmlflow run https:\/\/github.com\/mlflow\/mlflow-example.git -P alpha=5\r\n```\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 60, in <module>\r\n    mlflow.log_param(\"alpha\", alpha)\r\n  File \"\/opt\/anaconda3\/envs\/mlflow-3eee9bd7a0713cf80a17bc0a4d659bc9c549efac\/lib\/python3.6\/site-packages\/mlflow\/tracking\/fluent.py\", line 214, in log_param\r\n    MlflowClient().log_param(run_id, key, value)\r\n  File \"\/opt\/anaconda3\/envs\/mlflow-3eee9bd7a0713cf80a17bc0a4d659bc9c549efac\/lib\/python3.6\/site-packages\/mlflow\/tracking\/client.py\", line 206, in log_param\r\n    self._tracking_client.log_param(run_id, key, value)\r\n  File \"\/opt\/anaconda3\/envs\/mlflow-3eee9bd7a0713cf80a17bc0a4d659bc9c549efac\/lib\/python3.6\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 179, in log_param\r\n    self.store.log_param(run_id, param)\r\n  File \"\/opt\/anaconda3\/envs\/mlflow-3eee9bd7a0713cf80a17bc0a4d659bc9c549efac\/lib\/python3.6\/site-packages\/mlflow\/store\/tracking\/file_store.py\", line 663, in log_param\r\n    self._log_run_param(run_info, param)\r\n  File \"\/opt\/anaconda3\/envs\/mlflow-3eee9bd7a0713cf80a17bc0a4d659bc9c549efac\/lib\/python3.6\/site-packages\/mlflow\/store\/tracking\/file_store.py\", line 671, in _log_run_param\r\n    run_id=run_info.run_id, new_value=writeable_param_value)\r\n  File \"\/opt\/anaconda3\/envs\/mlflow-3eee9bd7a0713cf80a17bc0a4d659bc9c549efac\/lib\/python3.6\/site-packages\/mlflow\/store\/tracking\/file_store.py\", line 690, in _validate_new_param_value\r\n    databricks_pb2.INVALID_PARAMETER_VALUE)\r\nmlflow.exceptions.MlflowException: Changing param values is not allowed. Param with key='alpha' was already logged with value='5' for run ID='f829e9d818904139968a4b39baadab5a'. Attempted logging new value '5.0'.\r\n2020\/05\/12 20:39:38 ERROR mlflow.cli: === Run (ID 'f829e9d818904139968a4b39baadab5a') failed ===                     \/4.1s\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n","738":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [X] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: \r\nNo\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nUbuntu 16.04.6 LTS\r\n- **MLflow installed from (source or binary)**:\r\nsource\r\n- **MLflow version (run ``mlflow --version``)**:\r\nmlflow, version 1.8.0\r\n- **Python version**:\r\nPython 3.7.5\r\n- **npm version, if running the dev UI**:\r\n6.9.0\r\n- **Exact command to reproduce**:\r\n![image](https:\/\/user-images.githubusercontent.com\/465606\/81689736-2200d180-948d-11ea-8d7b-220f4bce2990.png)\r\n\r\n\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\nRun MlflowClient.download_artifacts in a different directory with the rightly setting the absolute tracking_uri with `mlflow.set_tracking_uri`\r\n\r\nThe MlflowClient could find the right run_info, but it use a relative path to load the the artifacts.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n![image](https:\/\/user-images.githubusercontent.com\/465606\/81689717-1e6d4a80-948d-11ea-9242-02fb4ba1b50e.png)\r\n\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n![image](https:\/\/user-images.githubusercontent.com\/465606\/81689351-c8000c00-948c-11ea-81aa-a10e5572cd39.png)\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [X] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [X] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\n","739":"## Willingness to contribute\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nAdd native support for the built-in algorithms (training jobs) in SageMaker.\r\n\r\n## Motivation\r\nI work with an AWS partner and many of our ML projects use the built-in algorithms for quick iteration and creation of baseline models. On top of that, we use SageMaker to \r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [ ] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [x] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [ ] `area\/projects`: MLproject format, project running backends\r\n- [x] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [x] `integrations\/sagemaker`: SageMaker integrations\r\n\r\n## Details\r\nThere might be several challenges to this, especially in serialization\/deserialization for other platforms. The AWS formats are, on occasion, not very user friendly and internals are poorly documented.\r\nHowever, my company is looking to use MLFlow with all of our ML clients and this feature would be a great selling point.\r\nI'd love to contribute this feature on my free time with some guidance.\r\n","740":"I am using Google Colab and mounting my drive on my local system. Then in the same folder where my code is, I am running the mlflow ui. The example code works fine but any other program is not working. Any suggestions would help.","741":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix\r\nfor this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes, but this issue can be recreated from stock example by running via cmd line and trying to set run_name in script.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.8.0\r\n- **Python version**: 3.8\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n- modify any mlflow example  as follow:\r\n```\r\nwith mlflow.start_run(\"run_name\") as run:\r\n```\r\n- then run via command line `mlflow run .`\r\n\r\n### Describe the problem\r\nThe run_name will not be added since the run has already been kicked off from the command line. Additionally, there is no way to set run names via command line as the command never sets an `MLFLOW_RUN_NAME` tag\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for\r\nModel Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [x] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nThis is related to https:\/\/github.com\/mlflow\/mlflow\/issues\/2735, but unlike that one, run_name cannot even be passed in.\r\n","742":"## What changes are proposed in this pull request?\r\n\r\nAdd `clear_run`, equivalent of `end_run` but DOES NOT SEND termination signal to the client.\r\n\r\nThis is a feature much needed in some distributed scenarios.\r\n\r\n## How is this patch tested?\r\n\r\n(Details)\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nAdd `clear_run`, equivalent of `end_run` but DOES NOT SEND termination signal to the client.\r\n\r\n### What component(s) does this PR affect?\r\n\r\n- [ ] UI\r\n- [ ] Command Line Interface\r\n- [ ] API\r\n- [ ] Examples\r\n- [ ] Docs\r\n- [x] Tracking\r\n- [ ] Projects\r\n- [ ] Artifacts\r\n- [ ] Models\r\n- [ ] Model Registry\r\n- [ ] Scoring\r\n- [ ] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","743":"## What changes are proposed in this pull request?\r\n\r\nSimple update to the documentation of `end_run()` to help with mlflow integration in distributed settings.\r\n\r\n## How is this patch tested?\r\n\r\n(Details)\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s) does this PR affect?\r\n\r\n- [ ] UI\r\n- [ ] Command Line Interface\r\n- [ ] API\r\n- [ ] Examples\r\n- [ ] Docs\r\n- [x] Tracking\r\n- [ ] Projects\r\n- [ ] Artifacts\r\n- [ ] Models\r\n- [ ] Model Registry\r\n- [ ] Scoring\r\n- [ ] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [x] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","744":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix\r\nfor this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04 (host), nvcr.io\/nvidia\/pytorch:19.12-py3 (container)\r\n\r\n- **MLflow installed from (source or binary)**: binary(pip install mlflow)\r\n- **MLflow version (run ``mlflow --version``)**: 1.8.0\r\n- **Python version**: 3.7.5 (host), 3.6 (container)\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: \r\n```\r\nMLFLOW_TRACKING_URI=MY_URL AWS_DEFAULT_REGION=ap-east-1 AWS_ACCESS_KEY_ID=MY_KEY AWS_SECRET_ACCESS_KEY=MY_ACCESS_KEY mlflow run mlflow_test_torch -A gpus=all\r\n```\r\n\r\n### Describe the problem\r\nmlflow is able to propagate MLFLOW_TRACKING_URI, AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY to the docker container but not the AWS_DEFAULT_REGION. This causes boto3 error when the training script tries to log artifact to S3 as AWS region is not set.\r\n\r\n```\r\nmlflow.pytorch.log_model(model_ft, \"models\")\r\n```\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/boto3\/s3\/transfer.py\", line 279, in upload_file\r\n    future.result()\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/s3transfer\/futures.py\", line 106, in result\r\n    return self._coordinator.result()\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/s3transfer\/futures.py\", line 265, in result\r\n    raise self._exception\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/s3transfer\/tasks.py\", line 126, in __call__\r\n    return self._execute_main(kwargs)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/s3transfer\/tasks.py\", line 150, in _execute_main\r\n    return_value = self._main(**kwargs)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/s3transfer\/upload.py\", line 692, in _main\r\n    client.put_object(Bucket=bucket, Key=key, Body=body, **extra_args)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/botocore\/client.py\", line 272, in _api_call\r\n    return self._make_api_call(operation_name, kwargs)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/botocore\/client.py\", line 576, in _make_api_call\r\n    raise error_class(parsed_response, operation_name)\r\nbotocore.exceptions.ClientError: An error occurred (IllegalLocationConstraintException) when calling the PutObject operation: The ap-east-1 location constraint is incompatible for the region specific endpoint this request was sent to.\r\n```\r\nI try setting AWS_DEFAULT_REGION in the Dockerfile and there is no more boto3 error.\r\n\r\n### Code to reproduce issue\r\nDockerfile\r\n```\r\nFROM nvcr.io\/nvidia\/pytorch:19.12-py3\r\n\r\nRUN pip install mlflow\r\n\r\n```\r\n\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks,\r\nplease include the full traceback. Large logs and files should be attached.\r\n","745":"Hi, \r\nI need some help to configure setting up hdfs as the artifact store for mlflow. I have mlflow and hdfs all running in separate containers across a docket network. When I try to log the model I get the following error:\r\n\r\n```---------------------------------------------------------------------------\r\nFileNotFoundError                         Traceback (most recent call last)\r\n<ipython-input-35-e54b25688d8e> in <module>\r\n      1 # log model artifacts\r\n----> 2 pyfunc.log_model('hdfs:\/\/hdfs:8020\/', python_model=LGBWrapper(), artifacts=artifacts, conda_env=conda_env)\r\n      3 # pyfunc.save_model('prediction_model8', python_model=LGBWrapper(), artifacts=artifacts, conda_env=conda_env)\r\n      4 \r\n      5 # set tag for selecting model\r\n\r\n~\/opt\/anaconda3\/envs\/soptai\/lib\/python3.6\/site-packages\/mlflow\/pyfunc\/__init__.py in log_model(artifact_path, loader_module, data_path, code_path, conda_env, python_model, artifacts, registered_model_name)\r\n    697                      artifacts=artifacts,\r\n    698                      conda_env=conda_env,\r\n--> 699                      registered_model_name=registered_model_name)\r\n    700 \r\n    701 \r\n\r\n~\/opt\/anaconda3\/envs\/soptai\/lib\/python3.6\/site-packages\/mlflow\/models\/__init__.py in log(cls, artifact_path, flavor, registered_model_name, **kwargs)\r\n    100             mlflow_model = cls(artifact_path=artifact_path, run_id=run_id)\r\n    101             flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\r\n--> 102             mlflow.tracking.fluent.log_artifacts(local_path, artifact_path)\r\n    103             try:\r\n    104                 mlflow.tracking.fluent._record_logged_model(mlflow_model)\r\n\r\n~\/opt\/anaconda3\/envs\/soptai\/lib\/python3.6\/site-packages\/mlflow\/tracking\/fluent.py in log_artifacts(local_dir, artifact_path)\r\n    321     \"\"\"\r\n    322     run_id = _get_or_start_run().info.run_id\r\n--> 323     MlflowClient().log_artifacts(run_id, local_dir, artifact_path)\r\n    324 \r\n    325 \r\n\r\n~\/opt\/anaconda3\/envs\/soptai\/lib\/python3.6\/site-packages\/mlflow\/tracking\/client.py in log_artifacts(self, run_id, local_dir, artifact_path)\r\n    265         :param artifact_path: If provided, the directory in ``artifact_uri`` to write to.\r\n    266         \"\"\"\r\n--> 267         self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)\r\n    268 \r\n    269     def _record_logged_model(self, run_id, mlflow_model):\r\n\r\n~\/opt\/anaconda3\/envs\/soptai\/lib\/python3.6\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py in log_artifacts(self, run_id, local_dir, artifact_path)\r\n    266         run = self.get_run(run_id)\r\n    267         artifact_repo = get_artifact_repository(run.info.artifact_uri)\r\n--> 268         artifact_repo.log_artifacts(local_dir, artifact_path)\r\n    269 \r\n    270     def list_artifacts(self, run_id, path=None):\r\n\r\n~\/opt\/anaconda3\/envs\/soptai\/lib\/python3.6\/site-packages\/mlflow\/store\/artifact\/hdfs_artifact_repo.py in log_artifacts(self, local_dir, artifact_path)\r\n     47         hdfs_base_path = _resolve_base_path(self.path, artifact_path)\r\n     48 \r\n---> 49         with hdfs_system(host=self.host, port=self.port) as hdfs:\r\n     50 \r\n     51             if not hdfs.exists(hdfs_base_path):\r\n\r\n~\/opt\/anaconda3\/envs\/soptai\/lib\/python3.6\/contextlib.py in __enter__(self)\r\n     79     def __enter__(self):\r\n     80         try:\r\n---> 81             return next(self.gen)\r\n     82         except StopIteration:\r\n     83             raise RuntimeError(\"generator didn't yield\") from None\r\n\r\n~\/opt\/anaconda3\/envs\/soptai\/lib\/python3.6\/site-packages\/mlflow\/store\/artifact\/hdfs_artifact_repo.py in hdfs_system(host, port)\r\n    175                                 driver=driver,\r\n    176                                 kerb_ticket=kerb_ticket,\r\n--> 177                                 extra_conf=extra_conf)\r\n    178     yield connected\r\n    179     connected.close()\r\n\r\n~\/opt\/anaconda3\/envs\/soptai\/lib\/python3.6\/site-packages\/pyarrow\/hdfs.py in connect(host, port, user, kerb_ticket, driver, extra_conf)\r\n    213     fs = HadoopFileSystem(host=host, port=port, user=user,\r\n    214                           kerb_ticket=kerb_ticket, driver=driver,\r\n--> 215                           extra_conf=extra_conf)\r\n    216     return fs\r\n\r\n~\/opt\/anaconda3\/envs\/soptai\/lib\/python3.6\/site-packages\/pyarrow\/hdfs.py in __init__(self, host, port, user, kerb_ticket, driver, extra_conf)\r\n     36                  driver='libhdfs', extra_conf=None):\r\n     37         if driver == 'libhdfs':\r\n---> 38             _maybe_set_hadoop_classpath()\r\n     39 \r\n     40         self._connect(host, port, user, kerb_ticket, driver, extra_conf)\r\n\r\n~\/opt\/anaconda3\/envs\/soptai\/lib\/python3.6\/site-packages\/pyarrow\/hdfs.py in _maybe_set_hadoop_classpath()\r\n    138             classpath = _hadoop_classpath_glob(hadoop_bin)\r\n    139     else:\r\n--> 140         classpath = _hadoop_classpath_glob('hadoop')\r\n    141 \r\n    142     os.environ['CLASSPATH'] = classpath.decode('utf-8')\r\n\r\n~\/opt\/anaconda3\/envs\/soptai\/lib\/python3.6\/site-packages\/pyarrow\/hdfs.py in _hadoop_classpath_glob(hadoop_bin)\r\n    163 \r\n    164     hadoop_classpath_args = (hadoop_bin, 'classpath', '--glob')\r\n--> 165     return subprocess.check_output(hadoop_classpath_args)\r\n    166 \r\n    167 \r\n\r\n~\/opt\/anaconda3\/envs\/soptai\/lib\/python3.6\/subprocess.py in check_output(timeout, *popenargs, **kwargs)\r\n    354 \r\n    355     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\r\n--> 356                **kwargs).stdout\r\n    357 \r\n    358 \r\n\r\n~\/opt\/anaconda3\/envs\/soptai\/lib\/python3.6\/subprocess.py in run(input, timeout, check, *popenargs, **kwargs)\r\n    421         kwargs['stdin'] = PIPE\r\n    422 \r\n--> 423     with Popen(*popenargs, **kwargs) as process:\r\n    424         try:\r\n    425             stdout, stderr = process.communicate(input, timeout=timeout)\r\n\r\n~\/opt\/anaconda3\/envs\/soptai\/lib\/python3.6\/subprocess.py in __init__(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\r\n    727                                 c2pread, c2pwrite,\r\n    728                                 errread, errwrite,\r\n--> 729                                 restore_signals, start_new_session)\r\n    730         except:\r\n    731             # Cleanup if the child failed starting.\r\n\r\n~\/opt\/anaconda3\/envs\/soptai\/lib\/python3.6\/subprocess.py in _execute_child(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\r\n   1362                         if errno_num == errno.ENOENT:\r\n   1363                             err_msg += ': ' + repr(err_filename)\r\n-> 1364                     raise child_exception_type(errno_num, err_msg, err_filename)\r\n   1365                 raise child_exception_type(err_msg)\r\n   1366 \r\n\r\nFileNotFoundError: [Errno 2] No such file or directory: 'hadoop': 'hadoop'\r\n```\r\n\r\n\r\nAccess to hdfs is not an issue as they are in the same network and other services running on the same network can access hdfs as well. \r\nMaybe there are some changes to be made to the core-site.xml or hdfs-site.xml as someone who reported a similar issue suggested (https:\/\/github.com\/mlflow\/mlflow\/issues\/1466). Unfortunately, I have no idea what those changes need to be. Please assist! ","746":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix\r\nfor this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **MLflow installed from (source or binary)**: Binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.8.0\r\n- **Python version**: 3.6\r\n- **npm version, if running the dev UI**: N\/A.\r\n- **Exact command to reproduce**: See below \r\n\r\n### Describe the problem\r\nWhile attempting to run the tests for a fix to #2759 , which use absolute paths for temporary directories, I discovered that url parsing doesn't work for absolute paths on windows.  This blocks a lot of the tests running on Windows. \r\n\r\nI guess we should detect windows paths and prepend a `file` prefix? \r\n\r\n### Code to reproduce issue\r\n\r\n```python\r\n from mlflow.tracking.artifact_utils import _download_artifact_from_uri\r\n_download_artifact_from_uri('C:\\\\some_path\\\\to\\\\artifacts')\r\n```\r\n\r\nresults in: \r\n\r\n```\r\nMlflowException: Could not find a registered artifact repository for: c:. Currently registered schemes are: ['', 'file', 's3', 'gs', 'wasbs', 'ftp', 'sftp', 'dbfs', 'hdfs', 'viewfs', 'runs', 'models']\r\n```\r\n\r\n### Other info \/ logs\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nMlflowException                           Traceback (most recent call last)\r\n<ipython-input-9-c34fb6c38ec0> in <module>\r\n----> 1 _download_artifact_from_uri('C:\\\\some_path\\\\to\\\\artifacts')\r\n\r\nartifact_utils.py in _download_artifact_from_uri(artifact_uri, output_path)\r\n     73         root_uri = prefix + urllib.parse.urlunparse(parsed_uri)\r\n     74\r\n---> 75     return get_artifact_repository(artifact_uri=root_uri).download_artifacts(\r\n     76         artifact_path=artifact_path, dst_path=output_path)\r\n\r\nartifact_repository_registry.py in get_artifact_repository(artifact_uri)\r\n    100              requirements.\r\n    101     \"\"\"\r\n--> 102     return _artifact_repository_registry.get_artifact_repository(artifact_uri)\r\n\r\nartifact_repository_registry.py in get_artifact_repository(self, artifact_uri)\r\n     66                 \"Could not find a registered artifact repository for: {}. \"\r\n     67                 \"Currently registered schemes are: {}\".format(\r\n---> 68                     artifact_uri, list(self._registry.keys())\r\n     69                 )\r\n     70             )\r\n\r\nMlflowException: Could not find a registered artifact repository for: c:. Currently registered schemes are: ['', 'file', 's3', 'gs', 'wasbs', 'ftp', 'sftp', 'dbfs', 'hdfs', 'viewfs', 'runs', 'models']\r\n```\r\n","747":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix\r\nfor this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [X] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: \r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.8.0\r\n- **Python version**: 3.6.9\r\n- **npm version, if running the dev UI**: N\/A\r\n- **Exact command to reproduce**:\r\n1) Load a spacy model from disk `nlp = spacy.load(\"path\/to\/model\")`\r\n2) Save Spacy as MLflow model to disk `mlflow.spacy.save_model(spacy_model=nlp, path=\"\/path\/to\/saved\/model\")`\r\n3) Loading the Spacy model works from code\r\n`nlp2 = mlflow.spacy.load_model(\"path\/to\/model\")`\r\n4) However, `mlflow models serve -m \/path\/to\/model` fails with stack trace below. It says that it cannot find suitable flavor backend.\r\n\r\n\r\n### Describe the problem\r\nCannot serve Spacy model via cli.\r\n\r\n### Other info \/ logs\r\n```\r\nTraceback (most recent call last):\r\n  File \"\/home\/dima\/miniconda2\/envs\/basemodel\/bin\/mlflow\", line 8, in <module>\r\n    sys.exit(cli())\r\n  File \"\/home\/dima\/miniconda2\/envs\/basemodel\/lib\/python3.6\/site-packages\/click\/core.py\", line 829, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\/home\/dima\/miniconda2\/envs\/basemodel\/lib\/python3.6\/site-packages\/click\/core.py\", line 782, in main\r\n    rv = self.invoke(ctx)\r\n  File \"\/home\/dima\/miniconda2\/envs\/basemodel\/lib\/python3.6\/site-packages\/click\/core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/home\/dima\/miniconda2\/envs\/basemodel\/lib\/python3.6\/site-packages\/click\/core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/home\/dima\/miniconda2\/envs\/basemodel\/lib\/python3.6\/site-packages\/click\/core.py\", line 1066, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\/home\/dima\/miniconda2\/envs\/basemodel\/lib\/python3.6\/site-packages\/click\/core.py\", line 610, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"\/home\/dima\/miniconda2\/envs\/basemodel\/lib\/python3.6\/site-packages\/mlflow\/models\/cli.py\", line 56, in serve\r\n    install_mlflow=install_mlflow).serve(model_uri=model_uri, port=port,\r\n  File \"\/home\/dima\/miniconda2\/envs\/basemodel\/lib\/python3.6\/site-packages\/mlflow\/models\/cli.py\", line 167, in _get_flavor_backend\r\n    raise Exception(\"No suitable flavor backend was found for the model.\")\r\nException: No suitable flavor backend was found for the model.\r\n```\r\n","748":"\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nIt would be nice if there was a `mlflow.gensim` module for gensim models. [Here is documentation of a gensim tfidf model.](https:\/\/radimrehurek.com\/gensim\/models\/tfidfmodel.html)\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n   Save, load and use gensim models such as tfidf as a built-in flavor\r\n- Why is this use case valuable to support for MLflow users in general?\r\n  gensim models are widely used by the NLP community, not being able to use mlflow for those models is a shame \r\n- Why is this use case valuable to support for your project(s) or organization?\r\n  We are thinking about moving models to mlflow, but we cannot do it if mlflow does not support gensim.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\n\r\n## Which MLflow component(s) does this feature affect?\r\n\r\n- [ ] UI\r\n- [ ] Command Line Interface\r\n- [x] API\r\n- [x] Examples\r\n- [x] Docs\r\n- [ ] Tracking\r\n- [ ] Projects\r\n- [ ] Artifacts\r\n- [x] Models\r\n- [ ] Model Registry\r\n- [ ] Scoring\r\n- [ ] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n## Details\r\n\r\n(Use this section to include any additional information about the feature. If you have a proposal\r\nfor how to implement this feature, please include it here. For implementation guidelines, please\r\nrefer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","749":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nAllow Tracking server to plot metrics across runs with timestamp as the x-axis.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nWe use tracking server to log model artifacts, job metrics & metadata. Job metadata is logged in tags section. However, if we re-run the job and log information to a new run, tracking server does not allow the users to plot the metrics across multiple runs. This change will allow users to log metrics, and job metadata to a new run.\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\nIt extends the functionality of tracking server.\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nWe have automated workflows that run at a schedule. We want to save automated workflow information as a new run but also want the ability to see the metrics trends over time.\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nTracking server cannot plot metrics across runs.\r\n\r\n## Which MLflow component(s) does this feature affect?\r\n\r\n- [x] UI\r\n- [ ] Command Line Interface\r\n- [ ] API\r\n- [ ] Examples\r\n- [ ] Docs\r\n- [x] Tracking\r\n- [ ] Projects\r\n- [ ] Artifacts\r\n- [ ] Models\r\n- [ ] Model Registry\r\n- [ ] Scoring\r\n- [ ] R\r\n- [ ] Java\r\n- [ ] Python\r\n","750":"## What changes are proposed in this pull request?\r\n\r\nChange the front end router from HashRouter to BrowserRouter.\r\n\r\n## How is this patch tested?\r\n\r\nTested manually in chrome, firefox, IE11 and Edge. Navigating the UI and refreshing the pages with different routes, and checking that the history is working\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [X] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nUsing BrowserRouter instead of HashRouter remove the \/#\/ between the host and the path in the url.\r\n\r\n### What component(s) does this PR affect?\r\n\r\n- [X] UI\r\n- [ ] Command Line Interface\r\n- [ ] API\r\n- [ ] Examples\r\n- [ ] Docs\r\n- [ ] Tracking\r\n- [ ] Projects\r\n- [ ] Artifacts\r\n- [ ] Models\r\n- [ ] Model Registry\r\n- [ ] Scoring\r\n- [ ] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","751":"Closed #2671\r\n```python\r\nimport mlflow\r\nmlflow.set_tracking_uri(\"http:\/\/127.0.0.1:5000\/\")\r\nmlflow.set_experiment(\"AutoPytorch\")\r\nwith mlflow.start_run(run_name=\"runtest\"):\r\n    print(mlflow.get_artifact_uri()) # .\/mlruns\/1\/fbad648257e549b0843bcb996e91a175\/artifacts\r\n```","752":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [X] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\n[Vega-lite](https:\/\/vega.github.io\/vega-lite\/) is rapidly becoming the de-facto standard for cross-language graphing, and it's spec is ideal for the frontend as it is just JSON.\r\n\r\nI propose that MLFlow add support for the following:\r\n1. API to obtain JSON containing metrics \/ parameters for runs in tabular form that is compatible with [Vega-Lite datasets](https:\/\/vega.github.io\/vega-lite\/docs\/data.html)\r\n2. custom plots in the UI via a Vega-Lite _template_. This builds on the previous bullet to allow the user to write standard Vega-Lite and produce a vast array of possible plots.\r\n\r\n## Motivation\r\n- What is the use case for this feature? **To allow users to customize the UI through custom plots of metrics\/parameters\/comparisons**\r\n- Why is this use case valuable to support for MLflow users in general? **Many users would benefit from seeing a plot that is important to their use case but too specific for the general userbase to be included as a standard feature.**\r\n- Why is this use case valuable to support for your project(s) or organization? **Rapid creation of visualizations is a crucial component for Data Science. Right now, producing custom charts requires multiple API calls + lots of data munging.**\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient) **Currently, producing custom plots in the UI requires forking MLflow**\r\n\r\n## Which MLflow component(s) does this feature affect?\r\n\r\n- [X] UI\r\n- [ ] Command Line Interface\r\n- [X] API\r\n- [ ] Examples\r\n- [ ] Docs\r\n- [ ] Tracking\r\n- [ ] Projects\r\n- [ ] Artifacts\r\n- [ ] Models\r\n- [ ] Model Registry\r\n- [ ] Scoring\r\n- [ ] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n## Details\r\n### Request\r\nendpoint: `2.0\/mlflow\/data\/get` HTTP Method: `GET`\r\n\r\n| Field Name  | Type                   | Description                        |\r\n|-------------|------------------------|------------------------------------|\r\n| experiments | An array of Experiment | Pass the run_ids you want data for |\r\n\r\n### Response\r\nJSON array of each observation (per [Tidy Data](https:\/\/vita.had.co.nz\/papers\/tidy-data.pdf)): [example response](https:\/\/gist.githubusercontent.com\/tbenst\/b03a5abc3d728aaf19cb520c03e94812\/raw\/6dc8e2acfc5d72ba6f450d8e725ab34d76af0b76\/two-mlflow-runs.json).\r\n\r\n\r\n### Example plot template\r\n```json\r\n{\r\n  \"data\": {\r\n    \"url\": \"https:\/\/gist.githubusercontent.com\/tbenst\/b03a5abc3d728aaf19cb520c03e94812\/raw\/6dc8e2acfc5d72ba6f450d8e725ab34d76af0b76\/two-mlflow-runs.json\"  \r\n},\r\n  \"mark\": {\r\n    \"type\": \"line\",\r\n    \"point\": true\r\n  },\r\n  \"encoding\": {\r\n    \"x\": {\"field\": \"step\", \"type\": \"quantitative\"},\r\n    \"y\": {\"field\": \"value\", \"type\": \"quantitative\"},\r\n    \"column\": {\"field\": \"metric\", \"type\": \"nominal\"},\r\n    \"color\": {\"field\": \"name\", \"type\": \"nominal\"}\r\n  }\r\n}\r\n```\r\n![visualization (1)](https:\/\/user-images.githubusercontent.com\/863327\/80319066-37a2a580-87c3-11ea-9f07-bbc2d5af5a92.png)\r\n\r\n### Response spec\r\n- each observation of a metric is its own row\r\n- each row contains all `run` parameters\r\n\r\nWhile this duplicates information, it vastly simplifies plotting. Suppose I want to plot by batch_size instead. It's a one-word switch: [try vega online editor](https:\/\/vega.github.io\/editor\/#\/url\/vega-lite\/N4KABGBEAmCGAutIC4yghSBXATgGxSgAt54AHAZ2QHpqBzASwvgDpH4isAjLCgUxwBjAPYA7eH3EsRAW2rwuk5tS4AGAMywArLC6D10AOwAmAByxYAMwCMATkFctx1YI19bAFlPXj1HLAB3anVTLlszLS4uaHVbaw1oaAA2Y2S+U0NYPnctWNtoLVUuUK5LeQDhAFoZPEs8YQDKnCxRChYAKwoxSHAwAF8AGl7IGVgcAGtCdAxIeABPMj5CSDwGUSWhjCgyYTX4Qnhmvl7B4ckRaDW6Kd7MAA8pyEsGPjxoZeY+MkgBqHnF5YARywsHEDEQ8AYADclqctpA5o9nq93qhIFDYHgsBs-gslmjgaDIRDobDNjMRFiZKIkS83ssZHxDgxBD9cQC0aJhDI1pjIHCKcJ6jhaSjllwEIIiAB9CgMABeONmeOWXJ5oj5fROIC1QA).\r\n\r\n### But mlflow can already do these plots!\r\nFirst of all, can only do one at a time not Facet plots and also there's far more customization available in Vega-Lite. Furthermore, there are [many more plots that vega-lite would enable](https:\/\/vega.github.io\/vega-lite\/examples\/).\r\n\r\n## Related issues that this solves or partially solves\r\nhttps:\/\/github.com\/mlflow\/mlflow\/issues\/2440 https:\/\/github.com\/mlflow\/mlflow\/issues\/1806 https:\/\/github.com\/mlflow\/mlflow\/issues\/2719 https:\/\/github.com\/mlflow\/mlflow\/issues\/2279 ","753":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's\r\n[Issue Policy for feature requests](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md#feature-requests)\r\nand the [MLflow Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nWe wonder does it make sense to have a dynamic sorting function at model comparison interface?\r\nFor now, we can only sort models by column before choosing the model to compare. \r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nFor visualization of model metrics comparison.\r\n- Why is this use case valuable to support for MLflow users in general?\r\nThe function should improve the experience of users who wants to sort the model results by metrics on the figure.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nWe are users who wants to sort the model results by metrics on the figures, and that improves our experience :)\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nFor now, we can only sort models by column before choosing the model to compare.  If we want to sort the models by other metrics we need to go back to do the same thing every time.\r\n\r\n## Which MLflow component(s) does this feature affect?\r\n\r\n- [x] UI\r\n- [ ] Command Line Interface\r\n- [ ] API\r\n- [ ] Examples\r\n- [ ] Docs\r\n- [ ] Tracking\r\n- [ ] Projects\r\n- [ ] Artifacts\r\n- [ ] Models\r\n- [ ] Model Registry\r\n- [ ] Scoring\r\n- [ ] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n## Details\r\nNAN\r\n(Use this section to include any additional information about the feature. If you have a proposal\r\nfor how to implement this feature, please include it here. For implementation guidelines, please\r\nrefer to the [Contributing Guide](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#contribution-guidelines).)\r\n","754":"## Describe the proposal\r\nCurrently, the TensorFlow format model is served through the python API. However, TensorFlow has a robust serving solution which more robust and performant. The proposal is to support serving Tensorflow models through the native TensorFlow based solution. \r\nMore info about TensorFlow Serving: https:\/\/www.tensorflow.org\/tfx\/guide\/serving\r\n\r\n### Motivation\r\nThe primary reason for supporting this is that models served in this way can be used for low-latency inference.\r\n\r\n### Proposed Changes\r\nIf the models is of TensorFlow flavor, `mlflow models build-docker` should build a serving image with using Tensorflow Serving.\r\n","755":"\r\n## Describe the proposal\r\nMLFlow currently seems to deploy each model to a new SageMaker instance. Since Novermber 2019, SageMaker has come up with something called multi-model endpoint, which allows users to deploy multiple models to the same instance.\r\n\r\nOne can read about multi-model endpoint here : https:\/\/aws.amazon.com\/blogs\/machine-learning\/save-on-inference-costs-by-using-amazon-sagemaker-multi-model-endpoints\/\r\n\r\n### Motivation\r\nMulti Model Endpoint can decrease cost tremendously for organizations, by deploying multiple models to one single instance. SageMaker handles the rest, of swapping inactive models with new models whose traffic is incoming.\r\n\r\n\r\n\r\n### Proposed Changes\r\nProbably in the `mlflow.sagemaker` API?","756":"### System information\r\n- **OS Platform and Distribution**: Linux Ubuntu 18.04\r\n- **MLflow installed from**: binary\r\n- **MLflow version**: 1.8\r\n- **Python version**: 3.8\r\n\r\n### Describe the problem\r\nSetting the experiment id in a python script with `mlflow.set_experiment('foo')` does not work when the script is run with `mlflow run . -e train_model_min`. In the case where something is logged to the experiment, the run fails with the exception \r\n\r\n> mlflow.exceptions.MlflowException: Cannot start run with ID c21d2c4e75c047608003235f213e5bb5 because active run ID does not match environment run ID. Make sure --experiment-name or --experiment-id matches experiment set with set_experiment(), or just use command-line arguments\r\n\r\neven though no experiment id was specified in the CLI.\r\n\r\nIf nothing is logged (commenting out the line with log_metric in the code below), the run is executed without error but is logged under the Default experiment instead of foo.\r\n\r\n### Code to reproduce issue\r\ntrain_model_min.py:\r\n```\r\nimport mlflow\r\n\r\ndef main():\r\n    mlflow.set_experiment('foo')\r\n    mlflow.log_metric('answer', 42)\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n\r\nMLproject file:\r\n```\r\nname: MLFlow Test\r\n\r\nconda_env: conda.yaml\r\n\r\nentry_points:\r\n  train_model_min:\r\n    command: \"python train_model_min.py\"\r\n```\r\n\r\ncommand to reproduce bug:\r\n`mlflow run . -e train_model_min`","757":"## Describe the proposal \r\nMlflow tracking backend currently is unable (with any of the currently supported storage backend) to scale in retrieval of runs beyond thousand of runs. My proposal is to consider this as an important issue for mlflow and to prioritize pull requests and issues that goes in this direction.\r\nHere are some ideas : \r\n* being able to retrieve only some of the metrics, tags, params https:\/\/github.com\/mlflow\/mlflow\/pull\/2212 => improve the backend speed by about x15 but still slow for more than 20000 runs\r\n* using a more efficient storage backend that is adapted to document storage (elastic search, graphql, ...) => that may be a real solution that could truly scale\r\n* I would be glad to hear about other ideas\r\n\r\n\r\n### Motivation\r\nThe use case would be supporting machine learning practitioners that run as teams or alone thousand of runs for a single experiment. Being able to retrieve these runs and compare them is quite important in this case.\r\n\r\n### Proposed Changes\r\nThe changes would affect the storage backend and possibly the backend API.\r\n\r\nThe objective of this issue is to hear what you think about this ? is it something you consider important for databricks ? are there lot of users of mlflow that have this use case ?\r\n","758":"\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04.\r\n- **MLflow installed from (source or binary)**: Binary Pip\r\n- **MLflow version (run ``mlflow --version``)**: 1.7.2\r\n- **Python version**: 3.6.9\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: `mlflow server --backend-store-uri postgresql:\/\/USER:PW@localhost\/mlflow --default-artifact-root \/mlflow_runs -h 0.0.0.0`\r\n\r\n### Describe the problem\r\nI try to change the artifact root to the folder `\/mlflow_runs` and mount this folder via simple NFS share on the client. If I execute the following on the client, the `artifact_uri` is unchanged.\r\n\r\n```python\r\nimport mlflow\r\nmlflow.set_tracking_uri(\"....\")\r\nmlflow.set_experiment(\"TEST\")\r\nmlflow.get_artifact_uri()\r\n# \/home\/ubuntu\/mlruns\/...\r\n# This is the old path\r\n```\r\n\r\nIf I create a new experiment the artifact path is correct.\r\n```python\r\nimport mlflow\r\nmlflow.set_tracking_uri(\"....\")\r\nmlflow.create_experiment(\"test123\")\r\nmlflow.set_experiment(\"test123\")\r\nmlflow.get_artifact_uri()\r\n# \/mlflow_runs\r\n# Right path\r\n```","759":"Propose:\r\nNot much of a proposal but want to know if it is possible to view custom tags in comparisons as it is very hard to gauge comparisons based only on the run_id to the right of the graphs. I read on [#2192](https:\/\/github.com\/mlflow\/mlflow\/issues\/2192#issue-536759760) that you can't really change the run_id as it is integral to the framework, but can we append a custom tag to each run in order to better gauge them in this view? \r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/14831613\/79609641-b3626b00-80bc-11ea-9468-c98d22fa1b7a.png)\r\n\r\n\r\n\r\n","760":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address.\r\n\r\nPlease fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n-------\r\n## Guidelines\r\n\r\nFeature requests typically go through the following lifecycle:\r\n\r\n1. Submit feature request with high-level description on GitHub issues (this is what you're doing now)\r\n2. Discuss feature request with a committer, who may ask for a more detailed design\r\n3. After discussion & agreement on feature request, start implementation\r\n\r\n\r\n## Describe the proposal\r\n#2620 made improvements to the line smoothness functionality in the metrics plot view; we now display the smoothed value and the original value at each point on a given metrics plot curve. Unfortunately, we do not provide any visual reference for the original value; this makes it somewhat difficult to reason about the original value.\r\n\r\nTo provide visual guidance for the original value figure displayed in a smoothed metrics plot, I propose displaying a faded \"shadow\" curve with the original values in addition to the smoothed curve in the metrics plot view.\r\n\r\n### Motivation\r\nAs discussed above, the lack of any visual reference for the original metric value displayed at a point along a given smoothed metric curve makes it difficult to reason about how this value changes as a function of `x`.\r\n\r\n### Proposed Changes\r\nWe propose to introduce a UI-only change that adds a shadow curve to the metrics plot view as follows:\r\n\r\n**Before**\r\n\r\n![79368483-5459f600-7f04-11ea-8054-cf0e49d2136b](https:\/\/user-images.githubusercontent.com\/39497902\/79497725-05cc5a80-7fdd-11ea-83e1-c01247678e1f.png)\r\n\r\n**After**\r\n\r\n<img width=\"774\" alt=\"79389927-acecbb80-7f23-11ea-988e-32409df246dc\" src=\"https:\/\/user-images.githubusercontent.com\/39497902\/79497749-11b81c80-7fdd-11ea-930f-62b208e4661d.png\">","761":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\nPlease fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OSX 10.14\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.7\r\n- **Python version**: 3.7\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: See steps below\r\n\r\n### Describe the problem\r\nPlotting a large number of metrics, each with multiple values recorded at different steps, produces significant browser lag in the UI. i.e., this UI is slow (and pretty unreadable):\r\n\r\n<img width=\"2474\" alt=\"Screen Shot 2020-04-16 at 12 13 09 PM\" src=\"https:\/\/user-images.githubusercontent.com\/39497902\/79496893-acaff700-7fdb-11ea-9a10-3d0d2e630be6.png\">\r\n\r\n### Code to reproduce issue\r\n1. Launch the MLflow UI \/ Tracking Server\r\n\r\n2. Create a python script with the following contents:\r\n```\r\nimport argparse\r\nimport time\r\nimport random\r\n\r\nimport numpy as np\r\n\r\nimport mlflow\r\nfrom mlflow.tracking.client import MlflowClient\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\r\n    parser.add_argument('--runs', type=int, default=1, help='The number of runs to generate')\r\n    parser.add_argument('--metrics', type=int, default=5, help='The number of metrics to generate for each run')\r\n    parser.add_argument('--min-step', type=int, default=-10, help='The minimum step to record for each metric')\r\n    parser.add_argument('--max-step', type=int, default=100, help='The maximum step to record for each metric')\r\n    parser.add_argument('--min-value', type=float, default=-10, help='The maximum value to record for each metric')\r\n    parser.add_argument('--max-value', type=float, default=10, help='The maximum value to record for each metric')\r\n    parser.add_argument('--entry-dropout', type=float, default=0.1, help='The fraction of entries to randomly omit')\r\n    parser.add_argument('--step-replication', type=float, default=0.1, help='The fraction of entries that should be given the same step')\r\n    parser.add_argument('--shuffle', action=\"store_true\", help='If specified, shuffles timestamps')\r\n\r\n    args = parser.parse_args()\r\n\r\n    mlflow_client = MlflowClient()\r\n\r\n    for i in range(args.runs):\r\n        with mlflow.start_run():\r\n            run_id = mlflow.active_run().info.run_uuid\r\n            for j in range(args.metrics):\r\n                metric_name = \"metric_{idx}\".format(idx=j)\r\n\r\n                steps = range(args.min_step, args.max_step)\r\n                replicated_steps = np.random.choice(steps, size=int(len(steps) * args.step_replication))\r\n                steps = np.concatenate([steps, replicated_steps])\r\n\r\n                curr_time = int(time.time())\r\n                timestamps = [1000 * item for item in range(curr_time, curr_time + len(steps))]\r\n                if args.shuffle:\r\n                    np.random.shuffle(timestamps)\r\n\r\n                steps_timestamps = list(zip(steps, timestamps))\r\n                sample_indices = random.sample(\r\n                    range(len(steps_timestamps)),\r\n                    int((1 - args.entry_dropout) * len(steps_timestamps)))\r\n                steps_timestamps = [steps_timestamps[i] for i in sorted(sample_indices)]\r\n\r\n                values = (args.max_value - args.min_value) * np.random.random(len(steps_timestamps)) + args.min_value\r\n\r\n                for k in range(len(steps_timestamps)):\r\n                    step, timestamp = steps_timestamps[k]\r\n                    value = values[k]\r\n                    print(step, timestamp, value)\r\n                    mlflow_client.log_metric(\r\n                        run_id=run_id,\r\n                        key=metric_name,\r\n                        value=value,\r\n                        timestamp=timestamp,\r\n                        step=step)\r\n```\r\n\r\n3. Invoke `python gen_metrics.py --runs 1 --metrics 35 --min-step -10 --max-step 100    --min-value -10 --max-value 10 --entry-dropout 0 --step-replication 0.0` from the command line\r\n\r\n4. Open the run metrics plot view and select all 35 metrics that were produced to plot each curve\r\n\r\n5. Observe browser lag\r\n\r\n### Other info \/ logs\r\nNA","762":"## Describe the proposal\r\nAdd an option to ignore previously saved code_paths when calling mlflow.pytorch.load_model\r\n \r\n### Motivation\r\nI previously used mlflow.pytorch.log_model to store pytorch models and used the code_paths options to store some relevant files. However, the code has since been refactored and some of the dependencies called by the stored code have been moved. This causes mlflow.pytorch.load_model to fail when trying to add the stored code to the system path. \r\n\r\n### Proposed Changes\r\nAdd an option (such as use_code_paths) to mlflow.pytorch.load_model. I believe the only change required is to check whether check use_code_paths=True at the if statement on line 353 of mlflow\/pytorch\/__init__.py \r\n","763":"## Describe the proposal\r\n* Support explicit AWS credentials and multiple MLFLOW connections to s3.\r\n\r\nRIght now the credentials come from ENV variables and there's no way to tell MLFLOW to change those credentials and instantiate a new boto3 Session.\r\n\r\nThis can be implemented easily by passing explicit AWS credentials and instantiating a boto3 Session rather than getting the default client. This can be a PATCH change, and can be backward compatible.\r\n\r\n### Motivation\r\nWe have various different environments at Yelp, each with their set of AWS credentials. \r\n* We'd like to be able to instantiate MLFlow clients for different environments.\r\n* It's hard for us to set environment variables in some of our live services.\r\n\r\n### Proposed Changes\r\nSimple internal change here: https:\/\/github.com\/mlflow\/mlflow\/blob\/60c71fae70aeff9841d60f63e023f129c02dec19\/mlflow\/store\/artifact\/s3_artifact_repo.py#L29 where we could instantiate an AWS Session rather than  getting the default client after cascading AWS credentials via function args.\r\n\r\nThe default boto3 client uses a global here https:\/\/boto3.amazonaws.com\/v1\/documentation\/api\/latest\/_modules\/boto3.html which gets the credentials from the user's home folder of from ENV variables but we'd like to instantiate a Session passing the credentials ourselves.\r\n\r\nNOTE: the problem is similar to https:\/\/github.com\/mlflow\/mlflow\/issues\/2458 but the solution I propose is different.  I am available to make the change if it's approved","764":"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.mleap.html\r\n\r\nI'm trying to download MLeap model flavor using the Java API method downloadArtifacts(String runId) and load the model using the method MLeapLoader.loadPipeline(String modelRootPath). \r\nBut I failed.\r\n\r\nNotice I replicate this notebook in my case and it works with serializeToBundle and deserializeToBundle (https:\/\/docs.azuredatabricks.net\/_static\/notebooks\/mleap-model-export-demo-python.html)\r\n\r\nLooking for some clarification\r\n\r\nIvan","765":"\r\n> install.packages(\"mlflow\")\r\ntrying URL 'https:\/\/cran.rstudio.com\/bin\/windows\/contrib\/3.6\/mlflow_1.7.0.zip'\r\nContent type 'application\/zip' length 195582 bytes (190 KB)\r\ndownloaded 190 KB\r\n\r\npackage \u2018mlflow\u2019 successfully unpacked and MD5 sums checked\r\n\r\nThe downloaded binary packages are in\r\n\tC:\\Users\\suppwksadmin\\AppData\\Local\\Temp\\RtmpM57pQQ\\downloaded_packages\r\n> mlflow::install_mlflow()\r\nCollecting package metadata (current_repodata.json): ...working... done\r\nSolving environment: ...working... done\r\n\r\n# All requested packages already installed.\r\n\r\nRequirement already up-to-date: mlflow==1.7.0 in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (1.7.0)\r\nRequirement already satisfied, skipping upgrade: entrypoints in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from mlflow==1.7.0) (0.3)\r\nRequirement already satisfied, skipping upgrade: waitress; platform_system == \"Windows\" in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from mlflow==1.7.0) (1.4.3)\r\nRequirement already satisfied, skipping upgrade: six>=1.10.0 in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from mlflow==1.7.0) (1.14.0)\r\nRequirement already satisfied, skipping upgrade: pyyaml in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from mlflow==1.7.0) (5.3.1)\r\nRequirement already satisfied, skipping upgrade: python-dateutil in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from mlflow==1.7.0) (2.8.1)\r\nRequirement already satisfied, skipping upgrade: cloudpickle in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from mlflow==1.7.0) (1.3.0)\r\nRequirement already satisfied, skipping upgrade: gitpython>=2.1.0 in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from mlflow==1.7.0) (3.1.0)\r\nRequirement already satisfied, skipping upgrade: simplejson in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from mlflow==1.7.0) (3.17.0)\r\nRequirement already satisfied, skipping upgrade: numpy in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from mlflow==1.7.0) (1.18.2)\r\nRequirement already satisfied, skipping upgrade: protobuf>=3.6.0 in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from mlflow==1.7.0) (3.11.3)\r\nRequirement already satisfied, skipping upgrade: alembic in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from mlflow==1.7.0) (1.4.2)\r\nRequirement already satisfied, skipping upgrade: gorilla in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from mlflow==1.7.0) (0.3.0)\r\nRequirement already satisfied, skipping upgrade: click>=7.0 in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from mlflow==1.7.0) (7.1.1)\r\nRequirement already satisfied, skipping upgrade: sqlparse in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from mlflow==1.7.0) (0.3.1)\r\nRequirement already satisfied, skipping upgrade: docker>=4.0.0 in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from mlflow==1.7.0) (4.2.0)\r\nRequirement already satisfied, skipping upgrade: querystring-parser in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from mlflow==1.7.0) (1.2.4)\r\nRequirement already satisfied, skipping upgrade: databricks-cli>=0.8.7 in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from mlflow==1.7.0) (0.10.0)\r\nRequirement already satisfied, skipping upgrade: Flask in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from mlflow==1.7.0) (1.1.2)\r\nRequirement already satisfied, skipping upgrade: requests>=2.17.3 in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from mlflow==1.7.0) (2.23.0)\r\nRequirement already satisfied, skipping upgrade: prometheus-flask-exporter in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from mlflow==1.7.0) (0.13.0)\r\nRequirement already satisfied, skipping upgrade: sqlalchemy in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from mlflow==1.7.0) (1.3.16)\r\nRequirement already satisfied, skipping upgrade: pandas in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from mlflow==1.7.0) (1.0.3)\r\nRequirement already satisfied, skipping upgrade: gitdb<5,>=4.0.1 in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from gitpython>=2.1.0->mlflow==1.7.0) (4.0.2)\r\nRequirement already satisfied, skipping upgrade: setuptools in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from protobuf>=3.6.0->mlflow==1.7.0) (46.1.3.post20200330)\r\nRequirement already satisfied, skipping upgrade: Mako in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from alembic->mlflow==1.7.0) (1.1.2)\r\nRequirement already satisfied, skipping upgrade: python-editor>=0.3 in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from alembic->mlflow==1.7.0) (1.0.4)\r\nRequirement already satisfied, skipping upgrade: websocket-client>=0.32.0 in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from docker>=4.0.0->mlflow==1.7.0) (0.57.0)\r\nRequirement already satisfied, skipping upgrade: pypiwin32==223; sys_platform == \"win32\" and python_version >= \"3.6\" in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from docker>=4.0.0->mlflow==1.7.0) (223)\r\nRequirement already satisfied, skipping upgrade: configparser>=0.3.5 in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from databricks-cli>=0.8.7->mlflow==1.7.0) (5.0.0)\r\nRequirement already satisfied, skipping upgrade: tabulate>=0.7.7 in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from databricks-cli>=0.8.7->mlflow==1.7.0) (0.8.7)\r\nRequirement already satisfied, skipping upgrade: Werkzeug>=0.15 in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from Flask->mlflow==1.7.0) (1.0.1)\r\nRequirement already satisfied, skipping upgrade: Jinja2>=2.10.1 in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from Flask->mlflow==1.7.0) (2.11.1)\r\nRequirement already satisfied, skipping upgrade: itsdangerous>=0.24 in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from Flask->mlflow==1.7.0) (1.1.0)\r\nRequirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from requests>=2.17.3->mlflow==1.7.0) (1.25.8)\r\nRequirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from requests>=2.17.3->mlflow==1.7.0) (2020.4.5.1)\r\nRequirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from requests>=2.17.3->mlflow==1.7.0) (2.9)\r\nRequirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from requests>=2.17.3->mlflow==1.7.0) (3.0.4)\r\nRequirement already satisfied, skipping upgrade: prometheus-client in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from prometheus-flask-exporter->mlflow==1.7.0) (0.7.1)\r\nRequirement already satisfied, skipping upgrade: pytz>=2017.2 in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from pandas->mlflow==1.7.0) (2019.3)\r\nRequirement already satisfied, skipping upgrade: smmap<4,>=3.0.1 in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow==1.7.0) (3.0.1)\r\nRequirement already satisfied, skipping upgrade: MarkupSafe>=0.9.2 in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from Mako->alembic->mlflow==1.7.0) (1.1.1)\r\nRequirement already satisfied, skipping upgrade: pywin32>=223 in c:\\progra~3\\anaconda3\\envs\\r-mlflow-1.7.0\\lib\\site-packages (from pypiwin32==223; sys_platform == \"win32\" and python_version >= \"3.6\"->docker>=4.0.0->mlflow==1.7.0) (227)\r\n> library(mlflow)\r\n> mlflow_log_param(\"param1\", 5)\r\nError in rethrow_call(c_processx_exec, command, c(command, args), stdin,  : \r\n  Command 'C:\/ProgramData\/Anaconda3\/envs\/r-mlflow-1.7.0\/mlflow' not found @win\/processx.c:983 (processx_exec)\r\nType .Last.error.trace to see where the error occured","766":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.7.2\r\n- **Python version**: 3.7.4\r\n- **npm version, if running the dev UI**: N\/A\r\n\r\n### Describe the problem\r\nWhen using a remote tracking server and a project with `MLproject` using a Docker env, I get an error thrown when `mlflow.start_run()` is called.\r\n\r\n### Code to reproduce issue\r\n1) Run `mlflow server` in a remote instance.\r\n2) Run `ssh -L 5000:127.0.0.1:5000 remote_server`.\r\n3) Run `export MLFLOW_TRACKING_URI=http:\/\/127.0.0.1:5000`.\r\n4) Run the [examples\/docker](https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/docker) mlflow example.\r\n\r\nOutput I get is:\r\n```\r\nkiran[@boira]:mlflow>mlflow run examples\/docker -P alpha=0.5\r\n2020\/04\/13 13:20:50 INFO mlflow.projects: === Building docker image docker-example:aeaca67 ===\r\n2020\/04\/13 13:20:50 INFO mlflow.projects: === Created directory \/tmp\/tmpr47gl3ca for downloading remote URIs passed to arguments of type 'path' ===\r\n2020\/04\/13 13:20:50 INFO mlflow.projects: === Running command 'docker run --rm -v \/home\/kiran\/.aws:\/.aws -e MLFLOW_RUN_ID=27fe6853cbda4df080abd0c0c7fa681a -e MLFLOW_TRACKING_URI=http:\/\/127.0.0.1:5000 -e MLFLOW_EXPERIMENT_ID=0 docker-example:aeaca67 python train.py --alpha 0.5 --l1-ratio 0.1' in run with ID '27fe6853cbda4df080abd0c0c7fa681a' === \r\n\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/__init__.py:55: DeprecationWarning: MLflow support for Python 2 is deprecated and will be dropped in a future release. At that point, existing Python 2 workflows that use MLflow will continue to work without modification, but Python 2 users will no longer get access to the latest MLflow features and bugfixes. We recommend that you upgrade to Python 3 - see https:\/\/docs.python.org\/3\/howto\/pyporting.html for a migration guide.\r\n  \"for a migration guide.\", DeprecationWarning)\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 53, in <module>\r\n    with mlflow.start_run():\r\n  File \"\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/tracking\/fluent.py\", line 122, in start_run\r\n    active_run_obj = MlflowClient().get_run(existing_run_id)\r\n  File \"\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/tracking\/client.py\", line 96, in get_run\r\n    return self._tracking_client.get_run(run_id)\r\n  File \"\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 49, in get_run\r\n    return self.store.get_run(run_id)\r\n  File \"\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 92, in get_run\r\n    response_proto = self._call_endpoint(GetRun, req_body)\r\n  File \"\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 32, in _call_endpoint\r\n    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)\r\n  File \"\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/utils\/rest_utils.py\", line 133, in call_endpoint\r\n    host_creds=host_creds, endpoint=endpoint, method=method, params=json_body)\r\n  File \"\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/utils\/rest_utils.py\", line 70, in http_request\r\n    url=url, headers=headers, verify=verify, **kwargs)\r\n  File \"\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/utils\/rest_utils.py\", line 51, in request_with_ratelimit_retries\r\n    response = requests.request(**kwargs)\r\n  File \"\/opt\/conda\/lib\/python2.7\/site-packages\/requests\/api.py\", line 58, in request\r\n    return session.request(method=method, url=url, **kwargs)\r\n  File \"\/opt\/conda\/lib\/python2.7\/site-packages\/requests\/sessions.py\", line 508, in request\r\n    resp = self.send(prep, **send_kwargs)\r\n  File \"\/opt\/conda\/lib\/python2.7\/site-packages\/requests\/sessions.py\", line 618, in send\r\n    r = adapter.send(request, **kwargs)\r\n  File \"\/opt\/conda\/lib\/python2.7\/site-packages\/requests\/adapters.py\", line 508, in send\r\n    raise ConnectionError(e, request=request)\r\nrequests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=5000): Max retries exceeded with url: \/api\/2.0\/mlflow\/runs\/get?run_uuid=27fe6853cbda4df080abd0c0c7fa681a&run_id=27fe6853cbda4df080abd0c0c7fa681a (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fad1b41cb90>: Failed to establish a new connection: [Errno 111] Connection refused',))\r\n2020\/04\/13 13:20:52 ERROR mlflow.cli: === Run (ID '27fe6853cbda4df080abd0c0c7fa681a') failed ===\r\n```\r\n\r\nI've tested projects with a conda environment and they work perfectly fine, which makes me think it's an issue with how Docker talks to the remote tracking server? Does it need some permissions? Is my approach wrong?\r\n\r\nThanks.","767":"#### Proposal: \r\nAdd ability to compare different artifacts (ie plots, pngs, txt files) of different experiment runs for a side-by-side comparison on the Comparison Dashboard. \r\n\r\n#### Motivation:\r\nAt the moment, the framework allows comparisons of parameters and metrics per run but there is no way to compare the artifacts of those runs. Some experiments require more than a line-graph to fully glance at the results. So we save those results as pngs and store them as artifacts. I am proposing to also be able to compare those artifacts the same way we compare parameters and metrics in the comparison-view. This would allow anyone to quickly glance at artifacts without having to open up different dashboard views to view the artifacts. \r\n\r\n__Example of what I envision:__\r\n![image](https:\/\/user-images.githubusercontent.com\/14831613\/79155504-d2988a00-7d96-11ea-8b9c-29adbb791b8c.png)\r\n\r\n\r\n#### Proposed Changes: \r\n**How achievable is this?** I believe it can be done using the rest API for listing artifacts [List Artifacts](https:\/\/www.mlflow.org\/docs\/latest\/rest-api.html#list-artifacts) but have not played around with that enough. \r\n\r\n\r\n","768":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\nPlease fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 Pro\r\n- **MLflow installed from (source or binary)**: pip\r\n- **MLflow version (run ``mlflow --version``)**: 1.7.2\r\n- **Python version**: 3.7.5\r\n\r\n### Describe the problem\r\nCan't start run Mlflow once the default experiment 0 has been deleted. I will expect it to either use the next available ID or overwrite experiment 0 and bring it back to active.\r\n\r\n### Code to reproduce issue\r\n1. Initialize mlflow in a folder by \r\n```mlflow experiments list```,\r\n which create default experiment 0\r\n2. Delete the experiment 0 by\r\n```mlflow experiments delete -x 0```\r\n3. Create a jupyter notebook in the same folder and run\r\n```\r\nimport mlflow\r\nwith mlflow.start_run():\r\n    pass\r\n``` \r\nIt will throw the error:\r\n```\r\nMlflowException: Could not create run under non-active experiment with ID 0.\r\n```\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks,\r\nplease include the full traceback. Large logs and files should be attached.\r\n```\r\n---------------------------------------------------------------------------\r\nMlflowException                           Traceback (most recent call last)\r\n<ipython-input-3-d6a861b94e0d> in <module>\r\n      1 import mlflow\r\n----> 2 with mlflow.start_run():\r\n      3     pass\r\n\r\nc:\\users\\louis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\mlflow\\tracking\\fluent.py in start_run(run_id, experiment_id, run_name, nested)\r\n    151         active_run_obj = MlflowClient().create_run(\r\n    152             experiment_id=exp_id_for_run,\r\n--> 153             tags=tags\r\n    154         )\r\n    155 \r\n\r\nc:\\users\\louis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\mlflow\\tracking\\client.py in create_run(self, experiment_id, start_time, tags)\r\n    121         :return: :py:class:`mlflow.entities.Run` that was created.\r\n    122         \"\"\"\r\n--> 123         return self._tracking_client.create_run(experiment_id, start_time, tags)\r\n    124 \r\n    125     def list_run_infos(self, experiment_id, run_view_type=ViewType.ACTIVE_ONLY):\r\n\r\nc:\\users\\louis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py in create_run(self, experiment_id, start_time, tags)\r\n     86             user_id=user_id,\r\n     87             start_time=start_time or int(time.time() * 1000),\r\n---> 88             tags=[RunTag(key, value) for (key, value) in iteritems(tags)]\r\n     89         )\r\n     90 \r\n\r\nc:\\users\\louis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py in create_run(self, experiment_id, user_id, start_time, tags)\r\n    392                 \"Could not create run under non-active experiment with ID \"\r\n    393                 \"%s.\" % experiment_id,\r\n--> 394                 databricks_pb2.INVALID_STATE)\r\n    395         run_uuid = uuid.uuid4().hex\r\n    396         artifact_uri = self._get_artifact_dir(experiment_id, run_uuid)\r\n\r\nMlflowException: Could not create run under non-active experiment with ID 0.\r\n```","769":"## What changes are proposed in this pull request?\r\n\r\n(Please fill in changes proposed in this fix)\r\n\r\n## How is this patch tested?\r\n\r\n(Details)\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [X] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s) does this PR affect?\r\n\r\n- [ ] UI\r\n- [ ] CLI\r\n- [ ] API\r\n- [ ] REST-API\r\n- [ ] Examples\r\n- [ ] Docs\r\n- [ ] Tracking\r\n- [ ] Projects\r\n- [X] Artifacts\r\n- [ ] Models\r\n- [ ] Scoring\r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [X] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [X] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","770":"I am able to spin up mlflow behind a kerberized reverse proxy.  Curl commands work perfect, e.g.\r\n\r\n> curl --negotiate --user $USER: http:\/\/hostname:54423\/api\/2.0\/preview\/mlflow\/experiments\/list\r\n\r\nIt also works when using my browser as I see in the logs that it attempts an unauthenticated session, receives a 401 and then attempts a kerberized session to receive a 200\r\n\r\nIt looks like we can patch around line 38 in rest_utils.py and create another elif for kerb\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/utils\/rest_utils.py \r\n\r\nI noticed that username password and token is managed via environment variable - I suppose we could do something similar MLFLOW_TRACKING_KERBEROS=1\r\n\r\n","771":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 2 x docker container Ubuntu 18.04 (client and server)\r\n- **MLflow installed from (source or binary)**: binary (pip package)\r\n- **MLflow version (run ``mlflow --version``)**: 1.7.2\r\n- **Python version**: 3.6.9\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI'm trying to setup remote tracking server. As artifacts storage I want to use FTP, but mlflow cannot send any artifacts to FTP. On client side stack overflow error occurs. \r\nAs I can see that problem is related to mkdir (logs below). When I logged into FTP server I'm able to create catalogs and upload files without any problems.\r\n\r\n\r\n### Code to reproduce issue\r\nTo run mlflow server with FTP I use command: \r\n```\r\nmlflow server --backend-store-uri \/media\/mlflow\/mlflow_data\/backend_store\/ --default-artifact-root ftp:\/\/user:name@IP_ADDR --host 0.0.0.0\r\n```\r\n\r\nMy client code: \r\n\r\n```\r\nfrom random import random, randint\r\nimport mlflow\r\n\r\nif __name__ == \"__main__\":\r\n    exp_name = 'testname'\r\n    mlflow.create_experiment(exp_name, artifact_location='ftp:\/\/user:name@IP_ADDR')\r\n    mlflow.set_tracking_uri(\"http:\/\/IP_ADDR:5002\")\r\n    mlflow.set_experiment(exp_name)\r\n    mlflow.log_param(\"param1\", randint(0, 100))\r\n\r\n    mlflow.log_artifact(\"test.txt\")  # File contains \"Hello world!\"\r\n```\r\n\r\n### Other info \/ logs\r\nI get on client side:\r\n```\r\nINFO: 'testname' does not exist. Creating a new experiment\r\n\/usr\/local\/lib\/python3.6\/dist-packages\/IPython\/utils\/module_paths.py:29: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n  import imp\r\nFatal Python error: Cannot recover from stack overflow.\r\n\r\nCurrent thread 0x00007f39b62dd740 (most recent call first):\r\n  File \"\/usr\/lib\/python3.6\/socket.py\", line 614 in readable\r\n  File \"\/usr\/lib\/python3.6\/socket.py\", line 581 in readinto\r\n  File \"\/usr\/lib\/python3.6\/ftplib.py\", line 204 in getline\r\n  File \"\/usr\/lib\/python3.6\/ftplib.py\", line 222 in getmultiline\r\n  File \"\/usr\/lib\/python3.6\/ftplib.py\", line 236 in getresp\r\n  File \"\/usr\/lib\/python3.6\/ftplib.py\", line 251 in voidresp\r\n  File \"\/usr\/lib\/python3.6\/ftplib.py\", line 278 in voidcmd\r\n  File \"\/usr\/lib\/python3.6\/ftplib.py\", line 631 in cwd\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 45 in _is_dir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 53 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 57 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/artifact\/ftp_artifact_repo.py\", line 58 in _mkdir\r\n  ...\r\nAborted (core dumped)\r\n\r\n```\r\n","772":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address.\r\n\r\nPlease fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n-------\r\n## Guidelines\r\n\r\nFeature requests typically go through the following lifecycle:\r\n\r\n1. Submit feature request with high-level description on GitHub issues (this is what you're doing now)\r\n2. Discuss feature request with a committer, who may ask for a more detailed design\r\n3. After discussion & agreement on feature request, start implementation\r\n\r\n\r\n## Describe the proposal\r\nThe `log_artifact` method in the mlflow tracking API currently requires artifacts to be stored in local directories. It would be useful if we could log **references** to artifacts instead of the artifacts themselves. \r\n\r\n### Motivation\r\nArtifacts are occasionally very large files. In those scenarios, they might already exist on a cloud-based file system. It does not make sense to transfer this large file to a local machine in order to log it as an artifact because (1) the file may not fit on local disk, and (2) download times are likely to be long.\r\n\r\n### Proposed Changes\r\nPseudocode for logging artifacts from a GCS artifact repository using the Python SDK:\r\n```python\r\nmlflow.log_artifacts(\"gs:\/\/path\/to\/some\/other\/file\/blob.txt\", \"mlflow\/artifact\/path\")\r\n```\r\nWe do not validate that the artifact exists or that the user has adequate auth scope. We simply store the URI so that it can be consumed by other operations such as `download_artifact`.","773":"When the server starts, the path is set via the command or created .\/mlruns\/\r\nThe mlflow.get_artifact_uri() function should receive the absolute path from the server, if it is a local path. Or return the FTP path, if specified in the settings.\r\n```python\r\nimport mlflow\r\nmlflow.set_tracking_uri(\"http:\/\/127.0.0.1:5000\/\")\r\nmlflow.set_experiment(\"AutoPytorch\")\r\nwith mlflow.start_run(run_name=\"runtest\"):\r\n    print(mlflow.get_artifact_uri()) # .\/mlruns\/1\/fbad648257e549b0843bcb996e91a175\/artifacts\r\n```\r\nWhen using mlflow.log_artifact(), the files are saved in the script folder, not the server.\r\n\r\nThe function mlflow.set_artifact_uri() is missing.","774":"### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Macos catalina\r\n- **MLflow installed from (source or binary)**: pip install mlflow\r\n- **MLflow version (run ``mlflow --version``)**: 1.7.2\r\n- **Python version**: Python 3.7.4\r\n- **Exact command to reproduce**: python examples\/quickstart\/mlflow_tracking.py\r\n\r\n### Describe the problem\r\nI have installed libraries like numpy, pandas, pyspark, koalas, and mlflow in one of the fresh conda environment. Then I downloaded this official repo and tried to run the examples.\r\n\r\nI used the following command as given in README:\r\n```\r\n mlflow run examples\/sklearn_elasticnet_wine -P alpha=0.4\r\n```\r\n\r\nThis fails and gives the following error:\r\n```\r\nConnectionRefusedError: [Errno 61] Connection refused\r\n```\r\n\r\n### Other info \/ logs\r\n```\r\n[04:47 PM]  Bhishan at BpMacpro in ~\/OneDrive - Ohio University\/a01_Data_Science\/c02_Modules\/mlflow\r\n$ mlflow run examples\/sklearn_elasticnet_wine -P alpha=0.4\r\n\/Users\/poudel\/.local\/lib\/python3.7\/site-packages\/markupsafe\/__init__.py:13: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n  from collections import Mapping\r\n\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/jinja2\/utils.py:485: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n  from collections import MutableMapping\r\n\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/pyspark\/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n  import imp\r\n\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/py4j\/java_collections.py:13: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n  from collections import (\r\n\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/pyspark\/resultiterable.py:23: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n  class ResultIterable(collections.Iterable):\r\n\/Users\/poudel\/.local\/lib\/python3.7\/site-packages\/yaml\/constructor.py:126: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n  if not isinstance(key, collections.Hashable):\r\nTraceback (most recent call last):\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/urllib3\/connection.py\", line 157, in _new_conn\r\n    (self._dns_host, self.port), self.timeout, **extra_kw\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/urllib3\/util\/connection.py\", line 84, in create_connection\r\n    raise err\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/urllib3\/util\/connection.py\", line 74, in create_connection\r\n    sock.connect(sa)\r\nConnectionRefusedError: [Errno 61] Connection refused\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/urllib3\/connectionpool.py\", line 672, in urlopen\r\n    chunked=chunked,\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/urllib3\/connectionpool.py\", line 387, in _make_request\r\n    conn.request(method, url, **httplib_request_kw)\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/http\/client.py\", line 1244, in request\r\n    self._send_request(method, url, body, headers, encode_chunked)\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/http\/client.py\", line 1290, in _send_request\r\n    self.endheaders(body, encode_chunked=encode_chunked)\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/http\/client.py\", line 1239, in endheaders\r\n    self._send_output(message_body, encode_chunked=encode_chunked)\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/http\/client.py\", line 1026, in _send_output\r\n    self.send(msg)\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/http\/client.py\", line 966, in send\r\n    self.connect()\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/urllib3\/connection.py\", line 184, in connect\r\n    conn = self._new_conn()\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/urllib3\/connection.py\", line 169, in _new_conn\r\n    self, \"Failed to establish a new connection: %s\" % e\r\nurllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x11b06f510>: Failed to establish a new connection: [Errno 61] Connection refused\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/requests\/adapters.py\", line 449, in send\r\n    timeout=timeout\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/urllib3\/connectionpool.py\", line 720, in urlopen\r\n    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/urllib3\/util\/retry.py\", line 436, in increment\r\n    raise MaxRetryError(_pool, url, error or ResponseError(cause))\r\nurllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: \/api\/2.0\/mlflow\/runs\/create (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x11b06f510>: Failed to establish a new connection: [Errno 61] Connection refused'))\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/bin\/mlflow\", line 10, in <module>\r\n    sys.exit(cli())\r\n  File \"\/Users\/poudel\/.local\/lib\/python3.7\/site-packages\/Click-7.0-py3.7.egg\/click\/core.py\", line 764, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\/Users\/poudel\/.local\/lib\/python3.7\/site-packages\/Click-7.0-py3.7.egg\/click\/core.py\", line 717, in main\r\n    rv = self.invoke(ctx)\r\n  File \"\/Users\/poudel\/.local\/lib\/python3.7\/site-packages\/Click-7.0-py3.7.egg\/click\/core.py\", line 1137, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/Users\/poudel\/.local\/lib\/python3.7\/site-packages\/Click-7.0-py3.7.egg\/click\/core.py\", line 956, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\/Users\/poudel\/.local\/lib\/python3.7\/site-packages\/Click-7.0-py3.7.egg\/click\/core.py\", line 555, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/mlflow\/cli.py\", line 138, in run\r\n    run_id=run_id\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/mlflow\/projects\/__init__.py\", line 288, in run\r\n    use_conda=use_conda, storage_dir=storage_dir, synchronous=synchronous, run_id=run_id)\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/mlflow\/projects\/__init__.py\", line 111, in _run\r\n    active_run = _create_run(uri, experiment_id, work_dir, entry_point)\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/mlflow\/projects\/__init__.py\", line 576, in _create_run\r\n    active_run = tracking.MlflowClient().create_run(experiment_id=experiment_id, tags=tags)\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/mlflow\/tracking\/client.py\", line 123, in create_run\r\n    return self._tracking_client.create_run(experiment_id, start_time, tags)\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 88, in create_run\r\n    tags=[RunTag(key, value) for (key, value) in iteritems(tags)]\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 117, in create_run\r\n    response_proto = self._call_endpoint(CreateRun, req_body)\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 32, in _call_endpoint\r\n    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/mlflow\/utils\/rest_utils.py\", line 136, in call_endpoint\r\n    host_creds=host_creds, endpoint=endpoint, method=method, json=json_body)\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/mlflow\/utils\/rest_utils.py\", line 70, in http_request\r\n    url=url, headers=headers, verify=verify, **kwargs)\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/mlflow\/utils\/rest_utils.py\", line 51, in request_with_ratelimit_retries\r\n    response = requests.request(**kwargs)\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/requests\/api.py\", line 61, in request\r\n    return session.request(method=method, url=url, **kwargs)\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/requests\/sessions.py\", line 530, in request\r\n    resp = self.send(prep, **send_kwargs)\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/requests\/sessions.py\", line 643, in send\r\n    r = adapter.send(request, **kwargs)\r\n  File \"\/Users\/poudel\/miniconda3\/envs\/spk\/lib\/python3.7\/site-packages\/requests\/adapters.py\", line 516, in send\r\n    raise ConnectionError(e, request=request)\r\nrequests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: \/api\/2.0\/mlflow\/runs\/create (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x11b06f510>: Failed to establish a new connection: [Errno 61] Connection refused'))\r\n```\r\n","775":"When we tried to deploy a mlflow model built using mlflow.log_model function (mlflow models serve -m 33733a7066044e0abf0716c289468a13\/artifacts\/model\/ -p 1234), it erred with the need to install Bash. We don't want to use Bash. Our effort to change the shell to one of the supported shells, e.g. tcsh didn't work. \r\n\r\n2020\/04\/02 02:30:06 INFO mlflow.pyfunc.backend: === Running command 'source activate mlflow-73c744371db890c52078f6e0ad5a53bc292e3c3c 1>&2 && gunicorn --timeout=60 -b 127.0.0.1:1234 -w 1 ${GUNICORN_CMD_ARGS} -- mlflow.pyfunc.scoring_server.wsgi:app' \r\nFile \"\/opt\/conda\/lib\/python3.7\/subprocess.py\", line 1551, in _execute_child\r\n    raise child_exception_type(errno_num, err_msg, err_filename)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'bash': 'bash'\r\n\r\nOur Environment Details,\r\nOS - Alpine 3.11\r\nPython  - 3.7.7\r\nConda - 4.8.2\r\nScikit-learn - 0.22.1\r\nmlflow - 1.7.2\r\n\r\nIt appears the issue is in gunicorn which mandates bash. Any suggestions?\r\n","776":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address.\r\n\r\nPlease fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n-------\r\n## Guidelines\r\n\r\nFeature requests typically go through the following lifecycle:\r\n\r\n1. Submit feature request with high-level description on GitHub issues (this is what you're doing now)\r\n2. Discuss feature request with a committer, who may ask for a more detailed design\r\n3. After discussion & agreement on feature request, start implementation\r\n\r\n## Describe the proposal\r\n\r\nI propose an enhancement to the scatter plot functionality in the UI. I would like to be able to plot not just one trace, but multiple traces by having the option to select multiple metrics on the Y axis drop down.\r\n\r\n### Motivation\r\n\r\nIt would allow people to gain greater insight on their hyperparameter optimization whenever they have more than just one KPI to optimize on. I'm working on a business case where I have to balance out multiple KPIs. In the initial phase, where I'm running a line search over one model parameter (the number of estimators in a GBM), the above feature would be a great way to track the trade-off between the competing KPIs as the model parameters changes.\r\n\r\n### Proposed Changes\r\n\r\nA change to the UI frontend only. Instead of being forced to select **one** metric\/parameter in the scatter plot's Y-axis drop down, I would like to be able to select multiple. Each selection would create a new trace in the scatter plot, clearly distinguished by an automatically assigned color. This should only require small (relatively) small changes to the code that controls the scatter plot section of the UI\r\n\r\nLet me know what you think - I know that this would really help me in my work, and I hope (and think) others would like to see this too! :)\r\n","777":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\nPlease fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian GNU\/Linux 10 (buster)\r\n- **MLflow installed from (source or binary)**: PyPi binary\r\n- **MLflow version (run ``mlflow --version``)**: mlflow==1.7.2\r\n- **Python version**: Python 3.7.6\r\n- **npm version, if running the dev UI**: n\/a\r\n- **Exact command to reproduce**: See code to reproduce.\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\n### Code to reproduce issue\r\n\r\n```\r\nPython 3.7.6 (default, Jan  8 2020, 19:59:22) \r\n[GCC 7.3.0] :: Anaconda, Inc. on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import mlflow\r\n>>> mlflow_client = mlflow.tracking.MlflowClient('.\/mlruns')\r\n>>> experiment = mlflow_client.create_experiment('test')\r\n>>> mlflow_client.list_experiments()\r\n[<Experiment: artifact_location='.\/mlruns\/0', experiment_id='0', lifecycle_stage='active', name='Default', tags={}>, <Experiment: artifact_location='.\/mlruns\/1', experiment_id='1', lifecycle_stage='active', name='test', tags={}>]\r\n>>> mlflow.delete_experiment('1')\r\n>>> mlflow_client.list_experiments()\r\n[<Experiment: artifact_location='.\/mlruns\/0', experiment_id='0', lifecycle_stage='active', name='Default', tags={}>]\r\n>>> quit()\r\n(base) root@a0ab3fe52510:\/workdir# mlflow gc --backend-store-uri .\/mlruns\r\n(base) root@a0ab3fe52510:\/workdir# python\r\nPython 3.7.6 (default, Jan  8 2020, 19:59:22) \r\n[GCC 7.3.0] :: Anaconda, Inc. on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import mlflow\r\n>>> mlflow_client = mlflow.tracking.MlflowClient('.\/mlruns')\r\n>>> mlflow_client.list_experiments()\r\n[<Experiment: artifact_location='.\/mlruns\/0', experiment_id='0', lifecycle_stage='active', name='Default', tags={}>]\r\n>>> experiment = mlflow_client.create_experiment('test')\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/tracking\/client.py\", line 161, in create_experiment\r\n    return self._tracking_client.create_experiment(name, artifact_location)\r\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 128, in create_experiment\r\n    artifact_location=artifact_location,\r\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/store\/tracking\/file_store.py\", line 239, in create_experiment\r\n    self._validate_experiment_name(name)\r\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/store\/tracking\/file_store.py\", line 232, in _validate_experiment_name\r\n    databricks_pb2.RESOURCE_ALREADY_EXISTS)\r\nmlflow.exceptions.MlflowException: Experiment 'test' already exists in deleted state. You can restore the experiment, or permanently delete the experiment from the .trash folder (under tracking server's root folder) in order to use this experiment name again.\r\n```\r\n\r\nThis error message is fine and provides a solution when using a filesystem-based backend store. However, if I use a database-based backend store I cannot resolve the issue. \r\n\r\n```\r\n>>> import mlflow\r\n>>> MLFLOW_TRACKING_SERVER = # IP address of the tracking server\r\n>>> mlflow_client = mlflow.tracking.MlflowClient(MLFLOW_TRACKING_SERVER)\r\n>>> mlflow_client.list_experiments()\r\n[<Experiment: artifact_location='s3:\/\/bucket\/project\/mlflow\/0', experiment_id='0', lifecycle_stage='active', name='Default', tags={}>, <Experiment: artifact_location='s3:\/\/bucket\/project\/mlflow\/5', experiment_id='5', lifecycle_stage='active', name='tests', tags={}>]\r\n>>> experiment = mlflow_client.create_experiment('testing')\r\n>>> mlflow_client.list_experiments()\r\n[<Experiment: artifact_location='s3:\/\/bucket\/project\/mlflow\/0', experiment_id='0', lifecycle_stage='active', name='Default', tags={}>, <Experiment: artifact_location='s3:\/\/bucket\/project\/mlflow\/5', experiment_id='5', lifecycle_stage='active', name='tests', tags={}>, <Experiment: artifact_location='s3:\/\/bucket\/project\/mlflow\/6', experiment_id='6', lifecycle_stage='active', name='testing', tags={}>]\r\n>>> mlflow.delete_experiment('6')\r\n>>> mlflow_client.list_experiments()\r\n[<Experiment: artifact_location='s3:\/\/bucket\/project\/mlflow\/0', experiment_id='0', lifecycle_stage='active', name='Default', tags={}>, <Experiment: artifact_location='s3:\/\/bucket\/project\/mlflow\/5', experiment_id='5', lifecycle_stage='active', name='tests', tags={}>]\r\n>>> experiment = mlflow_client.create_experiment('testing')\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/tracking\/client.py\", line 161, in create_experiment\r\n    return self._tracking_client.create_experiment(name, artifact_location)\r\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 128, in create_experiment\r\n    artifact_location=artifact_location,\r\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 54, in create_experiment\r\n    response_proto = self._call_endpoint(CreateExperiment, req_body)\r\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 32, in _call_endpoint\r\n    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)\r\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/utils\/rest_utils.py\", line 137, in call_endpoint\r\n    response = verify_rest_response(response, endpoint)\r\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/utils\/rest_utils.py\", line 103, in verify_rest_response\r\n    raise RestException(json.loads(response.text))\r\nmlflow.exceptions.RestException: RESOURCE_ALREADY_EXISTS: Experiment(name=testing) already exists. Error: (raised as a result of Query-invoked autoflush; consider using a session.no_autoflush block if this flush is occurring prematurely)\r\n(psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"experiments_name_key\"\r\nDETAIL:  Key (name)=(testing) already exists.\r\n\r\n[SQL: INSERT INTO experiments (name, artifact_location, lifecycle_stage) VALUES (%(name)s, %(artifact_location)s, %(lifecycle_stage)s) RETURNING experiments.experiment_id]\r\n[parameters: {'name': 'testing', 'artifact_location': '', 'lifecycle_stage': 'active'}]\r\n(Background on this error at: http:\/\/sqlalche.me\/e\/gkpj)\r\n```","778":"Related: https:\/\/github.com\/Neuraxio\/Neuraxle\/issues\/278\r\n\r\n## Describe the proposal\r\n\r\nSee here: https:\/\/mlflow.org\/docs\/latest\/models.html\r\n\r\nWe'd want to add these classes: \r\n- mlflow.neuraxle.save_model() \r\n- mlflow.neuraxle.log_model() \r\n- mlflow.neuraxle.load_model() \r\n\r\nThis is of minimal impact, and extensible. \r\n\r\n### Motivation\r\n\r\nScikit-learn, created in 2007, lacks support for deep learning, AutoML, and has an inflexible API. For instance, it's impossible to serialize scikit-learn pipelines if they contain TensorFlow or some other external librairies in the steps of the pipeline. \r\n\r\nSee our full list of problems of [using scikit-learn for deep learning and AutoML](https:\/\/www.neuraxio.com\/en\/blog\/scikit-learn\/2020\/01\/03\/what-is-wrong-with-scikit-learn.html). \r\n\r\nHere are our [solutions to doing deep learning with scikit-learn-like-pipelines using Neuraxle](https:\/\/www.neuraxle.org\/stable\/scikit-learn_problems_solutions.html#). \r\n\r\nHere is an [example Neuraxle deep learning pipeline using TensorFlow](https:\/\/github.com\/Neuraxio\/Neuraxle#deep-learning-pipeline-definition). The ability to serialize tensorflow steps inside scikit-learn pipelines is a pain reliever as explained in the solution link above. \r\n\r\n### Proposed Changes\r\n\r\nI explained this already in the title `Describe the proposal` above. \r\n\r\nFiles to get inspiration from: \r\n\r\n- https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/sklearn.py\r\n- https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/tensorflow.py\r\n\r\nMy only concern is that we don't save exactly 1 file like a pickle, but rather, many files with subfolders. May zip and unzip the whole thing if needed. \r\n\r\nSee also: https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.sklearn.html#module-mlflow.sklearn\r\n","779":"#2498  Describe the proposal\r\nProvide more info about the model version when viewing all the versions of a registered model. Right now we can only see **version number, registered at, created by, stage and pending request** attributes.\r\n\r\n### Motivation\r\nWhen viewing all the versions of a registered model (screenshot below), it will be very useful to see also the description of the versions along maybe with some other details like last activity on the version, SourceRun, etc.\r\n\r\n![Screen Shot 2020-03-27 at 10 13 25 AM](https:\/\/user-images.githubusercontent.com\/12852045\/77781956-b31e0500-7013-11ea-8b5d-5c528850a8a5.png)\r\n\r\n@gioa ","780":"https:\/\/github.com\/mlflow\/mlflow\/blob\/e0e19c6c19734b1847c417b3d59a799d9e007336\/mlflow\/java\/client\/src\/main\/java\/org\/mlflow\/tracking\/MlflowClient.java#L494\r\n\r\nI'm integrating MLFlow Tracking with a Spark application written in Scala that has very high code coverage. For unit\/integration testing purposes it would be preferable to:\r\n1. Not rely on an MLFLow server being available (both running & accessible via VPN or in docker)\r\n2. Not pollute an MLFlow server with repeated run information about mock expectations \/ small integration data sets. \r\n\r\nConsequently, the _file_ provider seems appealing as the file could be removed in an `afterAll` block. \r\n\r\nIt looks as though the quickest option would be to write an interface and provide two implementations: a no-op variant and one that uses `MlflowClient`. The _humble_ App object (or a test case) could instantiate the appropriate class based on the URI.","781":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nCentOS 7\r\n- **MLflow installed from (source or binary)**:\r\nbinary\r\n- **MLflow version (run ``mlflow --version``)**:\r\n1.7\r\n- **Python version**:\r\n3.8\r\n- **npm version, if running the dev UI**:\r\n20.0.2\r\n- **Exact command to reproduce**:\r\n1. Setup environment variables to connect on a mlflow server:\r\n```\r\nexport MLFLOW_TRACKING_URI=\r\nexport MLFLOW_TRACKING_USERNAME=\r\nexport MLFLOW_TRACKING_PASSWORD=\r\n```\r\n\r\n2. Create an experiment logging a parameter with a string value over 500 bytes\r\n```\r\nwith mlflow.start_run():\r\n    mlflow.log_param(\"A parameter\", \"Over 500 bytes string...\")\r\n```\r\n\r\n3. Run you experiment\r\npython3 your_file.py ....\r\n\r\n### Describe the problem\r\n\r\nThe rest API will return a generic error message.\r\nWe should see an error message indicating the maximum value are exceeded. \r\n\r\nI assume this maximum is intended because it is specified in the API documentation: https:\/\/www.mlflow.org\/docs\/latest\/rest-api.html#log-param\r\nTherefore, there is no reason not to give information regarding this error. \r\n\r\n### Other info \/ logs\r\n\r\nOnly the following message is returned:\r\n\r\n> ERROR mlflow.utils.rest_utils: API request to MLFLOW_SERVER\/api\/2.0\/mlflow\/runs\/log-parameter failed with code 500 != 200, retrying up to 2 more times. API response body: <!DOCTYPE HTML PUBLIC \"-\/\/W3C\/\/DTD HTML 3.2 Final\/\/EN\">\r\n> <title>500 Internal Server Error<\/title>\r\n> <h1>Internal Server Error<\/h1>\r\n> <p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.<\/p>\r\n","782":"-------\r\n## Describe the proposal\r\n\r\nThe `mlflow models build-docker` command uses the docker CLI. Supporting the docker-py interface instead would allow one to build images on remote docker installations, without having to install docker. \r\n\r\n### Motivation\r\n\r\nThe current interface requires the user to install docker on their system, which is not always possible or appropriate. The python API would allow users to build and deploy mlflow models on remote docker installations with simple configuration of their environment. \r\n\r\n### Proposed Changes\r\n\r\nInternal changes only would be required. Backwards compatibility could easily be maintained. \r\n\r\n* Replace the line in [docker_utils](https:\/\/github.com\/mlflow\/mlflow\/blob\/383374d7d90bb4494bb34a3e31d3e16e1900078e\/mlflow\/models\/docker_utils.py#L106) with a similar call in [docker-py API](https:\/\/docker-py.readthedocs.io\/en\/stable\/images.html)\r\n* Add docker to requirements. \r\n\r\n\r\n","783":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\nPlease fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Centos \r\n- **MLflow installed from (source or binary)**: installed using pip\r\n- **MLflow version (run ``mlflow --version``)**: 1.7\r\n- **Python version**: 3\r\n- **Exact command to reproduce**: $ mlflow models build-docker -m \"runs:\/ac105c61b91c418697db78bc6fe60639\/model\" -n \"my-image-name\"\r\n\r\n### Describe the problem\r\nI have downloaded the example https:\/\/github.com\/mlflow\/mlflow. and ran successfully the \"sklearn_elasticnet_wine\" experiment using the following command\r\n$ mlflow run sklearn_elasticnet_wine -P alpha=0.5 \r\n\r\nNow when I tried to docker the model using the below command\r\n$ mlflow models build-docker -m \"runs:\/ac105c61b91c418697db78bc6fe60639\/model\" -n \"my-image-name\"\r\n \r\nI got the following error\r\n\r\n**W: Failed to fetch http:\/\/archive.ubuntu.com\/ubuntu\/dists\/bionic\/InRelease  Cannot initiate the connection to archive.ubuntu.                                                                        com:80 (2001:67c:1360:8001::17). - connect (101: Network is unreachable) Cannot initiate the connection to archive.ubuntu.com                                                                        :80 (2001:67c:1560:8001::14). - connect (101: Network is unreachable) Cannot initiate the connection to archive.ubuntu.com:80**    \r\n\r\nI know I am working behind a http proxy, and I have got the docker \"run\" command to work after setting up the http proxy. but the docker \"build\" command always needs me to specify the http proxy in the command line using the \"build-args\"\r\n\r\nFor me to get this working, I think I need to either modify the default docker file that Mlflow uses to build the docker image to append the http-proxy param in it, or pass the http-proxy info to mlflow.\r\n\r\nIf it is the former, would you please share the location of the default docker file, or the code that produce it for me to change. if it is the later, please let me know how to pass on the http proxy info to mlflow so it can incorporate it into the docker build command.\r\n\r\nThank\r\n\r\n\r\n","784":"Add a new artifact viewer that can preview CSV and potentially other data in a tabular format.\r\n\r\n### Motivation\r\nWe've had a lot of previous interest in this feature in https:\/\/github.com\/mlflow\/mlflow\/pull\/436. It's generally helpful to be able to preview tabular data associated with a run in the artifact viewer.\r\n\r\n### Proposed Changes\r\nUse [ag-grid](https:\/\/www.ag-grid.com\/) to render data fetched client-side to preview tabular data. ","785":"Hi mlflow team,\r\n\r\ncurrently I do not see a way to use a Docker environment project with a login-protected docker registry.\r\n\r\n## Problem\r\n\r\nIn detail, the problem is that the Python `docker` package is used in the function `_docker_build` (https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/projects\/__init__.py#L754) and the Python docker client does not respect previous user logins to registries. Calling the `login` function of the client requires username and password also does not respect previous user login, and I do not see a (simple) safe way to provide the password. \r\n\r\n## Proposed Changes\r\n\r\nHowever, the docker command line client does respect user logins: the user can run `docker login [theregistry]`, the login data will be stored safely, and the user can work with the registry. I propose to remove the two calls to the Python `docker` package to calls to the shell `docker` client (as this is already done later to actually run the experiment in the docker image). This provides safe and consistent access to registries and removes the dependency to the Python docker package.\r\n","786":"## What changes are proposed in this pull request?\r\n\r\nThis ticket is about to fix https:\/\/github.com\/mlflow\/mlflow\/issues\/2475\r\n\r\nAdd a new service that list all columns of a experiment\r\nIn javascript, call this service when a new search is triggered.\r\n\r\nFor the future: Tags, params and metrics list are not injected in the ExperimentView component. It could be reuse to implement autocompletion in the search bar.\r\n\r\n## How is this patch tested?\r\n\r\nTested on our data + unit test\r\n\r\n![all_columns](https:\/\/user-images.githubusercontent.com\/658597\/76957626-6c932100-6916-11ea-92f7-2a9cec84227a.gif)\r\n\r\n\r\n## Release Notes\r\n### Is this a user-facing change?\r\n- [ ] No. You can skip the rest of this section.\r\n- [X] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nAll columns (parameters, tags, or metrics) are displayed in the experiment view even if the first runs does not contain values for these columns.\r\n\r\n### What component(s) does this PR affect?\r\n\r\n- [X] UI\r\n- [ ] CLI\r\n- [ ] API\r\n- [X] REST-API\r\n- [ ] Examples\r\n- [X] Docs\r\n- [X] Tracking\r\n- [ ] Projects\r\n- [ ] Artifacts\r\n- [ ] Models\r\n- [ ] Scoring\r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [X] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [X] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes","787":"I'm using mlflow with MySQL, and my artifacts are stored in S3.\r\nI manage the artifacts location for each run by myself.\r\nWhen creating a run with `MlflowClient`, looks like the `artifact_uri` is not something I can modify from outside.\r\n\r\nI couldn't find a way of changing the `artifact_uri` once the run was created.\r\n\r\nNOTE - I can make the update statement on MySQL by myself, but that's not something I want to do.","788":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Nope\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac\r\n- **MLflow installed from (source or binary)**: yep\r\n- **MLflow version (run ``mlflow --version``)**: 0.9.1\r\n- **Python version**: 2.7\r\n- **Exact command to reproduce**: mlflow sagemaker deploy --app-name super-model --model-path model --execution-role-arn arn:aws:iam::<account_id>:role\/service-role\/AmazonSageMaker-ExecutionRole --run-id d02fd1b8c16d4efa93a85a0510cd1b12 --image-url ecr.amazonaws.com\/mlflow:0.9.1 --mode replace --instance-type ml.t2.xlarge --instance-count 1 --vpc-config vpc_config_us_west_1.json --async --archive **--bucket bucket_in_us_east_1 --region-name us-west-1** \r\n\r\n### Describe the problem\r\nWhen SageMaker endpoint starts it fails with an error:\r\n`Failed to download model data for container \\\\\\\u201ccontainer_1\\\\\\\u201d from URL: \\\\\\\u201chttps:\/\/s3.us-west-1.amazonaws.com\/bucket_in_us_east_1\/d02fd1b8c16d4efa93a85a0510cd1b12\/model\/model.tar.gz\\\\\\\u201c. Please ensure that there is an object located at the URL and that the role passed to CreateModel has permissions to download the object.\\\u201c,\\\u201cregion\\\u201c:\\\u201cus-west-1\\\u201c}\u201d`\r\n\r\nSo in fact the bucket **bucket_in_us_east_1** does exist, but in different region us-east-1 whereas specified us-west-1.\r\n\r\n### Other info \/ logs\r\nI think the root cause of the error is that mlflow doesn't check the bucket region, but relies on url from the specified region.\r\nSo basically in order to this line of code to work:\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/c2f76f1aff4f12b80456c36427d8b2f55a8e5d32\/mlflow\/sagemaker\/__init__.py#L599\r\nthe client initialisation:\r\n`sess = boto3.Session(region_name=region_name)`\r\n needs to be in the same region as bucket:\r\n```\r\ns3 = boto3.resource('s3')\r\nbucket_region = s3.get_bucket_location(Bucket=bucket)['LocationConstraint']\r\nif bucket_region:\r\n    sess = boto3.Session(region_name = bucket_region) \r\nelse:\r\n    sess = boto3.Session()\r\n```\r\n","789":"## Describe the proposal\r\nAlongside the main `mlflow` PyPI package, we should consider publishing an `mlflow-client` package that excludes some of the heavier dependencies (sqlalchemy, alembic, flask, gunicorn) needed to run the MLflow server.\r\n\r\n### Motivation\r\nMany use cases do not actually require the MLflow server's dependencies - for example:\r\n* If running a production ML training job, it becomes harder to introduce MLflow when there are unneeded\/unused server dependencies - these increase the likelihood that MLflow will muck with the environment of your production job and change its behavior\r\n* If building a standard data-science docker image to share with your data science team, it becomes more complex to reason about the runtime environment if unnecessary server dependencies are pulled in. \r\n\r\n### Proposed Changes\r\nWe should additionally publish a standalone mlflow-client package containing only the Python client logic (i.e. for the tracking, projects, models, and model registry components). In particular, MLflow currently has the following Python requirements:\r\n\r\n```\r\n    install_requires=[\r\n        'alembic',\r\n        'click>=7.0',\r\n        'cloudpickle',\r\n        'databricks-cli>=0.8.7',\r\n        'requests>=2.17.3',\r\n        'six>=1.10.0',\r\n        'waitress; platform_system == \"Windows\"',\r\n        'gunicorn; platform_system != \"Windows\"',\r\n        'Flask',\r\n        'numpy',\r\n        'pandas',\r\n        'python-dateutil',\r\n        'protobuf>=3.6.0',\r\n        'gitpython>=2.1.0',\r\n        'pyyaml',\r\n        'querystring_parser',\r\n        'simplejson',\r\n        'docker>=4.0.0',\r\n        'entrypoints',\r\n        'sqlparse',\r\n        'sqlalchemy',\r\n        'gorilla',\r\n        'prometheus-flask-exporter',\r\n    ],\r\n```\r\n\r\nWhich contains the following, seemingly-unnecessary-for-client-only operation libraries:\r\n* `alembic`: used to run database migrations, currently invoked during initialization of the SqlAlchemyStore\r\n* `sqlalchemy`: used to perform database operations in SqlAlchemyStore\r\n* `waitress`, `gunicorn`, `flask`: used to run the open-source REST API server and serve MLflow models as part of `mlflow models serve`. Also used when building docker images for `mlflow sagemaker` and `mlflow azureml` CLIs?\r\n* `prometheus-flask-exporter`: used to expose service metrics to Prometheus when running the OSS server\r\n\r\nIf we were to remove these libraries, we'd end up with a client package dependent on:\r\n```\r\n    install_requires=[\r\n        'click>=7.0',\r\n        'cloudpickle',\r\n        'databricks-cli>=0.8.7',\r\n        'requests>=2.17.3',\r\n        'six>=1.10.0',\r\n        'numpy',\r\n        'pandas',\r\n        'python-dateutil',\r\n        'protobuf>=3.6.0',\r\n        'gitpython>=2.1.0',\r\n        'pyyaml',\r\n        'querystring_parser',\r\n        'simplejson',\r\n        'docker>=4.0.0',\r\n        'entrypoints',\r\n        'sqlparse',\r\n        'sqlalchemy',\r\n        'gorilla',\r\n    ],\r\n```\r\n\r\nWhich would be significantly smaller (TODO how much) & have a smaller transitive closure of dependencies.\r\n\r\n### What APIs will be available in the mlflow-client package? How will we document them?\r\nSay we publish an `mlflow-client` package with a reduced dependency set, but that this package contains all the APIs supported by the main `mlflow` package. This may lead to confusing behavior where users attempt to use APIs documented in the main package, only to find that they don't work (e.g. `mlflow models serve` will not work without the `gunicorn` server dependency, for example).\r\n\r\nOne simple approach could be to simply expose the same APIs (so that we don't need to separately document the two packages), but attempt to show informative error messages that clearly indicate to mlflow-client users why certain functionality fails or is otherwise unavailable.\r\n\r\nThe main APIs this is relevant for are (TODO flesh out this list):\r\n* `mlflow models serve` & `mlflow models predict`?\r\n* TODO: `mlflow sagemaker ...` and `mlflow azureml ...` CLIs?\r\n* \r\n\r\nMy hope is that this audit will show that the number of affected APIs is relatively small","790":"## What changes are proposed in this pull request?\r\n\r\nChanges to the composition of the docker cmd. It seems to be false ([please check my comment in the issue](https:\/\/github.com\/mlflow\/mlflow\/issues\/2501)). It also fails on windows. With the fix it works on Windows.\r\n\r\n## How is this patch tested?\r\n\r\nThrough simple usage of `mlflow run .` with MLProject as docker_env and a Dockerfile in the directory.\r\n\r\n## Release Notes\r\n\r\nFixed Docker Command, mounting wrong paths on container.\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nThis PR will change the docker command composition. I'm not aware of the whole scope of MLFlow Project, so i assume it might cause issues in another feature, that i am not aware of (closer review appreciated).\r\n\r\n### What component(s) does this PR affect?\r\n\r\n- [ ] UI\r\n- [x] CLI\r\n- [ ] API\r\n- [ ] REST-API\r\n- [ ] Examples\r\n- [ ] Docs\r\n- [ ] Tracking\r\n- [x] Projects\r\n- [ ] Artifacts\r\n- [ ] Models\r\n- [ ] Scoring\r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [x] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","791":"## Describe the proposal\r\nCan you please add compression to log_model? \r\n\r\n### Motivation\r\nThe motivation is that the files take less space on storage system. \r\nMy immediate usage is for Azure blob storage.\r\n\r\n### Proposed Changes\r\nyou would need to add a type to SUPPORTED_SERIALIZATION_FORMATS for example for sklearn it would a new type added to mlflow.sklearn.SUPPORTED_SERIALIZATION_FORMATS in addition to pickle and cloudpickel \r\n","792":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Simply tried to follow the tutorial example using my own PyTorch model.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: 1.7.0\r\n- **Python version**: 3.6.9\r\n- **npm version, if running the dev UI**: N\/A\r\n- **Exact command to reproduce**: N\/A\r\n\r\n### Describe the problem\r\nPyTorch [recommends storing the state dict instead of serializing the model](https:\/\/pytorch.org\/docs\/master\/notes\/serialization.html), seems like mlflow doesn't support ScriptModules? \r\n\r\n### Code to reproduce issue\r\n```python\r\nimport mlflow\r\nimport mlflow.pytorch\r\nimport torch\r\nimport torch.nn as nn\r\n\r\nclass Net(nn.Module):\r\n    def __init__(self):\r\n        super(Net, self).__init__()\r\n\r\n        self.lin1 = torch.jit.trace(nn.Linear(40, 20), torch.randn(1, 1, 40))\r\n        self.lin2 = torch.jit.trace(nn.Linear(20, 2), torch.randn(1, 1, 20))\r\n\r\n    def forward(self, x):\r\n        x = self.lin1(x)\r\n        x = self.lin2(x)\r\n        return x\r\n\r\nx = torch.randn(1, 40, 40)\r\nm = Net()\r\nprint(m(x).shape)\r\n\r\nwith mlflow.start_run():\r\n    mlflow.pytorch.log_model(m, \"model\")\r\n```\r\n### Other info \/ logs\r\nError:\r\n```\r\n File \"\/home\/kiran\/anaconda3\/lib\/python3.6\/site-packages\/torch\/jit\/__init__.py\", line 1712, in __getstate__\r\n    \"For purely script modules use my_script_module.save(<filename>) instead.\")\r\n_pickle.PickleError: ScriptModules cannot be deepcopied using copy.deepcopy or saved using torch.save. Mixed serialization of script and non-script modules is not supported. For purely script modules use my_script_module.save(<filename>) instead.\r\n```","793":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\nPlease fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: We've written infrastructure code but at the core we're trying to call `mlflow server` with `backend_store_uri` and `default_artifact_store`.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian GNU\/Linux 10\r\n- **MLflow installed from (source or binary)**: Source\r\n- **MLflow version (run ``mlflow --version``)**: 1.5.0\r\n- **Python version**: 3.7.6\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n```\r\nmlflow server \\\r\n  --backend-store-uri postgresql+psycopg2:\/\/$DB_USER:$DB_PW@$DB_ADDRESS:$DB_PORT\/$DB_NAME \\\r\n  --default-artifact-root s3:\/\/redacted \\\r\n  --host 0.0.0.0 \\\r\n  --port 5000 \\\r\n  --workers 1\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\nExpected: Command starts up the gunicorn workers with storage backed by Postgres (RDS) and S3.\r\n\r\nActual: The command exits with the following logs (set level to DEBUG in alembic.ini)\r\n```\r\n2020\/03\/04 20:47:14 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\r\n2020\/03\/04 20:47:14 INFO mlflow.store.db.utils: Updating database tables at postgresql+psycopg2:\/\/personalization:gBAvghsfANbkQeTZ2djQcpuv@dev-personalization.cxzg8lc498ob.us-east-1.rds.amazonaws.com:5432\/personalization\r\nINFO  [sqlalchemy.engine.base.Engine] select version()\r\nINFO  [sqlalchemy.engine.base.Engine] {}\r\nDEBUG [sqlalchemy.engine.base.Engine] Col ('version',)\r\nDEBUG [sqlalchemy.engine.base.Engine] Row ('PostgreSQL 11.4 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-11), 64-bit',)\r\nINFO  [sqlalchemy.engine.base.Engine] select current_schema()\r\nINFO  [sqlalchemy.engine.base.Engine] {}\r\nDEBUG [sqlalchemy.engine.base.Engine] Col ('current_schema',)\r\nDEBUG [sqlalchemy.engine.base.Engine] Row ('public',)\r\nINFO  [sqlalchemy.engine.base.Engine] SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1\r\nINFO  [sqlalchemy.engine.base.Engine] {}\r\nINFO  [sqlalchemy.engine.base.Engine] SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1\r\nINFO  [sqlalchemy.engine.base.Engine] {}\r\nINFO  [sqlalchemy.engine.base.Engine] show standard_conforming_strings\r\nINFO  [sqlalchemy.engine.base.Engine] {}\r\nDEBUG [sqlalchemy.engine.base.Engine] Col ('standard_conforming_strings',)\r\nDEBUG [sqlalchemy.engine.base.Engine] Row ('on',)\r\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\r\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\r\nINFO  [sqlalchemy.engine.base.Engine] BEGIN (implicit)\r\nINFO  [sqlalchemy.engine.base.Engine] select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\r\nINFO  [sqlalchemy.engine.base.Engine] {'name': 'alembic_version'}\r\nDEBUG [sqlalchemy.engine.base.Engine] Col ('relname',)\r\nDEBUG [sqlalchemy.engine.base.Engine] Row ('alembic_version',)\r\nINFO  [sqlalchemy.engine.base.Engine] SELECT alembic_version.version_num \r\nFROM alembic_version\r\nINFO  [sqlalchemy.engine.base.Engine] {}\r\nDEBUG [sqlalchemy.engine.base.Engine] Col ('version_num',)\r\nDEBUG [sqlalchemy.engine.base.Engine] Row ('7939bcff74ba',)\r\nINFO  [sqlalchemy.engine.base.Engine] ROLLBACK\r\n```\r\n\r\nI can't find any errors that would be cause the process to exit.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nThis command worked previously on this database so the tables are already present.\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks,\r\nplease include the full traceback. Large logs and files should be attached.\r\n","794":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: NO\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: 1.7.0\r\n- **Python version**: 3.6\r\n- **npm version, if running the dev UI**: 6.13.7\r\n- **Exact command to reproduce**: mlflow gc --backend-store-uri postgresql:\/\/\/mlflow\r\n\r\n### Describe the problem\r\nTrying to use mlflow gc command on an existing postgres mlflow databse leads to the following error.\r\n\r\n### Code to reproduce issue\r\nRun command `mlflow gc --backend-store-uri postgresql:\/\/\/mlflow`\r\n\r\n### Other info \/ logs\r\n\r\n```\r\n\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/sqlalchemy\/orm\/persistence.py:1365: SAWarning: DELETE statement on table 'metrics' expected to delete 480 row(s); 72 were matched.  Please set confirm_deleted_rows=False within the mapper configuration to prevent this warning.\r\n  % (table.description, expected, rows_matched)\r\nTraceback (most recent call last):\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/sqlalchemy\/engine\/base.py\", line 1246, in _execute_context\r\n    cursor, statement, parameters, context\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/sqlalchemy\/engine\/default.py\", line 588, in do_execute\r\n    cursor.execute(statement, parameters)\r\npsycopg2.errors.ForeignKeyViolation: update or delete on table \"runs\" violates foreign key constraint \"metrics_run_uuid_fkey\" on table \"metrics\"\r\nDETAIL:  Key (run_uuid)=(5dfec66f8711470c85245a349da31a09) is still referenced from table \"metrics\".\r\n\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"\/home\/sadanand\/Projects\/mlflow-dojo\/mlflow\/store\/db\/utils.py\", line 73, in make_managed_session\r\n    yield session\r\n  File \"\/home\/sadanand\/Projects\/mlflow-dojo\/mlflow\/store\/tracking\/sqlalchemy_store.py\", line 499, in _hard_delete_run\r\n    session.commit()\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/sqlalchemy\/orm\/session.py\", line 1036, in commit\r\n    self.transaction.commit()\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/sqlalchemy\/orm\/session.py\", line 503, in commit\r\n    self._prepare_impl()\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/sqlalchemy\/orm\/session.py\", line 482, in _prepare_impl\r\n    self.session.flush()\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/sqlalchemy\/orm\/session.py\", line 2479, in flush\r\n    self._flush(objects)\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/sqlalchemy\/orm\/session.py\", line 2617, in _flush\r\n    transaction.rollback(_capture_exception=True)\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/sqlalchemy\/util\/langhelpers.py\", line 68, in __exit__\r\n    compat.reraise(exc_type, exc_value, exc_tb)\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/sqlalchemy\/util\/compat.py\", line 153, in reraise\r\n    raise value\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/sqlalchemy\/orm\/session.py\", line 2577, in _flush\r\n    flush_context.execute()\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/sqlalchemy\/orm\/unitofwork.py\", line 422, in execute\r\n    rec.execute(self)\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/sqlalchemy\/orm\/unitofwork.py\", line 624, in execute\r\n    uow,\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/sqlalchemy\/orm\/persistence.py\", line 348, in delete_obj\r\n    delete,\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/sqlalchemy\/orm\/persistence.py\", line 1341, in _emit_delete_statements\r\n    c = connection.execute(statement, del_objects)\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/sqlalchemy\/engine\/base.py\", line 982, in execute\r\n    return meth(self, multiparams, params)\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/sqlalchemy\/sql\/elements.py\", line 293, in _execute_on_connection\r\n    return connection._execute_clauseelement(self, multiparams, params)\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/sqlalchemy\/engine\/base.py\", line 1101, in _execute_clauseelement\r\n    distilled_params,\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/sqlalchemy\/engine\/base.py\", line 1250, in _execute_context\r\n    e, statement, parameters, cursor, context\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/sqlalchemy\/engine\/base.py\", line 1476, in _handle_dbapi_exception\r\n    util.raise_from_cause(sqlalchemy_exception, exc_info)\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/sqlalchemy\/util\/compat.py\", line 398, in raise_from_cause\r\n    reraise(type(exception), exception, tb=exc_tb, cause=cause)\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/sqlalchemy\/util\/compat.py\", line 152, in reraise\r\n    raise value.with_traceback(tb)\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/sqlalchemy\/engine\/base.py\", line 1246, in _execute_context\r\n    cursor, statement, parameters, context\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/sqlalchemy\/engine\/default.py\", line 588, in do_execute\r\n    cursor.execute(statement, parameters)\r\nsqlalchemy.exc.IntegrityError: (psycopg2.errors.ForeignKeyViolation) update or delete on table \"runs\" violates foreign key constraint \"metrics_run_uuid_fkey\" on table \"metrics\"\r\nDETAIL:  Key (run_uuid)=(5dfec66f8711470c85245a349da31a09) is still referenced from table \"metrics\".\r\n\r\n[SQL: DELETE FROM runs WHERE runs.run_uuid = %(run_uuid)s]\r\n[parameters: {'run_uuid': '5dfec66f8711470c85245a349da31a09'}]\r\n(Background on this error at: http:\/\/sqlalche.me\/e\/gkpj)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/bin\/mlflow\", line 11, in <module>\r\n    load_entry_point('mlflow', 'console_scripts', 'mlflow')()\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/click\/core.py\", line 764, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/click\/core.py\", line 717, in main\r\n    rv = self.invoke(ctx)\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/click\/core.py\", line 1137, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/click\/core.py\", line 956, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/site-packages\/click\/core.py\", line 555, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"\/home\/sadanand\/Projects\/mlflow-dojo\/mlflow\/cli.py\", line 422, in gc\r\n    backend_store._hard_delete_run(run_id)\r\n  File \"\/home\/sadanand\/Projects\/mlflow-dojo\/mlflow\/store\/tracking\/sqlalchemy_store.py\", line 499, in _hard_delete_run\r\n    session.commit()\r\n  File \"\/home\/sadanand\/anaconda3\/envs\/py36-dev\/lib\/python3.6\/contextlib.py\", line 99, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"\/home\/sadanand\/Projects\/mlflow-dojo\/mlflow\/store\/db\/utils.py\", line 80, in make_managed_session\r\n    raise MlflowException(message=e, error_code=INTERNAL_ERROR)\r\nmlflow.exceptions.MlflowException: (psycopg2.errors.ForeignKeyViolation) update or delete on table \"runs\" violates foreign key constraint \"metrics_run_uuid_fkey\" on table \"metrics\"\r\nDETAIL:  Key (run_uuid)=(5dfec66f8711470c85245a349da31a09) is still referenced from table \"metrics\".\r\n\r\n[SQL: DELETE FROM runs WHERE runs.run_uuid = %(run_uuid)s]\r\n[parameters: {'run_uuid': '5dfec66f8711470c85245a349da31a09'}]\r\n(Background on this error at: http:\/\/sqlalche.me\/e\/gkpj\r\n```\r\n","795":"## What changes are proposed in this pull request?\r\n\r\nPreviously the best found parameters were only logged as tags, while the best metrics were logged as proper metrics. Let's log the parameters as well, so they can be viewed easier.\r\n\r\n## How is this patch tested?\r\n\r\nRun the relevant hyperparameter tuning example for hyperopt, and checked that values were logged correctly.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nWhen running the hyperopt example, the parent at the end of the runs also log the parameters for the best found solution, as proper parameters, not just a tag.\r\n\r\n### What component(s) does this PR affect?\r\n\r\n- [ ] UI\r\n- [ ] CLI\r\n- [ ] API\r\n- [ ] REST-API\r\n- [x] Examples\r\n- [ ] Docs\r\n- [ ] Tracking\r\n- [ ] Projects\r\n- [ ] Artifacts\r\n- [ ] Models\r\n- [ ] Scoring\r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","796":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Debian (Docker from python:3.7)\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: Tested on 1.6.0 and 1.7.0\r\n- **Python version**: 3.7\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: none\r\n\r\n### Describe the problem\r\nWhen logging large images (height-wise) the MLflow **server** UI cannot resize the Plotly Graph correctly in the Artifacts section (see the image below)\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/6637618\/75756738-6f482080-5d31-11ea-87fd-c2426293f7ca.png)\r\n\r\nThis image was automatically generated by `mlflow.lightgbm.autolog()` when the model has a lot of variables.\r\n\r\n**Expected looks:**\r\nLarger image with scrolling bar.\r\n![image](https:\/\/user-images.githubusercontent.com\/6637618\/75759388-c3ed9a80-5d35-11ea-80a1-64114d6af04d.png)\r\n\r\n\r\n### Code to reproduce issue\r\nLog any big image as artifact. For comparison, you can find the file `mlflow.lightgbm.autolog()` produced [here](https:\/\/user-images.githubusercontent.com\/6637618\/75758468-77ee2600-5d34-11ea-8b2d-46b9d43813bb.png).\r\n\r\n```python\r\nimport mlflow\r\nwith mlflow.start_run():\r\n    mlflow.log_artifact(big_image)\r\n```\r\n\r\n\r\n\r\n","797":"## Describe the proposal\r\nMLflow experiments can have tags but these tags are not visible in the mlflow ui.  The proposal is to display these tags in the ui, perhaps in the header near the experiment name, id, and notes.  \r\n\r\n### Motivation\r\nIf using experiment tags to organize experiments, being able to view these easily in the ui would facilitate a better workflow.  For example, if an experiment is run with a particular data version or model version and tagged with this data, it would be useful to see it in the ui.\r\n\r\n### Proposed Changes\r\nI am unsure on implementation details, but believe the APIs exist to allow incorporating this on the frontend.","798":"## Proposal\r\nCurrently, when using an MLflow server in combination with an AWS S3 bucket as artifact storage, clients are required to be able to directly upload and download artifacts to S3. As a new feature, please enable upload and download of artifacts via MLflow server (HTTP interface) in the same way as parameters, tags and metrics can be uploaded and downloaded via the MLflow server.\r\n\r\n### Motivation\r\nThis feature will remove the requirement that clients need to setup a security solution for authentication and authorization of direct access to an S3 bucket. Also, users of MLflow server with other types of backend storage such server-side file system will benefit in the same way.","799":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/docker\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **MLflow installed from (source or binary)**: pip install mlflow\r\n- **MLflow version (run ``mlflow --version``)**: 1.6\r\n- **Python version**: 3.7.6\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: mlflow run examples\/docker -P alpha=0.5\r\n\r\n### Describe the problem\r\nThe example MLflow project (and my own aswell) using a docker_env and run with above command throws a docker error.\r\n\r\nExpected behavior: Python file is executed and tracked and run is added in mlruns.\r\n\r\nActual behavior: \r\ndocker throws an error\r\n> docker: Error response from daemon: invalid mode: \\git_repos\\mlflow_example\\mlruns\\0\\e6763b1645214c54bb5d606e3be72170\\artifacts.\r\n\r\nThe problem seems to be that mlflow tries passes a -v flag to docker to map a host directory to itself:\r\n_docker run --rm -v D:\\git_repos\\mlflow_example\\mlruns:\/mlflow\/tmp\/mlruns **-v D:\\git_repos\\mlflow_example\\mlruns\\0\\e6763b1645214c54bb5d606e3be72170\\artifacts:D:\\git_repos\\mlflow_example\\mlruns\\0\\e6763b1645214c54bb5d606e3be72170\\artifacts** -e MLFLOW_RUN_ID=e6763b1645214c54bb5d606e3be72170 -e MLFLOW_TRACKING_URI=file:\/\/\/mlflow\/tmp\/mlruns -e MLFLOW_EXPERIMENT_ID=0 docker-example:93e3a50 python train.py --alpha 0.5 --l1-ratio 0.1' in run with ID 'e6763b1645214c54bb5d606e3be72170_\r\n\r\n\r\n### Code to reproduce issue\r\nSimply follow the instrucitons in [https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/docker]\r\n\r\n### Other info \/ logs\r\n`(CGa_env) D:\\git_repos\\mlflow_example>mlflow run examples\/docker -P alpha=0.5\r\n2020\/02\/27 16:31:49 INFO mlflow.projects: === Building docker image docker-example:93e3a50 ===\r\n2020\/02\/27 16:31:49 INFO mlflow.projects: Temporary docker context file C:\\Users\\CC073~1.GAI\\AppData\\Local\\Temp\\tmpfp1uz6ee was not deleted.\r\n2020\/02\/27 16:31:49 INFO mlflow.projects: === Created directory C:\\Users\\CC073~1.GAI\\AppData\\Local\\Temp\\tmp88nz0lmt for downloading remote URIs passed to arguments of type 'path' ===\r\n2020\/02\/27 16:31:49 INFO mlflow.projects: === Running command 'docker run --rm -v D:\\git_repos\\mlflow_example\\mlruns:\/mlflow\/tmp\/mlruns -v D:\\git_repos\\mlflow_example\\mlruns\\0\\e6763b1645214c54bb5d606e3be72170\\artifacts:D:\\git_repos\\mlflow_example\\mlruns\\0\\e6763b1645214c54bb5d606e3be72170\\artifacts -e MLFLOW_RUN_ID=e6763b1645214c54bb5d606e3be72170 -e MLFLOW_TRACKING_URI=file:\/\/\/mlflow\/tmp\/mlruns -e MLFLOW_EXPERIMENT_ID=0 docker-example:93e3a50 python train.py --alpha 0.5 --l1-ratio 0.1' in run with ID 'e6763b1645214c54bb5d606e3be72170' ===\r\ndocker: Error response from daemon: invalid mode: \\git_repos\\mlflow_example\\mlruns\\0\\e6763b1645214c54bb5d606e3be72170\\artifacts.\r\nSee 'docker run --help'.\r\n2020\/02\/27 16:31:49 ERROR mlflow.cli: === Run (ID 'e6763b1645214c54bb5d606e3be72170') failed ===`\r\n","800":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\nPlease fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 10.15.3\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**:1.6\r\n- **Python version**:3.8.1\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nSagemaker endpoint creation failed after running CLI command :\r\nmlflow sagemaker deploy -a $APP_NAME --model-uri $MODEL_URI -e $ROLE --region-name $REGION\r\n\r\n(see logs from cloudwatch below)\r\n\r\n### Code to reproduce issue\r\nexport APP_NAME=keras-model-1\r\nexport MODEL_URI=\/Users\/sigmarabi1\/Environments\/R_Env\/mlruns\/0\/5ec40745c50b4e7db12949d17328f74b\/artifacts\/keras_model\r\nexport REGION=us-east-2\r\nexport ROLE=arn:aws:iam::***:role\/service-role\/AmazonSageMaker-ExecutionRole-***\r\n\r\nmlflow sagemaker deploy -a $APP_NAME --model-uri $MODEL_URI -e $ROLE --region-name $REGION\r\n\r\n### Other info \/ logs\r\nTimestamp | Message\r\n-- | --\r\n2020-02-27T00:37:35.875-05:00 | UnavailableInvalidChannel: The channel is not accessible or is invalid. channel name: d channel url: https:\/\/conda.anaconda.org\/d error code: 404\r\n-- | --\r\n2020-02-27T00:37:35.875-05:00 | You will need to adjust your conda configuration to proceed.\r\n-- | --\r\n2020-02-27T00:37:35.875-05:00 | Use `conda config --show channels` to view your configuration's current state,\r\n-- | --\r\n2020-02-27T00:37:35.876-05:00 | and use `conda config --show-sources` to view config file locations.\r\n-- | --\r\n2020-02-27T00:37:35.876-05:00 | Traceback (most recent call last):  File \"<string>\", line 1, in <module>  File \"\/miniconda\/lib\/python3.7\/site-packages\/mlflow\/models\/container\/__init__.py\", line 48, in _init    _serve()  File \"\/miniconda\/lib\/python3.7\/site-packages\/mlflow\/models\/container\/__init__.py\", line 74, in _serve    _serve_pyfunc(m)  File \"\/miniconda\/lib\/python3.7\/site-packages\/mlflow\/models\/container\/__init__.py\", line 126, in _serve_pyfunc    _install_pyfunc_deps(MODEL_PATH, install_mlflow=True)  File \"\/miniconda\/lib\/python3.7\/site-packages\/mlflow\/models\/container\/__init__.py\", line 104, in _install_pyfunc_deps    raise Exception(\"Failed to create model environment.\")\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n","801":"## What changes are proposed in this pull request?\r\nFixes #2426 : Optimize docker image size\r\n\r\n## How is this patch tested?\r\n\r\nCreated a docker image using below command:\r\nmlflow models build-docker -m model -n docker_image_name --install-mlflow --no-conda\r\n\r\n## Release Notes\r\nWith this new feature, docker image is created either for python flavor or java flavor based on the model for which docker image is being created for. \r\n\r\nAlso added a new arguments to build-docker ``--no-conda`` that doesn't create a new conda environment \"custom_env\" instead uses the default miniconda base environment. \r\n\r\nThe current docker image size for sklearn iris example is 3.21GB and with the new changes docker image size is reduced to 2.14GB and by using ``--no-conda`` option (ie., using base miniconda environment), docker image size can be further reduced to 887MB.\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [X] Yes. Reduces the docker image size.\r\n\r\n### What component(s) does this PR affect?\r\n\r\n- [ ] UI\r\n- [X] CLI\r\n- [ ] API\r\n- [ ] REST-API\r\n- [ ] Examples\r\n- [ ] Docs\r\n- [ ] Tracking\r\n- [ ] Projects\r\n- [ ] Artifacts\r\n- [x] Models\r\n- [ ] Scoring\r\n- [ ] Serving\r\n- [ ] R\r\n- [X] Java\r\n- [X] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [X] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","802":"### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **MLflow installed from (source or binary)**: pip install mlflow\r\n- **MLflow version (run ``mlflow --version``)**: mlflow, version 1.6.0\r\n- **Python version**: Python 3.6.8\r\n- **Exact command to reproduce**: mlflow.sagemaker.deploy\r\n\r\n### Describe the problem\r\nWhen trying to deploy a model using `mlflow.sagemaker.deploy`, and `bucket=None` and a region: `us-west-2`, it goes to the function `_get_default_s3_bucket` and tries to create a bucket `s3.create_bucket`, but the problem is that `s3` object was initialized by default to `us-west-1` so it throws the error `IllegalLocationConstraintException`.\r\n\r\nThe solution should be to initialize the s3 session with the `region_name`\r\n\r\n\r\n### Code to reproduce issue\r\n`    mfs.deploy(app_name = app_name,\r\n            model_uri = model_uri,\r\n            region_name = \"us-west-2\",\r\n            mode = \"replace\", # like that you can overwrite\r\n            execution_role_arn = arn,\r\n            image_url = image_url)`\r\n\r\n### Other info \/ logs\r\n`botocore.exceptions.ClientError: An error occurred (IllegalLocationConstraintException) when calling the CreateBucket operation: The us-west-2 location constraint is incompatible for the region specific endpoint this request was sent to.`\r\n","803":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Centos\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: latest\r\n- **Python version**: 3.6\r\n- **npm version, if running the dev UI**: \r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nColumns (metrics, params, tags) in the ExperimentView are computed from the run displayed in the page. If a column is not present in the first X runs, it will not be in the UI..\r\nIt does not work well with the sorting & fitlering features. Following the runs that have been extracted from DB, the columns will change. \r\n![columnsmlflow](https:\/\/user-images.githubusercontent.com\/658597\/75256072-2fd67d00-57e3-11ea-80ad-d555b0cb7f43.gif)\r\n\r\n\r\n\r\n### Code to reproduce issue\r\nSort on a experiments with numerous runs but different tags,metrics and params\r\n","804":"SQL Server provides ML functionality through SQL Server Machine Learning Services that allow running Python scripts on relational data. This includes feature engineering, model training and model deployment within the database.\r\n\r\nDeploying models through MLflow to SQL Server is important for users that might train their models either outside SQL Server (e.g., using Spark in Microsoft\u2019s Big Data Cluster) or in SQL Server but want to eventually score the model in a different SQL Server instance for data privacy\/governance reasons as a large fraction of production data is still in the RDBMS. One such scenario would be training the model in the Big Data Cluster on-prem, but eventually deploying the model on SQL Edge.\r\n\r\nI have  created a [document ](https:\/\/docs.google.com\/document\/d\/1lJbxzIngLO5hOi0hGzlHljPdnc395OJTLT9T2PqmIUs\/edit?usp=sharing) that provides a high-level description on how to implement the deploy operation in SQL Server. The plan is to proceed in two steps:\r\n\r\n1) Implement a deploy operation through the following API:\r\n`mlflow database deploy --db_uri --flavor --table-name --column-name`\r\n\r\nWe already have a prototype for the ONNX flavors (See document for more details).\r\nIn this first part, we will simply download the model from the artifact store, make sure it is supported by SQL Server, and store it in the table\/column that the user provided as a BLOB.\r\n\r\n2) In the second step, we want to additionally automatically generate a SQL query (or stored procedure) that can be used to score the model in SQL Server. Please see a high-level description of this part on the document. We'd like to note that this part is not fully-fledged yet as we are in discussions with the SQL Server team on what is the best way to do this in the database. Once we have more clearance on some of the implementation issues, I will update the document with more concrete information.\r\n\r\n\r\n","805":"I have been trying to specify experiment name and artifact location for multiple experimentation runs.\r\nI used `create_experiment` and it worked fine in the first run, but it returned `MlflowException` in the second run apparently because `create_experiment` expects a unique experiment name.\r\n\r\nI managed to find a workaround using `try` and `except` as follows.\r\n\r\n```pytyon\r\nfrom mlflow import (\r\n    create_experiment,\r\n    set_experiment,\r\n    start_run,\r\n)\r\nfrom mlflow.exceptions import MlflowException\r\n\r\n# Some code here\r\n\r\n            try:\r\n                experiment_id = create_experiment(\r\n                    self.experiment_name, artifact_location=self.artifact_location\r\n                )\r\n                start_run(experiment_id=experiment_id)\r\n            except MlflowException:\r\n                set_experiment(self.experiment_name)\r\n```\r\n\r\nThis workaround does not look intuitive to me.\r\nI would like `create_experiment` to allow existing experiment name for intuitive multiple runs under the same experiment name.\r\n\r\nI use the latest version (1.6.0) of MLflow.","806":"Dear all,\r\n\r\n\r\nWe are using MLFlow with artifact store on S3. We have several AWS accounts (e.g. data science, production) to collaborate from. Also, we allow anonymous access to the models via VPN.\r\nBecause of how S3 is working [Why can't I access an object that was uploaded to my Amazon S3 bucket by another AWS account?](https:\/\/aws.amazon.com\/premiumsupport\/knowledge-center\/s3-bucket-owner-access\/): \r\n\r\n> By default, an S3 object is owned by the AWS account that uploaded it. This is true even when the bucket is owned by another account. To get access to the object, the object owner must explicitly grant you (the bucket owner) access.\r\n> \r\n> The object owner can grant the bucket owner full control of the object by updating the access control list (ACL) of the object. The object owner can update the ACL either during a put or copy operation, or after the object is added to the bucket.\r\n\r\n\r\nObviously we have the issue with access to the tracked models updated from different accounts. \r\n\r\nThe solution is to allow the bucket owner to have full or partial access to the objects in  `upload_file` via `(boto3.s3.transfer.TransferConfig)` ([boto3](https:\/\/boto3.amazonaws.com\/v1\/documentation\/api\/latest\/reference\/customizations\/s3.html#boto3.s3.transfer.S3Transfer.ALLOWED_UPLOAD_ARGS))\r\n\r\nThe ``upload_file`` and ``download_file`` methods also accept\r\n``**kwargs``, which will be forwarded through to the corresponding\r\nclient operation.  Here are a few examples using ``upload_file``::\r\n```\r\n    # Making the object public\r\n    transfer.upload_file('\/tmp\/myfile', 'bucket', 'key',\r\n                         extra_args={'ACL': 'bucket-owner-full-control'})\r\n\r\n```\r\nfor put_object it's easy\r\n```\r\nresponse = client.put_object(\r\n    ACL=''bucket-owner-read'|'bucket-owner-full-control',\r\n    Bucket='string',\r\n``` \r\n\r\n### Proposed Changes\r\nAdd bypass ACL from CLI\/environment \r\n to `log_artifacts` at https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/store\/artifact\/s3_artifact_repo.py#L53\r\n\r\n","807":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS\r\n- **MLflow installed from (source or binary)**: pip\r\n- **MLflow version (run ``mlflow --version``)**: from 0.8.1 to 1.6.0\r\n- **Python version**: 3.7\r\n- **Exact command to reproduce**: \r\n`mlflow\/examples\/xgboost > mlflow run .`\r\n\r\n### Describe the problem\r\nWhenever pip fails to install a dependency (artifactory unavailable or wrong version specified), mlflow doesn't remove conda environment as it does if conda dependency fails. This way, on second run, mlflow re-uses this environment since content of conda.yaml doesn't change. However, conda environment cannot be re-used when it is not successfully setup by both conda and pip.  \r\n\r\n### Code to reproduce issue\r\n`conda.yaml`\r\n\r\n> name: xgboost-example\r\n> channels:\r\n>   - defaults\r\n>   - conda-forge\r\n> dependencies:\r\n>   - python=3.6\r\n>   - xgboost\r\n>   - pip:\r\n>       - git+https:\/\/github.com\/mlflow\/mlflow==0\r\n> \r\n\r\n..\r\n`mlflow\/examples\/xgboost > mlflow run .`\r\n\r\n\r\n\r\n### Other info \/ logs\r\n\r\n> 2020\/02\/20 21:58:30 INFO mlflow.projects: === Creating conda environment **mlflow-605ca3beec0d13ae6e16f10cf433d51db8e58a09** ===\r\n> Collecting package metadata (repodata.json): \r\n...\r\n> CondaEnvException: Pip failed\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"\/Users\/username\/anaconda3\/bin\/mlflow\", line 11, in <module>\r\n>     load_entry_point('mlflow==0.9.1', 'console_scripts', 'mlflow')()\r\n>   File \"\/Users\/username\/anaconda3\/lib\/python3.7\/site-packages\/click\/core.py\", line 764, in __call__\r\n>     return self.main(*args, **kwargs)\r\n>   File \"\/Users\/username\/anaconda3\/lib\/python3.7\/site-packages\/click\/core.py\", line 717, in main\r\n>     rv = self.invoke(ctx)\r\n>   File \"\/Users\/username\/anaconda3\/lib\/python3.7\/site-packages\/click\/core.py\", line 1137, in invoke\r\n>     return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n>   File \"\/Users\/username\/anaconda3\/lib\/python3.7\/site-packages\/click\/core.py\", line 956, in invoke\r\n>     return ctx.invoke(self.callback, **ctx.params)\r\n>   File \"\/Users\/username\/anaconda3\/lib\/python3.7\/site-packages\/click\/core.py\", line 555, in invoke\r\n>     return callback(*args, **kwargs)\r\n>   File \"\/Users\/username\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/cli.py\", line 139, in run\r\n>     run_id=run_id,\r\n>   File \"\/Users\/username\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/projects\/__init__.py\", line 230, in run\r\n>     storage_dir=storage_dir, block=block, run_id=run_id)\r\n>   File \"\/Users\/username\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/projects\/__init__.py\", line 132, in _run\r\n>     conda_env_name = _get_or_create_conda_env(project.conda_env_path)\r\n>   File \"\/Users\/username\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/projects\/__init__.py\", line 462, in _get_or_create_conda_env\r\n>     conda_env_path], stream_output=True)\r\n>   File \"\/Users\/username\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/utils\/process.py\", line 38, in exec_cmd\r\n>     raise ShellCommandException(\"Non-zero exitcode: %s\" % (exit_code))\r\n> mlflow.utils.process.ShellCommandException: Non-zero exitcode: 1\r\n\r\n`conda env list |grep mlflow-605ca3beec0d13ae6e16f10cf433d51db8e58a09`\r\n>mlflow-605ca3beec0d13ae6e16f10cf433d51db8e58a09     \/Users\/username\/anaconda3\/envs\/mlflow-605ca3beec0d13ae6e16f10cf433d51db8e58a09\r\n\r\n","808":"## What changes are proposed in this pull request?\r\nAdd action type to MLProjects parameters. Currently there is support for string, uri, path and float. \r\n\r\nRelated issue:\r\nhttps:\/\/github.com\/mlflow\/mlflow\/issues\/1945\r\n\r\nHowever, to make this consistent with current parameter support there is no support for making the parameters optional but rather allow users to pass default value.\r\n\r\n## How is this patch tested?\r\nUnit tested and tests are included in test_entry_point in projects tests.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nAdd support for action type.\r\n\r\n### What component(s) does this PR affect?\r\n\r\n- [ ] UI\r\n- [ ] CLI\r\n- [ ] API\r\n- [ ] REST-API\r\n- [ ] Examples\r\n- [ ] Docs\r\n- [ ] Tracking\r\n- [x] Projects\r\n- [ ] Artifacts\r\n- [ ] Models\r\n- [ ] Scoring\r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [x] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [x] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","809":"how to log output from sklearn.roc_curve with mlflow.log_metric() ? The reason is the output is in array instead of single value. I would like to use the charting feature of mlflow.","810":"## What changes are proposed in this pull request?\r\n\r\nFix propagation of auth credentials to enable running MLflow projects from notebooks\r\n\r\n## How is this patch tested?\r\n\r\nTested manually in a notebook environment\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nFixes a bug that prevented running MLflow projects from within the Databricks notebook environment\r\n\r\n### What component(s) does this PR affect?\r\n\r\n- [ ] UI\r\n- [ ] CLI\r\n- [ ] API\r\n- [ ] REST-API\r\n- [ ] Examples\r\n- [ ] Docs\r\n- [ ] Tracking\r\n- [ ] Projects\r\n- [ ] Artifacts\r\n- [ ] Models\r\n- [ ] Scoring\r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","811":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\nPlease fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Applies to OSX, Unix, Windows\r\n- **MLflow installed from (source or binary)**: Binary (pip)\r\n- **MLflow version (run ``mlflow --version``)**: 1.6.0\r\n- **Python version**: 3.7\r\n- **npm version, if running the dev UI**: NA\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nFor distributed ML use cases, it is often useful to create multiple child runs within a single parent run from multiple nodes \/ processes. Accomplishing this task currently requires the following procedure:\r\n\r\n1. On the driver, create a parent run `run A`\r\n2. On the worker, resume `run A`\r\n3. On the worker, once `run A` has been resumed, create a nested run: `run B`\r\n\r\nThe worker procedure requires two separate calls to `mlflow.start_run()`, as follows:\r\n```\r\nwith mlflow.start_run(run_id=<run_id_of_run_A>):\r\n    with mlflow.start_run(nested=True):\r\n        mlflow.log_param(\"my-param\", \"my-value\")\r\n```\r\n\r\nThe following attempt to shorten\/optimize this procedure fails to create a nested run:\r\n```\r\nwith mlflow.start_run(run_id=run_id, nested=True):\r\n    mlflow.log_param(\"my-param\", \"my-value\")\r\n```\r\n\r\nIn this case, `my-param` is logged directly to `run A`, rather than a new nested run (`run B`). Apparently, the `nested=True` argument is ignored in this case.\r\n\r\nBased on the documentation for `start_run()` (https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.start_run), it seems like a new nested run should be created:\r\n```\r\nnested \u2013 Controls whether run is nested in parent run. True creates a nest run.\r\n```\r\n\r\nAccordingly, the current behavior appears to be a bug.","812":"## Describe the proposal\r\nChange the different plugin registries by lazy load functions. It will change all plugins except RunContextProviders\r\n\r\n### Motivation\r\nCurrently the registries load all plugin installed in current virtual environment. If one plugin fails to be loaded, the error is caught (https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/tracking\/context\/registry.py#L33) It makes the debug of the plugin more difficult.\r\nThe suggestion is to load the plugin on demand and don't catch the error if the plugin fails to be loaded.\r\n\r\n### Proposed Changes\r\nRemove Registry class. Replace by loader functions that use `entrypoints`","813":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian GNU\/Linux 10 (buster)\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.6.0\r\n- **Python version**: 3.7.6 \r\n- psycopg2-binary 2.8.4\r\n- backend: Postgres 11\r\n\r\n### Describe the problem\r\n\r\nI try to use a PostgreSQL database as a backend for ML Flow. I got an error when I try to update the database schema.\r\n\r\nError on the `mlflow db upgrade $MLFLOW_DB_URI` command: \r\n`[SQL: ALTER TABLE experiments DROP CONSTRAINT lifecycle_stage]`\r\n\r\nThere is an old issue about this, with MySQL, but it is closed and supposedly solved: #1397\r\n\r\n## Steps to reproduce\r\n\r\n### Dockerfile\r\nI run MLFlow from a Docker container, the Dockerfile is:\r\n\r\n```\r\nFROM python:3.7\r\n\r\n## ML FLOW SERVER CONFIG\r\nENV MLFLOW_DB_URI=postgresql:\/\/mlflow_user:mlflow_pwd@0.0.0.0:5432\/mlflow_db\r\n\r\n# Upgrade mlflow\r\nRUN python3 --version\r\nRUN pip3 install -U mlflow\r\n\r\nRUN pip install psycopg2-binary\r\n```\r\n### Commands\r\n\r\nCreate the database\r\n```\r\ndocker run --rm -it -p 5432:5432 -e POSTGRES_PASSWORD='mlflow_pwd' -e POSTGRES_USER='mlflow_user' -e POSTGRES_DB='mlflow_db' -e PGDATA='\/var\/lib\/postgresql\/data\/pgdata' postgres:11\r\n```\r\n\r\nCreate the ML Flow container and upgrade the db schema:\r\n```\r\ndocker build -t mlflow .\r\ndocker run --rm -it --network=host -v artifact_folder:artifact_folder mlflow bash\r\nmlflow db upgrade $MLFLOW_DB_URI\r\n```\r\n\r\n### Other info \/ logs\r\n\r\n```\r\n2020\/02\/19 16:44:21 INFO mlflow.store.db.utils: Updating database tables in preparation for MLflow 1.0 schema migrations\r\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\r\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\r\nINFO  [alembic.runtime.migration] Running upgrade  -> ff01da956556, ensure_unique_constraint_names\r\nTraceback (most recent call last):\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/base.py\", line 1246, in _execute_context\r\n    cursor, statement, parameters, context\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/default.py\", line 588, in do_execute\r\n    cursor.execute(statement, parameters)\r\npsycopg2.errors.UndefinedTable: relation \"experiments\" does not exist\r\n\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"\/usr\/local\/bin\/mlflow\", line 8, in <module>\r\n    sys.exit(cli())\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/click\/core.py\", line 764, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/click\/core.py\", line 717, in main\r\n    rv = self.invoke(ctx)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/click\/core.py\", line 1137, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/click\/core.py\", line 1137, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/click\/core.py\", line 956, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/click\/core.py\", line 555, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/mlflow\/db.py\", line 28, in upgrade\r\n    mlflow.store.db.utils._upgrade_db_initialized_before_mlflow_1(url)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/mlflow\/store\/db\/utils.py\", line 161, in _upgrade_db_initialized_before_mlflow_1\r\n    command.upgrade(config, 'heads')\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/alembic\/command.py\", line 298, in upgrade\r\n    script.run_env()\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/alembic\/script\/base.py\", line 489, in run_env\r\n    util.load_python_file(self.dir, \"env.py\")\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/alembic\/util\/pyfiles.py\", line 98, in load_python_file\r\n    module = load_module_py(module_id, path)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/alembic\/util\/compat.py\", line 173, in load_module_py\r\n    spec.loader.exec_module(module)\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/mlflow\/temporary_db_migrations_for_pre_1_users\/env.py\", line 78, in <module>\r\n    run_migrations_online()\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/mlflow\/temporary_db_migrations_for_pre_1_users\/env.py\", line 72, in run_migrations_online\r\n    context.run_migrations()\r\n  File \"<string>\", line 8, in run_migrations\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/alembic\/runtime\/environment.py\", line 846, in run_migrations\r\n    self.get_context().run_migrations(**kw)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/alembic\/runtime\/migration.py\", line 518, in run_migrations\r\n    step.migration_fn(**kw)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/mlflow\/temporary_db_migrations_for_pre_1_users\/versions\/ff01da956556_ensure_unique_constraint_names.py\", line 174, in upgrade\r\n    condition=column('lifecycle_stage').in_([\"active\", \"deleted\"])\r\n  File \"\/usr\/local\/lib\/python3.7\/contextlib.py\", line 119, in __exit__\r\n    next(self.gen)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/alembic\/operations\/base.py\", line 354, in batch_alter_table\r\n    impl.flush()\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/alembic\/operations\/batch.py\", line 83, in flush\r\n    fn(*arg, **kw)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/alembic\/ddl\/impl.py\", line 247, in drop_constraint\r\n    self._exec(schema.DropConstraint(const))\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/alembic\/ddl\/impl.py\", line 140, in _exec\r\n    return conn.execute(construct, *multiparams, **params)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/base.py\", line 982, in execute\r\n    return meth(self, multiparams, params)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/sqlalchemy\/sql\/ddl.py\", line 72, in _execute_on_connection\r\n    return connection._execute_ddl(self, multiparams, params)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/base.py\", line 1044, in _execute_ddl\r\n    compiled,\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/base.py\", line 1250, in _execute_context\r\n    e, statement, parameters, cursor, context\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/base.py\", line 1476, in _handle_dbapi_exception\r\n    util.raise_from_cause(sqlalchemy_exception, exc_info)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/sqlalchemy\/util\/compat.py\", line 398, in raise_from_cause\r\n    reraise(type(exception), exception, tb=exc_tb, cause=cause)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/sqlalchemy\/util\/compat.py\", line 152, in reraise\r\n    raise value.with_traceback(tb)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/base.py\", line 1246, in _execute_context\r\n    cursor, statement, parameters, context\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/default.py\", line 588, in do_execute\r\n    cursor.execute(statement, parameters)\r\nsqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation \"experiments\" does not exist\r\n\r\n[SQL: ALTER TABLE experiments DROP CONSTRAINT lifecycle_stage]\r\n(Background on this error at: http:\/\/sqlalche.me\/e\/f405)\r\n```","814":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Databricks, which I think is ubuntu 18.04\r\n- **MLflow installed from (source or binary)**: Pip, so binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.3.0\r\n- **Python version**: 3.7.3\r\n\r\n### Describe the problem\r\nMLflow's spark models just return the prediction column of a transformed spark dataframe. This would be fine, except Spark's ALS algorithm turns out to be annoying, and changes the order of the rows in the input DataFrame when it performs `.transform()`. Worse, it doesn't even change them to a sensible order that I can discern, so you cannot reconcile them after the fact.\r\n\r\nThis is a major problem for MLFlow's current implementation, because the way the `.predict()` function is [defined](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/spark.py#L472) means that it's impossible to tie back the output against the input:\r\n\r\n```Python\r\n    def predict(self, pandas_df):\r\n        \"\"\"\r\n        Generate predictions given input data in a pandas DataFrame.\r\n        :param pandas_df: pandas DataFrame containing input data.\r\n        :return: List with model predictions.\r\n        \"\"\"\r\n        spark_df = self.spark.createDataFrame(pandas_df)\r\n        return [x.prediction for x in\r\n                self.spark_model.transform(spark_df).select(\"prediction\").collect()]\r\n```\r\n\r\nFor instance, I have an ALS model trained and saved using `mlflow.spark.log_model()`. It's then hosted in Azure Container Instances. I can POST some data off for inference like so: \r\n\r\n```Python\r\nimport requests\r\nheaders = {'Content-Type':'application\/json'}\r\ninputs = '{\"columns\":[\"Customer_Key\", \"Item_Key\"], \"data\":[[3108376, 5404708], [3108376,5195688],[3108376,4973619],[3108376,5198076],[3108376,4978723],[3108376,5004878],[3108376,5033426],[3108376,5116142],[3108376,5097183]]}'\r\n\r\nprint(requests.post(endpoint_url, headers=headers, data=inputs).text)\r\n```\r\n\r\nand I get back...\r\n\r\n> [nan, 2.3523123672930524e-05, 6.751884939149022e-06, 0.0024953146930783987, 0.0008189469808712602, 0.00013733138621319085, 0.0005776321049779654, 2.1697404008591548e-05, 0.0004996642819605768]\r\n\r\nBut if I only POST `'...\"data\":[[3108376, 5195688]]}'` (being 2nd Item_Key in the above example) the returned value is `[0.0005776321049779654]` (which is not the second predicted value). \r\n\r\nWalking back through things, I can import the Model into a notebook and try things there:\r\n\r\n```\r\nmodel = mlflow.spark.load_model('runs:\/b77ef701adf14af8b62f6eddec5b60ea\/Model'.format(run_id))\r\n\r\ninputs = spark.createDataFrame([\r\n(3108376,5404708),\r\n(3108376,5195688),\r\n(3108376,4973619),\r\n(3108376,5198076),\r\n(3108376,4978723),\r\n(3108376,5004878),\r\n(3108376,5033426),\r\n(3108376,5116142),\r\n(3108376,5097183)\r\n], schema=['Customer_Key', 'Item_Key'])\r\n\r\nmodel.transform(inputs).show()\r\n```\r\n\r\nand immediately the problem is clear:\r\n```\r\n+------------+--------+------------+\r\n|Customer_Key|Item_Key|  prediction|\r\n+------------+--------+------------+\r\n|     3108376| 5404708|         NaN|\r\n|     3108376| 4973619|2.3523124E-5|\r\n|     3108376| 5198076| 6.751885E-6|\r\n|     3108376| 5004878|0.0024953147|\r\n|     3108376| 4978723|  8.18947E-4|\r\n|     3108376| 5097183|1.3733139E-4|\r\n|     3108376| 5195688| 5.776321E-4|\r\n|     3108376| 5033426|2.1697404E-5|\r\n|     3108376| 5116142| 4.996643E-4|\r\n+------------+--------+------------+\r\n```\r\n\r\nThe order of the items has changed. `5195688` is no longer the 2nd Item_Key in the list. \r\n\r\nAt the moment, the only workaround I can think of is to create a Python Function flavoured model instead and manually force it to return the Customer_Key and Item_Key columns, but that's a bit less than ideal","815":"I'm reopening issue #1336 because the stale bot closed it automatically a while ago.\r\n \r\nEvery project and every experiment has different needs that can also change over time. Giving users and organizations control over the way they (post-process and) visualize their configurations, metrics and artifacts could speedup experimentation, analysis, and reporting dramatically.\r\n\r\nSome use cases:\r\n- hierarchical configuration\r\n  Experiments with many components usually need a nested configuration structure (dictionary). \r\n\r\n- multi-dimensional metrics\r\n  Some metrics might not be scalars, but 2d (e.g. histograms) or 3d. \r\n\r\n- model comparison\r\n  One might want to visualize and compare model architectures.\r\n\r\nAn API for creating UI plugins that customize the experiment, run and run comparison views could be the solution.\r\n\r\nIn a [slack discussion](https:\/\/mlflow-users.slack.com\/messages\/CFYUVSHEZ\/), @jhadjar suggested that, this can be implemented using  Flask's Blueprint. The core (mlflow ui) application can discover plugins using `find_packages` from `setuptools`, register them and display them _if the plugins want to be displayed_.\r\n\r\nI think this would be useful for 3 reasons:\r\n1) let UI engineers \/ developers focus on the framework, instead of every detail a user could want.\r\n2) give control to the users to do exactly what they want.\r\n3) as a consequence of 2, ease users' life and speed up experimentation by 30000% (:P)","816":"Usually I run many experiments i want to compare together. I run them almost with identical settings for a number (lets say 100) epochs. During training for every batch I do register a multitude of metrics and I name them with `T\/...` to denote they are batch metrics. Then I do similar for epoch summarization metrics during validation and name them `V\/...`:\r\n\r\n```\r\nmlflow.log_metrics({'T\/accuracy':  0.9, 'T\/loss': 0.2}, step=current_batch_number)\r\n...\r\nmlflow.log_metrics({'V\/accuracy':  0.9, 'V\/loss': 0.2}, step=current_epoch)\r\n```\r\nIn the UI I can only see the metrics for the last batch\/epoch of the run, which it no always (almost never) the one I want to use to compare to other experiments. So, to allow better comparison across experiments from the UI table without having to go into the curves plot, I'd like to suggest two quick modifications to MLFLow tracking UI summary table (e.g. http:\/\/<yourmlflowserver>\/#\/experiments\/51):\r\n\r\n1. Make a distinction in `mlflow.tracking` to allow submitting batch metrics and epoch metrics and distinguish them in the database without having to prepend them with some keyword. E.g.\r\n\r\n```\r\nmlflow.log_batch_metrics(....)\r\nmlflow.log_epoch_metrics(...)\r\n```\r\n\r\n2. In the UI, for each individual run, and for the \"epoch metrics\", allow to select which epoch to display (and memorise it). As the number of runs grow, we could manually select the metrics from which epoch to display for each run in the tables so that we could compare future experiments against it very quickly. \r\n\r\nBasically, the ability to select the \"best step\" for each RUN so that those metrics are always visible and comparable across runs.","817":"## What changes are proposed in this pull request?\r\n\r\nIn some projects (e.g. hyperparameter search for deep learning) a large number of parameters are logged to each run. The UI always displays all parameters although most of them are the same for all runs. This makes comparing runs difficult, as one run alone fills the whole height of the screen.\r\n\r\nThis pull request adds an optional parameter to the search_runs API: `parameter_diff`. If this is set to true, only the parameters that are different are returned for the runs. For paginated search requests, only the current page is considered. This functionality is usable in the Python API. The functionality is usable in the UI, too.\r\n\r\nThe main contribution lies in the backend code handling the parameter diff. The integration in the UI is only as an example because I am not that knowledgable in React.\r\n\r\n## How is this patch tested?\r\n\r\nTests of the correctness of the functionality were added in all Python API levels:\r\n\r\n- test_file_store.py\r\n- test_rest_store.py\r\n- test_sqlalchemy_store.py\r\n- test_abstract_store.py\r\n- test_client.py\r\n- test_tracking.py\r\n\r\nThe tests cover the following scenarios:\r\n\r\n- The returned parameters for a single run are empty, as this is the trivial case\r\n- The returned parameters for runs with all the same parameter keys and values are empty\r\n- For runs with different parameters, only the different ones are returned\r\n- The parameter_key -> parameter_value pairings for the diffed parameters are consistent with the undiffed ones\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No.\r\n- [x] Yes.\r\n\r\nThe search_runs function can now filter the parameters of the runs to include only the ones that differ. This functionality is added to the UI, too.\r\n\r\n### What component(s) does this PR affect?\r\n\r\n- [x] UI\r\n- [ ] CLI\r\n- [x] API\r\n- [x] REST-API\r\n- [ ] Examples\r\n- [ ] Docs\r\n- [x] Tracking\r\n- [ ] Projects\r\n- [ ] Artifacts\r\n- [ ] Models\r\n- [ ] Scoring\r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [x] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","818":"### Motivation\r\nDocker Image produced by MLFlow for predicting the models is supposed to be the most portable format but unfortunately, the docker image produced by MLFlow is of huge size. We tried with a simple model file with 1kb size (a simple regression model) but the resultant docker image is 3.3 GB.  We are trying to deploy these docker images (about 60) in Kubernetes but since K8s nodes will have limited resources, docker images of this size make mlflow a non-viable option. \r\n### Proposed Changes\r\nPlease let us know how the docker image size for predicting the model can be reduced. \r\n","819":"## Describe the proposal\r\nMake the number of features to plot configurable for XGBoost & LightGBM autologging.\r\n\r\n### Motivation\r\nWhen we use XGBoost or LightGBM, we often feed lots of features (> 1000 sometimes) to improve the performance of a model. Currently, the `autolog` function plots all features. This might make the plot too dense to understand when the number of features is large.\r\n\r\n### Proposed Changes\r\nAdd a new argument to `autolog` which limits the number of features to plot and update `log_feature_importance_plot`.","820":"### Motivation\r\n\r\nCurrently there is no run-based reproducibility for the `mlflow run` CLI command. In order to re-execute a run, you have to somehow know its git URI as in  `mlflow run GIT_URI`. Reproducibility is a highly desired feature for machine learning experiments.\r\n\r\n### Proposed Changes\r\n* Enhance mlflow command to accept URIs with the `runs` scheme: `mlflow run runs:\/1234`.\r\n* This implies having the MLprojects file stored in the run\r\n\r\n### Solution\r\n* See: https:\/\/github.com\/amesar\/mlflow\/blob\/master\/mlflow\/projects\/__init__.py#L119","821":"In earlier versions of mlflow there was simple metrics view with autostep. Now default absolute step is 0, and step view is useless unless you manually specify step for each log_metric. It will be nice to make default behaviour more useful.\r\n\r\nDefault step view looks like this:\r\n\r\n![epoch_processing_time](https:\/\/user-images.githubusercontent.com\/2518859\/74248207-461b0e00-4cf8-11ea-84a3-0001597a55b4.png)\r\n\r\nAlso we are using mlflow for lazy metrics logging: we are running full experiment and sending metrics afterwards (so there will be no crashes during experiment because of network problems with mlflow). In this scenario we don't have any nice view of metrics with default step 0 or time-based views.\r\n\r\nWe had to write a wrapper to make counters work, but in our opinion better to make It once in mlflow than multiple times on client side.\r\n\r\n```\r\nclass MLFlowWrapper(StatsLogger):\r\n    def __init__(self, experiment_name, mlflow_uri):\r\n        super().__init__()\r\n        mlflow.set_tracking_uri(mlflow_uri)\r\n        mlflow.set_experiment(experiment_name)\r\n        self.counters = {}\r\n\r\n    def log_param(self, key, value):\r\n        mlflow.log_param(key, value)\r\n\r\n    def log_metric(self, key, value):\r\n        if not key in self.counters:\r\n            self.counters[key] = 0\r\n        mlflow.log_metric(key, value, step=self.counters[key])\r\n        self.counters[key] = self.counters[key] + 1\r\n\r\n    def log_artifact(self, local_path):\r\n        mlflow.log_artifact(local_path)\r\n```\r\n\r\nThank you!","822":"### Proposal\r\nCurrently in the UI if a run is nested twice then the second nesting is not visible (same indentation as the parent).\r\n\r\n### Motivation\r\nThe tracking API allows for arbitrary nesting so it would be cool to actually make the UI compatible.","823":"## Describe the proposal\r\nWe should consider using [HiPlot](https:\/\/ai.facebook.com\/blog\/hiplot-high-dimensional-interactive-plots-made-easy\/) for our parallel coordinates plot - the project still seems pretty early, and we should make sure to ensure UX consistency when introducing a new plotting library (e.g. make sure the HiPlot & Plotly UX is consistent), but it's worth keeping an eye on especially if\/as HiPlot adds new features.\r\n","824":"## What changes are proposed in this pull request?\r\nMatch tensorflow auto logging to work with tensorflow object detection api. #1964 \r\n\r\n- Added evaluate to tensorflow autologging    \r\n- evaluate will log checkpoint files as artifacts\r\n- log all evaluation metrics that are a number (skip serialized images)\r\n- Changed tensorflow signature key to match tensorflow object detection api\r\n\r\n## How is this patch tested?\r\nRan training on [Pets example](https:\/\/github.com\/tensorflow\/models\/blob\/master\/research\/object_detection\/g3doc\/running_pets.md) \r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s) does this PR affect?\r\n\r\n- [ ] UI\r\n- [ ] CLI\r\n- [ ] API\r\n- [ ] REST-API\r\n- [ ] Examples\r\n- [ ] Docs\r\n- [x] Tracking\r\n- [ ] Projects\r\n- [ ] Artifacts\r\n- [ ] Models\r\n- [ ] Scoring\r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [x] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [x] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","825":"Please fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.6.0\r\n- **Python version**: 3.7.4\r\n- **npm version, if running the dev UI**: n\/a\r\n- **Exact command to reproduce**: mlflow.keras.autolog()\r\n- **TensorFlow version**: 2.0.0\r\n- **keras version**: 2.2.4-tf\r\n\r\n### Describe the problem\r\nI try to use the keras autologger with the keras built-in in TensorFlow 2.0. The call to`mlflow.keras.autolog()` fails with `ModuleNotFoundError: No module named 'keras'`\r\n\r\n\r\n\r\n### Code to reproduce issue\r\n```python\r\nimport mlflow.keras\r\nmlflow.keras.autolog()\r\n```\r\n\r\n### Other info \/ logs\r\nThe the `autolog()` function  in `mlflow.keras` module tries to import keras directly from the global namespace, however in TF 2.0 keras is a submodule of TensorFlow. In fact if I change the line 427 in keras.py from `import keras` to `from tensorflow import keras` the autologging works as expected.\r\n\r\nTracelog of the exception:\r\n```\r\n---------------------------------------------------------------------------\r\nModuleNotFoundError                       Traceback (most recent call last)\r\n<ipython-input-9-8539acb3e9a3> in <module>\r\n----> 1 mlflow.keras.autolog()\r\n      2 \r\n      3 with mlflow.start_run():\r\n      4 \r\n      5     y = y_ctr\r\n\r\n~\/anaconda3\/envs\/tf2\/lib\/python3.7\/site-packages\/mlflow\/keras.py in autolog()\r\n    425     excluding ``mode`` and ``verbose``.\r\n    426     \"\"\"\r\n--> 427     import keras\r\n    428 \r\n    429     class __MLflowKerasCallback(keras.callbacks.Callback):\r\n\r\nModuleNotFoundError: No module named 'keras'\r\n```","826":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\nPlease fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n### System information\r\n- **OS Platform and Distribution Linux Ubuntu 16.04**:\r\n- **MLflow installed from binary**:\r\n- **MLflow version 1.5.0**:\r\n- **Python version 3.7**:\r\n\r\n### Describe the problem\r\nmost similar issue: https:\/\/github.com\/mlflow\/mlflow\/issues\/1963\r\n\r\nIm trying to use a custom image when deploying to AWS Sagemaker. I can use the `mlflow sagemaker build-and-push-container` to create the base image and then create another image with some custom python packages installed. However the default behavior when serving the pyfunc is to activate a conda environment inside the container (unless an environment variable is specified) which prevents the model from accessing the system dependencies. https:\/\/github.com\/mlflow\/mlflow\/blob\/bbf8886a2cbf4fa371f0a67157fdd3df3dfa47dd\/mlflow\/models\/container\/__init__.py#L121\r\n\r\nIn the custom image I create I can get around the conda env creation by adding \r\n```\r\nENV MLFLOW_DISABLE_ENV_CREATION=true\r\n```\r\nHowever, I think this line reveals a bug if the conda env is not created \r\n\r\nI think this line should be removed or moved inside the above `if` block https:\/\/github.com\/mlflow\/mlflow\/blob\/30a90ec9cbffa5c0d0212368b9f2a7e8c8a3fc81\/mlflow\/models\/container\/__init__.py#L127\r\n\r\nsince if the conda creation happens, it will be activated here https:\/\/github.com\/mlflow\/mlflow\/blob\/30a90ec9cbffa5c0d0212368b9f2a7e8c8a3fc81\/mlflow\/models\/container\/__init__.py#L106\r\n\r\n### Code to reproduce issue\r\n- run `mlflow sagemaker build-and-push-container`\r\n- build another container\r\n```\r\nFROM <container generated from first step>\r\n\r\nENV MLFLOW_DISABLE_ENV_CREATION=true\r\n```\r\n- Serve the model on sagemaker `mlflow sagemaker deploy ...`\r\n\r\n### Other info \/ logs\r\nWhen running the container, you should see this in the cloudwatch logs\r\n`Could not find conda environment: custom_env`\r\n\r\n### Edit\r\nIt looks like it was intentionally called out in this PR https:\/\/github.com\/mlflow\/mlflow\/pull\/1329. I still think its strange to activate the conda environment twice (especially if its specified to not create one).\r\n","827":"Hi perhaps this is already supported but what I am after is :\r\n\r\n\r\n1.train my model using pySpark code .\r\n2.extract model weights to artifactory\r\n3. deploy model within a Java application . \r\n\r\nBasically I am looking for the relevant load_model() Java function.\r\nmost probably this exists but I have not manage to figure it out from the java API provided .\r\n\r\n","828":"## Describe the proposal\r\n- provide a script\/tool to migrate file-based storage into sql (e.g.sqlite file)\r\n\r\n### Motivation\r\n- We started using MLFlow with the default file-based backend as it was the simplest one at a time. We want to use model registry, and hence, switch from file-based backend, but don't want to lose data. I am sure there will be more\r\n\r\n### Proposed Changes\r\nadd a migration tool from file-based storage to sql","829":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **MLflow installed from (source or binary)**: Source\r\n- **MLflow version (run ``mlflow --version``)**: latest 1.6\r\n- **Python version**:3.7\r\n- **npm version, if running the dev UI**:-\r\n- **Exact command to reproduce**: `mlflow.log_metric(\"dummy_metric\", 12)`\r\n\r\n### Describe the problem\r\nHey guys I am facing difficulty in creating a database tables using mlflow.  So I was doing my development on windows where I had no issues with the Database. The issue occurred when I **shifted** to **Linux** and installed **MariaDB** directly from the command line where as in windows I was using Xammp and the **MariaDB** version in that was **10.1.39**. On my Ubuntu VM the MariaDB version is 10.0.38 and I suspect this is the reason for the problem however I dont want to install a newer version on my Linux system at this time. Any help would be appreciated. \r\n\r\n### Code to reproduce issue\r\n1- open MariaDB terminal and create a new Database:  `CREATE DATABASE mlflow`\r\n2- Open python terminal\r\n3- `import mlflow`\r\n4- `mlflow.set_tracking_uri(\"mysql+pymysql:\/\/root@localhost\/mlflow\")`\r\n5- `mlflow.log_metric(\"dummy_metric\",12)`\r\n### `And boom I get this error!`\r\n\r\n### Error Logs\r\n`020\/02\/03 17:54:13 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\r\nTraceback (most recent call last):\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/base.py\", line 1246, in _execute_context\r\n    cursor, statement, parameters, context\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/default.py\", line 581, in do_execute\r\n    cursor.execute(statement, parameters)\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/pymysql\/cursors.py\", line 170, in execute\r\n    result = self._query(query)\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/pymysql\/cursors.py\", line 328, in _query\r\n    conn.query(q)\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/pymysql\/connections.py\", line 517, in query\r\n    self._affected_rows = self._read_query_result(unbuffered=unbuffered)\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/pymysql\/connections.py\", line 732, in _read_query_result\r\n    result.read()\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/pymysql\/connections.py\", line 1075, in read\r\n    first_packet = self.connection._read_packet()\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/pymysql\/connections.py\", line 684, in _read_packet\r\n    packet.check_error()\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/pymysql\/protocol.py\", line 220, in check_error\r\n    err.raise_mysql_exception(self._data)\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/pymysql\/err.py\", line 109, in raise_mysql_exception\r\n    raise errorclass(errno, errval)\r\npymysql.err.InternalError: (1071, 'Specified key was too long; max key length is 767 bytes')\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/mlflow\/tracking\/fluent.py\", line 251, in log_metric\r\n    run_id = _get_or_start_run().info.run_id\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/mlflow\/tracking\/fluent.py\", line 506, in _get_or_start_run\r\n    return start_run()\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/mlflow\/tracking\/fluent.py\", line 151, in start_run\r\n    active_run_obj = MlflowClient().create_run(\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/mlflow\/tracking\/client.py\", line 37, in __init__\r\n    self._tracking_client = TrackingServiceClient(final_tracking_uri)\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 31, in __init__\r\n    self.store = utils._get_store(self.tracking_uri)\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/mlflow\/tracking\/_tracking_service\/utils.py\", line 114, in _get_store\r\n    return _tracking_store_registry.get_store(store_uri, artifact_uri)\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/mlflow\/tracking\/_tracking_service\/registry.py\", line 37, in get_store\r\n    return builder(store_uri=store_uri, artifact_uri=artifact_uri)\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/mlflow\/tracking\/_tracking_service\/utils.py\", line 78, in _get_sqlalchemy_store\r\n    return SqlAlchemyStore(store_uri, artifact_uri)\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/mlflow\/store\/tracking\/sqlalchemy_store.py\", line 97, in __init__\r\n    mlflow.store.db.utils._initialize_tables(self.engine)\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/mlflow\/store\/db\/utils.py\", line 29, in _initialize_tables\r\n    InitialBase.metadata.create_all(engine)\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/sqlalchemy\/sql\/schema.py\", line 4316, in create_all\r\n    ddl.SchemaGenerator, self, checkfirst=checkfirst, tables=tables\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/base.py\", line 2049, in _run_visitor\r\n    conn._run_visitor(visitorcallable, element, **kwargs)\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/base.py\", line 1618, in _run_visitor\r\n    visitorcallable(self.dialect, self, **kwargs).traverse_single(element)\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/sqlalchemy\/sql\/visitors.py\", line 138, in traverse_single\r\n    return meth(obj, **kw)\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/sqlalchemy\/sql\/ddl.py\", line 781, in visit_metadata\r\n    _is_metadata_operation=True,\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/sqlalchemy\/sql\/visitors.py\", line 138, in traverse_single\r\n    return meth(obj, **kw)\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/sqlalchemy\/sql\/ddl.py\", line 826, in visit_table\r\n    include_foreign_key_constraints,\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/base.py\", line 982, in execute\r\n    return meth(self, multiparams, params)\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/sqlalchemy\/sql\/ddl.py\", line 72, in _execute_on_connection\r\n    return connection._execute_ddl(self, multiparams, params)\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/base.py\", line 1044, in _execute_ddl\r\n    compiled,\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/base.py\", line 1250, in _execute_context\r\n    e, statement, parameters, cursor, context\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/base.py\", line 1476, in _handle_dbapi_exception\r\n    util.raise_from_cause(sqlalchemy_exception, exc_info)\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/sqlalchemy\/util\/compat.py\", line 398, in raise_from_cause\r\n    reraise(type(exception), exception, tb=exc_tb, cause=cause)\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/sqlalchemy\/util\/compat.py\", line 152, in reraise\r\n    raise value.with_traceback(tb)\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/base.py\", line 1246, in _execute_context\r\n    cursor, statement, parameters, context\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/sqlalchemy\/engine\/default.py\", line 581, in do_execute\r\n    cursor.execute(statement, parameters)\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/pymysql\/cursors.py\", line 170, in execute\r\n    result = self._query(query)\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/pymysql\/cursors.py\", line 328, in _query\r\n    conn.query(q)\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/pymysql\/connections.py\", line 517, in query\r\n    self._affected_rows = self._read_query_result(unbuffered=unbuffered)\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/pymysql\/connections.py\", line 732, in _read_query_result\r\n    result.read()\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/pymysql\/connections.py\", line 1075, in read\r\n    first_packet = self.connection._read_packet()\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/pymysql\/connections.py\", line 684, in _read_packet\r\n    packet.check_error()\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/pymysql\/protocol.py\", line 220, in check_error\r\n    err.raise_mysql_exception(self._data)\r\n  File \"\/home\/saad\/miniconda3\/envs\/pxml\/lib\/python3.7\/site-packages\/pymysql\/err.py\", line 109, in raise_mysql_exception\r\n    raise errorclass(errno, errval)\r\nsqlalchemy.exc.InternalError: (pymysql.err.InternalError) (1071, 'Specified key was too long; max key length is 767 bytes')\r\n[SQL: \r\nCREATE TABLE experiments (\r\n        experiment_id INTEGER NOT NULL AUTO_INCREMENT, \r\n        name VARCHAR(256) NOT NULL, \r\n        artifact_location VARCHAR(256), \r\n        lifecycle_stage VARCHAR(32), \r\n        CONSTRAINT experiment_pk PRIMARY KEY (experiment_id), \r\n        CONSTRAINT experiments_lifecycle_stage CHECK (lifecycle_stage IN ('active', 'deleted')), \r\n        UNIQUE (name)\r\n)\r\n\r\n]\r\n(Background on this error at: http:\/\/sqlalche.me\/e\/2j85)","830":"It would be nice if the GUI would support searching for run ids because sometimes all I want is to display the details of a run and creating the URL manually is not very elegant, in particular when we want to compare different runs. Like this: \r\n![Screenshot from 2020-02-03 10-44-29](https:\/\/user-images.githubusercontent.com\/10477073\/73642574-3190a300-4672-11ea-8601-a7d869456484.png)\r\n\r\nAlternatively, we would add the run id as a [system tag](https:\/\/mlflow.org\/docs\/latest\/tracking.html#system-tags) but then the query would be longer than necessary for what we want to achieve: `tags.mlflow.run_id = ':run_id'`\r\n\r\nUnfortunately I cannot contribute code for this feature.","831":"## The Proposal\r\nCurrently it is necessary to have an executable for git and the git library in Python in order to run a project, even if it is not a git repository. Can it be altered in order to not use git at all and continue the execution of project?\r\n\r\n### Motivation\r\nIn deployment of an application using MLflow in production, it may be possible that a customer may not allow installation of git as it will be able to get code from a remote repository.\r\n\r\n### Proposed Changes\r\nIt may be inferred from an environment variable if git is to be used. This would bring a change in the ```run``` API of ```mlflow.projects```.\r\n","832":"Allow pyfunc kwargs as per #2360 \r\n\r\n## How is this patch tested?\r\n\r\nNo extra tests added.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [X] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s) does this PR affect?\r\n\r\n- [ ] UI\r\n- [ ] CLI\r\n- [ ] API\r\n- [ ] REST-API\r\n- [ ] Examples\r\n- [ ] Docs\r\n- [ ] Tracking\r\n- [ ] Projects\r\n- [ ] Artifacts\r\n- [X] Models\r\n- [ ] Scoring\r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [X] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","833":"### Describe the proposal\r\nCurrently, Pyfunc models' `predict` function strictly take a single data argument. For some models, you may want extra inputs, which is why, for example, [sklearn allows additional keyword args to be passed into a pipeline](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline.predict)\r\nI suggest allowing keyword args for Pyfunc models as well.\r\n\r\n### Motivation\r\nI appreciate a similar result can be achieved by making `model_input` a `dict`, containing a number of inputs. However, I do think it makes sense to keep the APIs reasonably consistent between the sklearn and pyfunc implementations.\r\n\r\n### Proposed Changes\r\n* `PythonModel.predict` to allow `**kwargs`\r\n* `_PythonModelPyfuncWrapper.predict` to take `**kwargs` and pass through to `PythonModel.predict`","834":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Mostly no. Slight variation on https:\/\/mlflow.org\/docs\/latest\/tracking.html#id42\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **MLflow installed from (source or binary)**: source (conda)\r\n- **MLflow version (run ``mlflow --version``)**: 1.5.0\r\n- **Python version**: 3.7.6\r\n- **npm version, if running the dev UI**: NA\r\n- **Exact command to reproduce**: NA\r\n\r\n### Describe the problem\r\nI am attempting to use MS SQL Server for my MLFlow tracking. I can connect it with a valid connection string (see below code - some details obfuscated for privacy), and it will create the necessary tables for tracking in the database (`experiments, metrics, params, runs, tags`). But it will not go any further and produce an error:\r\n`OperationalError: (pyodbc.OperationalError) ('08001', '[08001] [Microsoft][ODBC SQL Server Driver]Neither DSN nor SERVER keyword supplied (0) (SQLDriverConnect)')\r\n(Background on this error at: http:\/\/sqlalche.me\/e\/e3q8)`\r\n\r\nIt seems odd to me that it is able to access the DB, create the necessary tables, but fail at adding any data to the tables. My user privileges are adequate for INSERTing rows, and I have connected and INSERTed into this DB before with pyodbc, so I suspect the issue lies somewhere within MLFlow.\r\n\r\n### Code to reproduce issue\r\n```\r\nimport urllib\r\nimport mlflow\r\n\r\nparams = urllib.parse.quote_plus('DRIVER={SQL Server};'\r\n                              'SERVER=<server address>;'\r\n                              'DATABASE=<dbname>;'\r\n                              'UID=<username>;'\r\n                              'PWD=<password>')\r\nremote_server_uri = 'mssql+pyodbc:\/\/\/?odbc_connect={}'.format(params)\r\nmlflow.set_tracking_uri(remote_server_uri)\r\nwith mlflow.start_run():\r\n    mlflow.log_param(\"a\", 1)\r\n    mlflow.log_metric(\"b\", 2)\r\n```\r\n\r\nAs stated, this results in tables being created, but no data added.","835":"## Describe the proposal\r\nCurrently, users can delete runs from the experiment UI, which leads to a confirmation prompt like:\r\n![image](https:\/\/user-images.githubusercontent.com\/2358483\/73196992-6edeb900-40e5-11ea-97ed-4e79b615bacf.png)\r\n\r\nWhen deleting one or more parent runs (runs with children, as in the screenshot above), we should update this  to allow for deleting both the parents & their child runs, as this is usually the intended behavior. For example, if you run hyperparam tuning, you may generate a parent run to capture e.g. the best accuracy\/model generated across all trials, and record the individual trials as child runs of the parent. If you delete the hyperparam tuning run, you likely want to delete all associated child runs (trials) as well.\r\n\r\nWe can implement child-run deletion in JS by searching for runs via a [SearchRuns API request](https:\/\/www.mlflow.org\/docs\/latest\/rest-api.html#search-runs) with `filter=\"tags.mlflow.parentRunId = '<parent-uuid>'\"` (may need to iterate over successive pages of runs to ensure we delete all child runs). Note that this will only work for single-level nested runs - for multilevel nested runs (a less common use case), we'd need to recursively search for child runs of the children being deleted, which is likely more expensive server-side than it's worth.\r\n\r\n### Proposed Changes\r\nWe'd need to update:\r\n* [DeleteRunModal](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/server\/js\/src\/components\/modals\/DeleteRunModal.js) to be able to prompt for deletion of immediate children of the parent run & child runs, if one or more parent runs is selected.\r\n","836":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Centos 7\r\n- **MLflow installed from (source or binary)**: Yes\r\n- **MLflow version (run ``mlflow --version``)**: 1.5.1\r\n- **Python version**: 3.6\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n\r\nCurrently there are several issues with the [TensorFlow flavor](https:\/\/mlflow.org\/docs\/latest\/models.html#tensorflow-tensorflow) in MLFlow models.\r\n\r\n- Tensorflow model needs to be exported with columns names 0,1,2,3 to have it working. See https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/pyfunc\/__init__.py#L443. This brings a lot of constraints for the model owner to name the Pandas\/Spark df columns with generic names and also seems currently undocumented\r\n- The predict function of TF 1.x wrapper only works with regression models https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/tensorflow.py#L414 not with classification models for example where the output will be a dictionary of several tensors\r\n- PyArrow currently has several limitations on datastructures https:\/\/spark.apache.org\/docs\/latest\/sql-pyspark-pandas-with-arrow.html#supported-sql-types i.e. doesn't support ArrayTypes which means the inference with those tensors  doesn't work\r\n\r\n### Proposal for fixes:\r\n\r\n- One needs to document better on how the TensorFlow model needs to be exported and which use cases are supported\r\n- For Spark vectorized UDFs one workaround woud be to convert the whole dataframe to tf records and the export the model to accept udfs. This is all supported by default by TensorFlow. So it would be a very generic solution that doesn't have a lot of edge cases\r\nFor online inference it is still better to directly accept tensors (to prevent serialization and de-serialization). So this probably means that the model owner needs to export his model with two functions (one that accepts tensors and one that accepts tf records).\r\n\r\nFor DataFrame to tfr record conversion we could use this udf (in fact our own upstreamed solution from Criteo) that we use and that works well in a lot of cases:\r\nhttps:\/\/github.com\/tensorflow\/ecosystem\/tree\/master\/spark\/spark-tensorflow-connector#python-inference-with-pandas_udf-and-estimators-requires-spark--24\r\n\r\n- To fix the column naming problem in pyspark udfs we could get the input tensor keys directly from the TensorFlow model, but it means add an additional property to the pyfunc model wrapper (that currently only has the predict method), if we agree on the intermediate tf record step this would take away this constraint as we only need one single bytestream column for the tf record.\r\n\r\n###  Other remarks\r\n\r\n- we currently still mostly use estimators  but for keras one can also provide different serving functions https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/saved_model\/save\r\n- default export functions for estimators \r\nhttps:\/\/www.tensorflow.org\/api_docs\/python\/tf\/estimator\/export\/build_raw_serving_input_receiver_fn, \r\nhttps:\/\/www.tensorflow.org\/api_docs\/python\/tf\/estimator\/export\/build_parsing_serving_input_receiver_fn\r\n- to be checked how also this works with tf 2 (most probably the same)\r\n\r\n\r\n\r\n\r\n","837":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\nPlease fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux\r\n- **MLflow installed from (source or binary)**: pip\r\n- **MLflow version (run ``mlflow --version``)**: 1.5.0\r\n- **Python version**: 3.7.1\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nWhen we use hdfs url as artifact location, tracking http UI doesn't show the artifacts list , instead throws an error page.\r\n\r\nNote - artifacts are stored fine into the hdfs directory. \r\n\r\n### Code to reproduce issue\r\nserver started as - \r\nnohup mlflow server --backend-store-uri mysql+pymysql:\/\/ds_service_xyz:blah@dsdb-1-dev.las.xyz.com:3306\/test --default-artifact-root hdfs:\/\/xzz-1-005.live.bi2.las1.xyz.com:8020\/data\/abtracker --host 0.0.0.0  --port 8050 &> mlflow_process_log &\r\n\r\nexperiment created ,\r\nrun created\r\n\r\nable to see experiment\/run in tracking ui, but when clicked on the run hyperlink , error message \"Something went wrong\r\nIf this error persists, please report an issue on our GitHub page.\"\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks,\r\nplease include the full traceback. Large logs and files should be attached.\r\n","838":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\nPlease fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 10, v1909\r\n- **MLflow installed from (source or binary)**:\r\nBinary\r\n- **MLflow version (run ``mlflow --version``)**:\r\n1.5.0\r\n- **Python version**:\r\n3.7\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\nmlflow sagemaker build-and-push-container\r\n\r\n### Describe the problem\r\nThe aforementioned command fails on windows, with the error:\r\n`'$' is not recognized as an internal or external command,\r\noperable program or batch file.`\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n`mlflow sagemaker build-and-push-container` on a windows machine.\r\n\r\n### Other info \/ logs\r\n```\r\n>mlflow sagemaker build-and-push-container --build --push -c mlflow-pyfunc > fail.txt\r\nc:\\tools\\anaconda3\\lib\\site-packages\\werkzeug\\datastructures.py:16: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n  from collections import Container, Iterable, MutableSet\r\nc:\\tools\\anaconda3\\lib\\site-packages\\jinja2\\runtime.py:318: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n  from collections import Mapping\r\n2020\/01\/15 13:41:43 INFO mlflow.models.docker_utils: Building docker image with name mlflow-pyfunc\r\nFIND: Parameter format not correct\r\nSending build context to Docker daemon  3.072kB\r\n\r\nStep 1\/14 : FROM ubuntu:16.04\r\n ---> c6a43cd4801e\r\nStep 2\/14 : RUN apt-get -y update && apt-get install -y --no-install-recommends          wget          curl          nginx          ca-certificates          bzip2          build-essential          cmake          openjdk-8-jdk          git-core          maven     && rm -rf \/var\/lib\/apt\/lists\/*\r\n ---> Using cache\r\n ---> a11b5329711c\r\nStep 3\/14 : RUN curl https:\/\/repo.continuum.io\/miniconda\/Miniconda3-latest-Linux-x86_64.sh >> miniconda.sh\r\n ---> Using cache\r\n ---> 256a07c03fac\r\nStep 4\/14 : RUN bash .\/miniconda.sh -b -p \/miniconda; rm .\/miniconda.sh;\r\n ---> Using cache\r\n ---> 69ecfaa82197\r\nStep 5\/14 : ENV PATH=\"\/miniconda\/bin:$PATH\"\r\n ---> Using cache\r\n ---> 327d29d4ff6b\r\nStep 6\/14 : ENV JAVA_HOME=\/usr\/lib\/jvm\/java-8-openjdk-amd64\r\n ---> Using cache\r\n ---> 704ab3d3a91c\r\nStep 7\/14 : ENV GUNICORN_CMD_ARGS=\"--timeout 60 -k gevent\"\r\n ---> Using cache\r\n ---> 6d10a92767e6\r\nStep 8\/14 : WORKDIR \/opt\/mlflow\r\n ---> Using cache\r\n ---> 7e3beed3ee5d\r\nStep 9\/14 : RUN pip install mlflow==1.3.0\r\n ---> Using cache\r\n ---> 946e6f095a7a\r\nStep 10\/14 : RUN mvn  --batch-mode dependency:copy -Dartifact=org.mlflow:mlflow-scoring:1.3.0:pom -DoutputDirectory=\/opt\/java\r\n ---> Using cache\r\n ---> be8968c11b10\r\nStep 11\/14 : RUN mvn  --batch-mode dependency:copy -Dartifact=org.mlflow:mlflow-scoring:1.3.0:jar -DoutputDirectory=\/opt\/java\/jars\r\n ---> Using cache\r\n ---> 501f01ca6bde\r\nStep 12\/14 : ENV {disable_env}=\"false\"\r\n ---> Using cache\r\n ---> ba429bab7041\r\nStep 13\/14 : RUN python -c \"from mlflow.models.container import _install_pyfunc_deps;_install_pyfunc_deps(None, False)\"\r\n ---> Using cache\r\n ---> 898f711a0eab\r\nStep 14\/14 : ENTRYPOINT [\"python\", \"-c\", \"import sys; from mlflow.models import container as C;         C._init(sys.argv[1])\"]\r\n ---> Using cache\r\n ---> 3218207507a4\r\nSuccessfully built 3218207507a4\r\nSuccessfully tagged mlflow-pyfunc:latest\r\nSECURITY WARNING: You are building a Docker image from Windows against a non-Windows Docker host. All files and directories added to build context will have '-rwxr-xr-x' permissions. It is recommended to double check and reset permissions for sensitive files and directories.\r\n2020\/01\/15 13:41:44 INFO mlflow.sagemaker: Pushing image to ECR\r\n2020\/01\/15 13:41:45 INFO mlflow.sagemaker: Pushing docker image mlflow-pyfunc to 129457569888.dkr.ecr.eu-central-1.amazonaws.com\/mlflow-pyfunc:1.3.0\r\n'$' is not recognized as an internal or external command,\r\noperable program or batch file.\r\n```","839":"## What changes are proposed in this pull request?\r\n\r\nBeing able to delete a run in its run page. And make the difference between active run pages and deleted run pages more obvious by adding a banner. See more in #2184 \r\n\r\n## How is this patch tested?\r\n\r\nOnly by manual.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nBe able to delete a run on its run page. More intuitive Run Page UI.\r\n\r\n### What component(s) does this PR affect?\r\n\r\n- [x] UI\r\n- [ ] CLI\r\n- [ ] API\r\n- [ ] REST-API\r\n- [ ] Examples\r\n- [ ] Docs\r\n- [ ] Tracking\r\n- [ ] Projects\r\n- [ ] Artifacts\r\n- [ ] Models\r\n- [ ] Scoring\r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","840":"## Describe the proposal\r\nDisplay version information in REST API, so maintainer and user can check which version is deployed easily and fast.\r\n\r\n### Motivation\r\nAs a user, I want to know which version of tracking server is deployed by calling REST API.\r\nAs a maintainer, I want to present the version of tracking server simply to the user by calling REST API.\r\n\r\n### Proposed Changes\r\nDisplay version in the response when requesting `\/api\/version`. The version information can be extracted from tag of github.\r\n","841":"## Describe the proposal\r\nThe possibility to customize the logging format of the MLFlow Python tracking server.\r\n\r\n### Motivation\r\nWhen the command mlflow server [options] is run, two processes come alive: The MLFlow Tracking server and Gunicorn (the underlying HTTP server). These two processes don't use the same logging format by default. Example:\r\n\r\nGunicorn:\r\n`[2020-01-08 17:55:50 +0000] [19] [INFO] Starting gunicorn 20.0.4`\r\n\r\nMLFlow:\r\n`2020\/01\/08 18:22:17 ERROR mlflow.server: Exception on \/ajax-api\/2.0\/preview\/mlflow\/model-versions\/search [GET]`\r\n\r\nGunicorns' logging format can be changed using the mlflow server --gunicorn-opts. It would be useful to be able to do the same for MLFlow. Currently, this is not possible since the MLFlow logging format is not customizable.\r\n\r\n### Proposed Changes\r\nAn argument could be added to the mlflow server API: https:\/\/www.mlflow.org\/docs\/latest\/cli.html#mlflow-server to set the MLFLow tracking server logging format. The logging format is currently hardcoded here: https:\/\/github.com\/mlflow\/mlflow\/blob\/v1.5.0\/mlflow\/utils\/logging_utils.py#L10\r\n","842":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No custom code.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Win 10 Pro 10.0.18363\r\n- **MLflow installed from (source or binary)**: pip installed mlflow\r\n- **MLflow version (run ``mlflow --version``)**: tried 1.4 and 1.5\r\n- **Python version**: tried 3.7.4 and 3.8.1\r\n- **Exact command to reproduce**: ~ \\multistep_workflow> mlflow run .\r\n\r\n### Describe the problem\r\nRunning \"mlflow run .\" from the provided multistep_workflow folder in command prompt (or anaconda prompt) creates the mlflow-#### and then errors with:\r\n\r\n--------------------------------------------------------------------------------------\r\nCommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\r\n--------------------------------------------------------------------------------------\r\nRunning 'conda init\" or any of  the given variants \"conda init bash\" etc don't change the result.  I can activate the env manually from cli, but the \"mlflow run .\" command errors every time.  I even tried pairing down the yaml dependencies, MLproject file and main.py to bare minimum and same error.\r\n\r\n### Code to reproduce issue\r\nmlflow run .\r\n\r\n### Other info \/ logs\r\nMy only steps on a fresh windows 10 install are to download and install python 3.7.4, Anaconda 4.7.12, and pip install mlflow.  I also tried to conda-forge install mlflow, but got same result.\r\n\r\n------------------------\r\n2020\/01\/11 19:37:29 INFO mlflow.projects: === Running command 'conda activate mlflow-4172aafa43eb88172d061a0f0988e2658e7017e6 && python main.py' in run with ID 'aa92cfd61fc54a6d885b6c34a99ae541' ===\r\n\r\nCommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\r\nIf using 'conda activate' from a batch script, change your\r\ninvocation to 'CALL conda.bat activate'.\r\n\r\nTo initialize your shell, run\r\n\r\n    $ conda init <SHELL_NAME>\r\n\r\nCurrently supported shells are:\r\n  - bash\r\n  - cmd.exe\r\n  - fish\r\n  - tcsh\r\n  - xonsh\r\n  - zsh\r\n  - powershell\r\n\r\nSee 'conda init --help' for more information and options.\r\n\r\nIMPORTANT: You may need to close and restart your shell after running 'conda init'.\r\n\r\n\r\n2020\/01\/11 19:37:30 ERROR mlflow.cli: === Run (ID 'aa92cfd61fc54a6d885b6c34a99ae541') failed ===\r\n---------------------------\r\n","843":"# Describe the proposal\r\nAllow an environment variable version of `--no-conda` such as MLFLOW_NO_CONDA\r\n\r\n### Motivation\r\nConvenience to turn off conda without a cli argument.\r\n\r\n### Proposed Changes\r\nI'm new to mlflow and the click library, but i suspect using a `click.option(..., envvar=\"MLFLOW_NO_CONDA\")` would be relatively simple.\r\n\r\nI'm mostly looking at these lines.\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/utils\/cli_args.py#L23\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/cli.py#L72-L73\r\n","844":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address.\r\n\r\nPlease fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n-------\r\n## Describe the proposal\r\nWhen comparing runs with Parallel Coordinates Plot it shows all parameters by default. There is no option to select or deselect all parameters or metrics.  A button to select\/deselect all parameters\/metrics should be added.\r\n\r\n### Motivation\r\nMost experiments\/runs have many parameters, but only few are changed between runs or are relevant for run comparison analysis. Since all parameters are enabled in Parallel Coordinates Plot by default, it costs much time to deselect irrelevant parameters. Furthermore, having many parameters enabled in Parallel Coordinates Plots, the UI is less responsive, which increases time further to set up the plot as wanted. \r\n\r\n### Proposed Changes\r\nAdd buttons for parameters and metrics to toggle selection of parameters\/metrics.\r\n","845":"## What changes are proposed in this pull request?\r\n\r\nAdapt the MLprojects documentation to include an R example and adapt in places where only the Python API was mentioned. \r\n\r\nEssentially documenting the conclusion of #1014.\r\n\r\n## How is this patch tested?\r\n\r\n```bash\r\ncd docs\r\nmake rdocs\r\nmake livehtml\r\n```\r\n\r\nAnd inspection.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nDocumentation on how to use MLprojects with R entry points.\r\n\r\n### What component(s) does this PR affect?\r\n\r\n- [ ] UI\r\n- [ ] CLI\r\n- [ ] API\r\n- [ ] REST-API\r\n- [ ] Examples\r\n- [x] Docs\r\n- [ ] Tracking\r\n- [ ] Projects\r\n- [ ] Artifacts\r\n- [ ] Models\r\n- [ ] Scoring\r\n- [ ] Serving\r\n- [x] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [x] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","846":"## Describe the proposal\r\nOn `mlflow run` env creation can fail due to any errors in packages. There is no visability on what exactly happened, only following useless stacktrace:\r\n`Collecting package metadata (repodata.json): ...working... Traceback (most recent call last):\r\n  File \"\/opt\/conda\/bin\/mlflow\", line 8, in <module>\r\n    sys.exit(cli())\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/click\/core.py\", line 764, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/click\/core.py\", line 717, in main\r\n    rv = self.invoke(ctx)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/click\/core.py\", line 1137, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/click\/core.py\", line 956, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/click\/core.py\", line 555, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/cli.py\", line 139, in run\r\n    run_id=run_id,\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/projects\/__init__.py\", line 230, in run\r\n    storage_dir=storage_dir, block=block, run_id=run_id)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/projects\/__init__.py\", line 132, in _run\r\n    conda_env_name = _get_or_create_conda_env(project.conda_env_path)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/projects\/__init__.py\", line 462, in _get_or_create_conda_env\r\n    conda_env_path], stream_output=True)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/mlflow\/utils\/process.py\", line 38, in exec_cmd\r\n    raise ShellCommandException(\"Non-zero exitcode: %s\" % (exit_code))\r\nmlflow.utils.process.ShellCommandException: Non-zero exitcode: -9\r\n`\r\n\r\n### Motivation\r\nVisibility on failures of mlflow run command \r\n\r\n### Proposed Changes\r\nFirst and most important - rename that stream_output variable, because it is misleading.\r\nSecond - stream logs to log file (up to you, can be either separate log file or stderr) https:\/\/github.com\/mlflow\/mlflow\/blob\/cb07e3b4717075fd0d572a79c77ad9d85ea07f7b\/mlflow\/projects\/__init__.py#L450 \r\n\r\n","847":"## Describe the proposal\r\nOption to save torchscript model using `torch.jit.save` instead of `torch.save` which enables the deployment toolkits to pickup the optimized torchscript model for production\r\n\r\n### Motivation\r\nMlflow currently doesn't distinguish between native pytorch model (subclass of `torch.nn.Module`) and torchscript model (subclass of `torch.nn.ScriptModule`). This is crucial since the production deployment system works efficiently on models saved as torchscript models (using `torch.jit.save`)\r\nThis is not possible to achieve with the current `pytorch.save_model` since we use `torch.save` internally. \r\n\r\n### Proposed Changes\r\nI have two proposals in mind after talking to @mateiz in slack\r\n\r\n1. Use the existing `pytorch.save_model` itself with an argument user can control to tell mlflow that whether it's a torchscript model or a `torch.nn.Module` model (or we can check the type of the incoming model and decide which flavor but explicit is better than implicit, I guess). The only constraint here is the same `pytorch` file will now have to save two flavors -> `pytorch` or `torchscript`. This sort of doesn't follow the MLFlow API design where every flavor gets one `save`, `load` and `log` function. \r\n2. Use another flavor and call it as `torchscript` and make a module for that. The API here becomes `mlflow.torchscript`\r\n\r\nI have coded up a draft form of the second approach [here](https:\/\/github.com\/hhsecond\/mlflow-redisai\/blob\/master\/mlflow_redisai\/torchscript.py) but looking for suggestions before I make a PR for this to mlflow\r\n","848":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address.\r\n\r\nPlease fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n-------\r\n## Guidelines\r\n\r\nFeature requests typically go through the following lifecycle:\r\n\r\n1. Submit feature request with high-level description on GitHub issues (this is what you're doing now)\r\n2. Discuss feature request with a committer, who may ask for a more detailed design\r\n3. After discussion & agreement on feature request, start implementation\r\n\r\n\r\n\r\n## Describe the proposal\r\nImplement features\/UI for model monitoring after deployment e.g. accuracy logging over time and retraining\/deployment of new models.\r\n\r\n### Motivation\r\nAccurate tracking of production models' performance and model retraining necessity.","849":"### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MS Windows 10 Enterprise N\r\n- **MLflow installed from (source or binary)**: pip install mlflow\r\n- **MLflow version (run ``mlflow --version``)**: 1.5.0\r\n- **Python version**: Python 3.7.4 (anaconda)\r\n- **Exact command to reproduce**: mlflow models predict -m models\/scikitlearn -i testdata\/test_new.csv -t csv\r\n\r\n### Describe the problem\r\nI'm trying to run a prediction on an MLflow model that I have created with a python script and logged with mlflow.sklearn.log_model(). When running \"mlflow models predict\" I'm expecting to get predictions for the records that are included in a csv file, but instead I get an EOL error:\r\n\r\n> mlflow models predict -m models\/scikitlearn -i testdata\/test_new.csv -t csv\r\n2019\/12\/30 13:53:01 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\r\n2019\/12\/30 13:53:03 INFO mlflow.pyfunc.backend: === Running command 'conda activate mlflow-0a64134cb46544fe47c7e20ac258fdf249f3f174 & python -c \"from mlflow.pyfunc.scoring_server import _predict; _predict(model_uri='file:\/\/\/C:\/Users\/xxx\/Documents\/mlflowtest\/models\/scikitlearn', input_path='testdata\/test_new.csv', output_path=None, content_type='csv', json_format='split')\"'\r\nFile \"\", line 1\r\n\"from\r\n^\r\nSyntaxError: EOL while scanning string literal\r\n\r\nWhen I copy and execute the command that mlflow is trying to execute\r\n`conda activate mlflow-0a64134cb46544fe47c7e20ac258fdf249f3f174 & python -c \"from mlflow.pyfunc.scoring_server import _predict; _predict(model_uri='file:\/\/\/C:\/Users\/xxx\/Documents\/mlflowtest\/models\/scikitlearn', input_path='testdata\/test_new.csv', output_path=None, content_type='csv', json_format='split')\"`\r\nit works perfectly fine and returns the predictions for the records in the csv file. So the model seems to be working.\r\n\r\nGoing into the source code, the issue seems to be located inside the backend.py file (https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/pyfunc\/backend.py). Where the command above is executed with\r\n`subprocess.Popen([\"cmd\", \"\/c\", command], close_fds=True, env=command_env)`\r\nSo it seems the Popen command is creating this issue.\r\n\r\nI confirmed this by running a simple python script with the following lines, which returned the same EOL error:\r\n```\r\nimport subprocess\r\ncommand = '''conda activate mlflow-0a64134cb46544fe47c7e20ac258fdf249f3f174 & python -c \"from mlflow.pyfunc.scoring_server import _predict; _predict(model_uri='file:\/\/\/C:\/Users\/xxx\/Documents\/mlflowtest\/models\/scikitlearn', input_path='testdata\/test_new.csv', output_path=None, content_type='csv', json_format='split')\"'''\r\nchild = subprocess.Popen([\"cmd\", \"\/c\", command], close_fds=True, env=None)\r\n```\r\n\r\n### Code to reproduce issue\r\nmlflow models predict -m models\/scikitlearn -i testdata\/test_new.csv -t csv\r\n\r\n### Other info \/ logs\r\n\r\nFull error:\r\n> mlflow models predict -m models\/scikitlearn -i testdata\/test_new.csv -t csv\r\n2019\/12\/30 13:53:01 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\r\n2019\/12\/30 13:53:03 INFO mlflow.pyfunc.backend: === Running command 'conda activate mlflow-0a64134cb46544fe47c7e20ac258fdf249f3f174 & python -c \"from mlflow.pyfunc.scoring_server import _predict; _predict(model_uri='file:\/\/\/C:\/Users\/xxx\/Documents\/mlflowtest\/models\/scikitlearn', input_path='testdata\/test_new.csv', output_path=None, content_type='csv', json_format='split')\"'\r\nFile \"\", line 1\r\n\"from\r\n^\r\nSyntaxError: EOL while scanning string literal\r\nTraceback (most recent call last):\r\nFile \"c:\\programdata\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n\"\\__main\\__\", mod_spec)\r\nFile \"c:\\programdata\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\r\nexec(code, run_globals)\r\nFile \"C:\\ProgramData\\Anaconda3\\Scripts\\mlflow.exe__main__.py\", line 9, in\r\nFile \"c:\\programdata\\anaconda3\\lib\\site-packages\\click\\core.py\", line 764, in \\__call\\__\r\nreturn self.main(*args, **kwargs)\r\nFile \"c:\\programdata\\anaconda3\\lib\\site-packages\\click\\core.py\", line 717, in main\r\nrv = self.invoke(ctx)\r\nFile \"c:\\programdata\\anaconda3\\lib\\site-packages\\click\\core.py\", line 1137, in invoke\r\nreturn _process_result(sub_ctx.command.invoke(sub_ctx))\r\nFile \"c:\\programdata\\anaconda3\\lib\\site-packages\\click\\core.py\", line 1137, in invoke\r\nreturn _process_result(sub_ctx.command.invoke(sub_ctx))\r\nFile \"c:\\programdata\\anaconda3\\lib\\site-packages\\click\\core.py\", line 956, in invoke\r\nreturn ctx.invoke(self.callback, **ctx.params)\r\nFile \"c:\\programdata\\anaconda3\\lib\\site-packages\\click\\core.py\", line 555, in invoke\r\nreturn callback(*args, **kwargs)\r\nFile \"c:\\programdata\\anaconda3\\lib\\site-packages\\mlflow\\models\\cli.py\", line 92, in predict\r\njson_format=json_format)\r\nFile \"c:\\programdata\\anaconda3\\lib\\site-packages\\mlflow\\pyfunc\\backend.py\", line 62, in predict\r\nreturn _execute_in_conda_env(conda_env_path, command, self._install_mlflow)\r\nFile \"c:\\programdata\\anaconda3\\lib\\site-packages\\mlflow\\pyfunc\\backend.py\", line 172, in _execute_in_conda_env\r\ncommand, rc\r\nException: Command 'conda activate mlflow-0a64134cb46544fe47c7e20ac258fdf249f3f174 & python -c \"from mlflow.pyfunc.scoring_server import _predict; _predict(model_uri='file:\/\/\/C:\/Users\/xxx\/Documents\/mlflowtest\/models\/scikitlearn', input_path='testdata\/test_new.csv', output_path=None, content_type='csv', json_format='split')\"' returned non zero return code. Return code = 1\r\n\r\nMLflow model conda.yaml file:\r\n- channels:\r\n  - defaults\r\n- dependencies:\r\n  - python=3.6.9\r\n  - scikit-learn=0.22\r\n  - pip:\r\n    - mlflow\r\n    - cloudpickle==1.2.2\r\n- name: mlflow-env","850":"### URL(s) with the issue:\r\n\r\nhttps:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.html\r\nhttps:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.tracking.html\r\n\r\n### Description of proposal (what needs changing):\r\n\r\nDocument what errors are returned for method calls especially in the core mlflow and mlflow.tracking packages. \r\n\r\nFor example, if we pass a non-existent experiment ID to MlflowClient.get_experiment, document that an exception is thrown. \r\n\r\nIf we pass a non-existent experiment name to MlflowClient.get_experiment_by_name, document that None is returned. \r\n\r\nhttps:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.tracking.html#mlflow.tracking.MlflowClient.get_experiment\r\n\r\nhttps:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.tracking.html#mlflow.tracking.MlflowClient.get_experiment_by_name\r\n","851":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OSX\r\n- **MLflow installed from (source or binary)**: PyPi \r\n- **MLflow version (run ``mlflow --version``)**: 1.5.0\r\n- **Python version**: 3.7.5\r\n\r\n### Describe the problem\r\n\r\nMlflowClient.get_experiment() returns the Default experiment (experiment ID 0) for some non-existent experiment IDs when using the MySQL backend-store. \r\n\r\nFor file-based backend-store or in Databricks, get_experiment correctly throws a \"RESOURCE_DOES_NOT_EXIST\" RestException.\r\n\r\n### Code to reproduce issue\r\n\r\nmlflow server --host 0.0.0.0 --port 5000 \\\r\n  --backend-store-uri  mysql:\/\/MY_USER:MY_PASSWORD@localhost:3306\/mlflow \\\r\n  --default-artifact-root $PWD\/mlruns \r\n\r\nexport MLFLOW_TRACKING_URI=http:\/\/localhost:5000\r\n\r\nclient = mlflow.tracking.MlflowClient()\r\nexp = client.get_experiment(\"5bad\") # returns Default experiment\r\nexp = client.get_experiment(\"6bad\") # throws exception\r\n\r\n\r\n\r\n","852":"## What changes are proposed in this pull request?\r\n\r\nIn a MLproject file, when a parameter has a path type and is an hdfs uri, the artifact will be downloaded from hdfs.\r\n\r\n## How is this patch tested?\r\n\r\nWith unit test and by creating an MLflow project that tries to download a file from hdfs.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [X] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nAdded support of hdfs for path parameters in MLflow project.\r\n\r\n### What component(s) does this PR affect?\r\n\r\n- [ ] UI\r\n- [ ] CLI\r\n- [ ] API\r\n- [ ] REST-API\r\n- [ ] Examples\r\n- [ ] Docs\r\n- [ ] Tracking\r\n- [X] Projects\r\n- [ ] Artifacts\r\n- [ ] Models\r\n- [ ] Scoring\r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [X] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","853":"### System information\r\n- **OS Platform and Distribution**: Ubuntu 16.04\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.4.0\r\n- **Python version**: 3.6.9\r\n- **Exact command to reproduce**: mlflow server     --backend-store-uri \"<DB_CONNECTION>\"     --default-artifact-root <ARTIFACT_LOCATION>     --host 0.0.0.0     --port 5100\r\n\r\n### Describe the problem\r\nI cannot use it with HTTPS. This is my NGINX configuration:  \r\n```\r\nserver {\r\n    listen 80;\r\n    listen 443 ssl;\r\n    listen [::]:443 ssl;\r\n    server_name domain.com;\r\n\r\n    auth_basic \"Restricted Content\";\r\n    auth_basic_user_file \/home\/user\/.htpasswd;\r\n\r\n    access_log \/var\/log\/nginx\/reverse-access.log;\r\n    error_log \/var\/log\/nginx\/reverse-error.log;\r\n\r\n    location \/ {\r\n        proxy_set_header    Host                $host;\r\n        proxy_set_header    X-Forwarded-For     $proxy_add_x_forwarded_for;\r\n        proxy_set_header    X-Forwarded-Proto   $scheme;\r\n        proxy_set_header    Accept-Encoding     \"\";\r\n        proxy_set_header    Proxy               \"\";\r\n        proxy_pass $scheme:\/\/127.0.0.1:5000;\r\n        include uwsgi_params;\r\n        uwsgi_pass unix:\/home\/user\/app\/uwsgi.sock;\r\n    }\r\n\r\n    location \/mlflow\/ {\r\n        proxy_pass https:\/\/localhost:5100\/;\r\n    }\r\n}\r\n```\r\nBut it doesn't work. It only works with HTTP. \r\n","854":"## What changes are proposed in this pull request?\r\n\r\nAdded yarn backend to launch MLflow projects on Yarn.\r\n\r\n## How is this patch tested?\r\n\r\nWith unit tests and by launching run with --backend yarn option in the command line\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [X] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\nAdded yarn backend to launch runs on yarn when using MLflow project. This can be used by using --backend yarn option in the mlflow run command line.\r\n\r\n### What component(s) does this PR affect?\r\n\r\n- [ ] UI\r\n- [ ] CLI\r\n- [ ] API\r\n- [ ] REST-API\r\n- [ ] Examples\r\n- [ ] Docs\r\n- [ ] Tracking\r\n- [X] Projects\r\n- [ ] Artifacts\r\n- [ ] Models\r\n- [ ] Scoring\r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [X] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","855":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address.\r\n\r\nPlease fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n-------\r\n## Guidelines\r\n\r\nFeature requests typically go through the following lifecycle:\r\n\r\n1. Submit feature request with high-level description on GitHub issues (this is what you're doing now)\r\n2. Discuss feature request with a committer, who may ask for a more detailed design\r\n3. After discussion & agreement on feature request, start implementation\r\n\r\n\r\n## Describe the proposal\r\nAllow MLproject files to support passing None type down to command line arguments of the underlying application or allow the specification of optional params that are ignored when not supplied.\r\n\r\nCurrently, providing a None value is not allowed for non-string types and is a \"None\" string when used in the downstream python script.\r\n\r\n### Motivation\r\nAllowing this functionality will allow for maximum compatiblity with common python commandline parsing packages (argparse) without the need to modify that code to conform to how mlflow treats MLproject parameters.\r\n\r\nCurrently, we are able to define defaults and optional arguments in our argparse ArgumentParser arguments and can perform checking for the presence of such arguments in the application\r\n\r\n```\r\nparser = argparse.ArgumentParser()\r\nparser.add_argument('--assume_role', type=str, default=None)\r\n_args = parser.parse_args()\r\n\r\nif _args.assume_role:\r\n    # some logic here\r\n```\r\n\r\nHowever, MLproject files would force us to either provide the argument or default to some other string value, which causes us to have to conform our code to always expect some sort of default value i.e. `if _args.assume_role == \"\"` and ultimately changes how we need to use it outside of mlflow workflows\r\n\r\n### Proposed Changes\r\nFor user-facing changes, what APIs are you proposing to add or modify? For internal changes, what code paths will need to be modified?\r\n\r\nModify the MLproject file specification and interpretation such that it better aligns with argparsing functionality as described above\r\n","856":"## What changes are proposed in this pull request?\r\n\r\nAllow usage of a private version control system when displaying experiment source and version links\r\n\r\nWe want to package the app without having to rebuild the UI with custom VCS settings so these settings are passed at runtime to the Python backend through environment variables and served to the UI.\r\n\r\nIn `mlflow\/server\/js\/src\/utils\/Utils.js`:\r\n* Added cases to `Utils.getGitRepoUrl()` and `Utils.getGitCommitUrl()` to generate urls to a private vcs. \r\n* Added `getPrivateVcsRegex` and `getPrivateVcsUrl` which are called when Utils.js is loaded to set the values we need for regex matching and url generation.\r\n\r\n## How is this patch tested?\r\n\r\nAdded tests for the new JS functions, and manual testing.\r\n \r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [X] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nDisplays links pointing to a private version control system for run source repo and version.\r\n\r\n### What component(s) does this PR affect?\r\n\r\n- [X] UI\r\n- [ ] CLI\r\n- [ ] API\r\n- [x] REST-API\r\n- [ ] Examples\r\n- [x] Docs\r\n- [ ] Tracking\r\n- [ ] Projects\r\n- [ ] Artifacts\r\n- [ ] Models\r\n- [ ] Scoring\r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [X] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [X] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","857":"## What changes are proposed in this pull request?\r\n\r\nAdded a tag mlflow.project.backendConfig to store this information in the DB. Retrieve this tag in the UI to add the backend-config option in the run command.\r\n\r\n## How is this patch tested?\r\n\r\nLocally, checking that the backend config appears in the command in the UI\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [X] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nAdded backend config in run command line in the ui.\r\n\r\n### What component(s) does this PR affect?\r\n\r\n- [X] UI\r\n- [ ] CLI\r\n- [ ] API\r\n- [ ] REST-API\r\n- [ ] Examples\r\n- [ ] Docs\r\n- [ ] Tracking\r\n- [ ] Projects\r\n- [ ] Artifacts\r\n- [ ] Models\r\n- [ ] Scoring\r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [X] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","858":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.6 LTS\r\n- **MLflow installed from (source or binary)**: pip\r\n- **MLflow version (run ``mlflow --version``)**: 1.4.0\r\n- **Python version**: 3.6.9 \r\n\r\n### Describe the problem\r\nThe model registry UI does not show the user tag value, both when viewing all versions within one registry in the table (fig1) and when accessing version details (fig2).\r\nMlfow user is recognized\/logged normally in the tracking UI (fig3)\r\n\r\n### Code to reproduce issue\r\nUsing a tracking remote PostgreSQL db and saving artifacts with a nfs mount.\r\nMlflow user is set with mlflow.utils.mlflow_tags.MLFLOW_USER.\r\n\r\n### Other info \/ logs\r\nFig1\r\n![image](https:\/\/user-images.githubusercontent.com\/58782224\/70905328-7f3a4900-1ffb-11ea-8d54-f9cd771b2ffe.png)\r\nFig2\r\n![image](https:\/\/user-images.githubusercontent.com\/58782224\/70905372-9c6f1780-1ffb-11ea-882d-279b9f7250ae.png)\r\nFig3\r\n![image](https:\/\/user-images.githubusercontent.com\/58782224\/70905414-b577c880-1ffb-11ea-8853-148429a542b2.png)\r\n\r\n","859":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address.\r\n\r\nPlease fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n-------\r\n\r\n## Describe the proposal\r\nWhen deploying a model via build-docker it would be useful to provide a transformation function that takes raw (non-encoded) data. This will enable anyone using the Prediction REST API to pass human readable data to the service and thus better encapsulates the transformation dependency.  \r\n\r\n### Motivation\r\nUsers of the Prediction REST API will not be required to manage and run a transformation dependency.\r\n\r\n### Proposed Changes\r\nIt feels like the best place to add this functionality is in the model API. The predict method will call the transform method before proceeding. Thoughts?\r\n","860":"## What changes are proposed in this pull request?\r\n\r\nThe ability specify a custom base image and disable Java installation and building when using build-docker.\r\n\r\n## How is this patch tested?\r\n\r\nIt's not yet. I'll think about this and am open to suggestions.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [X ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nYou can now optionally specify a base image in build-docker and disable Java.\r\n\r\n### What component(s) does this PR affect?\r\n\r\n- [ ] UI\r\n- [X ] CLI\r\n- [ ] API\r\n- [ ] REST-API\r\n- [ ] Examples\r\n- [ ] Docs\r\n- [ ] Tracking\r\n- [ ] Projects\r\n- [ ] Artifacts\r\n- [X ] Models\r\n- [ ] Scoring\r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [X ] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [X] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","861":"## What changes are proposed in this pull request?\r\n\r\n(Please fill in changes proposed in this fix)\r\n\r\n## How is this patch tested?\r\n\r\n(Details)\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n\r\n### What component(s) does this PR affect?\r\n\r\n- [ ] UI\r\n- [ ] CLI\r\n- [ ] API\r\n- [ ] REST-API\r\n- [x] Examples\r\n- [ ] Docs\r\n- [ ] Tracking\r\n- [ ] Projects\r\n- [ ] Artifacts\r\n- [ ] Models\r\n- [ ] Scoring\r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","862":"## Describe the proposal\r\nAdd 'delete' and 'add to comparison' buttons in the run view page.\r\n\r\n### Motivation\r\nWhen on run view page, it would be much easier to delete the run from that page, rather than having to go back to the runs list page and find that run again and then delete the run. Similarly for run comparisons.\r\n\r\n### Proposed Changes\r\nAdd 'delete' and 'add to comparison' buttons in the run view page.\r\n","863":"## Describe the proposal\r\nAs described in [this post](http:\/\/feedback.databricks.com\/forums\/263785-product-feedback\/suggestions\/39092506-for-an-mlflow-experiment-you-were-able-to-see-all), we should enable we should make the number of runs that appear per \"page\" load configurable, so that users can view more than 100 runs at a time without clicking \"load more\" a bunch of times. \r\n\r\n### Motivation\r\nSee above - we should make the number of runs that appear per \"page\" load configurable, so that users can view more than 100 runs at a time without clicking \"load more\" a bunch of times\r\n\r\n### Proposed Changes\r\nTo implement this proposal, we can expose the [max_results SearchRuns API parameter](https:\/\/github.com\/mlflow\/mlflow\/blob\/23df0e111a9802181d4e0ea1e85934805514e3d0\/mlflow\/protos\/service.proto#L926) via the search UI rendered by [ExperimentView](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/server\/js\/src\/components\/ExperimentView.js#L364) & likely updating logic [here](https:\/\/github.com\/mlflow\/mlflow\/blob\/23df0e111a9802181d4e0ea1e85934805514e3d0\/mlflow\/server\/js\/src\/components\/ExperimentPage.js#L145) & [here](https:\/\/github.com\/mlflow\/mlflow\/blob\/23df0e111a9802181d4e0ea1e85934805514e3d0\/mlflow\/server\/js\/src\/components\/ExperimentPage.js#L76) to pass the number of results to the REST API call. We should also add unit tests [here](https:\/\/github.com\/mlflow\/mlflow\/blob\/23df0e111a9802181d4e0ea1e85934805514e3d0\/mlflow\/server\/js\/src\/components\/ExperimentPage.test.js#L173)\r\n","864":"\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 18.04)**:\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --1.4.0``)**:\r\n- **Python version 3.7**:\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI defined my own custom activation function named \"Div\" in keras\/tensorflow. But at the time of deploying, I got the messages:\r\n```\r\nFile \"\/home\/llu\/anaconda3\/envs\/mlflow-01807f49b51ed6764ff5c74ddd4eabaeb13f7151\/lib\/python3.7\/site-packages\/keras\/activations.py\", line 208, in deserialize\r\n    printable_module_name='activation function')\r\n  File \"\/home\/llu\/anaconda3\/envs\/mlflow-01807f49b51ed6764ff5c74ddd4eabaeb13f7151\/lib\/python3.7\/site-packages\/keras\/utils\/generic_utils.py\", line 167, in deserialize_keras_object\r\n    ':' + function_name)\r\nValueError: Unknown activation function:Div\r\n```\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks,\r\nplease include the full traceback. Large logs and files should be attached.\r\n","865":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **MLflow installed from (source or binary)**: Binary using pip\r\n- **MLflow version (run ``mlflow --version``)**: 1.4.0\r\n- **Python version**: 3.6\r\n- **Exact command to reproduce**: mlflow_client.log_artifact(run.info.run_id, FILE_PATH)\r\n\r\n### Describe the problem\r\nI'm using Google buckets as the artifacts store, and when I log an artifact using `log_artifact`, it is uploaded fine and displayed in the UI fine. But when I log the same file to the same location again but with different contents (like a log file), in the UI I still get the very first content of the file. \r\nI checked the file uploaded to the GCP bucket each time and yes it is uploaded correctly with the new content each time. But for some reason (maybe caching), the MlFlow UI still displays the very first content of that file. However, in the size filed, it displays the new updated file size correctly. \r\nEven when I use the download button from the UI, it gets me the old content. But the actual file in the bucket has the new content. \r\n\r\n### Code to reproduce issue\r\n```\r\nmlflow_client = MlflowClient(URI)\r\nrun = mlflow_client.get_run(args.run_id)\r\nmlflow_client.log_artifact(run.info.run_id, LOG_FILE)\r\n# Do some changes in the LOG_FILE\r\nmlflow_client.log_artifact(run.info.run_id, LOG_FILE)\r\n```\r\n","866":"## What changes are proposed in this pull request?\r\n\r\nas the user name is taken from system variable can be very generic, this tries to get user name from git configuration which seems to be more accurate.\r\n\r\n## How is this patch tested?\r\n\r\nadded doc-test\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.","867":"### Proposal\r\nIt would be extremely valuable to have the ability to discover what version of a registered model was running in production at any time in the past. \r\n\r\n### Motivation\r\nAs an ML Flow user, I would like to be able to easily roll back to a model version that I know was working well in the past. Consider the case where a model that undergoes automated re-training and re-deployment degrades in performance or becomes buggy in a way that requires immediate attention. While I am working to discover the root cause of the issue, I would like to be able to easily find a previous version that I know to be in a working state and quickly promote that model to production. \r\n\r\n### Proposed Changes\r\nTo do so, it would be helpful to have a model registry history that displays which model versions were considered the latest model in the Production stage at a given time. This might take the form of an additional column in the versions table representing a \"Deployed at\" time along with the restriction that only one version of a registered model can be marked as \"deployed\" at any given time. \r\n","868":"Added the authentication through service principal in an azure machine learning workspace in order to be able to authenticate \r\nfor CI\/CD\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nI have added a way to authenticate directly to the Azure Machine Learning Workspace without the interactive login. \r\nIt uses a service principal authentication in order to directly log into azure subscription and the workspace.\r\nIt is an option that can be enable. So, it only extends the actual method of the cli `mlflow azureml build-image`.\r\n\r\n## How is this patch tested?\r\n\r\nI have create a workspace in one of the multiples subscritptions that I had.\r\nI also have created an application to log into the workspace and finally run the command.\r\nI checked that the image was succesfully created.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nAdded support in the CLI to log with an active directory application in order to create the image inside the azure machine learning workspace.\r\n\r\n### What component(s) does this PR affect?\r\n\r\n- [ ] UI\r\n- [x] CLI\r\n- [ ] API\r\n- [ ] REST-API\r\n- [ ] Examples\r\n- [ ] Docs\r\n- [ ] Tracking\r\n- [ ] Projects\r\n- [ ] Artifacts\r\n- [ ] Models\r\n- [ ] Scoring\r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","869":"## What changes are proposed in this pull request?\r\n\r\nThe proposed change aims at giving the user slightly more control on the Docker image produced.\r\nIn some circumstances it can be useful to be able to set a docker tag instead of relying on the default behaviour (commit sha1).\r\n\r\n## How is this patch tested?\r\n\r\nManual and unit tests.\r\n\r\n## Release Notes\r\n\r\n### Is this a user-facing change?\r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nOptionally provide the image tag used for the Project execution docker image in the backend configuration file.\r\n\r\n### What component(s), interfaces, languages, and integrations does this PR affect?\r\nComponents \r\n- [ ] `area\/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area\/build`: Build and test infrastructure for MLflow\r\n- [x] `area\/docs`: MLflow documentation pages\r\n- [ ] `area\/examples`: Example code\r\n- [ ] `area\/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area\/models`: MLmodel format, model serialization\/deserialization, flavors\r\n- [x] `area\/projects`: MLproject format, project running backends\r\n- [ ] `area\/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area\/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area\/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area\/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area\/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area\/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area\/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language\/r`: R APIs and clients\r\n- [ ] `language\/java`: Java APIs and clients\r\n- [ ] `language\/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations\/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations\/sagemaker`: SageMaker integrations\r\n- [ ] `integrations\/databricks`: Databricks integrations\r\n\r\n<!--\r\nInsert an empty named anchor here to allow jumping to this section with a fragment URL\r\n(e.g. https:\/\/github.com\/mlflow\/mlflow\/pull\/123#user-content-release-note-category).\r\nNote that GitHub prefixes anchor names in markdown with \"user-content-\".\r\n-->\r\n<a name=\"release-note-category\"><\/a>\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","870":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Pop OS 18.04\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.4\r\n- **Python version**: 3.6.5\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: \r\n\r\n### Describe the problem\r\nAfter I create an artifact that is logged to a remote artifact uri using FTP I cannot preview the text file in MLflow Tracking Server UI it forwards me to \"Something went wrong\" page.\r\n\r\n### Code to reproduce issue\r\nFirst start a remote MLflow Tracking Server with FTP as default-artifact-store. Then on client run the code:\r\nimport mlflow\r\nwith mlflow.start_run() as run:\r\n    with open(\"output.txt\", \"w\") as f:\r\n        f.write(\"Hello world!\")\r\n    mlflow.log_artifact(\"output.txt\")\r\n\r\n\r\nThanks!","871":"I have this issue when I have a project with a docker Image:\r\n\r\n```\r\nBuilding docker image Employee Experience Categorisation:d9f321a ===\r\n```\r\n\r\n```\r\nTraceback (most recent call last):\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/urllib3\/connectionpool.py\", line 672, in urlopen  chunked=chunked,\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/urllib3\/connectionpool.py\", line 387, in _make_requestconn.request(method, url, **httplib_request_kw)\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/http\/client.py\", line 1252, in request  self._send_request(method, url, body, headers, encode_chunked)\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/http\/client.py\", line 1298, in _send_requestself.endheaders(body, encode_chunked=encode_chunked)\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/http\/client.py\", line 1247, in endheaders   self._send_output(message_body, encode_chunked=encode_chunked)\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/http\/client.py\", line 1065, in _send_output self.send(chunk)\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/http\/client.py\", line 987, in send  self.sock.sendall(data)\r\nConnectionResetError: [Errno 104] Connection reset by peer\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/requests\/adapters.py\", line 449, in send  timeout=timeout\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/urllib3\/connectionpool.py\", line 720, in urlopen  method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/urllib3\/util\/retry.py\", line 400, in incrementraise six.reraise(type(error), error, _stacktrace)\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/urllib3\/packages\/six.py\", line 734, in reraiseraise value.with_traceback(tb)\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/urllib3\/connectionpool.py\", line 672, in urlopen  chunked=chunked,\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/urllib3\/connectionpool.py\", line 387, in _make_requestconn.request(method, url, **httplib_request_kw)\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/http\/client.py\", line 1252, in request  self._send_request(method, url, body, headers, encode_chunked)\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/http\/client.py\", line 1298, in _send_requestself.endheaders(body, encode_chunked=encode_chunked)\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/http\/client.py\", line 1247, in endheaders   self._send_output(message_body, encode_chunked=encode_chunked)\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/http\/client.py\", line 1065, in _send_output self.send(chunk)\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/http\/client.py\", line 987, in send  self.sock.sendall(data)\r\nurllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/bin\/mlflow\", line 8, in <module>  sys.exit(cli())\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/click\/core.py\", line 764, in __call__ return self.main(*args, **kwargs)\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/click\/core.py\", line 717, in main rv = self.invoke(ctx)\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/click\/core.py\", line 1137, in invoke  return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/click\/core.py\", line 956, in invoke   return ctx.invoke(self.callback, **ctx.params)\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/click\/core.py\", line 555, in invoke   return callback(*args, **kwargs)\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/mlflow\/cli.py\", line 134, in run  run_id=run_id\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/mlflow\/projects\/__init__.py\", line 285, in runuse_conda=use_conda, storage_dir=storage_dir, synchronous=synchronous, run_id=run_id)  File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/mlflow\/projects\/__init__.py\", line 154, in _run   run_id=active_run.info.run_id)\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/mlflow\/projects\/__init__.py\", line 818, in _build_docker_imagefileobj=docker_build_ctx, custom_context=True, encoding=\"gzip\")\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/docker\/models\/images.py\", line 279, in build  resp = self.client.api.build(**kwargs)\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/docker\/api\/build.py\", line 269, in build  timeout=timeout,\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/docker\/utils\/decorators.py\", line 46, in innerreturn f(self, *args, **kwargs)\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/docker\/api\/client.py\", line 226, in _post return self.post(url, **self._set_request_timeout(kwargs))\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/requests\/sessions.py\", line 581, in post  return self.request('POST', url, data=data, json=json, **kwargs)   File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/requests\/sessions.py\", line 533, in request   resp = self.send(prep, **send_kwargs)\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/requests\/sessions.py\", line 646, in send  r = adapter.send(request, **kwargs)\r\n File \"\/workspace\/marc\/miniconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/requests\/adapters.py\", line 498, in send  raise ConnectionError(err, request=request)\r\nrequests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\r\n```\r\n\r\nMy docker image is correctly built on my system. Is it because it does not find it on the machine and tries to find it somehwere else?\r\n\r\nMy MLproject file:\r\n```yaml\r\n\r\nname: Employee Experience Categorisation\r\n\r\ndocker_env:\r\n  image: mlflow-docker\r\n\r\nentry_points:\r\n  train:\r\n    parameters:\r\n      data_file: path\r\n      regularization: {type: float, default: 0.1}\r\n    command: \"python src\/train.py -r {regularization} {data_file}\"\r\n  encode:\r\n    parameters:\r\n      save_path: path\r\n      threshold: {type: int, default: 100}\r\n    command: \"python src\/label_encoder.py --save_path {save_path} --map {map} --threshold {threshold} --log\"\r\n```\r\n\r\n\r\nI verified that my docker image was on the system:\r\n\r\n```\r\ndocker images mlflow-docker\r\n\r\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\r\nmlflow-docker       latest              245f9ddbbb75        45 minutes ago      4.47GB\r\n```\r\n\r\n\r\nAny idea?\r\n\r\n\r\n","872":"Hello, \r\n\r\nCan you provide an optional functionality for when you delete a run from the UI with the 'x' button, it is permanently deleted?\r\nI have all the log files and artifacts stored in a local storage, but when I delete the run I have to also manually delete them from the terminal and it is hard to find all the run IDs for multiple deletes. \r\n If you do not want to include this in your code in general, can you provide me the way to do it on my local repo?\r\n\r\nThanks in advance","873":"Hi, \r\nI understand that there is an example in the github on pyspark codes, namely the multistep workflow, however, I have problem understanding how a saved spark model should be served (with their spark configuration specified). If would be great if you can provide some examples since it is actually not written in the documentations. Many many thanks!\r\n\r\nCurrently when i am trying to serve the spark model with \r\n```mlflow models serve -m runs:\/6162603c99234ff6801c8346d6871630\/model --port 5002```\r\nI get errors of the python environment in worker nodes is not the same as the python environment in driver:\r\n```\r\n19\/11\/29 18:10:58 ERROR TaskSetManager: Task 0 in stage 0.0 failed 1 times; aborting job\r\n[2019-11-29 18:10:58 +0800] [28178] [ERROR] Exception in worker process\r\nTraceback (most recent call last):\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/gunicorn\/arbiter.py\", line 583, in spawn_worker\r\n    worker.init_process()\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/gunicorn\/workers\/base.py\", line 129, in init_process\r\n    self.load_wsgi()\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/gunicorn\/workers\/base.py\", line 138, in load_wsgi\r\n    self.wsgi = self.app.wsgi()\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/gunicorn\/app\/base.py\", line 67, in wsgi\r\n    self.callable = self.load()\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 52, in load\r\n    return self.load_wsgiapp()\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 41, in load_wsgiapp\r\n    return util.import_app(self.app_uri)\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/gunicorn\/util.py\", line 350, in import_app\r\n    __import__(module)\r\n  File \"\/home\/davidooi\/.local\/lib\/python3.6\/site-packages\/mlflow\/pyfunc\/scoring_server\/wsgi.py\", line 6, in <module>\r\n    app = scoring_server.init(load_model(os.environ[scoring_server._SERVER_MODEL_PATH]))\r\n  File \"\/home\/davidooi\/.local\/lib\/python3.6\/site-packages\/mlflow\/pyfunc\/__init__.py\", line 290, in load_model\r\n    return importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\r\n  File \"\/home\/davidooi\/.local\/lib\/python3.6\/site-packages\/mlflow\/spark.py\", line 436, in _load_pyfunc\r\n    return _PyFuncModelWrapper(spark, _load_model(model_uri=path))\r\n  File \"\/home\/davidooi\/.local\/lib\/python3.6\/site-packages\/mlflow\/spark.py\", line 378, in _load_model\r\n    return PipelineModel.load(model_path)\r\n  File \"\/opt\/apps\/ecm\/service\/spark\/2.4.3-1.2.0\/package\/spark-2.4.3-1.2.0-bin-hadoop2.8\/python\/pyspark\/ml\/util.py\", line 362, in load\r\n    return cls.read().load(path)\r\n  File \"\/opt\/apps\/ecm\/service\/spark\/2.4.3-1.2.0\/package\/spark-2.4.3-1.2.0-bin-hadoop2.8\/python\/pyspark\/ml\/pipeline.py\", line 240, in load\r\n    metadata = DefaultParamsReader.loadMetadata(path, self.sc)\r\n  File \"\/opt\/apps\/ecm\/service\/spark\/2.4.3-1.2.0\/package\/spark-2.4.3-1.2.0-bin-hadoop2.8\/python\/pyspark\/ml\/util.py\", line 558, in loadMetadata\r\n    metadataStr = sc.textFile(metadataPath, 1).first()\r\n  File \"\/opt\/apps\/ecm\/service\/spark\/2.4.3-1.2.0\/package\/spark-2.4.3-1.2.0-bin-hadoop2.8\/python\/pyspark\/rdd.py\", line 1378, in first\r\n    rs = self.take(1)\r\n  File \"\/opt\/apps\/ecm\/service\/spark\/2.4.3-1.2.0\/package\/spark-2.4.3-1.2.0-bin-hadoop2.8\/python\/pyspark\/rdd.py\", line 1360, in take\r\n    res = self.context.runJob(self, takeUpToNumLeft, p)\r\n  File \"\/opt\/apps\/ecm\/service\/spark\/2.4.3-1.2.0\/package\/spark-2.4.3-1.2.0-bin-hadoop2.8\/python\/pyspark\/context.py\", line 1069, in runJob\r\n    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\r\n  File \"\/home\/davidooi\/.local\/lib\/python3.6\/site-packages\/py4j\/java_gateway.py\", line 1257, in __call__\r\n    answer, self.gateway_client, self.target_id, self.name)\r\n  File \"\/opt\/apps\/ecm\/service\/spark\/2.4.3-1.2.0\/package\/spark-2.4.3-1.2.0-bin-hadoop2.8\/python\/pyspark\/sql\/utils.py\", line 63, in deco\r\n    return f(*a, **kw)\r\n  File \"\/home\/davidooi\/.local\/lib\/python3.6\/site-packages\/py4j\/protocol.py\", line 328, in get_return_value\r\n    format(target_id, \".\", name), value)\r\npy4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\r\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\r\n  File \"\/opt\/apps\/ecm\/service\/spark\/2.4.3-1.2.0\/package\/spark-2.4.3-1.2.0-bin-hadoop2.8\/python\/lib\/pyspark.zip\/pyspark\/worker.py\", line 267, in main\r\n    (\"%d.%d\" % sys.version_info[:2], version))\r\nException: Python in worker has different version 3.7 than that in driver 3.6, PySpark cannot run with different minor versions.Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.\r\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\r\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\r\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\r\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\r\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\r\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\r\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\r\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:153)\r\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:153)\r\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\r\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\r\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1893)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1881)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1880)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1880)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2114)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2063)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2052)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\r\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:153)\r\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\r\n  File \"\/opt\/apps\/ecm\/service\/spark\/2.4.3-1.2.0\/package\/spark-2.4.3-1.2.0-bin-hadoop2.8\/python\/lib\/pyspark.zip\/pyspark\/worker.py\", line 267, in main\r\n    (\"%d.%d\" % sys.version_info[:2], version))\r\nException: Python in worker has different version 3.7 than that in driver 3.6, PySpark cannot run with different minor versions.Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.\r\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\r\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\r\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\r\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\r\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\r\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\r\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\r\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:153)\r\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:153)\r\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\r\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\n\r\n[2019-11-29 18:10:58 +0800] [28178] [INFO] Worker exiting (pid: 28178)\r\n[2019-11-29 18:10:58 +0800] [28169] [INFO] Shutting down: Master\r\n[2019-11-29 18:10:58 +0800] [28169] [INFO] Reason: Worker failed to boot.\r\nTraceback (most recent call last):\r\n  File \"\/home\/davidooi\/.conda\/envs\/mlflow\/bin\/mlflow\", line 10, in <module>\r\n    sys.exit(cli())\r\n  File \"\/home\/davidooi\/.local\/lib\/python3.7\/site-packages\/click\/core.py\", line 764, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\/home\/davidooi\/.local\/lib\/python3.7\/site-packages\/click\/core.py\", line 717, in main\r\n    rv = self.invoke(ctx)\r\n  File \"\/home\/davidooi\/.local\/lib\/python3.7\/site-packages\/click\/core.py\", line 1137, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/home\/davidooi\/.local\/lib\/python3.7\/site-packages\/click\/core.py\", line 1137, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/home\/davidooi\/.local\/lib\/python3.7\/site-packages\/click\/core.py\", line 956, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\/home\/davidooi\/.local\/lib\/python3.7\/site-packages\/click\/core.py\", line 555, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"\/home\/davidooi\/.conda\/envs\/mlflow\/lib\/python3.7\/site-packages\/mlflow\/models\/cli.py\", line 56, in serve\r\n    host=host)\r\n  File \"\/home\/davidooi\/.conda\/envs\/mlflow\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/backend.py\", line 84, in serve\r\n    command_env=command_env)\r\n  File \"\/home\/davidooi\/.conda\/envs\/mlflow\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/backend.py\", line 164, in _execute_in_conda_env\r\n    command, rc\r\nException: Command 'source \/opt\/anaconda3\/bin\/..\/etc\/profile.d\/conda.sh && conda activate mlflow-9ebeece9d3ad59af4a788f4ffa82db1db63f7d99 1>&2 && gunicorn --timeout=60 -b 127.0.0.1:5002 -w 1 ${GUNICORN_CMD_ARGS} -- mlflow.pyfunc.scoring_server.wsgi:app' returned non zero return code. Return code = 3\r\n```\r\nAny idea what i did wrong when submitting or saving the spark model itself? I did a spark submit on the python file with the right PYSPARK_PYTHON and DRIVER_PYSPARK_PYTHON set ","874":"\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: centos\r\n- **MLflow installed from (source or binary)**: pip install mlflow\r\n- **MLflow version (run ``mlflow --version``)**: 1.4.0\r\n- **Python version**: 3.7\r\n- **Exact command to reproduce**: mlflow server --default-artifact-root s3:\/\/bucket_name\/ --host 0.0.0.0\r\n\r\n### Describe the problem\r\nBasically I'm running an mlflow server on an AWS EC2 instance. I have mlflow==1.4.0, boto3==1.10.28 and botocore==1.13.28. The ideia is having a remote server on ec2 and persiste experiment artifaxcts on S3. From my local machine I do: mlflow run sklearn_elasticnet_wine (the example in mlflow repo), having MLFLOW_TRACKING_URI env variable set to point to my ec2 instance. Everithing works fine, it runs successfuly, artifacts are stored in S3. The problem is when I access the UI and select a specific run the server send an exception:\r\n\r\n`2019\/11\/27 19:26:44 ERROR mlflow.server: Exception on \/ajax-api\/2.0\/preview\/mlflow\/model-versions\/search [GET]\r\nTraceback (most recent call last):\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/flask\/app.py\", line 2446, in wsgi_app\r\n    response = self.full_dispatch_request()\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/flask\/app.py\", line 1951, in full_dispatch_request\r\n    rv = self.handle_user_exception(e)\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/flask\/app.py\", line 1820, in handle_user_exception\r\n    reraise(exc_type, exc_value, tb)\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/flask\/app.py\", line 1949, in full_dispatch_request\r\n    rv = self.dispatch_request()\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/flask\/app.py\", line 1935, in dispatch_request\r\n    return self.view_functions[rule.endpoint](**req.view_args)\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/mlflow\/server\/handlers.py\", line 137, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/mlflow\/server\/handlers.py\", line 581, in _search_model_versions\r\n    model_versions_detailed = _get_model_registry_store().search_model_versions(\r\nAttributeError: 'NoneType' object has no attribute 'search_model_versions'\r\n2019\/11\/27 19:26:45 ERROR mlflow.server: Exception on \/ajax-api\/2.0\/preview\/mlflow\/artifacts\/list [GET]\r\nTraceback (most recent call last):\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/flask\/app.py\", line 2446, in wsgi_app\r\n    response = self.full_dispatch_request()\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/flask\/app.py\", line 1951, in full_dispatch_request\r\n    rv = self.handle_user_exception(e)\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/flask\/app.py\", line 1820, in handle_user_exception\r\n    reraise(exc_type, exc_value, tb)\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/flask\/app.py\", line 1949, in full_dispatch_request\r\n    rv = self.dispatch_request()\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/flask\/app.py\", line 1935, in dispatch_request\r\n    return self.view_functions[rule.endpoint](**req.view_args)\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/mlflow\/server\/handlers.py\", line 137, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/mlflow\/server\/handlers.py\", line 394, in _list_artifacts\r\n    artifact_entities = _get_artifact_repo(run).list_artifacts(path)\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/mlflow\/store\/artifact\/s3_artifact_repo.py\", line 68, in list_artifacts\r\n    for result in results:\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/botocore\/paginate.py\", line 255, in __iter__\r\n    response = self._make_request(current_kwargs)\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/botocore\/paginate.py\", line 332, in _make_request\r\n    return self._method(**current_kwargs)\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/botocore\/client.py\", line 357, in _api_call\r\n    return self._make_api_call(operation_name, kwargs)\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/botocore\/client.py\", line 648, in _make_api_call\r\n    operation_model, request_dict, request_context)\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/botocore\/client.py\", line 667, in _make_request\r\n    return self._endpoint.make_request(operation_model, request_dict)\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/botocore\/endpoint.py\", line 102, in make_request\r\n    return self._send_request(request_dict, operation_model)\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/botocore\/endpoint.py\", line 132, in _send_request\r\n    request = self.create_request(request_dict, operation_model)\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/botocore\/endpoint.py\", line 116, in create_request\r\n    operation_name=operation_model.name)\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/botocore\/hooks.py\", line 356, in emit\r\n    return self._emitter.emit(aliased_event_name, **kwargs)\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/botocore\/hooks.py\", line 228, in emit\r\n    return self._emit(event_name, kwargs)\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/botocore\/hooks.py\", line 211, in _emit\r\n    response = handler(**kwargs)\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/botocore\/signers.py\", line 90, in handler\r\n    return self.sign(operation_name, request)\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/botocore\/signers.py\", line 157, in sign\r\n    auth.add_auth(request)\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/botocore\/auth.py\", line 425, in add_auth\r\n    super(S3SigV4Auth, self).add_auth(request)\r\n  File \"\/usr\/lib\/python2.7\/site-packages\/botocore\/auth.py\", line 357, in add_auth\r\n    raise NoCredentialsError\r\nNoCredentialsError: Unable to locate credentials`\r\n\r\nI have my AWS credentials set in the ec2 instance, both as env variables and in ~\/.aws\/credentials.\r\n\r\nCan you guys please advise on this?\r\n\r\nThank you\r\n\r\n","875":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: **Yes**\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: **Ubuntu 16.04**\r\n- **MLflow installed from (source or binary)**: **binary**\r\n- **MLflow version (run ``mlflow --version``)**: **1.2.0**\r\n- **Python version**: **3.7**\r\n- **npm version, if running the dev UI**: **NA**\r\n- **Exact command to reproduce**: **NA**\r\n\r\n### Describe the problem\r\nPredict operation is not working for the spark models that are deployed as REST end point using mlflow serve command and have prediction column name other than \"prediction\".  For instance, I have attached the code snippet to build a GBTClassifier on IRIS dataset and deploy it as REST endpoint using mlflow. Now when I pass the model some sample data using curl command to see the predictions, I am getting the mentioned error:\r\n\r\n### Code to reproduce issue\r\nfrom pyspark.ml import Pipeline\r\nfrom pyspark.ml.classification import GBTClassifier\r\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler\r\nfrom pyspark.context import SparkContext\r\nfrom pyspark.sql.session import SparkSession\r\nimport mlflow\r\nimport mlflow.spark\r\n# Load and parse the data file, converting it to a DataFrame.\r\nsc = SparkContext('local')\r\nspark = SparkSession(sc)\r\n\r\n# Training DataFrame\r\ntraining = spark.createDataFrame([\r\n(5.1,3.5,1.4,0.2,\"setosa\"),\r\n(4.9,3.0,1.4,0.2,\"setosa\"),\r\n(4.7,3.2,1.3,0.2,\"setosa\"),\r\n(4.6,3.1,1.5,0.2,\"setosa\"),\r\n(5.0,3.6,1.4,0.2,\"setosa\"),\r\n(5.1,3.5,1.4,0.3,\"setosa\"),\r\n(5.7,3.8,1.7,0.3,\"setosa\"),\r\n(5.1,3.8,1.5,0.3,\"setosa\"),\r\n(5.4,3.4,1.7,0.2,\"setosa\"),\r\n(5.1,3.7,1.5,0.4,\"setosa\"),\r\n(7.0,3.2,4.7,1.4,\"versicolor\"),\r\n(6.4,3.2,4.5,1.5,\"versicolor\"),\r\n(6.9,3.1,4.9,1.5,\"versicolor\"),\r\n(5.5,2.3,4.0,1.3,\"versicolor\"),\r\n(6.5,2.8,4.6,1.5,\"versicolor\"),\r\n(6.8,2.8,4.8,1.4,\"versicolor\"),\r\n(6.7,3.0,5.0,1.7,\"versicolor\"),\r\n(6.0,2.9,4.5,1.5,\"versicolor\"),\r\n(5.7,2.6,3.5,1.0,\"versicolor\"),\r\n(5.5,2.4,3.8,1.1,\"versicolor\")], [\"SepalWidth\",\"SepalLength\",\"PetalWidth\",\"PetalLength\",\"Species\"])\r\n\r\nlabelIndexer = StringIndexer(inputCol=\"Species\", outputCol=\"indexedSpecies\")\r\n\r\nassembler = VectorAssembler(\r\n    inputCols=[\"SepalWidth\", \"SepalLength\", \"PetalWidth\", \"PetalLength\"],\r\n    outputCol=\"features\")\r\n\r\ngbt = GBTClassifier(labelCol=\"indexedSpecies\", featuresCol=\"features\", maxIter=10)\r\ngbt.setPredictionCol(\"predictionCol\")\r\npipeline = Pipeline(stages=[labelIndexer, assembler, gbt])\r\nmodel = pipeline.fit(training)\r\nmlflow.spark.log_model(model, <some_path>)\r\n\r\nprint('deploying model as a service')\r\ncmd = 'nohup mlflow models serve -m ' + '<path_to_model>'+ ' -p 7534 -h 0.0.0.0 --no-conda &'\r\npopen_obj = subprocess.Popen(cmd, shell=True)\r\npopen_obj.communicate()\r\n\r\n### Other info \/ logs\r\n\"stack_trace\": \"Traceback (most recent call last):\\n  File \\\"\/usr\/hdp\/current\/spark2-client\/python\/lib\/pyspark.zip\/pyspark\/sql\/utils.py\\\", line 63, in deco\\n    return f(*a, **kw)\\n  File \\\"\/usr\/hdp\/current\/spark2-client\/python\/lib\/py4j-0.10.7-src.zip\/py4j\/protocol.py\\\", line 328, in get_return_value\\n    format(target_id, \\\".\\\", name), value)\\npy4j.protocol.Py4JJavaError: An error occurred while calling o373.select.\\n: org.apache.spark.sql.AnalysisException: cannot resolve '`prediction`' given input columns: [PetalWidth, probability, features, SepalWidth, predictionCol, SepalLength, PetalLength, rawPrediction];;\\n'Project [features#58, 'prediction]\\n+- Project [SepalWidth#10, SepalLength#11, PetalWidth#12, PetalLength#13, features#58, rawPrediction#64, probability#71, UDF(rawPrediction#64) AS predictionCol#79]\\n   +- Project [SepalWidth#10, SepalLength#11, PetalWidth#12, PetalLength#13, features#58, rawPrediction#64, UDF(rawPrediction#64) AS probability#71]\\n      +- Project [SepalWidth#10, SepalLength#11, PetalWidth#12, PetalLength#13, features#58, UDF(features#58) AS rawPrediction#64]\\n         +- Project [SepalWidth#10, SepalLength#11, PetalWidth#12, PetalLength#13, UDF(named_struct(SepalWidth, SepalWidth#10, SepalLength, SepalLength#11, PetalWidth, PetalWidth#12, PetalLength, PetalLength#13)) AS features#58]\\n            +- LogicalRDD [SepalWidth#10, SepalLength#11, PetalWidth#12, PetalLength#13], false\\n\\n\\n\\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:92)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:89)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:289)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:289)\\n\\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:288)\\n\\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:95)\\n\\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:95)\\n\\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:107)\\n\\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:107)\\n\\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\\n\\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:106)\\n\\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:118)\\n\\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1$1.apply(QueryPlan.scala:122)\\n\\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\\n\\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\\n\\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\\n\\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\\n\\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\\n\\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\\n\\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:122)\\n\\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$2.apply(QueryPlan.scala:127)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\\n\\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:127)\\n\\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:95)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:89)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:84)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:127)","876":"## Describe the proposal\r\n    mlflow run implies running some bash script entry and the \"package model\"\r\n    manages the pipeline of ML : Data Extraction, Processing, ...\r\n\r\n    We may need to run pipeline of processes : several connected scripts and have intermediate results storage and metrics.\r\n    This is not clear if its better to manage outside of mlflow or within mlflow framework.\r\n\r\n    Some examples of pipelines : \r\n        https:\/\/github.com\/Mastercard\/Mastercard-Labs-ML-Pipeline\r\n        https:\/\/github.com\/Neuraxio\/Neuraxle\r\n\r\n\r\n### Motivation\r\n   Large end to end compute includes pipelines.\r\n\r\n\r\n### Proposed Changes\r\n\r\n\r\n\r\n","877":"The current HTML artifact is great for static plots, however I'd like to embed some DASH dashboards, like this one https:\/\/dash-demo.plotly.host\/ddk-clinical-trial-dashboard \r\n\r\nThe way I'm imagining this, is I create an HTML file and log it through `mlflow.log_artifact(..)`:\r\n\r\n```html\r\n<!DOCTYPE html>\r\n<html>\r\n<iframe src=\"https:\/\/dash-demo.plotly.host\/ddk-clinical-trial-dashboard\" style='width: 1200px; height: 1200px' sandbox='allow-same-origin allow-scripts'>\r\n<\/iframe>\r\n<\/html>\r\n```\r\n\r\nCurrently, it does not render, and I get an error (in my browser using inspect) :\r\n```\r\nUncaught DOMException: Failed to read the 'cookie' property from 'Document': The document is sandboxed and lacks the 'allow-same-origin' flag.\r\n```\r\nAfter debugging MLFlow code, I discovered that this is because the iframe where the HTML artifact is rendered only has `sandbox=\"allow-scripts\"` and what I need for DASH dashboard is  \r\n`sandbox=\"allow-same-origin allow-scripts \" `. After modifying this, my HTML is rendering nicely.\r\n\r\nTherefore, I would like to request to modify that line, if possible.\r\nin the file https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/server\/js\/src\/components\/artifact-view-components\/ShowArtifactHtmlView.js#L60 \r\n\r\nreplace this :\r\n```js\r\n<Iframe url=\"\"\r\n                src={this.getBlobURL(this.state.html, 'text\/html')}\r\n                width=\"100%\"\r\n                height=\"500px\"\r\n                id=\"html\"\r\n                className=\"html-iframe\"\r\n                display=\"block\"\r\n                position=\"relative\"\r\n                sandbox=\"allow-scripts\"\/> \r\n               \/\/  sandbox=\"allow-same-origin allow-scripts\"\/> \r\n      );\r\n```\r\n\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: YES\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS, Windows\r\n- **MLflow installed from (source or binary)**:  pre-installed on Databricks \r\n- **MLflow version (run ``mlflow --version``)**: 1.3 \r\n- **Python version**: 3.7\r\n- **npm version, if running the dev UI**: -\r\n- **Exact command to reproduce**: see above","878":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address.\r\n\r\nPlease fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n-------\r\n## Guidelines\r\n\r\nFeature requests typically go through the following lifecycle:\r\n\r\n1. Submit feature request with high-level description on GitHub issues (this is what you're doing now)\r\n2. Discuss feature request with a committer, who may ask for a more detailed design\r\n3. After discussion & agreement on feature request, start implementation\r\n\r\n\r\n## Describe the proposal\r\nWhen there are plenty of parameters, only show a summary of parameters instead of show all.\r\n\r\n### Motivation\r\nMake the list of runs clear when the parameters are too many to show\r\n\r\n### Proposed Changes\r\nShow a summary of parameters like tags.","879":"Cap `train_loss` at `null_train_loss` instead of `null_valid_loss`.\r\n\r\n## What changes are proposed in this pull request?\r\n\r\nCap `train_loss` at `null_train_loss` instead of `null_valid_loss`. Seems more reasonable, since `null_train_loss` is supplied anyway.\r\n\r\n### Is this a user-facing change?\r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\n### What component(s) does this PR affect?\r\n\r\n- [ ] UI\r\n- [ ] CLI\r\n- [ ] API\r\n- [ ] REST-API\r\n- [x] Examples\r\n- [ ] Docs\r\n- [ ] Tracking\r\n- [ ] Projects\r\n- [ ] Artifacts\r\n- [ ] Models\r\n- [ ] Scoring\r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n\r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","880":"I tried to start mlflow server in a load balancer pod in k8s and exposed port 8111, the server progress could start up successfully, but when I visit the url of the pod, the website keep showing the error page\r\n<img width=\"1232\" alt=\"d600794350d4092a8f6710513d296d01\" src=\"https:\/\/user-images.githubusercontent.com\/29878050\/69297942-62eafc80-0c47-11ea-95d8-623185ee6cf0.png\">\r\n\r\nI checked the server log and don't know how to solve it. I can make sure that the server progress started successfully, and there is a directory named mlruns with right structure and data in it.\r\n\r\n![d80ccf37c2a549b7d1cf0d64901e6dc2](https:\/\/user-images.githubusercontent.com\/29878050\/69297901-49e24b80-0c47-11ea-914a-69bb9d60f0e0.png)\r\n\r\n","881":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address.\r\n\r\nPlease fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n### URL(s) with the issue:\r\n\r\nhttps:\/\/groups.google.com\/forum\/#!topic\/mlflow-users\/E9QW4HdS8a8 \r\n\r\n### Description of proposal (what needs changing):\r\nML flow works great, I log E-V-E-R-Ything there ( including my mdoels ).My problem is that there is no authentication mechanism documented , no example in the documentation, only a few words on tokens....\r\nI would very appreciate it if one can add to the documentation how to run mlflow with username and password\r\n","882":"## Describe the proposal\r\nI would like to track multiple Git repo's with Mlflow Tracking. \r\nCurrently I have no specific implementation in mind.\r\n\r\n### Motivation\r\nMy projects often have other Python packages installed in develop mode (`python setup.py develop`). Changes in the code of those packages aren't tracked by Mlflow Tracking right now. I didn't find a method to track multiple repositories.\r\n\r\n### Proposed Changes\r\n\r\n","883":"- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian Stretch\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.4.0\r\n- **Python version**: 3.6.8\r\n- **Exact command to reproduce**: `mlflow db upgrade` (ran before the server is actually started)\r\n\r\n### Describe the problem\r\nI'm deploying mlflow tracking server on Kubernetes and I run the `mlflow db upgrade` in an init container i.e before the server is actually started. That procedure worked fine if the server has started at least once before.\r\n\r\nSo when I deploy mlflow for the first time (empty db), the migration fails because I suspect that it is the tracking server that setup the db on first deployment. Am I right? \r\n\r\nIt would be nice if the DB would actually setup via the migration process or a separate command like `mlflow db init`. This command should be run multiple time without crashing. In other words it should be idempotent. As you can imagine the init-container will always be run before the server starts.\r\n\r\n### Other info \/ logs\r\nHere are the logs:\r\n\r\n```\r\n019\/11\/18 18:25:45 INFO mlflow.store.db.utils: Updating database tables at postgresql:\/\/dbadmin:wIZ4LFHfzxR96eOu04da@mlflow.c4ikfbyrjbf9.eu-central-1.rds.amazonaws.com:5432\/mlflow in preparation for MLflow 1.0 schema migrations\r\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\r\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\r\nINFO  [alembic.runtime.migration] Running upgrade  -> ff01da956556, ensure_unique_constraint_names\r\nTraceback (most recent call last):\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/sqlalchemy\/engine\/base.py\", line 1249, in _execute_context\r\n    cursor, statement, parameters, context\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/sqlalchemy\/engine\/default.py\", line 552, in do_execute\r\n    cursor.execute(statement, parameters)\r\npsycopg2.errors.UndefinedTable: relation \"experiments\" does not exist\r\n\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"\/usr\/local\/bin\/mlflow\", line 8, in <module>\r\n    sys.exit(cli())\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/click\/core.py\", line 764, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/click\/core.py\", line 717, in main\r\n    rv = self.invoke(ctx)\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/click\/core.py\", line 1137, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/click\/core.py\", line 1137, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/click\/core.py\", line 956, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/click\/core.py\", line 555, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/mlflow\/db.py\", line 28, in upgrade\r\n    mlflow.store.db.utils._upgrade_db_initialized_before_mlflow_1(url)\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/mlflow\/store\/db\/utils.py\", line 155, in _upgrade_db_initialized_before_mlflow_1\r\n    command.upgrade(config, 'heads')\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/alembic\/command.py\", line 279, in upgrade\r\n    script.run_env()\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/alembic\/script\/base.py\", line 475, in run_env\r\n    util.load_python_file(self.dir, \"env.py\")\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/alembic\/util\/pyfiles.py\", line 98, in load_python_file\r\n    module = load_module_py(module_id, path)\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/alembic\/util\/compat.py\", line 174, in load_module_py\r\n    spec.loader.exec_module(module)\r\n  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/mlflow\/temporary_db_migrations_for_pre_1_users\/env.py\", line 78, in <module>\r\n    run_migrations_online()\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/mlflow\/temporary_db_migrations_for_pre_1_users\/env.py\", line 72, in run_migrations_online\r\n    context.run_migrations()\r\n  File \"<string>\", line 8, in run_migrations\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/alembic\/runtime\/environment.py\", line 846, in run_migrations\r\n    self.get_context().run_migrations(**kw)\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/alembic\/runtime\/migration.py\", line 365, in run_migrations\r\n    step.migration_fn(**kw)\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/mlflow\/temporary_db_migrations_for_pre_1_users\/versions\/ff01da956556_ensure_unique_constraint_names.py\", line 174, in upgrade\r\n    condition=column('lifecycle_stage').in_([\"active\", \"deleted\"])\r\n  File \"\/usr\/local\/lib\/python3.6\/contextlib.py\", line 88, in __exit__\r\n    next(self.gen)\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/alembic\/operations\/base.py\", line 325, in batch_alter_table\r\n    impl.flush()\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/alembic\/operations\/batch.py\", line 79, in flush\r\n    fn(*arg, **kw)\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/alembic\/ddl\/impl.py\", line 241, in drop_constraint\r\n    self._exec(schema.DropConstraint(const))\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/alembic\/ddl\/impl.py\", line 134, in _exec\r\n    return conn.execute(construct, *multiparams, **params)\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/sqlalchemy\/engine\/base.py\", line 988, in execute\r\n    return meth(self, multiparams, params)\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/sqlalchemy\/sql\/ddl.py\", line 72, in _execute_on_connection\r\n    return connection._execute_ddl(self, multiparams, params)\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/sqlalchemy\/engine\/base.py\", line 1050, in _execute_ddl\r\n    compiled,\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/sqlalchemy\/engine\/base.py\", line 1253, in _execute_context\r\n    e, statement, parameters, cursor, context\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/sqlalchemy\/engine\/base.py\", line 1473, in _handle_dbapi_exception\r\n    util.raise_from_cause(sqlalchemy_exception, exc_info)\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/sqlalchemy\/util\/compat.py\", line 398, in raise_from_cause\r\n    reraise(type(exception), exception, tb=exc_tb, cause=cause)\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/sqlalchemy\/util\/compat.py\", line 152, in reraise\r\n    raise value.with_traceback(tb)\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/sqlalchemy\/engine\/base.py\", line 1249, in _execute_context\r\n    cursor, statement, parameters, context\r\n  File \"\/usr\/local\/lib\/python3.6\/site-packages\/sqlalchemy\/engine\/default.py\", line 552, in do_execute\r\n    cursor.execute(statement, parameters)\r\nsqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation \"experiments\" does not exist\r\n\r\n[SQL: ALTER TABLE experiments DROP CONSTRAINT lifecycle_stage]\r\n(Background on this error at: http:\/\/sqlalche.me\/e\/f405)\r\n```\r\n","884":"## Describe the proposal & Motivation\r\nCurrently we put all runs in the same experiment, just to be able to compare them. It makes our experiments totally messy. \r\nI would like create more experiments with less runs in order to have a better organization in my server. But I want to be able to compare them.\r\nWe love tags. That would be great to compare all runs with a given tag cross experiments.\r\n\r\n### Proposed Changes\r\nProbably nothing... Today if I call `<my_mlflow_server_url>\/#\/compare-runs?runs=[...]` with runs from different experiments ... it works! \r\nI am wondering why there is a constraint on the experiment id. Is it possible to remove it ? It will enable to create runs views between different experiments. For example, a view that lists all the runs launched by a user. (For example, what are my 20 latest runs ?) ","885":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\nPlease fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 16.04\r\n- **MLflow installed from (source or binary)**:binary\r\n- **MLflow version (run ``mlflow --version``)**:1.3.0\r\n- **Python version**:3.7.0\r\n- **npm version, if running the dev UI**:N\/A\r\n- **Exact command to reproduce**:\r\ndocker run -p 5001:8080 <image_name>\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\nbuild docker with a keras model.\r\ndocker run fails when running with ubuntu.\r\non windows dev env it works fine.\r\n\r\nNot able to fix this issue with diff versions of keras or gevent 1.4.0 or 1.3.0\r\nTypeError: cannot create weak reference to 'gevent._local.local' object\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\napp = scoring_server.init(pyfunc.load_pyfunc(\"file:\/\/\/D:\\\\tmp\\\\zmodel_KerasImageClassificationMLFlow\"))\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks,\r\nplease include the full traceback. Large logs and files should be attached.\r\nd:\\tmp>docker run -p 5001:8080 \"keras_image_classification\"\r\npip 19.3.1 from \/miniconda\/lib\/python3.7\/site-packages\/pip (python 3.7)\r\nPython 3.7.4\r\n1.3.0\r\n[2019-11-18 03:51:04 +0000] [33] [INFO] Starting gunicorn 20.0.0\r\n[2019-11-18 03:51:04 +0000] [33] [INFO] Listening at: http:\/\/127.0.0.1:8000 (33)\r\n[2019-11-18 03:51:04 +0000] [33] [INFO] Using worker: gevent\r\n[2019-11-18 03:51:04 +0000] [37] [INFO] Booting worker with pid: 37\r\n[2019-11-18 03:51:04 +0000] [38] [INFO] Booting worker with pid: 38\r\n[2019-11-18 03:51:04 +0000] [39] [INFO] Booting worker with pid: 39\r\n[2019-11-18 03:51:04 +0000] [40] [INFO] Booting worker with pid: 40\r\n\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/models\/container\/scoring_server\/wsgi.py:3: DeprecationWarning: .. Warning:: ``mlflow.pyfunc.load_pyfunc`` is deprecated since 1.0. This method will be removed in a near future release. Use ``mlflow.pyfunc.load_model`` instead.\r\n  app = scoring_server.init(pyfunc.load_pyfunc(\"\/opt\/ml\/model\/\"))\r\n\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/tensorflow_core\/python\/pywrap_tensorflow_internal.py:15: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n  import imp\r\n[2019-11-18 03:51:06 +0000] [38] [ERROR] Exception in worker process\r\nTraceback (most recent call last):\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py\", line 583, in spawn_worker\r\n    worker.init_process()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/ggevent.py\", line 162, in init_process\r\n    super().init_process()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py\", line 133, in init_process\r\n    self.load_wsgi()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py\", line 142, in load_wsgi\r\n    self.wsgi = self.app.wsgi()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/base.py\", line 67, in wsgi\r\n    self.callable = self.load()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 49, in load\r\n    return self.load_wsgiapp()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 39, in load_wsgiapp\r\n    return util.import_app(self.app_uri)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/util.py\", line 331, in import_app\r\n    mod = importlib.import_module(module)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/importlib\/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/models\/container\/scoring_server\/wsgi.py\", line 3, in <module>\r\n    app = scoring_server.init(pyfunc.load_pyfunc(\"\/opt\/ml\/model\/\"))\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/utils\/annotations.py\", line 40, in deprecated_func\r\n    return func(*args, **kwargs)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py\", line 313, in load_pyfunc\r\n    return load_model(model_uri, suppress_warnings)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py\", line 290, in load_model\r\n    return importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/keras.py\", line 328, in _load_pyfunc\r\n    K.set_learning_phase(0)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/tensorflow_core\/python\/keras\/backend.py\", line 356, in set_learning_phase\r\n    _GRAPH_LEARNING_PHASES[_DUMMY_EAGER_GRAPH] = value\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/weakref.py\", line 407, in __setitem__\r\n    self.data[ref(key, self._remove)] = value\r\nTypeError: cannot create weak reference to 'gevent._local.local' object\r\n[2019-11-18 03:51:06 +0000] [38] [INFO] Worker exiting (pid: 38)\r\n\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/models\/container\/scoring_server\/wsgi.py:3: DeprecationWarning: .. Warning:: ``mlflow.pyfunc.load_pyfunc`` is deprecated since 1.0. This method will be removed in a near future release. Use ``mlflow.pyfunc.load_model`` instead.\r\n  app = scoring_server.init(pyfunc.load_pyfunc(\"\/opt\/ml\/model\/\"))\r\n\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/tensorflow_core\/python\/pywrap_tensorflow_internal.py:15: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n  import imp\r\n[2019-11-18 03:51:06 +0000] [37] [ERROR] Exception in worker process\r\nTraceback (most recent call last):\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py\", line 583, in spawn_worker\r\n    worker.init_process()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/ggevent.py\", line 162, in init_process\r\n    super().init_process()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py\", line 133, in init_process\r\n    self.load_wsgi()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py\", line 142, in load_wsgi\r\n    self.wsgi = self.app.wsgi()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/base.py\", line 67, in wsgi\r\n    self.callable = self.load()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 49, in load\r\n    return self.load_wsgiapp()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 39, in load_wsgiapp\r\n    return util.import_app(self.app_uri)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/util.py\", line 331, in import_app\r\n    mod = importlib.import_module(module)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/importlib\/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/models\/container\/scoring_server\/wsgi.py\", line 3, in <module>\r\n    app = scoring_server.init(pyfunc.load_pyfunc(\"\/opt\/ml\/model\/\"))\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/utils\/annotations.py\", line 40, in deprecated_func\r\n    return func(*args, **kwargs)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py\", line 313, in load_pyfunc\r\n    return load_model(model_uri, suppress_warnings)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py\", line 290, in load_model\r\n    return importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/keras.py\", line 328, in _load_pyfunc\r\n    K.set_learning_phase(0)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/tensorflow_core\/python\/keras\/backend.py\", line 356, in set_learning_phase\r\n    _GRAPH_LEARNING_PHASES[_DUMMY_EAGER_GRAPH] = value\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/weakref.py\", line 407, in __setitem__\r\n    self.data[ref(key, self._remove)] = value\r\nTypeError: cannot create weak reference to 'gevent._local.local' object\r\n[2019-11-18 03:51:06 +0000] [37] [INFO] Worker exiting (pid: 37)\r\n\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/models\/container\/scoring_server\/wsgi.py:3: DeprecationWarning: .. Warning:: ``mlflow.pyfunc.load_pyfunc`` is deprecated since 1.0. This method will be removed in a near future release. Use ``mlflow.pyfunc.load_model`` instead.\r\n  app = scoring_server.init(pyfunc.load_pyfunc(\"\/opt\/ml\/model\/\"))\r\n\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/tensorflow_core\/python\/pywrap_tensorflow_internal.py:15: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n  import imp\r\n[2019-11-18 03:51:06 +0000] [40] [ERROR] Exception in worker process\r\nTraceback (most recent call last):\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py\", line 583, in spawn_worker\r\n    worker.init_process()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/ggevent.py\", line 162, in init_process\r\n    super().init_process()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py\", line 133, in init_process\r\n    self.load_wsgi()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py\", line 142, in load_wsgi\r\n    self.wsgi = self.app.wsgi()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/base.py\", line 67, in wsgi\r\n    self.callable = self.load()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 49, in load\r\n    return self.load_wsgiapp()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 39, in load_wsgiapp\r\n    return util.import_app(self.app_uri)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/util.py\", line 331, in import_app\r\n    mod = importlib.import_module(module)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/importlib\/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/models\/container\/scoring_server\/wsgi.py\", line 3, in <module>\r\n    app = scoring_server.init(pyfunc.load_pyfunc(\"\/opt\/ml\/model\/\"))\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/utils\/annotations.py\", line 40, in deprecated_func\r\n    return func(*args, **kwargs)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py\", line 313, in load_pyfunc\r\n    return load_model(model_uri, suppress_warnings)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py\", line 290, in load_model\r\n    return importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/keras.py\", line 328, in _load_pyfunc\r\n    K.set_learning_phase(0)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/tensorflow_core\/python\/keras\/backend.py\", line 356, in set_learning_phase\r\n    _GRAPH_LEARNING_PHASES[_DUMMY_EAGER_GRAPH] = value\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/weakref.py\", line 407, in __setitem__\r\n    self.data[ref(key, self._remove)] = value\r\nTypeError: cannot create weak reference to 'gevent._local.local' object\r\n[2019-11-18 03:51:06 +0000] [40] [INFO] Worker exiting (pid: 40)\r\n\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/models\/container\/scoring_server\/wsgi.py:3: DeprecationWarning: .. Warning:: ``mlflow.pyfunc.load_pyfunc`` is deprecated since 1.0. This method will be removed in a near future release. Use ``mlflow.pyfunc.load_model`` instead.\r\n  app = scoring_server.init(pyfunc.load_pyfunc(\"\/opt\/ml\/model\/\"))\r\n\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/tensorflow_core\/python\/pywrap_tensorflow_internal.py:15: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n  import imp\r\n[2019-11-18 03:51:06 +0000] [39] [ERROR] Exception in worker process\r\nTraceback (most recent call last):\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py\", line 583, in spawn_worker\r\n    worker.init_process()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/ggevent.py\", line 162, in init_process\r\n    super().init_process()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py\", line 133, in init_process\r\n    self.load_wsgi()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py\", line 142, in load_wsgi\r\n    self.wsgi = self.app.wsgi()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/base.py\", line 67, in wsgi\r\n    self.callable = self.load()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 49, in load\r\n    return self.load_wsgiapp()\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 39, in load_wsgiapp\r\n    return util.import_app(self.app_uri)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/gunicorn\/util.py\", line 331, in import_app\r\n    mod = importlib.import_module(module)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/importlib\/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/models\/container\/scoring_server\/wsgi.py\", line 3, in <module>\r\n    app = scoring_server.init(pyfunc.load_pyfunc(\"\/opt\/ml\/model\/\"))\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/utils\/annotations.py\", line 40, in deprecated_func\r\n    return func(*args, **kwargs)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py\", line 313, in load_pyfunc\r\n    return load_model(model_uri, suppress_warnings)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py\", line 290, in load_model\r\n    return importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/mlflow\/keras.py\", line 328, in _load_pyfunc\r\n    K.set_learning_phase(0)\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/site-packages\/tensorflow_core\/python\/keras\/backend.py\", line 356, in set_learning_phase\r\n    _GRAPH_LEARNING_PHASES[_DUMMY_EAGER_GRAPH] = value\r\n  File \"\/miniconda\/envs\/custom_env\/lib\/python3.7\/weakref.py\", line 407, in __setitem__\r\n    self.data[ref(key, self._remove)] = value\r\nTypeError: cannot create weak reference to 'gevent._local.local' object\r\n[2019-11-18 03:51:06 +0000] [39] [INFO] Worker exiting (pid: 39)\r\n[2019-11-18 03:51:06 +0000] [33] [INFO] Shutting down: Master\r\n[2019-11-18 03:51:06 +0000] [33] [INFO] Reason: Worker failed to boot.\r\nGot sigterm signal, exiting.\r\n\r\n","886":"## Describe the proposal\r\nApart from run results, it would be useful to get execution logs, so in case of training failure, users could see the stack trace with failure reason.\r\n\r\n### Motivation\r\nWe are using MLflow as training tracking system in particular, making training and evaluation before packaging artifacts, it may fail on some module not found (dependency missed to be added for example). Another use case is when training process takes significant time, users may want to see the progress on MLFlow UI.\r\n\r\n### Proposed Changes\r\n![image](https:\/\/user-images.githubusercontent.com\/4522842\/68992067-efc03f80-086e-11ea-8fe7-0819b4c96858.png)\r\n\r\nAPI which would return path to logs and\/or tail logs itself while running training.\r\n","887":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address.\r\n\r\nPlease fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n-------\r\n## Guidelines\r\n\r\nFeature requests typically go through the following lifecycle:\r\n\r\n1. Submit feature request with high-level description on GitHub issues (this is what you're doing now)\r\n2. Discuss feature request with a committer, who may ask for a more detailed design\r\n3. After discussion & agreement on feature request, start implementation\r\n\r\n\r\n## Describe the proposal\r\nProvide a clear high-level description of the feature request in the following sections. Feature requests that are likely to be accepted:\r\n* Are minimal in scope (note that it's always easier to add additional functionality later than remove functionality)\r\n* Are extensible (e.g. if adding an integration with an ML framework, is it possible to add similar integrations with other frameworks?)\r\n* Have user impact & value that justifies the maintenance burden of supporting the feature moving forwards. The [JQuery contributor guide](https:\/\/contribute.jquery.org\/open-source\/#contributing-something-new) has an excellent discussion on this.\r\n\r\n### Motivation\r\nWhat is the use case in mind?  Why is it valuable to support, and why is it currently difficult or impossible to achieve? Could the desired functionality alternatively be implemented as a third-party package using MLflow public APIs?\r\n\r\n- The goal of this feature request is to provide a way to directly save models to remote paths using the MLflow API. Per my understanding, there is no existing workflow for this. The workaround I've used is to use `mlflow.<flavor>.save_model(model, temp_local_path)` to write it to a local file, then copy it out to the remote path. This method, while effective, is somewhat cumbersome, and does not generalize well between file systems like `mlflow.<flavor>.load_model()` does (`load_model()` does support remote file systems).\r\n\r\n- It appears that there is support for remote paths built into `mlflow.<flavor>.log_model()`, but there does not seem to be any way to save a MLflow artifact to a remote path without having a running tracking server (or at least it hasn't worked for me; happy to provide further details if it helps).\r\n\r\n### Proposed Changes\r\nFor user-facing changes, what APIs are you proposing to add or modify? For internal changes, what code paths will need to be modified?\r\n\r\n- I have a working implementation of this which leverages a decorator which provides `mlflow.<flavor>.save_model()` with access to a file-system-agnostic file path. The decorator function uses `fsspec`, so that it can generalize between `gcsfs`, `s3`, local paths, etc (happy to utilize another library if you don't want to add dependencies, although `gcsfs`' API is much smoother than the official GCS API). The workflow is roughly as follows:\r\n\r\n1. The decorator determines the file system. If it is remote it runs `mlflow.<flavor>.save_model()` with a temporary local path, and if not it runs it with the original local path.\r\n2. At the end of `mlflow.<flavor>.save_model()`, if the original path is a remote path, it uses the appropriate file system protocol to `put()` the MLflow artifact into the remote path. \r\n\r\n- In either case, the function behaves as expected, but is now able to directly write out to remote paths. The API remains unchanged, and it shouldn't break any existing functionality, or cause unusual behavior in existing codebases. \r\n\r\n\r\n\r\nI'm mainly interested in finding out if your team would be interested in supporting this sort of functionality. If so, I can get started on a pull request. If you have any comments, concerns, or suggestions, I would be happy to implement them. ","888":"When comparing runs, I would like to have the ability to dynamically change the selected runs, instead of going back and changing the filter query.","889":"## Describe the proposal\r\n\r\nWhen I create a run, I would like to override the experiment default artifact uri. I would like also to store my artifacts into my own folder in HDFS. It will enable me to contribute to an experiment owned by someone else.\r\n\r\n### Motivation\r\n\r\nWe use HDFS to store artifacts. If I create an experiment that uses my HDFS folder as default artifact URI. My colleagues cannot create a new runs in my experiment.\r\nOur current workaround is to use \"groups\" and gives access to the group to the mlflow artifacts folder. All members of the group will be allowed to add artifacts.\r\n We would like to remove this workaround and enable in MLFlow to have in the same experiment, several runs that use different artifacts folders.\r\n\r\n### Proposed Changes\r\nTo implement this story, I propose the following changes:\r\n* Override the default artifact URI when I create a run. => add an new option `artifact_uri` to create_run function\r\n* Add a function in HDFS store class to change the default artifact URI to point to a folder in my HDFS folder. For this task, we can assume HDFS folder are like `\/user\/USERNAME\/`\r\n* If I create a run to an experiment with default URI is like `hdfs:\/\/namenode\/user\/some_username\/...` replace some_username by my username and store my artifacts in this folder.","890":"Although it is described in various pages of the documentation, it is confusing and difficult to figure out where things will be stored.\r\nIn my opinion, this is due to:\r\n1. different names for the same things, e.g., artifact_uri, artifact_location, artifact-root (there is also artifact_path which means something else)\r\n2. the fact that experiment settings in backend store override artifact_uri\r\n\r\nSince I am just starting with mlflow there may be other reasons I am not aware of, but it seems to me that tracking_uri and artifact_uri explicitly set by the user would suffice. This could be either with `mlflow.set_*_uri()` methods, `MLFLOW_*_URI` env. vars or parameters passed to the server.\r\n\r\n### Examples\r\n#### Artifacts\r\nmlflow.get_artifact_uri()\r\nmlflow.log_artifacts(local_dir, artifact_path=None)\r\nmlflow.create_experiment(name, artifact_location=None)\r\n--default-artifact-root\r\n--artifact-uri\r\n\r\n#### Backend\r\n--backend-store-uri\r\nMLFLOW_TRACKING_URI\r\nmlflow.set_tracking_uri\r\n","891":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\nPlease fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Redhat 7.2\r\n- **MLflow installed from (source or binary)**: pip install\r\n- **MLflow version (run ``mlflow --version``)**: 1.3.0\r\n- **Python version**: 3.7.2\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\nmlflow db upgrade postgresql:\/\/user:pass@server\/db\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\nI deployed mlflow on a docker container running in Kubernetes.\r\nWe are seeing this error: \"Detected out-of-date database schema (found version 2b4d017a5e9b, but expected 89d4b8295536).\r\n\r\nThe db upgrade did not generate any errors, but it did not update the 'alembic_version' table at all.\r\nI updated manually that table since the db upgrade gave no errors:\r\nupdate alembic_version set version='89d4b8295536'\r\n\r\nBut then I am getting the same error message with the version # reversed.\r\n\"Detected out-of-date database schema (found version 89d4b8295536 , but expected 2b4d017a5e9b).\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nmlflow db upgrade postgresql:\/\/user:pass@server\/db\r\n\r\n### Other info \/ logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks,\r\nplease include the full traceback. Large logs and files should be attached.\r\n\r\nThe DB upgrade command generates no errors, only the following\r\nINFO [alembic.runtime.migration] Context impl PostgresqlImpl\r\nINFO [alembic.runtime.migration] Will assume transaction DDL.\r\n\r\n","892":"Current version of run comparison doesn't show run duration I suggest it will be useful to observe it there\r\n![image](https:\/\/user-images.githubusercontent.com\/8694829\/67938488-41629c00-fbd8-11e9-860a-05d50fe2d83f.png)\r\n","893":"Would it be possible to access the data about an active run from the `ActiveRun` object? This would prevent needing to go to the mlflow store itself to load the run information.\r\n\r\n### Motivation\r\nThe use case is for viewing the metadata about the current run. This would be valuable for exporting to other services and preventing the need to examine the data store for information that could be in memory.\r\n\r\n### Proposed Changes\r\nRather than returning an empty parameter dict for `ActiveRun.to_dictionary()` populate with the parameters that have been added so far. Similar changes for artifacts and metrics.","894":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Mojave 10.14.6\r\n- **MLflow installed from (source or binary)**: binary (pip install)\r\n- **MLflow version (run ``mlflow --version``)**: 1.3.0\r\n- **Python version**: 3.7.3\r\n- **npm version, if running the dev UI**: -\r\n- **Exact command to reproduce**: `mlflow run . -e some-command`\r\n\r\n### Describe the problem\r\nWhen running `mlflow run . -e ...`, everything in a project directory is copied to the new Docker image. If you have some models or datasets anywhere in the project structure - they're also copied, which makes the new image huge and the command execution really slow. To avoid it you should be able to create `.dockerignore` file, but it just doesn't work - there's no difference in the result regardless of whether the file exists or not. When running similar flow, but without mlflow - just with custom `docker build`, there's no problem and `.dockerignore` is respected.\r\n\r\nPS The file was created in the project's root folder - so in the same place, where `MLproject` file is stored.","895":"The recommended method for persisting H2O models, `mlflow.h2o.log_model()`  does not work as expected. It does not upload (at least to an S3 bucket created by MinIO) any file reminiscent of a model file - neither in the internal binary H2O format or the JAVA MOJO \/ POJO model deployment file. All we see in MLflow Artifacts section or in the remote objects folder (say an S3 bucket accessed with the MinIO browser) is a YAML file `h2o.yaml` generated by MLflow and put into the `h2o.model` subfolder, with the following sample contents:\r\n```\r\nfull_file: \/tmp\/tmpw6agr_er\/model\/model.h2o\/GBM_model_python_1572007960887_26750\r\nmodel_dir: \/tmp\/tmpw6agr_er\/model\/model.h2o\r\nmodel_file: GBM_model_python_1572007960887_26750\r\n\r\n```\r\nEven it this file was successfully uploaded (and it never does - as verified using dirrerent built-in H2O algos over 50+ runs), it would not be the correct one. These internal H2O model objects are way too slow for production (having latencies measured in seconds instead of ms even with the simplest of models). **The files we want persisted by MLflow are MOJO files** (which can for some time now be re-imported by H2O, at least for internal models, not yet xgboost).\r\n\r\nSo the workaround for the current version of mlflow (1.3) and a suggested solution to incorporate in its future versions is as follows:\r\n\r\n```\r\n# to archive models in case of H2O we use a workaround: calling h2o \r\n# function download_mojo() (which in R is in the h2o module, \r\n# but in python is in the model object itself) \r\nmodel.download_mojo(temp_folder+\"h2o-model-mojo.zip\")\r\n\r\n# after downloading mojo file, we treat it as an artifact\r\n# and log it using mlflow.log_artifact()\r\nmlflow.log_artifact(temp_folder+\"h2o-model-mojo.zip\", artifact_path=\"h2o-model-mojo\")\r\n```\r\n\r\n\r\n\r\n","896":"A default user-modifiable temporary folder and the ability to keep some or all temp files (off by default) would be very useful in both of the above functions, allowing the users to preserve models and other artifacts also on the client side if they wish to do so, \r\n\r\n\r\n_More info_\r\n\r\nThe need to specify the temporary location of artifacts on the client side prior to upload to a permanent remote location (e.g to S3 bucket or NFS) in the `log_artifact()` function is unnecessary. This function needs a parameter with a pre-defined default folder (mind the write permissions), just like `log_model()`, where client-side `\/tmp` folder is used for that purpose behing the scenes. The current behavior of log_model() is arguably worse, because even if a default is there, the model files get quickly deleted from the temporary location on the client side. So an accompanying `keep_local_copy=False` parameter is also needed to prevent such unwanted file deletions from temporary location.\r\n\r\n","897":"### Motivation\r\nIn Mlflow's UI, the string provided in \"Search Runs\" in the experiments' run lists is used to eliminate runs from search results based on given attribute masks (for instance ```param.xy = \"test\"```). While this works as expected, it requires nested runs to also store the parameters of the parent run if you want to query them in combination. If parameters are only assigned to parent runs, filtering for these will result in the elimination of the child runs.\r\n\r\nAs an example, consider organizing hyperparameter optimization runs by having a parent run characterized by more general settings, e.g. the maximal runtime budget for the complete optimization, while the nested runs are individual evaluations for specific parameter sets. It would be redundant to also store all the parent run's parameters (and also metrics btw) in the child runs. If you now want to filter runs with a specific maximal runtime, you will only get these parents runs, but none of their child runs.\r\n\r\nAdditionally, the lack of the ability to \"jump\" from a parent run to a list of the children runs (as you can jump from the child to the parent, which is of course more \"natural\" due to the ```1:n``` relation of parents to children) makes it difficult to retrieve the actual runs for a specific parameter, which is only available at parent nodes.\r\n\r\n### Proposed Changes\r\nOne could fix this issue by adding a checkbox indicating whether one would also include the nested runs in the search results. Consequently, filtering runs would keep the nested runs in the search result for easier traceability. Since this is often not desired, e.g. to keep the number of search results small, the checkbox is disabled by default. Alternatively, one could add a keyword for the search query, which would include the nested results.\r\nTechnically speaking, this checkbox would change the internal queries, s.t. for each run, which is returned by this statement, all of its nested runs are considered, too.","898":"### Describe the problem\r\n\"Oops! Something went wrong.\" appears in the mflow UI detail view for runs.\r\nThis error page comes up in different scenarios where logging artifacts to s3 is not successful. I don't know if other remotes are also affected in some form.\r\n\r\nThe UI should not break from this, but rather inform the user what the problem is (e.g. in the artifacts section).\r\nWhile logging on client side I would expect a warning message that the artifact logging failed.\r\n\r\n### Code to reproduce issue\r\nPossible ways to break artifact logging to s3 include\r\n- bucket missing on s3 (`--default-artifact-root`, `--artifact-location`)\r\n- wrong credentials (`AWS_ACCESS_KEY_ID, `AWS_SECRET_ACCESS_KEY`)\r\n- wrong endpoint_url ( `MLFLOW_S3_ENDPOINT_URL`)\r\n\r\n\r\n### Other info \/ logs\r\nrelated to https:\/\/github.com\/mlflow\/mlflow\/issues\/1855#issuecomment-534276087\r\n","899":"Currently only parameters that have a value less than 250 characters are allowed.\r\n\r\nIt would be great to make this limit an user parameter. I have a use case where I would like this to be 500 characters.\r\n","900":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 18.04\r\n- **MLflow installed from (source or binary)**:binary\r\n- **MLflow version (run ``mlflow --version``)**:1.3.0\r\n- **Python version**:3.6.5\r\n- **npm version, if running the dev UI**:\r\n\r\n\r\n### Describe the problem\r\nI am trying to use the **mlflow.tensorflow.autolog()** with [tensorflow object detection api](https:\/\/github.com\/tensorflow\/models\/tree\/master\/research\/object_detection). Adding **mlflow.tensorflow.autolog()** to **[model_main.py](https:\/\/github.com\/tensorflow\/models\/blob\/master\/research\/object_detection\/model_main.py)** logs some parameters like global_norm\/clipped_gradient_norm,global_norm\/gradient_norm,global_step\/sec,learning_rate_1,loss_1,loss_2 in mlflow. However the more important metrics linke map,precision,recall are not being logged in mlfow even if they are present in tensorboard.I used the example [here](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/examples\/tensorflow\/train_predict.py) as reference but did\r\n","901":"## Describe the proposal\r\nAdd the possibility of attaching a dockerfile for creating custom images and installing different tools inside the docker.\r\n\r\n### Motivation\r\nRight now the deployment of a model in microservices is limited. In order to export it to the Azure ML or Amazon Sagemaker or to create a docker image locally, you cannot specify a dockerfile that could facilitate the creation of a microservice through different steps. Although this service can be done in Azure ML directly, it cannot be done in mlflow.\r\nWith custom dockerfiles you can specify steps for installing different components like compilers or tools of the base image OS.\r\nThis feature is necessary to create customized microservices.\r\n\r\n### Proposed Changes\r\nThey are really small changes, we should make an append of the dockerfile file that creates mlflow with the file that the user passes and this can be the same for all frameworks because right now mlflow is already writing this dockerfile below without the user knowing.\r\n","902":"When will automated spark MLlib tracking and scikit-learn tracking be available for CrossValidators? It is available only for databricks + spark MLlib. If it is not on the roadmap, can it be added? In the meantime, is there a workaround to log all of the parameters and metrics a CrossValidator tried using a local spark MLlib pipeline or scikit-learn pipeline?\r\n\r\nhttps:\/\/docs.databricks.com\/applications\/machine-learning\/automl\/mllib-mlflow-integration.html\r\n\r\n","903":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 Version 10.0.17134 Build 17134\r\n- **MLflow installed from (source or binary)**: `conda install -c conda-forge mlflow` in clean conda environment\r\n- **MLflow version (run ``mlflow --version``)**: 1.3.0\r\n- **Python version**: 3.6\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: `mlflow ui`\r\n\r\n### Describe the problem\r\nWhen running `mlflow ui` the error below occurs. If I install on a clean conda environment useing `pip install mlflow` the error does not occur.\r\n\r\n### Code to reproduce issue\r\nIn clean conda environment:\r\n`conda install -c conda-forge mlflow`\r\n`mlflow ui`\r\n\r\n### Other info \/ logs\r\n`Fatal error in launcher: Unable to create process using '\"d:\\bld\\mlflow_1571311839941\\_h_env\\python.exe\"  \"C:\\Users\\matt.wenham\\AppData\\Local\\Continuum\\anaconda3\\envs\\mlflow2\\Scripts\\mlflow.exe\" ui'`\r\n","904":"## Proposal\r\n```name: My Project\r\n\r\nconda_env: my_env.yaml\r\n\r\nentry_points:\r\n  main:\r\n    parameters:\r\n      data_file: path\r\n      regularization: {type: float, default: 0.1}\r\n    command: \"python script.py -r {regularization} {data_file}\"\r\n  validate:\r\n    parameters:\r\n      data_file: path\r\n    command: \"python validate.py {data_file}\"\r\n```\r\nOnly allows you to pass a string, float, path or uri. \r\nHowever, python allows you to pass bool command line arguments that we cannot fit into this format.\r\n\r\n### Motivation\r\nCommand I want to execute is `python script.py --train -r {regularization} {data_file}`\r\nwhere --train is an optional boolean argument.\r\n\r\n### Proposed Changes\r\n```name: My Project\r\n\r\nconda_env: my_env.yaml\r\n\r\nentry_points:\r\n  main:\r\n    parameters:\r\n      data_file: path\r\n      regularization: {type: float, default: 0.1}\r\n      train : {type: bool, default: False}      \r\n    command: \"python script.py -r  {regularization} {train} {data_file} \"\r\n  validate:\r\n    parameters:\r\n      data_file: path\r\n    command: \"python validate.py {data_file}\"\r\n```\r\nMLflow run execution: `mlflow run . -P data_file=data.csv train=True`\r\ntranslates to `python script.py --train -r 0.1  data.csv`\r\n","905":"Creating a project from scratch is a difficult process and requires custom templating.  It'd be nice to add a command like `mlflow project init` to initialize a new project using a template.  It could also have commands to input values such as the project name, environment, etc.  It would then create a directory with all necessary files.\r\n\r\nThis would be a pretty lightweight change to MLflow","906":"### Proposal\r\nIn saving and loading models, the function `get_default_conda_env()` returns a minimal conda environment that is used with the target model. Currently, MLflow manually assigns different modules to either conda or pip dependencies. I am proposing we assign the modules to either pip or conda dependencies depending on the user's installation.\r\n\r\n### Motivation\r\nConda isn't always up to date with the most recent modules and frameworks. For example, conda doesn't have TensorFlow 2.0 - this would cause an error in trying to trying use the conda environment returned in `mlflow.tensorflow.get_default_conda_env()`, which assigns TensorFlow to always be a conda dependency. This fix will eliminate this error as the proposed code will detect that the user has TensorFlow 2.0 installed via pip and appropriately assign it as a pip dependency.\r\n\r\nIn addition, this change will allow for conda environments to more closely mimic the user's own environment. This can lead to easier debugging and usage of MLflow.\r\n\r\n### Proposed Changes\r\n`get_default_conda_env()` in all relevant model files should be updated to assign module-specific conda and pip dependencies based on user environments.\r\n","907":"found this issue while using mlflow to serve my model.","908":"## Proposal\r\nSpark model flavour to support deployment through [MMLSpark Serving](https:\/\/github.com\/Azure\/mmlspark\/blob\/master\/docs\/mmlspark-serving.md).\r\n\r\n### Motivation\r\nThis should make it possible to easily deploy Spark models also for high-performance use cases and from any Spark API language (Scala, Java, Python, R).\r\n\r\n### Proposed Changes\r\nThis could be exposed through the `mlflow.models` module's `serve` and possibly also `build_docker` commands.\r\n","909":"My colleagues and I have been keeping an eye on MLFlow for some time now, as its stated goals would meet many of the typical requirements we have when rolling out Machine Learning solutions. When it just launched we thought that it looked very promising, but we were not yet confident about using it in client projects and have thus far mainly stuck to creating our own bespoke solutions.\r\n\r\nSince launch a lot has happened though (kudos to Databricks and the MLFlow community!) and now seems to be a good time to get on board. We still have several requirements that are not met by MLFlow and I would like to start putting them up for discussion to see if the wider community have the same requirements.\r\n\r\nSo here is the first requirement we have:\r\n\r\n\r\n**Description**\r\n\r\nCurrently the dataset used in a run is **implicit** and any metric logging therefore only refers to the data used in this run. We prefer to be able to separate Training and Evaluation as separate processes (e.g. triggered and scaled as separate microservices on Kubernetes). Generally this would mean that during Training we only have **one** training dataset and **one** validation dataset. (These would be identifiable with their own UUID). \r\n\r\nHowever, once the model is trained and saved we typically run evaluations on **multiple** test datasets. Either because we want to test how well the model generalises to different data or because as time goes by we improve our test set and want to reevaluate the models we have developed thus far. We also have a process for setting existing models to inactive or changing the selected model for a given experiment which feeds from this, but that is a discussion or different FR.\r\n\r\nA typical DB Model might look like this:\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/25316920\/66550327-733a9280-eb45-11e9-8cb3-7ca568765829.png).\r\n\r\n`databunch` is the named collection of data (such as the Iris or Titanic data). `datasets` are (typically) the `train`, `valid`  and `test` data found within the `databunch`.\r\n\r\nA `run` implicitly produces one and only one model. An `evaluation_run` uses this one model to produce metrics on a specific `dataset`\r\n\r\n\r\n*Proposed Changes*\r\nAs far as I can see this proposal would least require changes here:\r\n- DB Schema\r\n- mflow.log_metric(...) will need something with which to identify the Dataset for which the metric is to be logged\r\n- Possibly it would make sense to create Dataset and Databunch classes to deal with the abstraction client side. \r\n- Something like `mlflow.register_dataset(databunch_name, dataset_name, artifact_location)` and then `data_set = mlflow.get_dataset(databunch_name=\"iris\", dataset_name=\"train\")` could be used to fetch the dataset from the artifact store\r\n- UI would need to be updated to filter between Datasets\r\n\r\n\r\nI hope I've made our use-case clear. I'd also be happy to have a go at a PR that implements these changes if this is something the community would find useful.\r\n","910":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\nPlease fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes, a Minor change\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04 \r\n- **MLflow installed from (source or binary)**: Source\r\n- **MLflow version (run ``mlflow --version``)**: 1.3.0\r\n- **Python version**: 3.7\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: mlflow models build-docker -m (uri to the MLmodel file)\r\n\r\n### Describe the problem\r\nWe are trying to build a docker image of a model using a private network, . We made changes in the MLflow backend in the dockerfile_template in Docker_utils.py file according to our needs but still we get the following error when the Daemon run **Run pip install mlflow==1.3.0**\r\n\r\n```\r\nStep 12\/18 : RUN pip install mlflow==1.3.0\r\n ---> Running in c768df4081d8\r\nCollecting mlflow==1.3.0\r\n  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')])\"))': \/simple\/mlflow\/\r\n  WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')])\"))': \/simple\/mlflow\/\r\n  WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')])\"))': \/simple\/mlflow\/\r\n  WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')])\"))': \/simple\/mlflow\/\r\n  WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')])\"))': \/simple\/mlflow\/\r\n  Could not fetch URL https:\/\/pypi.org\/simple\/mlflow\/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: \/simple\/mlflow\/ (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')])\"))) - skipping\r\n  ERROR: Could not find a version that satisfies the requirement mlflow==1.3.0 (from versions: none)\r\nERROR: No matching distribution found for mlflow==1.3.0\r\nCould not fetch URL https:\/\/pypi.org\/simple\/pip\/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: \/simple\/pip\/ (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')])\"))) - skipping\r\nThe command '\/bin\/sh -c pip install mlflow==1.3.0' returned a non-zero code: 1\r\n127.0.0.1 - - [10\/Oct\/2019 11:48:08] \"GET \/ HTTP\/1.1\" 200 -\r\n^Z\r\n[1]+  Stopped\r\n```\r\n\r\n### Code to reproduce issue\r\nDocker file template after our changes - \r\n\r\n```\r\n_DOCKERFILE_TEMPLATE = \"\"\"\r\nBuild an image that can serve mlflow models.\r\nFROM ubuntu:16.04\r\n\r\nCOPY . \/home\/pandae\/ZscalerRootCertificate-***********.crt\r\nCOPY . \/home\/pandae\/ca-certificates\r\nCMD update-ca-certificates --fresh\r\n\r\nRUN apt-get -y update && apt-get install -y --no-install-recommends \\\r\n         wget \\\r\n         curl \\\r\n         nginx \\\r\n         ca-certificates \\\r\n         bzip2 \\\r\n         build-essential \\\r\n         cmake \\\r\n         openjdk-8-jdk \\\r\n         git-core \\\r\n         maven \\\r\n    && rm -rf \/var\/lib\/apt\/lists\/*\r\n\r\n# Download and setup miniconda\r\nRUN curl https:\/\/repo.continuum.io\/miniconda\/Miniconda3-latest-Linux-x86_64.sh >> miniconda.sh -k\r\nRUN bash .\/miniconda.sh -b -p \/miniconda; rm .\/miniconda.sh;\r\nENV PATH=\"\/miniconda\/bin:$PATH\"\r\nENV JAVA_HOME=\/usr\/lib\/jvm\/java-8-openjdk-amd64\r\nENV GUNICORN_CMD_ARGS=\"--timeout 60 -k gevent\"\r\n\r\n# Set up the program in the image\r\nWORKDIR \/opt\/mlflow\r\n\r\n{install_mlflow}\r\n\r\n{custom_setup_steps}\r\n{entrypoint}\r\n\"\"\"\r\n```\r\n\r\nwhat am I doing wrong here?\r\nFor pip to install any packages from the net we have to provide that particular certificate, Right now the issue is I'm having a tough time figuring it out to where exactly to put that certificate so that pip can access it while building the image\r\n","911":"## Describe the proposal\r\n\r\nAdd a flag in UI (and database, if necessary) that identifies a commit hash as \"dirty\" if the git repository has local changes.\r\n\r\n\r\n### Motivation\r\n\r\nVersion: 1.3.0 (installed via pip)\r\n\r\nSteps:\r\n\r\n1. have a clean git repository, no un-commited local changes\r\n2. mlflow run .\r\n3. change a file, do not commit\r\n4. mlflow run .\r\n\r\nIn this situation, the first run is reproducible, the second one is not. In the UI both runs are displayed with the same (i.e. the most recent) commit hash. This gives the impression that both experiments where run with exactly the same code, which is not true. As far as I could find, there seems to be no way to identify the \"dirty\" second run. Please let me know if I missed something.\r\n\r\n### Proposed Changes\r\n\r\nOther tools such as omniboard for sacred or neptune show a flag that identifies the \"dirty\" run as such. This does not make the run reproducible, but it does at least alert the user that this is the case.","912":"\r\n## Describe the proposal\r\nMake MLFlow PyTorch log_model and save_model supports PyTorch models with custom inputs.\r\n\r\n### Motivation\r\nWe are currently using PyTorch models a list of inputs, so we cannot use MLFlow to deploy our model.\r\n\r\n\r\n","913":"\r\n\r\n## What changes are proposed in this pull request?\r\n \r\nThis commit adds a simple extension to the backend specification for\r\nthe databricks backend that allows users to pass additional dependent\r\nlibrary configurations to the job.  This allows mlflow to tacitly\r\nsupport use cases where an entry point requires libraries to available\r\non the worker nodes of a databricks cluster, and aligns `mlflow run` more\r\nclosely with mlflow-tracked databricks notebooks. \r\n\r\n## How is this patch tested?\r\n \r\nI did not add specific tests, as the functionality is provided by databricks.  I confirmed it has the expected functionality when run against the databricks API\r\n \r\n## Release Notes\r\n \r\n### Is this a user-facing change? \r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n \r\nDatabricks backend specification has been extended to accept an additional key 'libraries' which contains a list of databricks [Library](https:\/\/docs.databricks.com\/dev-tools\/api\/latest\/libraries.html#library) specifications\r\n \r\n### What component(s) does this PR affect?\r\n \r\n- [ ] UI\r\n- [x] CLI \r\n- [ ] API \r\n- [ ] REST-API \r\n- [ ] Examples \r\n- [ ] Docs\r\n- [ ] Tracking\r\n- [ ] Projects \r\n- [ ] Artifacts \r\n- [ ] Models \r\n- [ ] Scoring \r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n \r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","914":"## Problem\r\nCurrently, nested runs do not always appear underneath their parent, most commonly occurring for runs with many nested runs (e.g. hyperparameter search). Until the parent run itself is loaded, the nested runs are free floating causing a number of issues by polluting the list of runs. \r\n\r\nThe two attached gifs use results from the following code which generates two parent runs that each have 100 hypothetical nested hyperparameter runs. \r\n``` \r\n# Environment: Databricks Cloud on AWS. Runtime: 5.5 LTS ML \r\nimport mlflow\r\n\r\nfor model_name in ['Algo1', 'Algo2']:\r\n  with mlflow.start_run(run_name=model_name): \r\n    for hyperparameter in range(100):\r\n      with mlflow.start_run(nested=True):\r\n        mlflow.log_param(\"hyperparameter\", hyperparameter) \r\n```\r\n\r\nTo view my two parent runs, I first need to scroll down and \"Load More\" until I get all 202 runs into the UI before the UI recognizes which ones are intended to be nested. This pollution of the run list requires the first step of a workflow to be pressing \"Load More\" until all parent runs are loaded (note also the bug where \"Load More\" disappears after the 1st push)\r\n\r\n![ViewingNested](https:\/\/user-images.githubusercontent.com\/10503608\/66057906-7a3f2080-e507-11e9-813e-0bbcc555fb17.gif)\r\n\r\nSimilarly, when deleting runs, the nested runs essentially get lost and detached from the parent. See the experience below for deleting the 2 parent runs and all associated hyperparameter runs. (it also requires a hard refresh of the Tracking UI to find the zombie hyperparameter runs)\r\n\r\n![DeletingRuns](https:\/\/user-images.githubusercontent.com\/10503608\/66058609-aa3af380-e508-11e9-82d1-5bb50502c96f.gif)\r\n\r\n### Motivation\r\nI would like nested runs to more strictly belong to the parent run. When viewing runs, comparing runs, and deleting runs, I'd like a stronger sense of ownership between the parent and the nested runs. For example, always show nested runs underneath parents, and always delete all nested runs when deleting parent runs.\r\n\r\nSimilarly, selection of all child runs is very tricky now. A common use case is to select all hyperparameter runs for the \"Compare\" tool. Currently, there is no method for selecting all runs unless a unique ID is manually added to all siblings. This is partially because the nested runs don't seem to truly belong to the parent run. \r\n\r\n### Proposed Solution\r\nI'm not clear what the changes would be on the backend, but for user-facing changes, I would like:\r\n1) Always show nested runs underneath the parent, and load all nested runs simultaneously. \r\n2) Delete all nested runs when deleting the parent. \r\n3) Allow for comparing all sibling runs by selecting the parent instead of needing to manually select all nested runs. \r\n","915":"## What changes are proposed in this pull request?\r\n \r\nAdd a way to retrieve credentials context from artifact repository itself.\r\nTODO: explain why\r\n \r\n## How is this patch tested?\r\n \r\n(Details)\r\n \r\n## Release Notes\r\n \r\n### Is this a user-facing change? \r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n \r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n \r\n### What component(s) does this PR affect?\r\n \r\n- [ ] UI\r\n- [ ] CLI \r\n- [ ] API \r\n- [ ] REST-API \r\n- [ ] Examples \r\n- [ ] Docs\r\n- [ ] Tracking\r\n- [ ] Projects \r\n- [ ] Artifacts \r\n- [ ] Models \r\n- [ ] Scoring \r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n \r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","916":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **MLflow installed from (source or binary)**:  1.2\r\n- **MLflow version (run ``mlflow --version``)**:\r\n- **Python version**: 3.6\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI am trying to create a run and submit a param with a really long value (251 or higher)\r\n\r\nI expect to have 200 response or 4xx (the param value is too long)\r\nWhat I get is 500\r\n2019\/09\/23 14:44:09 ERROR mlflow.utils.rest_utils: API request to https:\/\/xxx\/api\/2.0\/mlflow\/runs\/log-parameter failed with code 500 != 200, retrying up to 0 more times. API response body: <!DOCTYPE HTML PUBLIC \"-\/\/W3C\/\/DTD HTML 3.2 Final\/\/EN\">\r\n<title>500 Internal Server Error<\/title>\r\n<h1>Internal Server Error<\/h1>\r\n<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.<\/p>\r\n\r\n\r\n### Code to reproduce issue\r\n> from mlflow.tracking import MlflowClient\r\n> client = MlflowClient()\r\n> client.create_run(0)\r\n> client.log_param(run.info.run_id, \"param251\", \"x\"*251)\r\n\r\n\r\n### Other info \/ logs\r\nI already grepped mlflow source code and noticed there is a limit on the length of a param which is 250 and it is pretty reasonable. What I did not expect is to get 5xx error\r\n\r\nI think it would improve user experience to return 4xx with an explanation of the problem\r\n\r\nWhat do you think?","917":"## Describe the proposal\r\n\r\nWhen I log 50 metrics (one for each epoch in 50 epochs) using MLflow's experimental keras autolog, the time it takes to perform each request quickly adds up. It takes around 14 seconds in total my case, when communicating with an MLflow tracking server (hosted on [MFlux.ai](https:\/\/www.mflux.ai)) over HTTPS. The main reason for the slowness is that for each log_metric, a full 3-way handshake is currently performed, and this takes time. The following article explains why: https:\/\/blog.insightdatascience.com\/learning-about-the-http-connection-keep-alive-header-7ebe0efa209d\r\n\r\nWhat I would do is initialize an instance of requests's `Session` class when an mlflow run starts. This instance is used to keep the HTTP connection with the MLflow server alive.\r\n\r\nExample with session, keeping the connection alive (fast):\r\n\r\n```\r\ns = requests.Session()\r\ns.post(\"https:\/\/example.com\/path\/to\/endpoint\")\r\ns.post(\"https:\/\/example.com\/path\/to\/endpoint\")\r\n```\r\n\r\nExample without session (slow):\r\n\r\n```\r\nrequests.post(\"https:\/\/example.com\/path\/to\/endpoint\")\r\nrequests.post(\"https:\/\/example.com\/path\/to\/endpoint\")\r\n```\r\n\r\n### Motivation\r\n\r\nThe time spent waiting for metrics to be submitted to the server can be reduced by around 70%. Wouldn't it be nice to wait only 4 seconds instead of 14?\r\n\r\n### Proposed Changes\r\n\r\nNo user-facing API changes. Only internal changes","918":"During the exploitation of MLFLow I faced the problem with starting\/stoping MLFlow Tracking Server. I did not find any information in the documentation about no rough stopping(pkill command) of Tracking Server. From my point of view, will be great if the following functionality will be added in the next versions.\r\n\r\nServer Stop \r\n```\r\nmlflow server stop\r\n```\r\n\r\nServer Restart\r\n```\r\nmlflow server restart\r\n```\r\n\r\nServer Restart with --time parameter in seconds or milliseconds\r\n```\r\nmlflow server pause --time 100\r\n```\r\n\r\nAnd something like\r\n\r\n```\r\nmlflow server list\r\n```\r\nServer List that return all information about stared mlflow server.","919":"## What changes are proposed in this pull request?\r\n \r\nThis PR addresses https:\/\/github.com\/mlflow\/mlflow\/issues\/1066, changing the behavior of the TensorFlow model flavor to not automatically ravel its output during prediction. In the case of multi-column outputs, multiple columns are returned.\r\n\r\nThis is required for TensorFlow model compatibility with Spark UDFs with multi-column outputs. I've named the outputs _output_tensor0_0_, _output_tensor0_1_, ..., _output_tensor0_n_, which doesn't make a difference in the Spark UDF case (since they it is called with `withColumn`), but may for scoring server and SageMaker\/Azure functionality.\r\n \r\n## How is this patch tested?\r\n\r\nI've modified the original tests with the expected output column names. Multi-column outputs are not explicitly tested, but if this if this design looks across the other deployment options, I can add the test.\r\n \r\n(Details)\r\n \r\n## Release Notes\r\n \r\n### Is this a user-facing change? \r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users. \r\n\r\nTensorFlow models with multidimensional outputs (e.g., Softmax) will not be automatically raveled during prediction.\r\n \r\n### What component(s) does this PR affect?\r\n \r\n- [ ] UI\r\n- [ ] CLI \r\n- [ ] API \r\n- [ ] REST-API \r\n- [ ] Examples \r\n- [ ] Docs\r\n- [ ] Tracking\r\n- [ ] Projects \r\n- [ ] Artifacts \r\n- [x] Models \r\n- [ ] Scoring \r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n \r\n- [x] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n\r\nGiven that this changes output shapes, I am marking as a breaking change. Presumably users handled this manually when using SageMaker\/Azure for scoring and reshaped the data client-side.\r\n","920":"### Description \/ Motivation\r\nAt the moment the website is not automatically reloaded when a new run is run or tags, parameters or metrics are updated. The automatic reload would make the use of mlflow more efficient. \r\n\r\n### Proposed Changes\r\nI'm not a web developer. But I think with react framework it should be pretty easy.\r\n","921":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)** => No I am using the example from the [databrick documentation](https:\/\/docs.databricks.com\/applications\/mlflow\/projects.html#id14) (which by the way is outdated): `mlflow run https:\/\/github.com\/mlflow\/mlflow#examples\/sklearn_elasticnet_wine -b databricks -c cluster-spec.json --param-list 'alpha'=1  --experiment-id <my_id>`\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OSX\r\n- **MLflow installed from (source or binary)**:  using pip install mflow\r\n- **MLflow version (run ``mlflow --version``)**: 1.2\r\n- **Python version**: 3.6\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n`mlflow run https:\/\/github.com\/mlflow\/mlflow#examples\/sklearn_elasticnet_wine -b databricks -c cluster-spec.json --param-list 'alpha'=1  --experiment-id <my_id>` where cluster-spec.json contains:\r\n```\r\n{\r\n  \"existing_cluster_id\": \"<myid>\"\r\n}\r\n```\r\n### Describe the problem\r\nInstead of running the example within an existing databrick cluster. The code error with:\r\n```\r\nmlflow.exceptions.RestException: INVALID_PARAMETER_VALUE: Missing required field: settings.cluster_spec.new_cluster.size\r\n```\r\nThis is due to [new_cluster](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/projects\/databricks.py#L162) being hard coded which do not allow to use the `existing_cluster_id` parameter which [according to databrick](https:\/\/docs.databricks.com\/api\/latest\/jobs.html#runs-submit) docs should be allowed.\r\n\r\n### What I tried\r\n\r\nI forked the code and allowed the parameter `existing_cluster` to be sent. However, I got a subsequent error:\r\n```\r\nmlflow.exceptions.RestException: INVALID_PARAMETER_VALUE: Shell command task is not allowed on existing cluster.\r\n```\r\nWhich makes sense since[ it is not part of the existing parameters in databricks](https:\/\/docs.databricks.com\/api\/latest\/jobs.html#runs-submit). It might be hidden somehow..\r\n\r\n### Code to reproduce issue\r\ncreate a file named `cluster-spec.json ` with:\r\n```\r\n{\r\n  \"existing_cluster_id\": \"<myid>\"\r\n}\r\n```\r\nAnd run:\r\n`mlflow run https:\/\/github.com\/mlflow\/mlflow#examples\/sklearn_elasticnet_wine -b databricks -c cluster-spec.json --param-list 'alpha'=1  --experiment-id <my_id>` where cluster-spec.json ","922":"## Describe the proposal\r\n\r\nSimply provide a link to download all the artefacts as tar.gz file(s).\r\n\r\n### Motivation\r\n\r\nThe use case i have in mind is building docker images for deployment of the models. The Dockerfile `ADD` command can take a file within its current folder or bellow OR it can download it from a URL. We have a local shared MLFlow server running and want to deploy by simply providing an experiment ID, which will be turned into a URL and the model artefacts. The docker image will be build and pushed to an image repo (with a version number) ready for deployment to an inference server.\r\n\r\nI'm not sure what the thoughts are on incorporating MLFlow into production environments, but this simple work flow would easily be supported with this simple feature.\r\n\r\n### Proposed Changes\r\n\r\nI guess adding something like this:\r\n```python\r\nimport tarfile\r\n\r\ndef make_tarfile(output_filename, source_dir):\r\n    with tarfile.open(output_filename, \"w:gz\") as tar:\r\n        tar.add(source_dir, arcname=os.path.basename(source_dir))\r\n```\r\nsomewhere and providing an additional URL that is predictable e.g.\r\n`http:\/\/192.168.1.25:5000\/#\/experiments\/0\/runs\/3959cf318439410abfb90792029789d9\/artefacts\/subfolder` or something like that.\r\n\r\nI guess if you wanted to get tricky you could let then target specific sub directories? ","923":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address.\r\n  \r\nPlease fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n## Describe the proposal\r\nAs a data scientist\/product owner I would like to create a freely configurable tag herachie on the experiment\/run table. We work with keys and values (tags) to structure our experiments. For example something like that: customer \/ project \/ task \/ ...\r\nWe assign these tags to each experiment to find them again\r\n\r\n### Motivation\r\nWith the help of the search function, the experiments are laborious to find. \r\nOn the left side of the run table the experiments are currently displayed. Some of the experiments have long names and we can not read certain experiments anymore. There are only one long list. \r\n\r\nTo find experiments faster, tags should be displayed on the left side of the experiment\/run table to filter experiments.","924":"## What changes are proposed in this pull request?\r\n \r\nI propose to change `mlflow_set_experiment()` in the R API to follow the conventions established in the rest of the R API. Currently, calls to `mlflow_set_experiment()` simply create a new MLFlow client and use that to set the active experiment. Elsewhere in the API, these functions accept a client as an argument and attempt to resolve it before performing the relevant operation.\r\n\r\nFor example:\r\n```\r\nmlflow_delete_experiment <- function(experiment_id, client = NULL) {\r\n  if (identical(experiment_id, mlflow_get_active_experiment_id()))\r\n    stop(\"Cannot delete an active experiment.\", call. = FALSE)\r\n\r\n  client <- resolve_client(client)\r\n  mlflow_rest(\r\n    \"experiments\", \"delete\",\r\n    verb = \"POST\", client = client,\r\n    data = list(experiment_id = experiment_id)\r\n\r\n  )\r\n  invisible(NULL)\r\n}\r\n```\r\n\r\nThis PR brings `mlflow_set_experiment()` in line with the other functions. The documentation was updated per the instructions in `CONTRIBUTING.rst` to reflect this change in the API.\r\n\r\n## How is this patch tested?\r\n \r\nI tested this by executing the R test suite per the instructions in `CONTRIBUTING.rst`. The tests threw two errors, but they were in namespaces that were unchanged by this commit:\r\n\r\n```\r\n1. Error: mlflow can read typed command line parameters (@test-params.R#6) \r\n2. Error: mlflow can launch the UI (@test-ui.R#6) \r\n```\r\n\r\nI changed the existing tests for the MLFlow Experiments R API to ensure the correct experiment ID was still returned when a client was passed into the function, and those tests passed. \r\n\r\n## Release Notes\r\n \r\n### Is this a user-facing change? \r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n \r\nAdding the ability to pass an existing client to `mlflow_set_experiment` in the R API\r\n \r\n### What component(s) does this PR affect?\r\n \r\n- [ ] UI\r\n- [ ] CLI \r\n- [x] API \r\n- [ ] REST-API \r\n- [ ] Examples \r\n- [x] Docs\r\n- [ ] Tracking\r\n- [ ] Projects \r\n- [ ] Artifacts \r\n- [ ] Models \r\n- [ ] Scoring \r\n- [ ] Serving\r\n- [x] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n \r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","925":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address.\r\n  \r\nPlease fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n-------\r\n\r\n## Describe the proposal\r\nAs a data scientist, I want to save global configurations of parameters and metrics of the Parallel coordinates Plot.\r\nIf I compare runs of an experiment, then I would like to compare certain parameters and metrics.\r\n\r\n### Motivation\r\nThis would allow me to compare models faster and require fewer clicks. My problem is that every time I compare runs with the parallel coordinates Plot, I have to add metrics again and again and hide parameters. This costs time and nerves.\r\n","926":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address.\r\n  \r\nPlease fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n-------\r\n## Guidelines\r\n\r\nFeature requests typically go through the following lifecycle:\r\n\r\n1. Submit feature request with high-level description on GitHub issues (this is what you're doing now)\r\n2. Discuss feature request with a committer, who may ask for a more detailed design\r\n3. After discussion & agreement on feature request, start implementation\r\n\r\n\r\n## Describe the proposal\r\nAs a data scientist, I want to create pivot tables to compare models. I want to aggregate by specific parameters, tasks or tags and display metrics.\r\n\r\n### Motivation\r\nThis provides an individual configuration option for different aggregations of the model data. The comparison of runs by model classes, datasets or tasks can be done flexibly. This enables easier and efficient operation.\r\n","927":"Hi, \r\n1) I am looking for a way to provide authentication to mlflow tracking server. I tried with setting up the environment variables(TRACKING_USERNAME & PASSWORD) but it is not showing anything on the logs ( I am running everything using Docker).\r\n2) Does mlflow supports OAuth and if it does then how?","928":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address. For help with debugging your code, please refer to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/mlflow).\r\n\r\nPlease fill in this template and do not delete it unless you are sure your issue is outside its scope.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nLinux Ubuntu 18.04\r\nMLflow installed from (source or binary):\r\nBinary\r\nMLflow version (run mlflow --version):\r\n1.2.0\r\nPython version:\r\n3.7.3\r\nnpm version, if running the dev UI:\r\nExact command to reproduce:\r\n\r\n### Describe the problem\r\nUnable to store\r\n\r\n### Code to reproduce issue\r\nHi\r\nIs there a way to store the artifacts on mlflow server\r\n \r\nwhile the below creates the artifacts in the directory\r\n\r\nimport os\r\nimport mlflow\r\nimport mlflow.pyfunc\r\n\r\nclass AddN(mlflow.pyfunc.PythonModel):\r\n\r\n    def __init__(self, n):\r\n        self.n = n\r\n\r\n    def predict(self, context, model_input):\r\n        return model_input.apply(lambda column: column + self.n)\r\n\r\nmodel_path = \"add_n_model\"\r\nadd5_model = AddN(n=5)\r\n\r\n\r\ntracking_uri=\"http:\/\/localhost:5000\"\r\nmlflowClient = mlflow.tracking.MlflowClient(tracking_uri)\r\n\r\nexperiment_id=mlflowClient.create_experiment(\"firstExperiment\",\"\/mlflowserver_default_artifact_root\")\r\n\r\nexperiment_to_run=mlflowClient.get_experiment_by_name(\"firstExperiment\")\r\ncreated_run=mlflowClient.create_run(experiment_to_run.experiment_id)\r\n\r\nos.environ['MLFLOW_TRACKING_URI'] = tracking_uri\r\nos.environ['MLFLOW_ARTIFACT_URI'] = tracking_uri\r\n\r\nmlflow.pyfunc.log_model(\r\n        artifact_path=\"artifacts\",\r\n        python_model=add5_model,\r\n   )\r\n\r\n====== when i run the below\r\n\r\nimport os\r\nimport mlflow\r\nimport mlflow.pyfunc\r\n\r\nclass AddN(mlflow.pyfunc.PythonModel):\r\n\r\n    def __init__(self, n):\r\n        self.n = n\r\n\r\n    def predict(self, context, model_input):\r\n        return model_input.apply(lambda column: column + self.n)\r\n\r\nmodel_path = \"add_n_model\"\r\nadd5_model = AddN(n=5)\r\n\r\n\r\ntracking_uri=\"http:\/\/localhost:5000\"\r\nmlflowClient = mlflow.tracking.MlflowClient(tracking_uri)\r\n\r\nexperiment_to_run=mlflowClient.get_experiment_by_name(\"firstExperiment\")\r\ncreated_run=mlflowClient.create_run(experiment_to_run.experiment_id)\r\n\r\nos.environ['MLFLOW_TRACKING_URI'] = tracking_uri\r\nos.environ['MLFLOW_ARTIFACT_URI'] = tracking_uri\r\n\r\nmlflow.pyfunc.log_model(\r\n        artifact_path=\"artifacts\",\r\n        python_model=add5_model,\r\n        )\r\n\r\n\r\nI get the below error\r\n\r\n\/home\/cyril\/anaconda3\/lib\/python3.7\/site-packages\/parso\/python\/tree.py:46: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n  from collections import Mapping\r\nTraceback (most recent call last):\r\n  File \"temp.py\", line 29, in <module>\r\n    python_model=add5_model,\r\n  File \"\/home\/cyril\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py\", line 664, in log_model\r\n    conda_env=conda_env)\r\n  File \"\/home\/cyril\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/models\/__init__.py\", line 78, in log\r\n    mlflow.tracking.fluent.log_artifacts(local_path, artifact_path)\r\n  File \"\/home\/cyril\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/tracking\/fluent.py\", line 277, in log_artifacts\r\n    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)\r\n  File \"\/home\/cyril\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/tracking\/client.py\", line 253, in log_artifacts\r\n    artifact_repo = get_artifact_repository(run.info.artifact_uri)\r\n  File \"\/home\/cyril\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact_repository_registry.py\", line 99, in get_artifact_repository\r\n    return _artifact_repository_registry.get_artifact_repository(artifact_uri)\r\n  File \"\/home\/cyril\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact_repository_registry.py\", line 67, in get_artifact_repository\r\n    artifact_uri, list(self._registry.keys())\r\nmlflow.exceptions.MlflowException: Could not find a registered artifact repository for: http:\/\/localhost:5000\/6a8e2424eb2a490bb7aec43a63c4f87e\/artifacts. Currently registered schemes are: ['', 'file', 's3', 'gs', 'wasbs', 'ftp', 'sftp', 'dbfs', 'hdfs', 'runs']\r\n\r\n\r\n\r\n","929":"## What changes are proposed in this pull request?\r\n \r\nUpgrade react-scripts to v3.1.1.\r\n\r\nMain purposes : \r\n\r\n- react-scripts v1 has not been updated since August 2018\r\n- enable use of higher version of es syntax, needed for https:\/\/github.com\/mlflow\/mlflow\/pull\/1556 \r\n \r\n## How is this patch tested?\r\n\r\n## Release Notes\r\n \r\n### Is this a user-facing change? \r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n\r\nNot directly for users, but for developers.\r\n \r\n### What component(s) does this PR affect?\r\n \r\n- [x] UI\r\n- [ ] CLI \r\n- [ ] API \r\n- [ ] REST-API \r\n- [ ] Examples \r\n- [ ] Docs\r\n- [ ] Tracking\r\n- [ ] Projects \r\n- [ ] Artifacts \r\n- [ ] Models \r\n- [ ] Scoring \r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n \r\n- [x] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","930":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: We wrapped Scala around the Java Implementation but this is pretty sure not influencing the issue\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian 10 \r\n- **MLflow installed from (source or binary)**: pypi\r\n- **MLflow version (run ``mlflow --version``)**: mlflow, version 1.1.0\r\n- **Python version**: 3.6.9\r\n- **Exact command to reproduce**: create_experiment(self, name, artifact_location=None):\r\n\r\n### Describe the problem\r\nIf multiple runs of the same experiment starts simultaneously and execute the create_experiment rest call. Our PostgresSQL throws following error:\r\nERROR:  duplicate key value violates unique constraint \"experiments_name_key\"\r\nDETAIL:  Key (name)=(***) already exists.\r\nINSERT INTO experiments (name, artifact_location, lifecycle_stage) VALUES ('***', '', 'active') RETURNING experiments.experiment_id\r\n\r\n### expected behavior ###\r\nMultiple create_experiment calls with the same experiment name will return the same unique experiment-id, so parallel\/distributed training is easily possible.\r\n\r\n\r\n### Relatives ###\r\nHere we need a lock and\/or create_or_get experiment-id handling:\r\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/30a90ec9cbffa5c0d0212368b9f2a7e8c8a3fc81\/mlflow\/store\/sqlalchemy_store.py#L238","931":"## Describe the proposal\r\n\r\n\r\n### Motivation\r\n*What is the use case in mind?  Why is it valuable to support, and why is it currently difficult or impossible to achieve? Could the desired functionality alternatively be implemented as a third-party package using MLflow public APIs?*\r\n\r\nWe often need to deploy our models (e.g. for image classification) at a certain operating point on a precision\/recall curve. For example: we want to only make predictions for a class if the probability for it is above a certain threshold, where we determine the threshold based on a trade-off between precision and recall (that one can glean from a precision recall curve).\r\nWe want to do this programmatically (automatically determine the right threshold given a requirement about the precion and\/or recall), instead of a human manually looking at some image to determine the right threshold.\r\n\r\n\r\n\r\n### Proposed Changes\r\n*For user-facing changes, what APIs are you proposing to add or modify? For internal changes, what code paths will need to be modified?*\r\n\r\nFor this to work we would like to log the (precision, recall, threshold) scores to MLFlow and make them queryable. As a bonus one could visualize the Precision\/Recall curve (or any other curve of that sort) natively in MLFlow.\r\nCurrently one can only log metrics that are single \"key: value\" pairs, which doesn't seem to work for our use-case.","932":"## What changes are proposed in this pull request?\r\n\r\nThis PR proposes a way to allow the user to specify any ```docker run``` option to be used after executing the ```mlflow run``` command. The options are written in the MLproject file under the ```docker_env.options``` as an array of dictionary containing a flag and value key.\r\n\r\nAn example use case is when the user prefer to mount their training-data instead of inserting them to their image or downloading them after the container was created (Issue #1441)\r\n\r\nExample MLproject:\r\n\r\n```\r\nname: my_project\r\n\r\ndocker_env:\r\n  image: \"test-mlflow\"\r\n  options:\r\n    - flag : \"--mount\"\r\n      value : \"source=my-volume,=\/mlflow\/projects\/code\/data\"\r\n    - flag : \"-w\"\r\n      value : \"\/mlflow\/projects\/code\/src\/\"\r\n    - flag : \"--network\"\r\n      value : \"host\"\r\n\r\nentry_points:\r\n  main:\r\n    command: \".\/run.sh\"\r\n```\r\n \r\n## How is this patch tested?\r\n \r\nManual testing\r\n \r\n## Release Notes\r\n \r\n### Is this a user-facing change? \r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n \r\nThis feature adds an optional ```options``` key under the ```docker_env``` of MLproject file which will be used when executing the ```mlflow run``` command.\r\n \r\n### What component(s) does this PR affect?\r\n \r\n- [ ] UI\r\n- [ ] CLI \r\n- [ ] API \r\n- [ ] REST-API \r\n- [ ] Examples \r\n- [ ] Docs\r\n- [ ] Tracking\r\n- [x] Projects \r\n- [ ] Artifacts \r\n- [ ] Models \r\n- [ ] Scoring \r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n \r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","933":"On the page for comparing metrics of one run, there is not enough opportunity to add an additional plot.\r\nThis is necessary when the compared metrics have too different ranges of values.\r\n\r\nFor example:\r\nfirst plot with a range of 1000, 5000\r\nsecond plot with a range of 0.0, 1.0","934":"## Describe the proposal\r\n\r\nI would love to have a Go client for the mlflow API, as it would allow to fetch infos over available runs directly from Go, which would be a great advantage for people implementing microservices in Go.\r\nIt should be straight forward to generate this client from the `.proto` files.\r\nI am currently working on getting this ready. I would be happy to as well add this to the mlflow repository, if it is of interest for you.\r\n\r\n### Motivation\r\nWe are using mlflow in a cloud setting which we are testing with terratest. For this it would come in handy to have a Go client of mlflow. I can imagine that the same applies to services written in Go and somehow handling mlflow data.\r\n\r\n### Proposed Changes\r\nA folder should be added containing the golang client and the `option go_package` has to be added to the `.proto` files. It would be generated from the `.proto` files using the `protoc-gen-go` project and the commands:\r\n\r\n```\r\nprotoc -I=\"$PROTOS\" \\\r\n    --go_out=plugins=grpc,paths=source_relative:\"$GOPATH\/src\" \\\r\n    \"$PROTOS\"\/databricks.proto \\\r\n    \"$PROTOS\"\/service.proto\r\n\r\nprotoc -I=\"$PROTOS\" \\\r\n    --go_out=plugins=grpc,paths=source_relative:\"$GOPATH\/src\" \\\r\n    \"$PROTOS\"\/scalapb\/scalapb.proto\r\n```\r\n\r\nwhich can be added to the `generate_protos.sh`. They have to be separate calls due to this issue: https:\/\/github.com\/golang\/protobuf\/issues\/39.\r\n\r\n","935":"## Describe the proposal\r\n\r\nThe Model class (in `mlflow.models`) has a static method to load itself by reading the MLModel file\r\n\r\n```python\r\n@classmethod\r\n    def load(cls, path):\r\n        \"\"\"Load a model from its YAML representation.\"\"\"\r\n        import os\r\n        if os.path.isdir(path):\r\n            path = os.path.join(path, \"MLmodel\")\r\n        with open(path) as f:\r\n            return cls(**yaml.safe_load(f.read()))\r\n```\r\n\r\nIf you add any extra property to a MLModel file then the `load` method fails. Even though you could parse the MLModel file yourself and just create the object, the `load` method is used sparingly throughout the code, so it is not a valid solution.\r\n\r\nDoes it make sense to allow users to add any additional properties to this file? The MLProject file supports any extra properties with not issues, so it would be consistent.\r\n\r\n### Motivation\r\n\r\nAs MLflow is intended to be a modular solution, some users might want to add some extra metadata in the MLmodel file to consume it in other parts of their systems (as we can do in a MLproject)\r\n\r\n### Proposed Changes\r\n\r\nChange the implementation of the `load` method to load the known attributes manually, so it does not break when it finds any extra property in the yaml file.","936":"mlflow models serve --model-uri runs:\/<run-id>\/model\r\nwhen use this script to served a model, and then I update the model to new version, but don't want to undeploy the old vesion service ?","937":"\r\n\r\n### System information\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nUbuntu VERSION=\"18.04.2 LTS (Bionic Beaver)\"\r\n\r\n- **MLflow installed from (source or binary)**: \r\npip\r\n\r\n- **MLflow version (run ``mlflow --version``)**:\r\n1.2.0\r\n\r\n- **Python version**: \r\n3.6\r\n\r\n\r\n### Describe the problem\r\n\r\nI have set up a **MLproject** like this\r\n\r\n\r\n```\r\nname: Same as project folder name\r\n\r\nconda_env: conda.yaml\r\n\r\nentry_points:\r\n  main:\r\n    command: \"python some.py -p some.json\"\r\n```\r\n\r\nwhen I execute \"`mlflow run \/project folder\/`\", I always get some error like \r\n\r\n ```\r\n File \"\/home\/miniconda\/bin\/mlflow\", line 10, in <module>\r\n    sys.exit(cli())\r\n  File \"\/home\/miniconda\/lib\/python3.6\/site-packages\/click\/core.py\", line 764, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\/home\/miniconda\/lib\/python3.6\/site-packages\/click\/core.py\", line 717, in main\r\n    rv = self.invoke(ctx)\r\n  File \"\/home\/miniconda\/lib\/python3.6\/site-packages\/click\/core.py\", line 1137, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/home\/miniconda\/lib\/python3.6\/site-packages\/click\/core.py\", line 956, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\/home\/miniconda\/lib\/python3.6\/site-packages\/click\/core.py\", line 555, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"\/home\/miniconda\/lib\/python3.6\/site-packages\/mlflow\/cli.py\", line 137, in run\r\n    run_id=run_id\r\n  File \"\/home\/miniconda\/lib\/python3.6\/site-packages\/mlflow\/projects\/__init__.py\", line 266, in run\r\n    use_conda=use_conda, storage_dir=storage_dir, synchronous=synchronous, run_id=run_id)\r\n  File \"\/home\/miniconda\/lib\/python3.6\/site-packages\/mlflow\/projects\/__init__.py\", line 94, in _run\r\n    active_run = _create_run(uri, experiment_id, work_dir, entry_point)\r\n  File \"\/home\/miniconda\/lib\/python3.6\/site-packages\/mlflow\/projects\/__init__.py\", line 622, in _create_run\r\n    active_run = tracking.MlflowClient().create_run(experiment_id=experiment_id, tags=tags)\r\n  File \"\/home\/miniconda\/lib\/python3.6\/site-packages\/mlflow\/tracking\/client.py\", line 88, in create_run\r\n    tags=[RunTag(key, value) for (key, value) in iteritems(tags)]\r\n  File \"\/home\/miniconda\/lib\/python3.6\/site-packages\/mlflow\/store\/rest_store.py\", line 153, in create_run\r\n    response_proto = self._call_endpoint(CreateRun, req_body)\r\n  File \"\/home\/miniconda\/lib\/python3.6\/site-packages\/mlflow\/store\/rest_store.py\", line 64, in _call_endpoint\r\n    response = self._verify_rest_response(response, endpoint)\r\n  File \"\/home\/miniconda\/lib\/python3.6\/site-packages\/mlflow\/store\/rest_store.py\", line 47, in _verify_rest_response\r\n    return verify_rest_response(response, endpoint)\r\n  File \"\/home\/miniconda\/lib\/python3.6\/site-packages\/mlflow\/utils\/rest_utils.py\", line 84, in verify_rest_response\r\n    raise RestException(json.loads(response.text))\r\nmlflow.exceptions.RestException: INVALID_PARAMETER_VALUE: experiment_id must be set to a non-zero value\r\n```\r\n\r\nhowever, when I directly execute the python command in MLproject command \"python some.py -p some.json\", it works and can correctly log stuff into my MLflow server in Azure data bricks\r\n\r\nanything wrong with MLproject? and do I use it in correct way?\r\n\r\nThanks\r\nRui\r\n","938":"## Describe the proposal\r\nAdd mypy checks in travis. \r\n\r\n### Motivation\r\nAnnotations and typing module catch errors by static analysis. In order to improve the code base, I suggest to start to annotate the code and add mypy analysis in travis.\r\n\r\n### Proposed Changes\r\n* Add mypy checks in travis \r\n* Use python2 compatible annotations (using comments) https:\/\/mypy.readthedocs.io\/en\/latest\/python2.html","939":"## Describe the proposal\r\nAllow for zoom functionality on the parallel coordinate plot similar to the zoom functionality in the scatter plot. \r\n\r\n","940":"## What changes are proposed in this pull request?\r\n\r\nAddresses  [#1711](https:\/\/github.com\/mlflow\/mlflow\/issues\/1711)\r\n\r\n- Refactors mlflow.projects to have standard remote backend API\r\n- Adds azure to mlflow projects run backends\r\n \r\n## How is this patch tested?\r\n \r\nAdding unittest tests\/projects\/test_azure.py\r\n \r\n## Release Notes\r\n \r\n### Is this a user-facing change? \r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [X] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n \r\nAdds new mode of project execution on Azure\r\n \r\n### What component(s) does this PR affect?\r\n \r\n- [ ] UI\r\n- [X ] CLI \r\n- [ ] API \r\n- [ ] REST-API \r\n- [X] Examples \r\n- [X] Docs\r\n- [ ] Tracking\r\n- [ ] Projects \r\n- [ ] Artifacts \r\n- [ ] Models \r\n- [ ] Scoring \r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [X] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n \r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [X] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","941":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address.\r\n  \r\nPlease do not delete this template unless you are sure your issue is outside its scope.\r\n\r\n-------\r\n## Guidelines\r\n\r\nFeature requests typically go through the following lifecycle:\r\n\r\n1. Submit feature request with high-level description on GitHub issues (this is what you're doing now)\r\n2. Discuss feature request with a committer, who may ask for a more detailed design\r\n3. After discussion & agreement on feature request, start implementation\r\n\r\n\r\n## Describe the proposal\r\nI propose the addition of functionality to identify the best-performing (by user-specified metric).\r\nFor example, consider the code used for model training at `examples\/sklearn_elasticnet_wine\/train.py`; it would be helpful to have use a function to identify the best-performing model - `my_best_model = mlflow.fetch_best_model(metric=rmse, minimum=True)` - so that I can then pass the model to `log_model()` for future use. \r\n\r\n### Motivation\r\nThe motivation is that implementation of a simple search based on metric would promote automation of identification of the best-performing model (instead of having the user manually viewing the tracking UI and specifying the model to pass to `log_model()`).\r\n\r\n### Proposed Changes\r\nI propose adding a (admittedly, simplistic) best model identification API to correspond with all `log_model` APIs.","942":"## Describe the proposal\r\n\r\nRight now we have autolog feature to automatically log tensorboard tracking status into mlflow tracking in tensorflow and keras, would like to have this feature also in pytorch(tensorboardX)\r\n\r\nsmoothly integrate current pytorch based machine learning code base into mlflow\r\n\r\n### Motivation\r\n\r\ncan help to migrate pytorch code which uses tensorboardX tracking easily into mlflow\r\n\r\n\r\n### Proposed Changes\r\nmlflow.pytorch.autolog()\r\n","943":"# Managed artifacts\r\n## Describe the proposal\r\nThe idea is to support \"managed artifacts\" that allow:\r\n* automatic artifact loading (load artifacts from a previous run replacing otherwise calculated artifacts (e.g., a sampled dataset or a trained neural network)\r\n* automatically handling temporary folders for artifacts during parallel runs (e.g., when you run your script multiple times on the same server)\r\n* central management of loading and logging\r\n* less biolerplate for saving artifacts\r\n\r\nPlease note that this proposal is a rough draft for now to gauge interest. I can go into more depth about specific API specifcations. For a more complete (but by all means not a final version), please see: [mlflowhelper](https:\/\/github.com\/mgbckr\/mlflowhelper)\r\n\r\n### Motivation\r\nI have written a lot of boilerplate code to log and load artifacts. This makes the code error prone and hard to maintain since it obfuscates the actual ML code by lot's of tracking code. The tracking API should be as unintrusive as possible while still giving as much control as necessary. \r\n\r\nIt is possible to implement the proposed functionality as a wrapper (see [mlflowhelper](https:\/\/github.com\/mgbckr\/mlflowhelper)) but I feel like this (or an improved version of this) should be part of the core API to improve the tracking experience.\r\n\r\n### Proposed Changes (Python API only)\r\nBasically, the idea is to introduce an `ArtifactManager`  that eases artifact management. However, I am only going to discuss the changes for the `fluent` API for now. Please note that this is a rough draft with quite a few missing details. For a more complete version please see: [mlflowhelper](https:\/\/github.com\/mgbckr\/mlflowhelper)\r\n\r\n#### Simple artifact management. \r\n\r\nTakes care of logging and deleting the artifact automatically.\r\n```python\r\nfrom matplotlib import pyplot as plt\r\nimport mlflow\r\n\r\nwith mlflow.start_run():\r\n    with mlflow.managed_artifact(\"plot.png\") as artifact:\r\n        fig = plt.figure()\r\n        plt.plot([1,2,3], [1,2,3])\r\n        fig.savefig(artifact.get_path())\r\n```\r\n\r\nSame works on the directory level:\r\n```python\r\nfrom matplotlib import pyplot as plt\r\nimport mlflow\r\n\r\nwith mlflow.start_run():\r\n    with mlflow.managed_artifact_dir(\"plots\") as artifact_dir:\r\n\r\n        # plot 1\r\n        fig = plt.figure()\r\n        plt.plot([1,2,3], [1,2,3])\r\n        fig.savefig(artifact_dir.get_path(\"plot1.png\"))\r\n\r\n        # plot 2\r\n        fig = plt.figure()\r\n        plt.plot([1,2,3], [1,2,3])\r\n        fig.savefig(artifact_dir.get_path(\"plot2.png\"))\r\n```\r\n\r\n#### Artifact loading\r\nArtifact loading allows to load artifacts from previous runs instead of recalcualting them.\r\n```python\r\nimport mlflow\r\nimport pandas as pd\r\n\r\nwith mlflow.start_run():\r\n    mlflow.set_load(run_id=\"e1363f760b1e4ab3a9e93f856f2e9341\", stages=[\"load_data\"]) # activate loading from previous run\r\n    with mlflow.managed_artifact_dir(\"data.csv\", stage=\"load_data\") as artifact:\r\n        if artifact.loaded:\r\n            # load artifact\r\n            data = pd.read_csv(artifact.get_path())\r\n        else:\r\n            # create and save artifact\r\n            data = pd.read_csv(\"\/shared\/dir\/data.csv\").sample(frac=1)\r\n            data.to_csv(artifact.get_path())\r\n```\r\n\r\nSame for directories:\r\n```python\r\nimport mlflow\r\nimport pandas as pd\r\n\r\nmlflow.set_load(run_id=\"e1363f760b1e4ab3a9e93f856f2e9341\", stages=[\"load_data\"]) # activate loading from previous run\r\nwith mlflow.start_run():\r\n    with mlflow.managed_artifact_dir(\"data\", stage=\"load_data\") as artifact_dir:\r\n        train_path = artifact_dir.get_path(\"test.csv\")\r\n        test_path = artifact_dir.get_path(\"train.csv\")\r\n        if artifact_dir.loaded:\r\n            # load artifacts\r\n            train = pd.read_csv(train_path)\r\n            test = pd.read_csv(test_path)\r\n        else:\r\n            data = pd.read_csv(\"\/shared\/dir\/data.csv\").sample(frac=1)\r\n            train = data.iloc[:100,:]\r\n            test = data.iloc[100:,:]\r\n            # save artifacts\r\n            train.to_csv(train_path)\r\n            test.to_csv(test_path)\r\n```\r\n\r\n#### Central logging behavior\r\n\r\n```python\r\nimport mlflow\r\nimport pandas as pd\r\n\r\nwith mlflow.start_run():\r\n\r\n    # activate loading the stage `load_data` from previous run `e1363f760b1e4ab3a9e93f856f2e9341`\r\n    mlflow.set_load(run_id=\"e1363f760b1e4ab3a9e93f856f2e9341\", stages=[\"load_data\"])\r\n\r\n    # deactivate logging the stage `load_data`, in this case for example because it was loaded from a previous run\r\n    mlflow.set_skip_log(stages=[\"load_data\"])\r\n\r\n    with mlflow.managed_artifact_dir(\"data\", stage=\"load_data\") as artifact_dir:\r\n        train_path = artifact_dir.get_path(\"test.csv\")\r\n        test_path = artifact_dir.get_path(\"train.csv\")\r\n        if artifact_dir.loaded:\r\n            # load artifacts\r\n            train = pd.read_csv(train_path)\r\n            test = pd.read_csv(test_path)\r\n        else:\r\n            data = pd.read_csv(\"\/shared\/dir\/data.csv\").sample(frac=1)\r\n            train = data.iloc[:100,:]\r\n            test = data.iloc[100:,:]\r\n            # save artifacts\r\n            train.to_csv(train_path)\r\n            test.to_csv(test_path)\r\n```\r\n\r\n#### Notes\r\nThere are many things that are up for discussion and which can be improved in this proposal. Also some details are missing. Here are some pointers:\r\n* API simplifications for multiple artifacts by returning paths instead of a \"managed resource\" object\r\n* loading across experiments\r\n* loading from external sources\r\n* behavior for nested runs (at the moment this can be easily covered manually, but again, adds biolderplate code)\r\n* load different stages from more than one run\r\n* tracking loading behavior\r\n* and on and on ... ;) ","944":"It would be great if diffing of text-files such as logs or other information serialised into text-files would be supported, or more generally a way to compare output that is not just numerical metrics.\r\n\r\nI am currently trying to compare the text-based output between different models and it's quite tedious.\r\n","945":"# Run MLFlow Project on Azure\r\n\r\n## Proposal\r\n\r\nExpand the open source remote execution backend for MLflow projects to include Azure. This will be similar and build off of kubernetes support in release 1.1.0. Once complete will add to the CLI the command: \r\n\r\n`mlflow run <project_uri> --backend azure --backend-config azure_config.json`\r\n\r\nwhere the `backend-config` is of the form:\r\n\r\n```json\r\n{\r\n   \"subscription-id\": \"b1c23f06-f9b5-4ccb-8a65-a8cb3dcd6a5a\",\r\n   \"resource-group\": \"myResourceGroup\",\r\n   \"workspace-name\": \"myWorkspaceName\",\r\n   \"aml-compute\": {\r\n     \"name\": \"cpu-compute\",\r\n     \"max-nodes\": 4,\r\n     \"vm-size\": \"Standard_D4_v2\",\r\n     \"vm-priority\": \"dedicated\",\r\n     \"retian-cluster\": false\r\n   }\r\n }\r\n```\r\n\r\n### Motivation\r\n\r\nExternal compute resources are very important to ML training. This will expand the functionality to the second largest cloud provider. It will also further solidify and develop the remote execution backend.\r\n\r\n### Proposed Changes\r\n\r\n- modify CLI for projects to accept `azure` as a backend\r\n","946":"Thank you for submitting an issue. Please refer to our [issue policy](https:\/\/www.github.com\/mlflow\/mlflow\/blob\/master\/ISSUE_POLICY.md)\r\nfor information on what types of issues we address.\r\n  \r\nPlease do not delete this template unless you are sure your issue is outside its scope.\r\n\r\n-------\r\n## Guidelines\r\n\r\nFeature requests typically go through the following lifecycle:\r\n\r\n1. Submit feature request with high-level description on GitHub issues (this is what you're doing now)\r\n2. Discuss feature request with a committer, who may ask for a more detailed design\r\n3. After discussion & agreement on feature request, start implementation\r\n\r\n\r\n## Describe the proposal\r\nTo be able to add extra functionalities to the MLFlow tracking server, we would like to be able to decorate flask endpoints. It could be used for many use cases like monitoring or authentication.\r\n\r\n### Motivation\r\nAt Criteo, we use MLFlow tracking server to track our experiments, and we would like to be able to monitor our server.\r\nFor this, we usually use prometheus, so we could use this for flask: https:\/\/pypi.org\/project\/prometheus-flask-exporter\/\r\nIt could be usefull to monitor the requests response time, the errors on the server...\r\n\r\nPossible alternative:\r\nOn my side, before launching the server, I get the list of endpoints and decorate them, but then it wouldn't be reusable by others and we are probably not the only ones who want to monitor the server.\r\n\r\n\r\n### Proposed Changes\r\n1\/ Add a mlflow-prometheus-exporter that decorates flask endpoint so prometheus can get metrics on server usage.\r\n2\/ Add a parameter to the mlflow server command line to activate the prometheus exporter\r\n","947":"Hi\r\n\r\nI went through the \"Dockerized Model Training with MLflow\" for the MLflow project with a Docker environment. I saw in the documentation, that when we run an MLflow project that specifies a Docker image, a new docker image will be created with specific configuration and code. \r\n\r\nCan we run MLflow which spawn a docker container from the specified image only,  without creating a new one on run time?\r\nThe configurations and codes can be volume mounted on run time. \r\n\r\nAnother question , Can we do same thing in docker swarm?  ","948":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **MLflow installed from (source or binary)**:  pip install mlflow in conda environmnet\r\n- **MLflow version (run ``mlflow --version``)**: 1.1.0\r\n- **Python version**:  3.7.3\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: mlflow run <git-repository>\r\n\r\n### Describe the problem\r\nWhen running the command `mlflow run <git-repository>` for a project that uses a conda environment, the project can't be run because of a _FileNotFoundError: [WinError 2] The system cannot find the file specified_ error.\r\n\r\n### Logs\r\n`2019\/07\/26 14:57:50 INFO mlflow.projects: === Running command 'source C:\\Users\\myUser\\AppData\\Local\\Continuum\\anaconda3\\Scripts\/..\/etc\/profile.d\/conda.sh && conda activate mlflow-5704e62345c83aec63a905fd394fede4b904cc8d 1>&2 && python run.py in run with ID '2115ac6375394aaea8a22376b81b1ee3' ===`\r\n\r\nRunning the project fails because the command \"source\" is not available on Windows. The bug might have been introduced in #1576. \r\n\r\n","949":"### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Databricks with DBR 5.4 Conda Beta\r\n- **MLflow version (run ``mlflow --version``)**: 1.1.0\r\n- **Python version**: 3.7.0\r\n\r\n### Describe the problem\r\nI have to save my MLFlow artifacts (using Databricks Unified Analytics) to a S3 bucket, with service-side encrpytion using a custom KMS key.\r\n\r\nMy instances are into an AWS account A, my S3 bucket and my KMS key into an account B. I can't have my KMS Key into my account A.\r\n\r\nI don't want to use DBFS to mount S3 buckets, for security reasons (buckets can contains sensitive data and I don't want to share this between users).\r\n\r\nI have to assume an IAM role in the account B order to access the bucket, as I did to access it through s3a (with `spark.hadoop.fs.s3a.credentialsType` and `spark.hadoop.fs.s3a.stsAssumeRole.arn` parameters).\r\n\r\n\r\n### Source code \/ logs\r\nWhen I create an experiment with s3 and try to log a model like this : \r\n```python\r\nimport mlflow\r\nimport mlflow.sklearn\r\nid_exp = mlflow.create_experiment(\"\/Users\/first.last@company.org\/Experiment\",'s3:\/\/s3-bucket-name\/')\r\nwith mlflow.start_run(experiment_id=id_exp):\r\n  clf_mlf = tree.DecisionTreeClassifier()\r\n  clf_mlf = clf_mlf.fit(X_train, y_train)\r\n  y_pred = clf_mlf.predict(X_test)\r\n  mlflow.sklearn.log_model(clf_mlf, \"model\", serialization_format='pickle')\r\n```\r\n\r\nI have this error : \r\n```\r\nS3UploadFailedError: Failed to upload \/tmp\/tmp2yl2olhi\/model\/conda.yaml to s3-bucket-name\/\/05c17a33a33d46a5ad3cc811a9faf35a\/artifacts\/model\/conda.yaml: An error occurred (KMS.NotFoundException) when calling the PutObject operation: Key 'arn:aws:kms:eu-central-1:account_a_id:key\/key_id' does not exist\r\n```\r\n\r\nHow can I told MLFlow to assume a role on another AWS account before accessing to S3 ?\r\n","950":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **Linux Ubuntu 18.04**:\r\n- **MLflow installed from (source or binary)**: \r\n- **MLflow version 1.0.0**:\r\n- **Python 3.7**: \r\n- **`mlflow models serve`**:\r\n\r\n### Describe the problem\r\nRight now when using `mlflow models serve`, we can pass data to the service using a command like:\r\n`curl -X POST -H 'Content-Type: application\/json; format=pandas-records' --data '{}' http:\/\/127.0.0.1:5000\/invocations`\r\n\r\nWhere the \"--data\" has to be of type pandas.DataFrame, pandas.Series, or numpy array.\r\n\r\nI was interested in sending additional data to mlflow.pyfunc.PythonModel.predict() method. For example, a string flag on what type of thresholding should be used for the .predict() output.\r\n\r\nAt the moment, it seems there is no way to do this (correct me if I am wrong). I believe it would be nice to be able to extract the header data directly in PythonModel, or provide means to pass additional flags.\r\n\r\n\r\n","951":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution**: ubuntu 18.04 bionic beaver\r\n- **MLflow installed from**: using pip3  \r\n- **MLflow version (run ``mlflow --version``)**: 1.0.0\r\n- **Python version**: 3.6.8\r\n\r\n### Description\r\nI have created a custom model using mlflow.pyfunc.log_model() and also I have deployed it using the **mlflow models serve** command, but now I want to add the same thing in a docker and deploy the docker image, but I couldn't sync the custom model with the given environment of mlflow for docker utility. I used the following command,\r\n\r\n**$sudo mlflow models build-docker -m .\/mlruns\/0\/abc123abc\/artifacts\/model\/ -n test_image**\r\n\r\nI get the following error,\r\n**ModuleNotFoundError: No module named 'custom_model'**\r\n","952":"Currently the expresion in UI doesn't support filter on column `Date`. I think it is very useful for user to do some filter on this field.\r\n\r\n","953":"## What changes are proposed in this pull request?\r\n \r\nMake Nginx listening port and gunicorn server overridable. So every time the Mlflow Model image is ran, ENV can be set to change these two configurations. \r\n \r\n## How is this patch tested?\r\n \r\nUnit test passed.\r\n \r\n## Release Notes\r\n \r\n### Is this a user-facing change? \r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n \r\nThe Nginx listening port and gunicorn server can be dynamically configured at model image runtime.\r\n \r\n### What component(s) does this PR affect?\r\n \r\n- [ ] UI\r\n- [ ] CLI \r\n- [ ] API \r\n- [ ] REST-API \r\n- [ ] Examples \r\n- [ ] Docs\r\n- [ ] Tracking\r\n- [ ] Projects \r\n- [ ] Artifacts \r\n- [x] Models \r\n- [ ] Scoring \r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n \r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","954":"MLFlow \u600e\u4e48\u652f\u6301DAG workflow\uff0cif ture\uff0cplease show an example","955":"## What changes are proposed in this pull request?\r\n \r\nAdd an artifact view for notebooks\r\n \r\n## How is this patch tested?\r\n \r\nManually.\r\n \r\n## Release Notes\r\n \r\n### Is this a user-facing change? \r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [x] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n \r\nAdd a view for notebook artifact in mlflow ui.\r\n \r\n### What component(s) does this PR affect?\r\n \r\n- [x] UI\r\n- [ ] CLI \r\n- [ ] API \r\n- [ ] REST-API \r\n- [ ] Examples \r\n- [ ] Docs\r\n- [ ] Tracking\r\n- [ ] Projects \r\n- [ ] Artifacts \r\n- [ ] Models \r\n- [ ] Scoring \r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n \r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [x] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","956":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macos 10\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.0.0\r\n- **Python version**: 3.7.3\r\n\r\n### Describe the problem\r\nCurrently there is no endpoint to delete logged artifacts\/model. It would be a great addition to be able to also delete artifacts because checkpoints can be quite large when logged frequently in many parallel runs. Another option would be to just keep the `keep_n_best` connected to \r\nhttps:\/\/github.com\/mlflow\/mlflow\/issues\/1554.\r\n\r\nThanks in advance.\r\n","957":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macos 10.14.5\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**:  1.0.0\r\n- **Python version**:  3.7.3\r\n- **Exact command to reproduce**: https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.models.html#mlflow.models.Model.log\r\n\r\n### Describe the problem\r\nLogging a model with the mlflow Model.log function will use internally the log_artifact function which does not provide any possibility to provide a step like suggested here https:\/\/github.com\/mlflow\/mlflow\/issues\/32#issuecomment-461017625. Is there still current work going on in this direction? Logging a model without specifying the step\/epoch\/iteration it was generated doesn't make a lot of sense. For our project we would like to get the best model of a run\/experiment where best means:\r\nDuring the training some metrics and checkpoints\/models are logged periodically (currently it all happens at the same time i.e. once per epoch). Now get the the run and timestamp when some logged metric is a global maximum\/minimum (across all experiments, or all runs in one experiment). But at this point it gets hard because the models\/artifacts are not mapped to the metrics (or the other way around). \r\n\r\nIs there something I'm missing out on? Is there some way how this is supposed to be done? I would say it's a crucial feature to get the best model for a run\/experiment given some metric-key. \r\n\r\nThank you in advance.\r\n","958":"### System information\r\n- **MLflow version (run ``mlflow --version``)**: 1.0.0\r\n\r\nMLflow Python API get_experiment does not return an array of RunInfo as specified by the REST API. It only returns an Experiment. The REST and Java versions return an Experiment and list[RunInfo]. \r\n\r\nDocumentation links: \r\n* Python: https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.tracking.html#mlflow.tracking.MlflowClient.get_experiment\r\n* REST: https:\/\/mlflow.org\/docs\/latest\/rest-api.html#get-experiment\r\n* Java: https:\/\/mlflow.org\/docs\/latest\/java_api\/org\/mlflow\/api\/proto\/Service.GetExperiment.Response.html#getExperiment--","959":"As @ankitmathur-db found, attempting to `npm install` packages to run the dev UI fails with node 12.4.0, with a very similar error to that described in https:\/\/github.com\/fsevents\/fsevents\/issues\/278. Downgrading to node 11.14 by installing from conda fixed the issue, but we should document this or upgrade the version of fsevents we depend on","960":"This proposal is for allowing Oracle databases to be used as backing stores, using the same SqlAlchemyStore implementation used for other databases.  There are three identified issues that need to be addressed to add this support:  URI parsing, autoincrementing primary keys, and creation of the default experiment.\r\n\r\n### URI Parsing\r\n\r\nThe URI parsing in six.moves.urllib does not appear to like underscores in the scheme part of URIs, which is unfortunate considering that cx_Oracle is a commonly-used driver:\r\n\r\n```\r\n>>> from six.moves import urllib\r\n>>> urllib.parse.urlparse('oracle+cx_Oracle:\/\/user:passw0rd@127.0.0.1:1521\/?service_name=FOO')\r\nParseResult(scheme='', netloc='', path='oracle+cx_Oracle:\/\/user:passw0rd@127.0.0.1:1521\/', params='', query='service_name=FOO', fragment='')\r\n>>> urllib.parse.urlparse('oracle+cxOracle:\/\/user:passw0rd@127.0.0.1:1521\/?service_name=FOO')\r\nParseResult(scheme='oracle+cxoracle', netloc='user:passw0rd@127.0.0.1:1521', path='\/', params='', query='service_name=FOO', fragment='')\r\n```\r\n\r\nThe six.moves.urllib behavior seems to be the same as the python3 urllib behavior (as expected).\r\n\r\nAltering this behavior is not proposed in this RFC.  Instead, it should be documented that URIs intending to specify the use of the cx_Oracle driver should start with \u201coracle:\/\/\u201c instead of \u201coracle+cx_Oracle:\/\/\u201c (leveraging the fact that cx_Oracle is the default driver for that dialect).\r\n\r\n### Autoincrementing Primary Keys\r\n\r\nDatabases generally support one (or both) of two techniques for producing monotonically-increasing primary keys.  First is the use of database-specific autoincrementig column types; this is supported in SqlAlchemy by passing autoincrement=True when creating a column.  This technique is supported by sqlite, mssql, mysql, and postgresql.  It is not supported by Oracle.  (Technically, recent versions of Oracle database products, 12.1 or later, add an IDENTITY column type that implements this behavior, but SqlAlchemy is not currently capable of emitting SQL using that column type.)\r\n\r\nThe second technique is the use of Sequences, which are database constructs used to produce monotonically-increasing values.  With an autoincrement column type, the primary key does not need to be specified in INSERT statements; it will automatically receive the next value.  With sequences, the value of a primary key must be specified in an INSERT statement (it is specified as next_val(seq), or similar).  Sequences are supported in Oracle (and, incidentally, in postgresql).\r\n\r\nThere is only one autoincrementing value in the current schema: the primary key in the experiments table.  This proposal is to define the column as either:\r\n```\r\n    experiment_id = Column(Integer, autoincrement=True)\r\n```\r\nor\r\n```\r\n    experiment_id = Column(Integer, Sequence('experiment_seq\u2019, start=1))\r\n```\r\ndepending on the dialect that is being used.\r\n\r\nNote that the sequence should be created to start at 1, since 0 is reserved for the default experiment.  Oracle defaults to starting sequences at 1, but it should be made explicit in case that changes, or in case other dialects need to use Sequences in the future.\r\n\r\n### Creating the default experiment\r\n\r\nThe _create_default_experiment method in the SqlAlchemyStore class (mlflow\/store\/sqlalchemy_store,py) includes an SQL INSERT statement for creating the default (ID: 0) experiment.  This statement produces the following error:\r\n\r\n```\r\nmlflow.exceptions.MlflowException: (cx_Oracle.DatabaseError) ORA-00933: SQL command not properly ended\r\n```\r\n\r\nFurther investigation shows that the cx_Oracle driver rejects statements that are terminated with semicolons; the statement works as expected if the semicolon is omitted.  I have been able to test sqlite, which works correctly if the semicolon is deleted.  This proposal includes removing the semicolon at the end of the INSERT statement, assuming it does not affect the other dialects.\r\n","961":"KFServing (https:\/\/github.com\/kubeflow\/kfserving) is an open source Kubeflow effort for model serving on Kubernetes. The effort is aligned with MLSpec and already supports a bunch of frameworks and is working on supporting more advanced inference graph scenarios. KFServing is intended to work on-prem as well as on major cloud providers.\r\n\r\nOpening this issue to get feedback on if it makes sense to support KFServing as a serving target from MLFlow so that data scientists have a clean unified interface open optimized serving across clouds.","962":"Right now it seems the coarsest level of organization within mlflow tracking is the \"experiment\". \r\n\r\nMy group is working on three completely separate types of tasks (for example, predicting housing prices, classifying images of cats, and clustering customers), and are therefore using three separate mlflow tracking servers. As their manager, I'd rather have one centralized server where the top level of organization is the project they are working on, then within each there are the experiments, and further there are the runs. Is this possible, or is this expected to be possible in future mlflow releases? I really think this would be a useful feature.\r\n\r\nThis comment got several upvotes in the mlflow slack channel, so I am creating an official feature request here.","963":"Microsoft releases open source ML.NET https:\/\/github.com\/dotnet\/machinelearning,  c# as machine learning language will get better, Is there someone started to implement the c# API?\r\n\r\n","964":"The current web ui of mlflow, in the runs' table summary shows the last value of the metrics.\r\nIt would be nice to see the minimum and the maximum (of the error for example) as they might be more relevant. Especially to detect the \"bouncing\" overfitting curve on the validation set.","965":"### Feature request\r\nI would like to be able to compare runs belonging to different experiments. Currently runs from different experiments cannot be selected simultaneously.\r\n","966":"## What changes are proposed in this pull request?\r\n \r\nSpark model pyfunc implementation expects the output column `prediction` to be a scalar (usually an integer label). But the output might instead be a `Vector` of probabilities or other scores. The current implementation would just pass those through unchanged which can cause problems down the line, e.g., when serializing as JSON. Therefore it is best to convert those `Vector`s to lists before processing them further.\r\n \r\n## How is this patch tested?\r\n \r\nTests passed.\r\n \r\n## Release Notes\r\n \r\n### Is this a user-facing change? \r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n \r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n \r\n### What component(s) does this PR affect?\r\n \r\n- [ ] UI\r\n- [ ] CLI \r\n- [ ] API \r\n- [ ] REST-API \r\n- [ ] Examples \r\n- [ ] Docs\r\n- [ ] Tracking\r\n- [ ] Projects \r\n- [ ] Artifacts \r\n- [x] Models \r\n- [ ] Scoring \r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n \r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [x] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","967":"## What changes are proposed in this pull request?\r\n`mlflow server --backend-store-uri \"mysql+pymysql:\/\/localhost:3306\/mlflow\" --default-artifact-root mlruns`\r\nthis command failed because of 'pymysql' in uri\r\n![2019-06-05 19-27-40\u5c4f\u5e55\u622a\u56fe](https:\/\/user-images.githubusercontent.com\/6824651\/58953083-08103680-87c8-11e9-9f76-0f36be7e67d1.png)\r\n\r\nthis pr change is_database_uri check to support sqlalchemy driver\r\n \r\n## How is this patch tested?\r\n \r\n[x] Manual tests\r\n \r\n## Release Notes\r\n \r\n### Is this a user-facing change? \r\n\r\n- [ ] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n \r\n(Details in 1-2 sentences. You can just refer to another PR with a description if this PR is part of a larger change.)\r\n \r\n### What component(s) does this PR affect?\r\n \r\n- [ ] UI\r\n- [x] CLI \r\n- [ ] API \r\n- [ ] REST-API \r\n- [ ] Examples \r\n- [ ] Docs\r\n- [ ] Tracking\r\n- [ ] Projects \r\n- [ ] Artifacts \r\n- [ ] Models \r\n- [ ] Scoring \r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [ ] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n \r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [ ] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","968":"## What changes are proposed in this pull request?\r\n \r\nThis PR adds new tag named `mlflow.conda.envName` (MLFLOW_CONDA_ENV_NAME) to standard MLflow tags. This tag is added for runs that are used Conda and it contains name of Conda environment. \r\n\r\nThis PR is required to allow external applications reuse MLflow models with theirs environments (e.g. install additional package into them).\r\n\r\nThis tag with description has been added into documentation.\r\n \r\n## How is this patch tested?\r\n \r\nNew test named `tests\/projects\/test_projects.py::test_use_conda_tags` has been added. It uses test model `example_project` with main entrypoint.\r\n \r\n## Release Notes\r\n \r\n### Is this a user-facing change? \r\n\r\n- [x] No. You can skip the rest of this section.\r\n- [ ] Yes. Give a description of this change to be included in the release notes for MLflow users.\r\n  \r\n### What component(s) does this PR affect?\r\n \r\n- [ ] UI\r\n- [ ] CLI \r\n- [ ] API \r\n- [ ] REST-API \r\n- [ ] Examples \r\n- [x] Docs\r\n- [ ] Tracking\r\n- [ ] Projects \r\n- [ ] Artifacts \r\n- [ ] Models \r\n- [ ] Scoring \r\n- [ ] Serving\r\n- [ ] R\r\n- [ ] Java\r\n- [x] Python\r\n\r\n### How should the PR be classified in the release notes? Choose one:\r\n \r\n- [ ] `rn\/breaking-change` - The PR will be mentioned in the \"Breaking Changes\" section\r\n- [x] `rn\/none` - No description will be included. The PR will be mentioned only by the PR number in the \"Small Bugfixes and Documentation Updates\" section\r\n- [ ] `rn\/feature` - A new user-facing feature worth mentioning in the release notes\r\n- [ ] `rn\/bug-fix` - A user-facing bug fix worth mentioning in the release notes\r\n- [ ] `rn\/documentation` - A user-facing documentation change worth mentioning in the release notes\r\n","969":"There doesn't seem to be any information on how the MLFlow open-source is managed. Can you please add clarification on the process around contributions, commits and strategic design decisions for the MLFlow open-source project ? Is there a specific governance model in place ?\r\n\r\nThanks,\r\nCristian Opris\r\n","970":"Hi, thank you for the awesome library.\r\n\r\nI am running mlflow in my notebook environment and there have been cases where I mistakenly use the wrong params for my model. Is there a way to edit the params in the UI rather than using log_params?","971":"The principal goal of this PR is to expose existing logic for parsing run filter strings.\r\n\r\nPrior to this PR, the `SearchFilter` class was wholly responsible for parsing filter strings and determining if runs satisfied them. Broadly, this was achieved by parsing the string into a list of dicts representing the conditions to filter by (each containing the key to filter by, the value and the operator), then testing to see if a provided run satisfied all of them.\r\n\r\nThis PR factors out the parsing logic into a separate module and exposes an API with more rigidly defined data structures. The exposed API will be available to store implementations, which can then use MLflow's parsing logic to interpret filter strings without necessarily having the filtering happen in Python.\r\n\r\nIn our case, we can then implement a `search_runs` method on our tracking store that calls `search_filter.comparsions()` to get a list of `Comparison` objects like:\r\n\r\n```python\r\n[Comparison(KeyType.PARAM, \"alpha\", ComparisonOperator.EQUAL, \"0.1\"),\r\n Comparison(KeyType.METRIC, \"accuracy\", ComparisonOperator.GREATER_THAN, 0.9)]\r\n```\r\n\r\nThese can then be easily converted into a JSON payload like:\r\n\r\n```json\r\n[\r\n  {\"by\": \"param\", \"key\": \"alpha\", \"operator\": \"eq\", \"value\": \"0.1\"},\r\n  {\"by\": \"metric\", \"key\": \"accuracy\", \"operator\": \"gt\", \"value\": 0.9}\r\n]\r\n```\r\n\r\nwhich can easily be sent to our backend server to be applied as a filter.\r\n\r\nThe alternatives to this would be to re-implement the filter parsing logic in our Scala backend (hard to be consistent) or have the filtering happen client-side (which results in us passing around potentially very large payloads with many runs).\r\n\r\nAside from facilitating more flexible use of the filter parsing logic, this PR also makes the representation of parsed filters in code more structured, introducing some semblance of type safety (in so far as this is possible in Python).\r\n\r\nExtra context:\r\nhttps:\/\/docs.google.com\/document\/d\/1mi3KqaeFoJ_U0q1IA4X4YCjGQVrq4k3LN1j5hsaSQcE\/edit#","972":"## Update experiment_id in protos to string, change semantics around default experiment id to support more id schemas\r\n### Describe the problem\r\nCurrently experiment_id is an int, FileStore and SQLAlchemyStore handle the local case by incrementing an integer, however, this behavior does not translate well to servers that might benefit from using UUIDs or other unique identifiers.\r\n\r\nThe overall proposal includes an update from int64 -> string for experiment_id\r\nHowever, updating the type is also not enough, this is best explained below:\r\n\r\n### Quote from @acroz  that covers a lot of the benefits of removing default experiment_id and possible ways to implement this change\r\nRetaining a default experiment ID of \"0\" seems like a lost opportunity in this case - it (for example) prevents a backend developer from using UUIDs as their ID schema.For the experiment ID schema to truly be flexible like the run ID schema, I think a fixed default value hard coded in MLflow would need to be removed. This could be solved either by something like https:\/\/github.com\/mlflow\/mlflow\/pull\/1032 or by making store implementation responsible for determining the ID of a default experiment with something like:\r\n\r\n\r\n```class StoreWithIntIds(AbstractStore):\r\n\r\n    def _create_experiment_with_id(self, name, experiment_id, artifact_location=None):\r\n\r\n        pass\r\n\r\n    def create_default_experiment(self):\r\n\r\n        self._create_experiment_with_id('Default', 0)\r\n\r\n    def create_experiment(self, name, artifact_location=None):\r\n\r\n        self._create_experiment_with_id(name, self._next_available_id(), artifact_location)\r\n```\r\n\r\nUUIDs (for example) could then be supported with:\r\n\r\n```from uuid import uuid4\r\n\r\nclass StoreWithUuids(AbstractStore):\r\n\r\n    def _create_experiment_with_id(self, name, experiment_id, artifact_location=None):\r\n\r\n        pass\r\n\r\n    def create_default_experiment(self):\r\n\r\n        self._create_experiment_with_id('Default', uuid4())\r\n\r\n    def create_experiment(self, name, artifact_location=None):\r\n\r\n        self._create_experiment_with_id(name, uuid4(), artifact_location)\r\n```\r\n\r\n### Proposal\r\n- make experiment_id an optional string parameter of the REST API\/protos\r\n- return None instead of a value for experiment_id if no value is set\r\n- stores implement the default behavior as desired for store.get_experiment(None)\r\n### Benefits\r\n#### Support varying id schemas\r\nFor this, changing the type to string allows for UUID based id schemas, as well as many other id schemas\r\n#### Reduce complexity of store and server implementations by removing a specified default experiment_id\r\n\r\n### Test Proposal\r\n#### to and from proto\r\n- new client reading old proto\r\nThis will be added by editing the yaml of a new proto, int casting experiment_id, then loading the entity from the new modified proto\/yaml\r\n- new client reading new proto(existing tests cover this)\r\n#### servers\r\n- New client old server\r\n(option 1) Test serialization and deserialization logic for old and new protos - less expansive but also lower maintenance costs\r\n(option 2) add a flag for old and new server behavior parametrize tests for rest store to run against both\r\n- new client new server(existing tests cover this)\r\n- optional(nice to have), old client new server","973":"In #955 we added Python fluent\/client APIs for batched logging. It'd be nice to add analogous APIs in Java, e.g. in the `MlflowClient` class, as described in [this design doc](https:\/\/docs.google.com\/document\/d\/1hOymz5TJPdNwRD0O7Ne94dfsGjGeq5q8g8-8Src85M4\/edit#heading=h.4chqbbxqafuv).","974":"","975":"I would like to be able to delete and create Experiments folders as well as move runs from one Experiment to another from the mlflow ui.\r\n\r\nBest Regards.\r\nKleyson Rios.","976":"### System information\r\n MLflow)**:\r\n- **OS Platform and Distribution (windows 10 64x)**:\r\n- **MLflow installed from (source)**: \r\n- **MLflow version (run ``mlflow 0.8``)**:\r\n- **Python version**:  N\/A Running in Rstudio\r\n### Script\r\ninstall.packages('mlflow', dependencies = T, repos = \"https:\/\/cloud.r-project.org\/\")\r\nmlflow::mlflow_install()\r\nlibrary(mlflow)\r\n\r\nmlflow_ui()\r\n\r\n### Describe the problem\r\nwhen I run mllflow_ui().... i get the following error:  Error in process_initialize(self, private, command, args, stdin, stdout, : Command not found\r\n\r\n### Source code \/ logs\r\n    Failed validating 'additionalProperties' in error:\r\n\r\n    On instance['cells'][2]['outputs'][0]:\r\n    {'ename': 'ERROR',\r\n     'evalue': 'Error in process_initialize(self, private, command, args, '\r\n               'stdin,...',\r\n     'execution_count': 3,\r\n     'output_type': 'error',\r\n     'traceback': ['Error in process_initialize(self, private, command, args, '\r\n                   'stdin,...',\r\n                   '1. mlflow_ui()',\r\n                   '2. mlflow_ui.NULL()',\r\n                   '3. mlflow_client()',\r\n                   '4. mlflow_server(file_store = tracking_uri, port = '\r\n                   'mlflow_connec...',\r\n                   '5. do.call(\"mlflow_cli\", c(\"server\", args, list(background = '\r\n                   'get...',\r\n                   '6. mlflow_cli(\"server\", \"--port\", 5139, \"--file-store\", '\r\n                   '\"C:\/User...',\r\n                   '7. with_envvar(env, {\\n'\r\n                   ' .     if (background) {\\n'\r\n                   ' .         result...',\r\n                   '8. force(code)',\r\n                   '9. process$new(mlflow_bin, args = unlist(args), echo_cmd = '\r\n                   'verbo...',\r\n                   '10. .subset2(public_bind_env, \"initialize\")(...)',\r\n                   '11. process_initialize(self, private, command, args, stdin, '\r\n                   'stdo...']}","977":"Initial checkin for conda.yaml and MLProject.  Adding mlflow input for 'hidden_units' list input, which converts from string to list in train_predict.py.","978":"### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04.5\r\n- **MLflow installed from (source or binary)**: pip install mlflow\r\n- **MLflow version (run ``mlflow --version``)**: mlflow, version 0.8.2\r\n- **Python version**: Python 3.6.6 :: Anaconda, Inc.\r\n- **npm version (if running the dev UI):\r\n- **Exact command to reproduce**: `mlflow server --file-store \/bigdata\/mlflow --host 0.0.0.0`\r\n\r\n### Describe the problem\r\nMLflow UI shows Niagara falls with \"Oops! Something went wrong\" every time I try opening it. I've been using it for two months, but recently it has started crashing until today I cannot get the UI to open at all anymore.\r\n\r\n### Logs\r\n\r\nserver logs after fresh restart:\r\n```\r\n[2019-02-26 12:34:36 +0000] [9] [INFO] Starting gunicorn 19.9.0\r\n[2019-02-26 12:34:36 +0000] [9] [INFO] Listening at: http:\/\/0.0.0.0:5000 (9)\r\n[2019-02-26 12:34:36 +0000] [9] [INFO] Using worker: sync\r\n[2019-02-26 12:34:36 +0000] [12] [INFO] Booting worker with pid: 12\r\n[2019-02-26 12:34:36 +0000] [14] [INFO] Booting worker with pid: 14\r\n[2019-02-26 12:34:36 +0000] [15] [INFO] Booting worker with pid: 15\r\n[2019-02-26 12:34:36 +0000] [18] [INFO] Booting worker with pid: 18\r\n[2019-02-26 12:35:30 +0000] [9] [CRITICAL] WORKER TIMEOUT (pid:14)\r\n[2019-02-26 12:35:30 +0000] [14] [INFO] Worker exiting (pid: 14)\r\n[2019-02-26 12:35:30 +0000] [28] [INFO] Booting worker with pid: 28\r\n```\r\n\r\n\r\n\ufffcbrowser console logs when opening UI:\r\n```\r\nsetupAjaxHeaders.js:22 \r\n{_xsrf: \"2|a583f945|b32757069a3ea1c54e37f87dba1c1428|1549020795\"}\r\nservice-worker.js:1 Uncaught (in promise) Error: Request for http:\/\/localhost:5000\/static-files\/static-files\/static\/css\/main.fbf8a477.css returned a response with status 404\r\n    at service-worker.js:1\r\nservice-worker.js:1 Uncaught (in promise) Error: Request for http:\/\/localhost:5000\/static-files\/static-files\/static\/css\/main.fbf8a477.css returned a response with status 404\r\n    at service-worker.js:1\r\njquery.js:9355 POST http:\/\/localhost:5000\/ajax-api\/2.0\/preview\/mlflow\/runs\/search net::ERR_EMPTY_RESPONSE\r\nActions.js:155 XHR failed \r\n{readyState: 0, getResponseHeader: \u0192, getAllResponseHeaders: \u0192, setRequestHeader: \u0192, overrideMimeType: \u0192, \u2026}\r\nreact-dom.production.min.js:151 TypeError: Cannot read property 'getErrorCode' of undefined\r\n    at errorRenderFunc (ExperimentPage.js:122)\r\n    at e.value (RequestStateWrapper.js:51)\r\n    at f (react-dom.production.min.js:131)\r\n    at beginWork (react-dom.production.min.js:138)\r\n    at o (react-dom.production.min.js:176)\r\n    at a (react-dom.production.min.js:176)\r\n    at x (react-dom.production.min.js:182)\r\n    at y (react-dom.production.min.js:181)\r\n    at v (react-dom.production.min.js:181)\r\n    at d (react-dom.production.min.js:180)\r\nAppErrorBoundary.js:19 TypeError: Cannot read property 'getErrorCode' of undefined\r\n    at errorRenderFunc (ExperimentPage.js:122)\r\n    at e.value (RequestStateWrapper.js:51)\r\n    at f (react-dom.production.min.js:131)\r\n    at beginWork (react-dom.production.min.js:138)\r\n    at o (react-dom.production.min.js:176)\r\n    at a (react-dom.production.min.js:176)\r\n    at x (react-dom.production.min.js:182)\r\n    at y (react-dom.production.min.js:181)\r\n    at v (react-dom.production.min.js:181)\r\n    at d (react-dom.production.min.js:180)\r\n:5000\/#\/experiments\/1:1 Uncaught (in promise) \r\nt {xhr: {\u2026}}\r\n\ufeff```","979":"Implemented some of the proposed fixes in #732 \r\n\r\n","980":"As a developer, I want to leverage data version control libraries (i.e. [dvc](https:\/\/dvc.org\/), [pachyderm](https:\/\/pachyderm.io\/), or [dat](https:\/\/datproject.org\/)), so that I can more easily keep track of files and data sets.","981":"As a developer, I want to deploy mlflow to [Google Cloud Platform (GCP)](https:\/\/cloud.google.com\/), so that I can leverage additional [built-in deployment tools](https:\/\/mlflow.org\/docs\/latest\/models.html#built-in-deployment-tools).","982":"To support multi-users, mlflow tracking server should provide an optional to turn on some basic authentication, and to filter the experiments only to the user.","983":"Right now, the run page links to the parent run (if it exists). It would be valuable to also be able to navigate to the child runs (if they exist).","984":"Right now, if a run has children, you can expand the view to also display its children under it and slightly offset. However, it gathers all children of children and so on and displays them at the same offset as the immediate children instead of hiding them.\r\n\r\nFor deep model relationship trees, this makes the experiment table view confusing since there's no visual distinction between what is a child and what is a child of a child. If we could have the same collapsing\/expanding and offsetting available for child runs as well, it would be much easier to grok what is going on at what level of the run hierarchy.","985":"Could the project please post prebuilt containers up to the docker hub? There are lots of folks posting their own builds but are not kept up to date and are not official.","986":"### Describe the problem\r\nIt would be nice to run mlflow tracking and mlflow ui as a central service to allow multiple user send their data to tracking API and view and share their results from central service.\r\n\r\nFor each user, it would be nice to give each of them an 'namespace', so each user only log to their own namespace. When accessing the UI, they pass the 'namespace' as a parameter and then the UI only show their own experiments. \r\n\r\nUsers can share their experiment result with a URL with have their namespace in it. Proper access control can be added later.","987":"Right now, we can only track the status of a run, possibly marking it as failed upon failure. It would be nice to be able to add a failure reason along with the failure status. The reason could be something like a serialized stacktrace stored as a tag or simply an error code provided by the user. In either case, the user would be responsible for specifying the failure reason.","988":"This issue is a feature request.\r\nWe try to version a whole Machine Learning pipeline using [MLV-tools](https:\/\/github.com\/peopledoc\/ml-versioning-tools\/) and we need to have a deterministic output structure for each run. \r\nFor example:\r\n`mlflow.start_run(ouput_path='\/my\/custom\/path', experiment_id=12)`\r\n\r\n\r\n          \/my\/custom\/path\/12\/\r\n                          |- [param_name_combi1]\r\n                          |- [param_name_combi2]\r\n\r\nHere the major difference is the replacement of unpredictable uuid with a deterministic name.\r\n","989":"Currently in comparing runs, there is possibility to plot metric vs. parameter, only when parameter is scalar. Many parameters have values in form of category (ex. name of used sampling strategy). It would be great to add option for categorical plots.","990":"### System information\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: `Linux ip-172-16-44-178 4.9.119-44.140.amzn1.x86_64 #1 SMP Fri Aug 10 19:17:29 UTC 2018 x86_64 x86_64 x86_64 GNU\/Linux`\r\n- **MLflow installed from (source or binary)**:  `pip install --no-cache-dir mlflow`\r\n- **MLflow version (run ``mlflow --version``)**: `mlflow v0.6.0`\r\n- **Python version**: `Python 3.6.5 :: Anaconda custom (64-bit)`\r\n\r\n### Describe the problem\r\n\r\nI have a problem to install `mlflow` in sagemaker notebook.\r\nI use sagemaker lifecycle configuration with next script on start:\r\n\r\n```\r\n#!\/bin\/bash\r\n\r\nset -e # exit immediately on error\r\nset -x # print command before execution\r\n\r\nsudo su ec2-user\r\n\r\nsudo ln -s \/usr\/libexec\/gcc\/x86_64-amazon-linux\/4.8.5\/cc1plus \/usr\/bin\r\n\r\nsource \/home\/ec2-user\/anaconda3\/bin\/activate python3\r\n\r\npip install --upgrade pip\r\npip install --no-cache-dir xgboost\r\npip install --no-cache-dir graphviz\r\npip install --no-cache-dir shap\r\npip install --no-cache-dir mlflow\r\npip install --no-cache-dir lightgbm\r\npip install --no-cache-dir catboost\r\n\r\nsource \/home\/ec2-user\/anaconda3\/bin\/deactivate\r\n```\r\n\r\nAnd very often (~50%) it failes with error:\r\n\r\n```\r\nRequirement already satisfied: docutils>=0.10 in .\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from botocore<1.11.0,>=1.10.79->boto3->mlflow) (0.14)\r\nRequirement already satisfied: nose in .\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from nose-exclude>=0.5.0->mleap>=0.8.1->mlflow) (1.3.7)\r\nCould not install packages due to an EnvironmentError: [Errno 2] No such file or directory: '\/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/sagemaker-1.9.0.dist-info\/METADATA'\r\n```\r\n\r\nLooks like it tries to find `sagmaker v1.9.0`, but as I see in sagemaker terminal (when it's launched successfully) there is `sagemaker v1.10.0` only:\r\n\r\n```\r\nsh-4.2$ pwd\r\n\/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\r\nsh-4.2$ cd sagemaker\r\nsagemaker\/                         sagemaker_pyspark\/\r\nsagemaker-1.10.0.dist-info\/        sagemaker_pyspark-1.1.4.dist-info\/\r\nsh-4.2$ cd sagemaker\r\n```\r\n\r\nCould you please to help to find workaround?\r\n\r\n","991":"The idea would be to add a binder badge to let people try mlflow with a single click on small toy datasets. Ideally we would also add a test notebook for interactively using mlflow with pyspark","992":"Based on [this PR comment](https:\/\/github.com\/mlflow\/mlflow\/pull\/382#discussion_r214762073) - it'd be nice to use [reselect](https:\/\/www.npmjs.com\/package\/reselect) in JS components to compute derived data (e.g. data computed based on Redux's state store) to allow for memoization \/ improved UI performance. ","993":"Support calling Python (pyfunc) models from R or rfunc models from Python.\r\n\r\nOne approach here is to use `mlflow pyfunc predict`from R and `mlflow rfunc predict` from Python; however, this would mean serializing to CSV, etc. We could consider Feather or Arrow once the R bindings become available.\r\n\r\nIn any case, this seems more like a follow up feature we can implement after the initial merge.","994":"When running projects on Databricks, we should filter out the uid \/ guid \/ username \/ group name when tarring projects for upload to DBFS, since we use the hash of the tarfile to determine whether to reupload a project to DBFS. This could be done by updating the [helper method](https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/utils\/file_utils.py#L246) used to modify file metadata [(TarInfos)](https:\/\/docs.python.org\/3\/library\/tarfile.html#tarfile.TarInfo.uid) while creating the archive. ","995":"### Describe the problem\r\n\r\nThe script used to generate the API and object definition for the Javascript SDK from the protobuf definitions is not available in the open source codebase. I spoke with @aarondav who said that the script is available internally but needs to be ported and released, possibly along with internal dependencies. It would be nice to see the script released because adding features that require changing the service proto would be tedious without being able to regenerate the JS SDK.","996":"For REST API operations, currently all errors return 500 (Internal Server Error). The API should return standard 4xx HTTP status codes when the error is caused by the client. 5xx should be rare - returned only by unexpected internal server errors. \r\n\r\nSome examples:\r\n- 404 (Not Found) should be returned when looking up a non-existent resource, .e.g. experiments\/get?experiment_id=foo\r\n- 400 (Bad Request) when bad JSON is submitted to any POST operation such as create experiment\r\n- 409 (Conflict)- when trying to create an experiment with duplicate name \r\n\r\n See: https:\/\/www.w3.org\/Protocols\/rfc2616\/rfc2616-sec10.html#sec10.4","997":"### Describe the problem\r\nCurrently there is no support for logging of the run's environment. Being able to retrieve the exact environment is critical for reproducibility. While the users can log it manually e.g. as an param and \/ or an artifact  it's not easy. I would be nice to automatically log the Conda environment of every run, or at least to add more logging support specific to the environment. \r\n","998":"When you log multiple values for a metric in a single run, the MLFlow Tracking UI run overview table shows the latest logged metrics as the value for each metric. This makes sense when training e.g. Neural Networks and you want to log performance after multiple iterations. \r\n\r\nIt makes less sense when logging different metric values from different Cross Validation folds, which I think are logical to log under the same run. In this use-case it would be more beneficial to display the average metric value. \r\n\r\nBoth ways have merit, so if there could be a toggle somewhere to change between these two options that would be perfect. ","999":"### Describe the problem\r\nThere are often natural ways to order parameters, e.g. to group related quantities. Currently the UI orders them alphabetically. It would be nice to be able to control the ordering, e.g. to match the order in which the logging happens or by providing a list in the desired order."},"pull_request":{"0":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5447","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5447","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5447.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5447.patch","merged_at":null},"1":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5444","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5444","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5444.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5444.patch","merged_at":null},"2":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5443","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5443","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5443.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5443.patch","merged_at":null},"3":null,"4":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5438","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5438","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5438.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5438.patch","merged_at":null},"5":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5434","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5434","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5434.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5434.patch","merged_at":null},"6":null,"7":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5421","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5421","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5421.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5421.patch","merged_at":null},"8":null,"9":null,"10":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5405","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5405","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5405.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5405.patch","merged_at":null},"11":null,"12":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5394","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5394","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5394.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5394.patch","merged_at":null},"13":null,"14":null,"15":null,"16":null,"17":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5380","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5380","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5380.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5380.patch","merged_at":null},"18":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5378","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5378","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5378.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5378.patch","merged_at":null},"19":null,"20":null,"21":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5371","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5371","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5371.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5371.patch","merged_at":null},"22":null,"23":null,"24":null,"25":null,"26":null,"27":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5350","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5350","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5350.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5350.patch","merged_at":null},"28":null,"29":null,"30":null,"31":null,"32":null,"33":null,"34":null,"35":null,"36":null,"37":null,"38":null,"39":null,"40":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5309","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5309","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5309.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5309.patch","merged_at":null},"41":null,"42":null,"43":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5296","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5296","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5296.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5296.patch","merged_at":null},"44":null,"45":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5290","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5290","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5290.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5290.patch","merged_at":null},"46":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5286","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5286","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5286.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5286.patch","merged_at":null},"47":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5276","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5276","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5276.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5276.patch","merged_at":null},"48":null,"49":null,"50":null,"51":null,"52":null,"53":null,"54":null,"55":null,"56":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5250","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5250","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5250.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5250.patch","merged_at":null},"57":null,"58":null,"59":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5237","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5237","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5237.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5237.patch","merged_at":null},"60":null,"61":null,"62":null,"63":null,"64":null,"65":null,"66":null,"67":null,"68":null,"69":null,"70":null,"71":null,"72":null,"73":null,"74":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5201","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5201","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5201.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5201.patch","merged_at":null},"75":null,"76":null,"77":null,"78":null,"79":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5187","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5187","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5187.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5187.patch","merged_at":null},"80":null,"81":null,"82":null,"83":null,"84":null,"85":null,"86":null,"87":null,"88":null,"89":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5157","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5157","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5157.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5157.patch","merged_at":null},"90":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5154","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5154","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5154.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5154.patch","merged_at":null},"91":null,"92":null,"93":null,"94":null,"95":null,"96":null,"97":null,"98":null,"99":null,"100":null,"101":null,"102":null,"103":null,"104":null,"105":null,"106":null,"107":null,"108":null,"109":null,"110":null,"111":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5090","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5090","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5090.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5090.patch","merged_at":null},"112":null,"113":null,"114":null,"115":null,"116":null,"117":null,"118":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5068","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5068","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5068.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5068.patch","merged_at":null},"119":null,"120":null,"121":null,"122":null,"123":null,"124":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5050","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5050","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5050.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5050.patch","merged_at":null},"125":null,"126":null,"127":null,"128":null,"129":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5013","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5013","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5013.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5013.patch","merged_at":null},"130":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/5004","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5004","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5004.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/5004.patch","merged_at":null},"131":null,"132":null,"133":null,"134":null,"135":null,"136":null,"137":null,"138":null,"139":null,"140":null,"141":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4972","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4972","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4972.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4972.patch","merged_at":null},"142":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4961","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4961","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4961.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4961.patch","merged_at":null},"143":null,"144":null,"145":null,"146":null,"147":null,"148":null,"149":null,"150":null,"151":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4915","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4915","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4915.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4915.patch","merged_at":null},"152":null,"153":null,"154":null,"155":null,"156":null,"157":null,"158":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4896","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4896","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4896.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4896.patch","merged_at":null},"159":null,"160":null,"161":null,"162":null,"163":null,"164":null,"165":null,"166":null,"167":null,"168":null,"169":null,"170":null,"171":null,"172":null,"173":null,"174":null,"175":null,"176":null,"177":null,"178":null,"179":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4831","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4831","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4831.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4831.patch","merged_at":null},"180":null,"181":null,"182":null,"183":null,"184":null,"185":null,"186":null,"187":null,"188":null,"189":null,"190":null,"191":null,"192":null,"193":null,"194":null,"195":null,"196":null,"197":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4794","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4794","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4794.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4794.patch","merged_at":null},"198":null,"199":null,"200":null,"201":null,"202":null,"203":null,"204":null,"205":null,"206":null,"207":null,"208":null,"209":null,"210":null,"211":null,"212":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4733","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4733","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4733.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4733.patch","merged_at":null},"213":null,"214":null,"215":null,"216":null,"217":null,"218":null,"219":null,"220":null,"221":null,"222":null,"223":null,"224":null,"225":null,"226":null,"227":null,"228":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4656","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4656","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4656.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4656.patch","merged_at":null},"229":null,"230":null,"231":null,"232":null,"233":null,"234":null,"235":null,"236":null,"237":null,"238":null,"239":null,"240":null,"241":null,"242":null,"243":null,"244":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4606","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4606","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4606.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4606.patch","merged_at":null},"245":null,"246":null,"247":null,"248":null,"249":null,"250":null,"251":null,"252":null,"253":null,"254":null,"255":null,"256":null,"257":null,"258":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4543","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4543","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4543.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4543.patch","merged_at":null},"259":null,"260":null,"261":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4531","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4531","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4531.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4531.patch","merged_at":null},"262":null,"263":null,"264":null,"265":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4514","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4514","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4514.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4514.patch","merged_at":null},"266":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4510","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4510","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4510.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4510.patch","merged_at":null},"267":null,"268":null,"269":null,"270":null,"271":null,"272":null,"273":null,"274":null,"275":null,"276":null,"277":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4472","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4472","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4472.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4472.patch","merged_at":null},"278":null,"279":null,"280":null,"281":null,"282":null,"283":null,"284":null,"285":null,"286":null,"287":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4443","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4443","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4443.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4443.patch","merged_at":null},"288":null,"289":null,"290":null,"291":null,"292":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4425","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4425","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4425.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4425.patch","merged_at":null},"293":null,"294":null,"295":null,"296":null,"297":null,"298":null,"299":null,"300":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4401","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4401","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4401.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4401.patch","merged_at":null},"301":null,"302":null,"303":null,"304":null,"305":null,"306":null,"307":null,"308":null,"309":null,"310":null,"311":null,"312":null,"313":null,"314":null,"315":null,"316":null,"317":null,"318":null,"319":null,"320":null,"321":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4317","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4317","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4317.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4317.patch","merged_at":null},"322":null,"323":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4312","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4312","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4312.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4312.patch","merged_at":null},"324":null,"325":null,"326":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4300","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4300","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4300.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4300.patch","merged_at":null},"327":null,"328":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4294","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4294","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4294.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4294.patch","merged_at":null},"329":null,"330":null,"331":null,"332":null,"333":null,"334":null,"335":null,"336":null,"337":null,"338":null,"339":null,"340":null,"341":null,"342":null,"343":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4224","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4224","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4224.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4224.patch","merged_at":null},"344":null,"345":null,"346":null,"347":null,"348":null,"349":null,"350":null,"351":null,"352":null,"353":null,"354":null,"355":null,"356":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4189","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4189","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4189.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4189.patch","merged_at":null},"357":null,"358":null,"359":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4182","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4182","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4182.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4182.patch","merged_at":null},"360":null,"361":null,"362":null,"363":null,"364":null,"365":null,"366":null,"367":null,"368":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4148","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4148","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4148.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4148.patch","merged_at":null},"369":null,"370":null,"371":null,"372":null,"373":null,"374":null,"375":null,"376":null,"377":null,"378":null,"379":null,"380":null,"381":null,"382":null,"383":null,"384":null,"385":null,"386":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4098","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4098","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4098.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4098.patch","merged_at":null},"387":null,"388":null,"389":null,"390":null,"391":null,"392":null,"393":null,"394":null,"395":null,"396":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4072","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4072","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4072.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4072.patch","merged_at":null},"397":null,"398":null,"399":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4065","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4065","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4065.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4065.patch","merged_at":null},"400":null,"401":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4058","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4058","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4058.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4058.patch","merged_at":null},"402":null,"403":null,"404":null,"405":null,"406":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/4045","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4045","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4045.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/4045.patch","merged_at":null},"407":null,"408":null,"409":null,"410":null,"411":null,"412":null,"413":null,"414":null,"415":null,"416":null,"417":null,"418":null,"419":null,"420":null,"421":null,"422":null,"423":null,"424":null,"425":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3985","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3985","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3985.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3985.patch","merged_at":null},"426":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3974","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3974","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3974.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3974.patch","merged_at":null},"427":null,"428":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3971","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3971","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3971.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3971.patch","merged_at":null},"429":null,"430":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3967","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3967","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3967.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3967.patch","merged_at":null},"431":null,"432":null,"433":null,"434":null,"435":null,"436":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3960","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3960","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3960.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3960.patch","merged_at":null},"437":null,"438":null,"439":null,"440":null,"441":null,"442":null,"443":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3945","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3945","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3945.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3945.patch","merged_at":null},"444":null,"445":null,"446":null,"447":null,"448":null,"449":null,"450":null,"451":null,"452":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3897","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3897","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3897.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3897.patch","merged_at":null},"453":null,"454":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3879","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3879","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3879.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3879.patch","merged_at":null},"455":null,"456":null,"457":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3865","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3865","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3865.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3865.patch","merged_at":null},"458":null,"459":null,"460":null,"461":null,"462":null,"463":null,"464":null,"465":null,"466":null,"467":null,"468":null,"469":null,"470":null,"471":null,"472":null,"473":null,"474":null,"475":null,"476":null,"477":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3790","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3790","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3790.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3790.patch","merged_at":null},"478":null,"479":null,"480":null,"481":null,"482":null,"483":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3766","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3766","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3766.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3766.patch","merged_at":null},"484":null,"485":null,"486":null,"487":null,"488":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3748","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3748","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3748.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3748.patch","merged_at":null},"489":null,"490":null,"491":null,"492":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3742","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3742","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3742.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3742.patch","merged_at":null},"493":null,"494":null,"495":null,"496":null,"497":null,"498":null,"499":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3724","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3724","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3724.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3724.patch","merged_at":null},"500":null,"501":null,"502":null,"503":null,"504":null,"505":null,"506":null,"507":null,"508":null,"509":null,"510":null,"511":null,"512":null,"513":null,"514":null,"515":null,"516":null,"517":null,"518":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3661","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3661","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3661.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3661.patch","merged_at":null},"519":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3657","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3657","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3657.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3657.patch","merged_at":null},"520":null,"521":null,"522":null,"523":null,"524":null,"525":null,"526":null,"527":null,"528":null,"529":null,"530":null,"531":null,"532":null,"533":null,"534":null,"535":null,"536":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3581","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3581","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3581.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3581.patch","merged_at":null},"537":null,"538":null,"539":null,"540":null,"541":null,"542":null,"543":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3569","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3569","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3569.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3569.patch","merged_at":null},"544":null,"545":null,"546":null,"547":null,"548":null,"549":null,"550":null,"551":null,"552":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3532","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3532","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3532.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3532.patch","merged_at":null},"553":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3529","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3529","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3529.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3529.patch","merged_at":null},"554":null,"555":null,"556":null,"557":null,"558":null,"559":null,"560":null,"561":null,"562":null,"563":null,"564":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3484","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3484","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3484.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3484.patch","merged_at":null},"565":null,"566":null,"567":null,"568":null,"569":null,"570":null,"571":null,"572":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3473","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3473","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3473.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3473.patch","merged_at":null},"573":null,"574":null,"575":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3461","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3461","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3461.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3461.patch","merged_at":null},"576":null,"577":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3458","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3458","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3458.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3458.patch","merged_at":null},"578":null,"579":null,"580":null,"581":null,"582":null,"583":null,"584":null,"585":null,"586":null,"587":null,"588":null,"589":null,"590":null,"591":null,"592":null,"593":null,"594":null,"595":null,"596":null,"597":null,"598":null,"599":null,"600":null,"601":null,"602":null,"603":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3379","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3379","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3379.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3379.patch","merged_at":null},"604":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3378","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3378","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3378.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3378.patch","merged_at":null},"605":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3375","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3375","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3375.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3375.patch","merged_at":null},"606":null,"607":null,"608":null,"609":null,"610":null,"611":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3343","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3343","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3343.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3343.patch","merged_at":null},"612":null,"613":null,"614":null,"615":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3325","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3325","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3325.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3325.patch","merged_at":null},"616":null,"617":null,"618":null,"619":null,"620":null,"621":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3307","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3307","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3307.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3307.patch","merged_at":null},"622":null,"623":null,"624":null,"625":null,"626":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3296","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3296","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3296.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3296.patch","merged_at":null},"627":null,"628":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3292","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3292","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3292.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3292.patch","merged_at":null},"629":null,"630":null,"631":null,"632":null,"633":null,"634":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3274","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3274","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3274.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3274.patch","merged_at":null},"635":null,"636":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3262","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3262","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3262.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3262.patch","merged_at":null},"637":null,"638":null,"639":null,"640":null,"641":null,"642":null,"643":null,"644":null,"645":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3221","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3221","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3221.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3221.patch","merged_at":null},"646":null,"647":null,"648":null,"649":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3201","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3201","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3201.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3201.patch","merged_at":null},"650":null,"651":null,"652":null,"653":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3176","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3176","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3176.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3176.patch","merged_at":null},"654":null,"655":null,"656":null,"657":null,"658":null,"659":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3150","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3150","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3150.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3150.patch","merged_at":null},"660":null,"661":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3136","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3136","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3136.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3136.patch","merged_at":null},"662":null,"663":null,"664":null,"665":null,"666":null,"667":null,"668":null,"669":null,"670":null,"671":null,"672":null,"673":null,"674":null,"675":null,"676":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3057","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3057","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3057.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3057.patch","merged_at":null},"677":null,"678":null,"679":null,"680":null,"681":null,"682":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/3024","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3024","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3024.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/3024.patch","merged_at":null},"683":null,"684":null,"685":null,"686":null,"687":null,"688":null,"689":null,"690":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2995","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2995","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2995.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2995.patch","merged_at":null},"691":null,"692":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2990","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2990","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2990.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2990.patch","merged_at":null},"693":null,"694":null,"695":null,"696":null,"697":null,"698":null,"699":null,"700":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2964","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2964","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2964.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2964.patch","merged_at":null},"701":null,"702":null,"703":null,"704":null,"705":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2934","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2934","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2934.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2934.patch","merged_at":null},"706":null,"707":null,"708":null,"709":null,"710":null,"711":null,"712":null,"713":null,"714":null,"715":null,"716":null,"717":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2878","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2878","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2878.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2878.patch","merged_at":null},"718":null,"719":null,"720":null,"721":null,"722":null,"723":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2848","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2848","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2848.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2848.patch","merged_at":null},"724":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2847","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2847","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2847.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2847.patch","merged_at":null},"725":null,"726":null,"727":null,"728":null,"729":null,"730":null,"731":null,"732":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2826","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2826","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2826.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2826.patch","merged_at":null},"733":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2825","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2825","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2825.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2825.patch","merged_at":null},"734":null,"735":null,"736":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2822","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2822","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2822.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2822.patch","merged_at":null},"737":null,"738":null,"739":null,"740":null,"741":null,"742":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2796","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2796","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2796.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2796.patch","merged_at":null},"743":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2795","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2795","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2795.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2795.patch","merged_at":null},"744":null,"745":null,"746":null,"747":null,"748":null,"749":null,"750":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2767","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2767","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2767.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2767.patch","merged_at":null},"751":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2753","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2753","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2753.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2753.patch","merged_at":null},"752":null,"753":null,"754":null,"755":null,"756":null,"757":null,"758":null,"759":null,"760":null,"761":null,"762":null,"763":null,"764":null,"765":null,"766":null,"767":null,"768":null,"769":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2681","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2681","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2681.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2681.patch","merged_at":null},"770":null,"771":null,"772":null,"773":null,"774":null,"775":null,"776":null,"777":null,"778":null,"779":null,"780":null,"781":null,"782":null,"783":null,"784":null,"785":null,"786":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2601","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2601","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2601.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2601.patch","merged_at":null},"787":null,"788":null,"789":null,"790":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2555","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2555","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2555.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2555.patch","merged_at":null},"791":null,"792":null,"793":null,"794":null,"795":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2541","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2541","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2541.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2541.patch","merged_at":null},"796":null,"797":null,"798":null,"799":null,"800":null,"801":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2496","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2496","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2496.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2496.patch","merged_at":null},"802":null,"803":null,"804":null,"805":null,"806":null,"807":null,"808":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2453","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2453","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2453.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2453.patch","merged_at":null},"809":null,"810":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2450","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2450","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2450.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2450.patch","merged_at":null},"811":null,"812":null,"813":null,"814":null,"815":null,"816":null,"817":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2432","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2432","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2432.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2432.patch","merged_at":null},"818":null,"819":null,"820":null,"821":null,"822":null,"823":null,"824":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2396","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2396","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2396.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2396.patch","merged_at":null},"825":null,"826":null,"827":null,"828":null,"829":null,"830":null,"831":null,"832":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2361","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2361","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2361.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2361.patch","merged_at":null},"833":null,"834":null,"835":null,"836":null,"837":null,"838":null,"839":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2310","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2310","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2310.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2310.patch","merged_at":null},"840":null,"841":null,"842":null,"843":null,"844":null,"845":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2268","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2268","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2268.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2268.patch","merged_at":null},"846":null,"847":null,"848":null,"849":null,"850":null,"851":null,"852":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2241","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2241","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2241.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2241.patch","merged_at":null},"853":null,"854":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2239","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2239","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2239.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2239.patch","merged_at":null},"855":null,"856":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2214","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2214","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2214.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2214.patch","merged_at":null},"857":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2209","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2209","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2209.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2209.patch","merged_at":null},"858":null,"859":null,"860":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2189","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2189","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2189.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2189.patch","merged_at":null},"861":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2185","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2185","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2185.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2185.patch","merged_at":null},"862":null,"863":null,"864":null,"865":null,"866":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2171","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2171","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2171.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2171.patch","merged_at":null},"867":null,"868":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2168","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2168","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2168.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2168.patch","merged_at":null},"869":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2166","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2166","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2166.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2166.patch","merged_at":null},"870":null,"871":null,"872":null,"873":null,"874":null,"875":null,"876":null,"877":null,"878":null,"879":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/2127","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2127","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2127.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/2127.patch","merged_at":null},"880":null,"881":null,"882":null,"883":null,"884":null,"885":null,"886":null,"887":null,"888":null,"889":null,"890":null,"891":null,"892":null,"893":null,"894":null,"895":null,"896":null,"897":null,"898":null,"899":null,"900":null,"901":null,"902":null,"903":null,"904":null,"905":null,"906":null,"907":null,"908":null,"909":null,"910":null,"911":null,"912":null,"913":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/1899","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1899","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1899.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1899.patch","merged_at":null},"914":null,"915":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/1875","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1875","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1875.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1875.patch","merged_at":null},"916":null,"917":null,"918":null,"919":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/1850","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1850","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1850.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1850.patch","merged_at":null},"920":null,"921":null,"922":null,"923":null,"924":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/1828","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1828","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1828.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1828.patch","merged_at":null},"925":null,"926":null,"927":null,"928":null,"929":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/1812","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1812","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1812.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1812.patch","merged_at":null},"930":null,"931":null,"932":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/1808","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1808","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1808.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1808.patch","merged_at":null},"933":null,"934":null,"935":null,"936":null,"937":null,"938":null,"939":null,"940":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/1747","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1747","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1747.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1747.patch","merged_at":null},"941":null,"942":null,"943":null,"944":null,"945":null,"946":null,"947":null,"948":null,"949":null,"950":null,"951":null,"952":null,"953":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/1627","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1627","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1627.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1627.patch","merged_at":null},"954":null,"955":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/1556","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1556","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1556.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1556.patch","merged_at":null},"956":null,"957":null,"958":null,"959":null,"960":null,"961":null,"962":null,"963":null,"964":null,"965":null,"966":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/1412","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1412","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1412.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1412.patch","merged_at":null},"967":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/1402","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1402","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1402.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1402.patch","merged_at":null},"968":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/1284","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1284","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1284.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1284.patch","merged_at":null},"969":null,"970":null,"971":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/1128","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1128","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1128.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1128.patch","merged_at":null},"972":null,"973":null,"974":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/1030","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1030","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1030.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/1030.patch","merged_at":null},"975":null,"976":null,"977":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/946","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/946","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/946.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/946.patch","merged_at":null},"978":null,"979":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/919","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/919","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/919.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/919.patch","merged_at":null},"980":null,"981":null,"982":null,"983":null,"984":null,"985":null,"986":null,"987":null,"988":null,"989":null,"990":null,"991":{"url":"https:\/\/api.github.com\/repos\/mlflow\/mlflow\/pulls\/457","html_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/457","diff_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/457.diff","patch_url":"https:\/\/github.com\/mlflow\/mlflow\/pull\/457.patch","merged_at":null},"992":null,"993":null,"994":null,"995":null,"996":null,"997":null,"998":null,"999":null},"labels":{"0":["rn\/none","area\/tracking"],"1":[],"2":["rn\/bug-fix"],"3":["bug"],"4":["rn\/bug-fix","area\/artifacts"],"5":[],"6":[],"7":["rn\/none","area\/models"],"8":["enhancement"],"9":["bug","area\/models"],"10":["rn\/feature","area\/tracking"],"11":["enhancement","area\/uiux","area\/tracking"],"12":[],"13":[],"14":[],"15":["enhancement","area\/tracking"],"16":["enhancement","area\/docs","area\/scoring"],"17":["rn\/none"],"18":[],"19":["enhancement","area\/models","area\/tracking"],"20":["bug","area\/examples","area\/tracking"],"21":["rn\/bug-fix","area\/docker"],"22":["bug","area\/uiux"],"23":["bug","area\/tracking"],"24":["bug"],"25":["bug"],"26":["bug"],"27":["rn\/bug-fix","area\/tracking"],"28":["enhancement","area\/tracking","area\/sqlalchemy"],"29":["area\/tracking","area\/sqlalchemy"],"30":["enhancement","area\/models","area\/scoring","integrations\/azure"],"31":["bug","area\/tracking"],"32":["enhancement","good first issue","Acknowledged","area\/model-registry","area\/models","priority\/important-soon"],"33":["enhancement","area\/scoring"],"34":["bug","area\/scoring","priority\/important-soon"],"35":["bug"],"36":["bug"],"37":["enhancement","area\/uiux"],"38":["bug","area\/artifacts","area\/models","area\/tracking"],"39":["enhancement","area\/model-registry"],"40":["rn\/none","area\/tracking"],"41":["bug","area\/projects"],"42":["bug","area\/artifacts","area\/examples","area\/tracking"],"43":["rn\/feature","area\/artifacts","area\/model-registry","area\/models","area\/tracking","area\/sqlalchemy"],"44":["bug","area\/uiux","area\/model-registry"],"45":["rn\/breaking-change"],"46":["rn\/none"],"47":[],"48":["bug","area\/model-registry"],"49":["enhancement","area\/tracking"],"50":["bug","area\/model-registry"],"51":["bug"],"52":["bug","area\/tracking"],"53":["bug","area\/models"],"54":["enhancement","area\/models"],"55":["bug","area\/model-registry"],"56":["rn\/none","area\/tracking"],"57":[],"58":["enhancement","area\/artifacts"],"59":["dependencies","java"],"60":["enhancement","area\/uiux","area\/artifacts"],"61":["enhancement","area\/artifacts","area\/model-registry","area\/models"],"62":["bug"],"63":["bug","area\/model-registry"],"64":["enhancement"],"65":["enhancement","area\/projects"],"66":["enhancement","area\/models"],"67":[],"68":["bug"],"69":["enhancement","area\/docs","area\/sqlalchemy"],"70":["enhancement","area\/server-infra"],"71":["enhancement","area\/model-registry","area\/models"],"72":["bug","language\/r","area\/artifacts","integrations\/azure"],"73":["enhancement"],"74":["rn\/none","area\/examples"],"75":["bug","language\/r","area\/model-registry"],"76":["bug"],"77":["bug","area\/docs"],"78":["bug"],"79":["rn\/bug-fix","area\/projects"],"80":["bug","integrations\/azure"],"81":["enhancement","area\/docs","language\/r","area\/artifacts","area\/examples","area\/models"],"82":[],"83":["bug","area\/windows","help wanted","area\/artifacts","area\/models","area\/tracking","area\/docker"],"84":["enhancement","area\/docs","area\/examples","area\/tracking"],"85":["bug","Acknowledged","area\/model-registry"],"86":["enhancement","area\/models","area\/docker"],"87":["bug","area\/artifacts","area\/examples","area\/tracking"],"88":[],"89":[],"90":["rn\/bug-fix"],"91":["bug","area\/models"],"92":["bug","area\/tracking"],"93":["bug"],"94":["bug"],"95":[],"96":["enhancement","area\/models"],"97":[],"98":["bug"],"99":["bug","area\/models"],"100":["bug","area\/tracking","area\/sqlalchemy","area\/server-infra"],"101":["bug","area\/uiux"],"102":["enhancement","area\/server-infra"],"103":["bug","area\/artifacts","integrations\/databricks"],"104":["enhancement"],"105":["bug","area\/windows","area\/artifacts","area\/model-registry","area\/tracking","area\/sqlalchemy"],"106":["enhancement","area\/artifacts"],"107":[],"108":[],"109":["bug","area\/model-registry","area\/docker","integrations\/azure"],"110":["bug","area\/tracking","area\/sqlalchemy"],"111":["rn\/none"],"112":["bug"],"113":["enhancement","help wanted","area\/scoring"],"114":["bug","help wanted","area\/model-registry","area\/tracking"],"115":["bug"],"116":["enhancement","area\/tracking"],"117":["bug"],"118":["rn\/none","area\/artifacts","area\/sqlalchemy"],"119":["enhancement","area\/artifacts","area\/sqlalchemy"],"120":["enhancement","area\/tracking"],"121":[],"122":["bug"],"123":["bug","language\/r","area\/tracking"],"124":["rn\/none","area\/tracking"],"125":[],"126":["enhancement","area\/models"],"127":["bug"],"128":["enhancement"],"129":["rn\/feature","area\/tracking"],"130":["rn\/feature","area\/models"],"131":["bug"],"132":["bug","area\/examples"],"133":[],"134":["area\/docs"],"135":["bug"],"136":["bug","language\/r","area\/model-registry"],"137":["enhancement","area\/tracking"],"138":["bug"],"139":["bug","area\/artifacts","area\/models","area\/docker"],"140":["bug","area\/tracking"],"141":["rn\/none"],"142":["rn\/none","area\/projects"],"143":["bug"],"144":["bug"],"145":["area\/docs"],"146":["enhancement","area\/windows","language\/r","language\/java","area\/artifacts","area\/tracking","language\/new"],"147":["enhancement","area\/scoring"],"148":["bug","area\/uiux","area\/model-registry"],"149":["bug","area\/uiux","area\/artifacts","area\/models","integrations\/azure"],"150":["bug"],"151":["rn\/none","area\/tracking"],"152":["enhancement","area\/models"],"153":["bug"],"154":["bug","help wanted","area\/artifacts"],"155":["area\/docs"],"156":["enhancement","area\/uiux"],"157":["bug","area\/scoring"],"158":["area\/scoring"],"159":[],"160":["bug","Acknowledged","area\/models","priority\/important-soon"],"161":["area\/scoring","area\/docker"],"162":["bug","area\/uiux","help wanted","area\/projects","integrations\/databricks"],"163":["bug","area\/artifacts","area\/tracking"],"164":["enhancement","area\/uiux"],"165":["enhancement","area\/projects","priority\/awaiting-more-evidence","integrations\/databricks"],"166":["bug","area\/sqlalchemy","area\/build"],"167":["bug"],"168":["bug"],"169":[],"170":["bug","area\/uiux","area\/build"],"171":[],"172":["enhancement","area\/uiux"],"173":["bug"],"174":["bug","area\/windows","area\/artifacts","area\/docker"],"175":["enhancement","area\/models"],"176":["enhancement"],"177":["bug","area\/examples","area\/docker"],"178":["bug"],"179":["rn\/bug-fix","area\/artifacts","area\/scoring"],"180":["bug","area\/examples","area\/projects","area\/tracking"],"181":["enhancement","good first issue","area\/tracking"],"182":["bug","area\/docs","area\/build"],"183":["enhancement","area\/uiux","help wanted"],"184":["enhancement","area\/models","needs design"],"185":["bug","language\/r","area\/tracking"],"186":["bug"],"187":["bug","area\/tracking"],"188":["enhancement"],"189":["bug","area\/model-registry","area\/tracking"],"190":["enhancement","area\/uiux","area\/model-registry"],"191":["enhancement","area\/uiux","area\/model-registry"],"192":["enhancement"],"193":["enhancement","area\/tracking"],"194":["enhancement"],"195":["bug"],"196":["enhancement","integrations\/sagemaker"],"197":["area\/docs","rn\/feature","area\/artifacts","area\/models"],"198":["area\/docs"],"199":["enhancement"],"200":["bug","area\/models"],"201":["bug","area\/projects","priority\/important-longterm"],"202":["bug"],"203":["enhancement"],"204":["enhancement","area\/uiux","area\/tracking"],"205":["enhancement","area\/uiux","area\/tracking"],"206":["enhancement"],"207":[],"208":["bug"],"209":["enhancement"],"210":["enhancement"],"211":["enhancement","area\/projects"],"212":["rn\/none","area\/build"],"213":["enhancement","area\/server-infra"],"214":["enhancement","area\/uiux"],"215":["enhancement"],"216":["bug","area\/tracking"],"217":["bug"],"218":[],"219":["bug"],"220":["enhancement","area\/artifacts","area\/models"],"221":["bug","area\/uiux","Acknowledged","area\/artifacts","area\/tracking"],"222":["enhancement","area\/artifacts"],"223":["bug","Acknowledged","help wanted","area\/artifacts","area\/model-registry","area\/models"],"224":[],"225":["bug","area\/windows","area\/models","area\/scoring"],"226":["bug","area\/artifacts","area\/tracking"],"227":["enhancement","area\/artifacts"],"228":["area\/server-infra"],"229":["bug","area\/models"],"230":["bug","area\/artifacts"],"231":["area\/docs"],"232":["enhancement","area\/tracking","priority\/awaiting-more-evidence"],"233":["enhancement"],"234":["bug","area\/uiux"],"235":[],"236":["bug","area\/model-registry"],"237":[],"238":["area\/docs"],"239":["bug"],"240":[],"241":["bug","area\/build"],"242":["enhancement","area\/windows","area\/projects","area\/docker"],"243":["bug","area\/artifacts","area\/models","area\/scoring","area\/tracking","integrations\/sagemaker"],"244":["area\/projects","area\/docker"],"245":["enhancement"],"246":["enhancement","area\/uiux"],"247":["enhancement","area\/docs","area\/tracking","area\/server-infra"],"248":["enhancement"],"249":["enhancement","area\/uiux"],"250":["bug"],"251":["area\/docs"],"252":["enhancement","area\/uiux","area\/model-registry","area\/models"],"253":["enhancement","area\/tracking"],"254":[],"255":["enhancement"],"256":["enhancement","area\/uiux","area\/tracking"],"257":["bug","help wanted","area\/docker","integrations\/sagemaker"],"258":["rn\/none","area\/artifacts"],"259":["enhancement"],"260":["enhancement","area\/models"],"261":["rn\/none","area\/docker"],"262":["bug","area\/server-infra"],"263":["area\/docs"],"264":["bug","integrations\/sagemaker"],"265":["area\/windows","language\/r","rn\/none"],"266":["rn\/feature","area\/artifacts","area\/tracking","integrations\/azure"],"267":["enhancement"],"268":["area\/docs"],"269":["bug"],"270":["area\/docs"],"271":["area\/docs"],"272":["bug","area\/models"],"273":["bug"],"274":[],"275":["bug"],"276":["enhancement","area\/server-infra"],"277":["rn\/feature","area\/models","area\/docker"],"278":["enhancement"],"279":["bug"],"280":["enhancement","language\/r"],"281":["area\/docs"],"282":["enhancement","language\/java","area\/artifacts","integrations\/databricks"],"283":["bug","area\/tracking"],"284":["bug","area\/artifacts","area\/tracking","integrations\/azure","integrations\/databricks"],"285":[],"286":[],"287":["area\/artifacts","area\/models"],"288":["enhancement","area\/artifacts","area\/models"],"289":["enhancement","area\/uiux"],"290":["enhancement","area\/uiux","area\/model-registry","area\/scoring"],"291":["enhancement"],"292":["rn\/bug-fix","area\/artifacts"],"293":["bug"],"294":["bug"],"295":[],"296":[],"297":["bug","area\/build"],"298":["enhancement","area\/tracking"],"299":[],"300":["area\/docs","rn\/feature","rn\/documentation","area\/projects","area\/docker"],"301":["bug"],"302":["enhancement","area\/uiux","area\/model-registry"],"303":["enhancement","area\/uiux","area\/tracking"],"304":["enhancement"],"305":[],"306":[],"307":[],"308":[],"309":["enhancement","area\/scoring"],"310":["bug","area\/build"],"311":["bug","area\/tracking","area\/sqlalchemy"],"312":[],"313":["bug","area\/artifacts","area\/tracking"],"314":["bug","area\/examples","area\/models","area\/scoring"],"315":["bug","area\/windows"],"316":["enhancement","area\/projects","area\/docker"],"317":["bug","area\/uiux","area\/artifacts"],"318":["enhancement","area\/uiux","area\/model-registry"],"319":["bug"],"320":["bug","area\/scoring","area\/docker","integrations\/sagemaker"],"321":["rn\/feature","area\/examples","area\/projects","area\/docker"],"322":[],"323":["rn\/feature","help wanted","area\/models"],"324":["enhancement","area\/artifacts","area\/examples"],"325":["bug","needs author feedback"],"326":["rn\/feature","area\/tracking"],"327":["enhancement","help wanted","area\/tracking","area\/sqlalchemy"],"328":["rn\/feature","area\/models","area\/docker"],"329":["enhancement","area\/uiux","area\/tracking"],"330":["enhancement","area\/tracking"],"331":["enhancement","area\/uiux","area\/tracking"],"332":["enhancement","area\/docker"],"333":["enhancement","area\/model-registry"],"334":["enhancement","area\/uiux","area\/tracking"],"335":["enhancement","area\/build"],"336":["bug","area\/uiux","Acknowledged"],"337":["enhancement"],"338":["enhancement","area\/projects"],"339":["enhancement","area\/models"],"340":["bug","area\/tracking"],"341":["bug","area\/artifacts"],"342":["enhancement","area\/artifacts","integrations\/azure"],"343":["rn\/none"],"344":["enhancement","area\/docs","area\/uiux","help wanted"],"345":["bug","area\/sqlalchemy","area\/build"],"346":["needs author feedback"],"347":["enhancement","needs author feedback"],"348":["enhancement","area\/tracking"],"349":["bug","needs author feedback","area\/models","area\/tracking"],"350":["good first issue","area\/docs"],"351":["bug","area\/uiux","area\/model-registry"],"352":["good first issue","area\/docs"],"353":["bug","area\/tracking","area\/server-infra"],"354":["bug","area\/uiux","area\/artifacts"],"355":["enhancement","area\/models","area\/scoring"],"356":[],"357":["enhancement","area\/uiux"],"358":["enhancement","area\/artifacts"],"359":[],"360":["enhancement","area\/uiux","area\/tracking"],"361":["area\/projects"],"362":[],"363":["bug","needs author feedback","area\/projects"],"364":["enhancement"],"365":["area\/docs"],"366":["enhancement","area\/models","area\/scoring"],"367":["enhancement","good first issue","area\/artifacts","area\/models"],"368":["rn\/none"],"369":["bug","area\/examples","area\/models","area\/docker"],"370":["needs author feedback","area\/artifacts"],"371":["enhancement","area\/projects","area\/docker"],"372":["enhancement","area\/uiux","area\/tracking"],"373":["bug","area\/examples","area\/scoring","area\/docker"],"374":["bug"],"375":["bug","needs author feedback"],"376":["enhancement","area\/uiux"],"377":["enhancement","area\/uiux"],"378":["bug","area\/tracking"],"379":["enhancement","area\/uiux"],"380":["area\/docs"],"381":["enhancement","area\/uiux","area\/server-infra"],"382":["area\/docs"],"383":["enhancement","area\/models","area\/projects","area\/scoring","area\/docker"],"384":["enhancement","area\/artifacts","area\/models"],"385":["bug","area\/model-registry","area\/models"],"386":["rn\/none"],"387":["enhancement","area\/docs","area\/projects","area\/docker"],"388":["bug","area\/models"],"389":["bug","area\/tracking"],"390":["bug","area\/scoring","integrations\/azure"],"391":["enhancement","area\/model-registry","area\/tracking","integrations\/databricks"],"392":["enhancement","good first issue"],"393":["enhancement","area\/tracking"],"394":["bug","area\/artifacts","area\/model-registry","area\/sqlalchemy","area\/build"],"395":["enhancement","area\/uiux"],"396":["rn\/feature","area\/projects"],"397":["enhancement","area\/artifacts"],"398":["bug"],"399":["area\/docs","rn\/feature","area\/tracking"],"400":["bug"],"401":["rn\/feature","area\/model-registry","area\/sqlalchemy"],"402":["enhancement","area\/uiux"],"403":["bug","good first issue","area\/models","area\/tracking","priority\/important-soon"],"404":["bug","area\/examples","area\/models","area\/tracking"],"405":["bug","area\/tracking","area\/build"],"406":["rn\/none"],"407":["enhancement","area\/models","area\/scoring"],"408":["bug","area\/docs","Acknowledged","area\/model-registry","integrations\/azure"],"409":["bug","language\/r","area\/model-registry","area\/models","area\/docker","integrations\/sagemaker","area\/build"],"410":[],"411":["bug","area\/models","area\/tracking"],"412":["bug","area\/artifacts","area\/tracking"],"413":["bug"],"414":["enhancement","area\/artifacts","area\/tracking"],"415":[],"416":["bug","area\/artifacts","area\/model-registry"],"417":[],"418":["bug","area\/windows","area\/uiux","area\/model-registry","area\/docker","area\/sqlalchemy"],"419":["enhancement","area\/models"],"420":["bug","area\/models","area\/tracking"],"421":["bug","area\/model-registry"],"422":["language\/java","area\/tracking"],"423":["bug","area\/models","area\/scoring"],"424":["area\/docs"],"425":["rn\/feature","area\/artifacts"],"426":["area\/projects"],"427":["bug","area\/projects"],"428":["rn\/feature","rn\/bug-fix","area\/build"],"429":["bug","area\/examples","area\/build"],"430":["rn\/none"],"431":["enhancement","area\/tracking"],"432":["enhancement","area\/scoring"],"433":["bug","area\/projects","area\/docker"],"434":["bug","area\/projects"],"435":["enhancement","area\/docs","area\/projects","area\/docker"],"436":["rn\/none","language\/java","area\/model-registry"],"437":["enhancement"],"438":["enhancement","area\/artifacts","area\/tracking"],"439":["bug","area\/uiux","area\/artifacts","area\/model-registry"],"440":[],"441":["bug","area\/uiux","area\/examples","area\/scoring"],"442":["enhancement","area\/examples","area\/tracking"],"443":["rn\/feature","area\/tracking","area\/sqlalchemy"],"444":["bug","area\/uiux"],"445":["enhancement","area\/uiux","area\/model-registry","area\/tracking"],"446":["bug","area\/tracking"],"447":["enhancement","area\/tracking","area\/sqlalchemy"],"448":["bug","language\/r","area\/models"],"449":["bug"],"450":["bug","area\/tracking","area\/docker"],"451":["enhancement"],"452":["rn\/bug-fix","area\/models"],"453":["bug"],"454":[],"455":["bug","area\/models"],"456":["enhancement","area\/scoring"],"457":["area\/scoring"],"458":["enhancement","area\/uiux"],"459":["area\/models","area\/tracking"],"460":["area\/projects"],"461":["enhancement","area\/model-registry","area\/models"],"462":["enhancement","area\/projects","area\/docker"],"463":["enhancement","area\/uiux","area\/tracking"],"464":["enhancement","area\/tracking","area\/sqlalchemy"],"465":["bug","area\/uiux","language\/java","area\/model-registry","area\/tracking"],"466":["bug","integrations\/sagemaker"],"467":["enhancement"],"468":["bug","area\/model-registry","area\/models"],"469":["enhancement","language\/r"],"470":["enhancement","language\/r","area\/models","area\/docker"],"471":["bug","area\/models","area\/scoring"],"472":["enhancement","area\/tracking"],"473":[],"474":["area\/docs"],"475":["enhancement","area\/uiux"],"476":["bug","area\/windows"],"477":["language\/r","rn\/feature","area\/artifacts"],"478":["bug","help wanted","area\/tracking","area\/sqlalchemy"],"479":["enhancement","area\/docker","area\/build"],"480":["enhancement","area\/projects","integrations\/databricks"],"481":["area\/docs","needs author feedback","area\/model-registry"],"482":["enhancement","area\/uiux","area\/model-registry"],"483":["area\/windows","language\/r","rn\/bug-fix","area\/models","area\/tracking","area\/server-infra"],"484":["enhancement","area\/uiux"],"485":["enhancement","area\/uiux","area\/tracking"],"486":["bug"],"487":["bug"],"488":[],"489":["bug","area\/artifacts","integrations\/azure"],"490":["enhancement","area\/tracking"],"491":["enhancement","area\/projects"],"492":[],"493":["enhancement"],"494":["bug","area\/uiux","area\/model-registry"],"495":["enhancement","area\/tracking"],"496":["enhancement","area\/uiux","area\/docker"],"497":["bug"],"498":["area\/tracking"],"499":["rn\/none","area\/examples"],"500":["bug","area\/artifacts"],"501":["enhancement","area\/uiux","area\/tracking"],"502":["needs author feedback"],"503":["bug","area\/windows","area\/tracking"],"504":["enhancement","area\/tracking"],"505":["enhancement"],"506":["enhancement"],"507":["enhancement"],"508":["enhancement"],"509":["bug","area\/tracking"],"510":["enhancement"],"511":["enhancement"],"512":["enhancement","area\/docs","area\/model-registry"],"513":["bug","area\/models","area\/scoring"],"514":["bug","area\/models","area\/scoring"],"515":["bug"],"516":["bug","area\/tracking"],"517":["enhancement","area\/projects"],"518":["rn\/bug-fix","area\/artifacts"],"519":["rn\/none","area\/tracking"],"520":["enhancement","area\/tracking"],"521":["area\/windows"],"522":["bug","area\/tracking"],"523":[],"524":[],"525":["bug","area\/uiux"],"526":["enhancement","language\/r"],"527":["enhancement","area\/tracking"],"528":["enhancement","area\/docs","area\/artifacts","area\/model-registry","integrations\/azure"],"529":["enhancement"],"530":["bug","area\/uiux"],"531":["enhancement","area\/uiux","area\/model-registry","area\/tracking","priority\/important-longterm"],"532":["bug","area\/artifacts","area\/sqlalchemy"],"533":[],"534":["bug","area\/docker","integrations\/azure","area\/build"],"535":["bug"],"536":["rn\/feature","area\/examples","area\/projects"],"537":["enhancement","area\/model-registry","area\/models"],"538":["enhancement","area\/build"],"539":["enhancement","area\/models"],"540":["enhancement","area\/tracking"],"541":["bug","area\/uiux","area\/artifacts","area\/model-registry","area\/models","area\/tracking","area\/docker"],"542":["bug","area\/models"],"543":["rn\/none","area\/artifacts","integrations\/sagemaker"],"544":["enhancement"],"545":["enhancement","area\/artifacts"],"546":["area\/tracking"],"547":["enhancement","area\/docs","area\/scoring"],"548":["bug","area\/artifacts","area\/model-registry","area\/models","integrations\/databricks"],"549":["bug","area\/models"],"550":["area\/docs","area\/tracking"],"551":["bug","area\/projects","area\/tracking"],"552":["area\/docs"],"553":["area\/docs"],"554":["enhancement","area\/uiux","integrations\/databricks"],"555":["bug"],"556":["enhancement","area\/models","area\/tracking"],"557":["bug","area\/tracking"],"558":["bug"],"559":["bug","area\/tracking"],"560":[],"561":["area\/model-registry","area\/models"],"562":["bug","area\/uiux"],"563":["enhancement","area\/docs","area\/artifacts","area\/examples","area\/model-registry","area\/models","area\/tracking","area\/server-infra","language\/new"],"564":["area\/docs","rn\/feature","area\/artifacts","area\/model-registry","integrations\/azure"],"565":["enhancement","area\/docs","area\/artifacts","integrations\/azure"],"566":["bug","area\/build"],"567":["bug","area\/build"],"568":["bug","area\/build"],"569":["bug","language\/r","area\/artifacts","area\/server-infra"],"570":["area\/windows","area\/tracking"],"571":["bug","area\/tracking"],"572":["rn\/feature","area\/artifacts","area\/model-registry","area\/tracking","area\/server-infra"],"573":["enhancement","area\/docs","area\/artifacts","area\/examples"],"574":["bug","area\/docs","area\/tracking"],"575":["area\/docs","rn\/none"],"576":["area\/docs"],"577":[],"578":["bug","integrations\/azure"],"579":["bug","area\/tracking"],"580":["bug","area\/docs","area\/examples","area\/projects"],"581":["bug","area\/models","area\/tracking"],"582":["enhancement","area\/uiux","area\/artifacts"],"583":["enhancement","area\/tracking"],"584":["bug","area\/windows","area\/projects"],"585":["bug","area\/tracking","priority\/important-soon"],"586":["enhancement","area\/artifacts","area\/model-registry","area\/models","priority\/important-longterm"],"587":["enhancement","area\/uiux"],"588":["enhancement","area\/models"],"589":["enhancement","area\/docs","language\/r","area\/examples","area\/models","area\/tracking"],"590":["enhancement","area\/tracking"],"591":["bug","area\/models"],"592":["bug","area\/scoring","priority\/important-soon"],"593":["bug","area\/projects","area\/docker"],"594":["bug","area\/tracking"],"595":["area\/docs"],"596":["bug","area\/windows","language\/r","area\/examples"],"597":["enhancement","area\/models","area\/tracking"],"598":["enhancement","area\/tracking"],"599":[],"600":["bug","area\/uiux","priority\/important-soon"],"601":["bug","area\/uiux","area\/projects"],"602":["bug","area\/projects","area\/docker"],"603":["rn\/bug-fix","area\/uiux"],"604":["area\/uiux"],"605":["rn\/feature","area\/projects"],"606":["bug","area\/tracking","area\/sqlalchemy"],"607":["bug","area\/models","area\/tracking"],"608":["bug","area\/models"],"609":["bug","area\/sqlalchemy"],"610":["bug","area\/scoring"],"611":["rn\/feature","integrations\/sagemaker"],"612":["enhancement","integrations\/sagemaker"],"613":["bug","area\/tracking"],"614":["bug","area\/windows","area\/models"],"615":["rn\/feature","area\/model-registry","area\/sqlalchemy"],"616":["bug","area\/windows","language\/r"],"617":["bug","area\/models","area\/scoring"],"618":["enhancement","area\/tracking"],"619":["enhancement"],"620":["enhancement","area\/tracking","area\/sqlalchemy"],"621":["rn\/bug-fix","area\/models"],"622":["enhancement","area\/models","area\/scoring"],"623":["enhancement","area\/model-registry"],"624":["enhancement","area\/projects"],"625":["enhancement","area\/docs","area\/uiux","area\/tracking"],"626":["rn\/feature","area\/model-registry","area\/sqlalchemy"],"627":["bug","area\/uiux","area\/tracking","priority\/important-soon"],"628":["rn\/none","area\/uiux"],"629":["enhancement","area\/uiux","help wanted","area\/tracking"],"630":["bug"],"631":["enhancement","area\/models","area\/docker"],"632":["enhancement","area\/models","area\/docker"],"633":["area\/docs"],"634":[],"635":["bug","area\/sqlalchemy"],"636":["rn\/feature","area\/tracking"],"637":["bug","area\/models","area\/scoring","priority\/important-soon"],"638":["enhancement","area\/models"],"639":["area\/docs","area\/artifacts","priority\/important-longterm"],"640":["enhancement","area\/uiux","area\/tracking","priority\/awaiting-more-evidence"],"641":["enhancement","area\/models","integrations\/pytorch"],"642":["bug","area\/models"],"643":["bug","area\/models"],"644":["enhancement","area\/uiux","needs author feedback","area\/tracking"],"645":["rn\/feature","area\/projects"],"646":["enhancement","area\/docker"],"647":["bug","language\/r","area\/build"],"648":["enhancement","area\/tracking"],"649":["rn\/feature","area\/tracking"],"650":["bug","area\/models","priority\/important-soon"],"651":["area\/docs","area\/tracking","priority\/important-soon"],"652":["enhancement","area\/windows","area\/models","priority\/important-soon"],"653":["rn\/bug-fix"],"654":["enhancement","help wanted","area\/model-registry","area\/tracking","needs design"],"655":["enhancement","area\/model-registry","area\/tracking"],"656":["enhancement","area\/models","area\/scoring","priority\/important-soon","integrations\/pytorch"],"657":["bug","area\/artifacts","area\/models"],"658":["bug","area\/docker"],"659":["rn\/feature","area\/model-registry"],"660":["enhancement","area\/tracking"],"661":["rn\/bug-fix","area\/model-registry"],"662":["enhancement","help wanted","priority\/important-longterm","area\/build"],"663":["bug","area\/docs","area\/examples","area\/models","priority\/important-soon"],"664":["enhancement","area\/models","priority\/important-soon"],"665":["enhancement","area\/tracking"],"666":["enhancement","area\/uiux","area\/tracking","priority\/important-longterm"],"667":["bug","area\/tracking"],"668":["enhancement","language\/r","area\/models","priority\/important-longterm"],"669":["enhancement","area\/projects","priority\/important-longterm"],"670":["area\/docs","needs author feedback"],"671":["bug","language\/r","area\/tracking","needs committer feedback"],"672":["enhancement","area\/models","area\/docker","priority\/backlog"],"673":["bug","language\/r","area\/artifacts","priority\/awaiting-more-evidence"],"674":["enhancement","area\/models","area\/scoring","priority\/important-soon","integrations\/pytorch"],"675":["bug","area\/examples","area\/projects","area\/docker","priority\/important-soon"],"676":["rn\/none","area\/tracking"],"677":["enhancement","area\/uiux","priority\/backlog"],"678":["enhancement","area\/uiux","priority\/important-soon"],"679":["enhancement","area\/projects","area\/tracking","priority\/backlog"],"680":["bug","area\/tracking","priority\/important-soon"],"681":["bug","area\/models","priority\/important-soon"],"682":["area\/sqlalchemy"],"683":["enhancement","area\/projects"],"684":["enhancement","area\/uiux","help wanted","priority\/important-longterm"],"685":["enhancement","help wanted","area\/model-registry","area\/tracking","priority\/important-longterm"],"686":["bug","integrations\/sagemaker"],"687":["enhancement","area\/tracking","priority\/important-longterm"],"688":["enhancement","area\/sqlalchemy","priority\/important-soon"],"689":["enhancement","area\/models","priority\/important-soon"],"690":["area\/docs","rn\/feature","area\/projects","area\/docker"],"691":["bug","language\/r","area\/examples","area\/projects","area\/tracking","area\/sqlalchemy","priority\/awaiting-more-evidence"],"692":[],"693":["bug","area\/windows","area\/tracking","priority\/important-longterm"],"694":["enhancement","area\/models","area\/projects","priority\/awaiting-more-evidence"],"695":["bug","area\/models","priority\/important-longterm"],"696":["enhancement","area\/uiux","priority\/important-soon"],"697":["enhancement","area\/tracking","priority\/backlog"],"698":["enhancement","area\/tracking"],"699":["enhancement","area\/uiux","area\/projects","priority\/backlog"],"700":[],"701":["bug","area\/uiux","priority\/important-soon"],"702":["enhancement","area\/docs","help wanted","area\/model-registry","area\/tracking","priority\/important-longterm"],"703":["bug","area\/tracking","priority\/important-longterm"],"704":["enhancement","area\/artifacts","area\/tracking","priority\/awaiting-more-evidence"],"705":["rn\/none","area\/projects","needs review"],"706":["bug","area\/scoring","area\/docker","integrations\/sagemaker","priority\/important-soon"],"707":["enhancement","good first issue","help wanted","area\/tracking","priority\/important-longterm"],"708":["enhancement","area\/models","area\/scoring","priority\/important-longterm","integrations\/pytorch"],"709":["enhancement","area\/tracking","priority\/backlog"],"710":["enhancement","area\/models","priority\/important-longterm"],"711":["enhancement","area\/tracking","priority\/important-longterm"],"712":["area\/tracking","priority\/awaiting-more-evidence"],"713":["enhancement","area\/uiux","area\/artifacts","area\/tracking","priority\/awaiting-more-evidence"],"714":["enhancement","area\/tracking","area\/sqlalchemy","priority\/awaiting-more-evidence","needs design"],"715":["area\/windows","area\/docs","help wanted"],"716":["bug","area\/docs","area\/artifacts","area\/examples","area\/docker","priority\/important-longterm"],"717":["rn\/feature","area\/models"],"718":["enhancement","area\/docs","help wanted","area\/projects","priority\/important-soon","needs design"],"719":["enhancement","help wanted","area\/models","area\/tracking","priority\/important-longterm"],"720":["enhancement","help wanted","area\/projects","priority\/backlog"],"721":["bug","help wanted","area\/examples","area\/projects","area\/docker","priority\/important-longterm"],"722":["enhancement","help wanted","area\/examples","area\/projects","area\/docker","priority\/important-longterm","needs design"],"723":["rn\/feature","area\/scoring"],"724":["area\/model-registry","area\/scoring"],"725":["bug","area\/artifacts","priority\/awaiting-more-evidence"],"726":["enhancement","area\/uiux","area\/tracking","priority\/backlog"],"727":["area\/docs","area\/artifacts","area\/models","priority\/important-soon"],"728":["enhancement","area\/uiux","area\/tracking","priority\/important-longterm"],"729":["area\/docs","area\/artifacts","area\/tracking","priority\/important-soon"],"730":["bug","area\/docs","area\/models","area\/scoring","area\/tracking","priority\/important-longterm"],"731":["enhancement","area\/scoring","priority\/awaiting-more-evidence"],"732":["area\/projects","needs review"],"733":["area\/projects"],"734":["bug","area\/projects","priority\/important-longterm"],"735":["enhancement","area\/docs","help wanted","area\/model-registry","area\/tracking","priority\/important-longterm","needs design"],"736":["needs author feedback","area\/projects"],"737":["bug","area\/tracking","priority\/important-longterm"],"738":["bug","Acknowledged","area\/artifacts","area\/tracking","priority\/important-soon"],"739":["enhancement","needs author feedback","area\/artifacts","area\/models","area\/scoring","area\/tracking","integrations\/sagemaker","priority\/backlog"],"740":["area\/tracking","priority\/backlog"],"741":["bug","good first issue","area\/docs","Acknowledged","help wanted","area\/projects","area\/tracking","priority\/important-soon"],"742":["needs author feedback","area\/tracking"],"743":["area\/docs","needs author feedback","area\/tracking"],"744":["bug","Acknowledged","area\/artifacts","area\/docker","priority\/important-soon"],"745":["area\/artifacts","priority\/important-soon"],"746":["bug","area\/windows","help wanted","area\/models","priority\/important-longterm"],"747":["bug","area\/models","area\/scoring","priority\/awaiting-more-evidence"],"748":["enhancement","area\/models","priority\/important-soon"],"749":["enhancement","area\/uiux","help wanted","area\/tracking","priority\/important-longterm"],"750":["area\/uiux","dependencies","needs review"],"751":["area\/artifacts"],"752":["enhancement","area\/uiux","Acknowledged","area\/tracking","priority\/important-longterm"],"753":["enhancement","area\/uiux","Acknowledged","priority\/important-soon"],"754":["enhancement","Acknowledged","help wanted","area\/scoring","priority\/backlog"],"755":["enhancement","Acknowledged","integrations\/sagemaker"],"756":["bug","area\/projects","priority\/important-soon"],"757":["enhancement","area\/tracking","priority\/important-longterm"],"758":["bug","area\/tracking"],"759":["enhancement","area\/uiux","Acknowledged","help wanted","priority\/important-soon"],"760":["enhancement","area\/uiux","help wanted","area\/tracking","priority\/backlog"],"761":["bug","area\/uiux","priority\/important-longterm"],"762":["enhancement","area\/docs","help wanted"],"763":["enhancement","area\/artifacts","priority\/important-longterm","needs committer feedback"],"764":["area\/docs","needs author feedback","priority\/important-longterm"],"765":["bug","area\/windows","priority\/backlog","area\/build"],"766":["bug","area\/projects","area\/tracking","priority\/important-soon"],"767":["enhancement","area\/uiux","Acknowledged","help wanted","area\/tracking","priority\/important-longterm","needs design"],"768":["bug","Acknowledged","help wanted","area\/tracking","priority\/important-soon"],"769":[],"770":["enhancement","area\/tracking","priority\/backlog"],"771":["bug","good first issue","area\/artifacts","priority\/important-soon"],"772":["enhancement","area\/artifacts","priority\/awaiting-more-evidence"],"773":["bug","area\/artifacts","area\/tracking","priority\/important-soon"],"774":["bug","Acknowledged","area\/examples","area\/projects","priority\/awaiting-more-evidence"],"775":["enhancement","Acknowledged","area\/models","area\/tracking","priority\/awaiting-more-evidence"],"776":["enhancement","area\/uiux","help wanted","area\/tracking","priority\/important-longterm"],"777":["enhancement","area\/tracking","priority\/important-longterm","needs review"],"778":["enhancement","help wanted","area\/tracking","priority\/backlog"],"779":["enhancement","area\/uiux","Acknowledged","area\/model-registry","priority\/important-soon"],"780":["language\/java","Acknowledged","help wanted","area\/tracking"],"781":["bug","Acknowledged","area\/tracking","priority\/important-longterm"],"782":["enhancement","dependencies","Acknowledged","help wanted","area\/models","area\/scoring","area\/docker","priority\/awaiting-more-evidence"],"783":["bug","area\/models","area\/docker","priority\/awaiting-more-evidence"],"784":["enhancement","area\/uiux","help wanted","priority\/important-soon"],"785":["enhancement","Acknowledged","area\/projects","area\/docker","priority\/awaiting-more-evidence"],"786":["rn\/bug-fix","area\/uiux","area\/tracking"],"787":["area\/artifacts","priority\/awaiting-more-evidence"],"788":["bug","help wanted","integrations\/sagemaker"],"789":["enhancement","help wanted","priority\/important-longterm","area\/build"],"790":["rn\/bug-fix"],"791":["enhancement","area\/models","priority\/backlog"],"792":["bug","Acknowledged","area\/models","priority\/important-longterm"],"793":["bug","area\/tracking","priority\/important-soon"],"794":["bug","area\/docs","area\/tracking","priority\/backlog"],"795":[],"796":["bug","area\/uiux","priority\/important-soon"],"797":["enhancement","good first issue","help wanted","area\/tracking","priority\/important-longterm"],"798":["enhancement","area\/artifacts","priority\/important-longterm"],"799":["bug","area\/windows","area\/docker","priority\/important-soon"],"800":["bug","integrations\/sagemaker"],"801":["rn\/feature"],"802":["bug","integrations\/sagemaker"],"803":["bug","area\/uiux","area\/tracking","priority\/important-longterm"],"804":["enhancement","Acknowledged","area\/models","priority\/awaiting-more-evidence"],"805":["enhancement","area\/tracking","priority\/important-soon"],"806":["enhancement","area\/artifacts","priority\/important-longterm"],"807":["bug","area\/projects","priority\/important-longterm"],"808":[],"809":["enhancement","area\/uiux","Acknowledged","area\/tracking","priority\/important-longterm"],"810":["rn\/feature"],"811":["bug","area\/tracking","priority\/important-longterm"],"812":["enhancement","area\/tracking","priority\/awaiting-more-evidence"],"813":["bug","area\/sqlalchemy","priority\/important-soon"],"814":["bug","area\/models","priority\/important-soon"],"815":["enhancement","area\/uiux","priority\/important-longterm"],"816":["enhancement","area\/tracking","priority\/awaiting-more-evidence"],"817":[],"818":["enhancement","Acknowledged","area\/scoring","area\/docker","priority\/important-soon"],"819":["enhancement","area\/tracking","priority\/important-longterm"],"820":["enhancement","area\/projects","priority\/backlog"],"821":["enhancement","area\/tracking","priority\/awaiting-more-evidence"],"822":["enhancement","area\/uiux","area\/tracking","priority\/important-longterm"],"823":["enhancement","area\/uiux","area\/tracking","priority\/important-soon"],"824":["rn\/bug-fix"],"825":["bug","area\/models","priority\/important-soon"],"826":["bug","area\/models","integrations\/sagemaker","priority\/important-soon"],"827":["enhancement","language\/java","area\/models","priority\/awaiting-more-evidence"],"828":["enhancement","help wanted","area\/model-registry","area\/tracking","area\/sqlalchemy","priority\/important-longterm","needs design"],"829":["bug","area\/tracking","priority\/awaiting-more-evidence"],"830":["enhancement","area\/uiux","priority\/awaiting-more-evidence"],"831":["enhancement","area\/scoring","priority\/backlog"],"832":[],"833":["enhancement","area\/models","priority\/backlog"],"834":["bug","help wanted","area\/sqlalchemy","priority\/important-soon"],"835":["enhancement","area\/uiux","priority\/important-soon"],"836":["bug","area\/models","priority\/important-longterm"],"837":["bug","area\/artifacts","priority\/important-soon"],"838":["enhancement","good first issue","area\/windows"],"839":["rn\/feature","area\/uiux"],"840":["enhancement","area\/tracking","priority\/important-longterm"],"841":["enhancement","help wanted","priority\/backlog","needs design","area\/build"],"842":["bug","area\/windows","area\/projects","priority\/important-longterm"],"843":["enhancement","area\/projects","area\/scoring","priority\/backlog"],"844":["enhancement","area\/uiux","area\/tracking","priority\/important-soon"],"845":[],"846":["enhancement","area\/projects","priority\/awaiting-more-evidence"],"847":["enhancement","Acknowledged","area\/models","priority\/important-soon"],"848":["enhancement","area\/tracking","priority\/backlog"],"849":["bug","area\/scoring","priority\/important-soon"],"850":["area\/docs","priority\/important-longterm"],"851":["bug","area\/tracking","priority\/awaiting-more-evidence"],"852":[],"853":["bug","needs author feedback","area\/tracking","priority\/awaiting-more-evidence"],"854":[],"855":["enhancement","area\/projects","priority\/backlog"],"856":[],"857":[],"858":["bug","help wanted","area\/model-registry","priority\/backlog"],"859":["enhancement","area\/docker","priority\/awaiting-more-evidence"],"860":["area\/docker","needs committer feedback"],"861":[],"862":["enhancement","area\/uiux","area\/tracking","priority\/important-soon"],"863":["enhancement","area\/uiux","area\/tracking","priority\/backlog"],"864":["bug","stale","area\/scoring","area\/tracking","priority\/backlog"],"865":["bug","area\/uiux","area\/artifacts","priority\/important-soon"],"866":[],"867":["enhancement","area\/model-registry","priority\/important-longterm"],"868":[],"869":["area\/docs","rn\/feature","area\/projects","area\/docker"],"870":["bug","area\/uiux","area\/tracking","priority\/backlog"],"871":["bug","help wanted","area\/projects","area\/docker","priority\/important-longterm"],"872":["enhancement","area\/artifacts","area\/tracking","priority\/backlog"],"873":["bug","area\/models","priority\/awaiting-more-evidence"],"874":["bug","area\/artifacts","area\/tracking","priority\/awaiting-more-evidence"],"875":["bug","stale","area\/models","priority\/important-soon"],"876":["enhancement","area\/tracking","priority\/backlog"],"877":["bug","area\/uiux","stale","priority\/important-longterm"],"878":["enhancement","area\/uiux","needs author feedback"],"879":[],"880":["bug","stale","area\/tracking","priority\/awaiting-more-evidence"],"881":["area\/docs","stale","help wanted","area\/tracking"],"882":["enhancement","area\/tracking","priority\/awaiting-more-evidence"],"883":["bug","help wanted","area\/tracking"],"884":["enhancement","area\/uiux","area\/tracking","priority\/backlog","needs design"],"885":["bug","area\/docker","priority\/important-longterm"],"886":["enhancement","area\/tracking","priority\/backlog"],"887":["enhancement","area\/artifacts","priority\/backlog"],"888":["enhancement","area\/uiux","priority\/important-longterm"],"889":["enhancement","area\/artifacts","area\/tracking","priority\/awaiting-more-evidence"],"890":["stale","area\/artifacts","area\/tracking","priority\/awaiting-more-evidence"],"891":["bug","stale","area\/tracking"],"892":["enhancement","good first issue","area\/uiux","help wanted","priority\/important-longterm"],"893":["enhancement","help wanted","area\/tracking","priority\/awaiting-more-evidence"],"894":["bug","help wanted","area\/projects","priority\/backlog"],"895":["bug","area\/models"],"896":["enhancement","area\/tracking","priority\/awaiting-more-evidence"],"897":["enhancement","area\/uiux","area\/tracking","priority\/important-longterm"],"898":["bug","area\/uiux","stale","priority\/important-soon"],"899":["enhancement","area\/tracking","priority\/backlog"],"900":["bug","area\/models","area\/tracking","priority\/important-soon"],"901":["enhancement","area\/docker","priority\/important-soon"],"902":["enhancement","area\/models","area\/tracking","priority\/backlog"],"903":["bug","area\/windows"],"904":["enhancement","good first issue","area\/projects","priority\/important-soon"],"905":["enhancement","Acknowledged","help wanted","area\/projects","priority\/important-longterm"],"906":["enhancement","area\/models","priority\/important-longterm"],"907":["good first issue","area\/models","area\/tracking","priority\/important-longterm"],"908":["enhancement","area\/scoring","priority\/backlog"],"909":["enhancement","area\/tracking"],"910":["bug","area\/docker","priority\/important-soon"],"911":["enhancement","area\/tracking","priority\/backlog"],"912":["enhancement","area\/models","priority\/backlog"],"913":[],"914":["enhancement","area\/uiux","area\/tracking","priority\/important-longterm"],"915":[],"916":["bug","good first issue","help wanted","area\/tracking","priority\/backlog"],"917":["enhancement","area\/tracking","priority\/awaiting-more-evidence"],"918":["enhancement","Acknowledged","area\/tracking","priority\/important-longterm"],"919":[],"920":["enhancement","area\/uiux","Acknowledged","priority\/important-longterm"],"921":["bug","stale","area\/examples","area\/projects","priority\/important-longterm"],"922":["enhancement","area\/artifacts","priority\/important-longterm"],"923":["enhancement","area\/uiux","priority\/important-longterm"],"924":[],"925":["enhancement","area\/uiux","help wanted","priority\/important-longterm"],"926":["enhancement","area\/uiux","priority\/awaiting-more-evidence"],"927":["area\/tracking","priority\/backlog"],"928":["bug","stale","area\/artifacts","priority\/important-soon"],"929":[],"930":["enhancement","stale","area\/tracking","priority\/important-longterm"],"931":["enhancement","area\/tracking","priority\/important-longterm"],"932":[],"933":["enhancement","area\/uiux","Acknowledged","area\/tracking","priority\/backlog"],"934":["enhancement","help wanted","area\/tracking","priority\/backlog"],"935":["enhancement","area\/models","priority\/important-soon"],"936":["enhancement","area\/model-registry","area\/scoring","priority\/important-longterm"],"937":["bug","stale","area\/projects","priority\/backlog"],"938":["enhancement","help wanted","priority\/important-soon","area\/build"],"939":["enhancement","area\/uiux","priority\/awaiting-more-evidence"],"940":[],"941":["enhancement","area\/tracking","priority\/awaiting-more-evidence"],"942":["enhancement","area\/tracking","priority\/backlog"],"943":["enhancement","area\/artifacts","priority\/awaiting-more-evidence"],"944":["enhancement","area\/uiux","help wanted","area\/tracking","priority\/backlog"],"945":["enhancement","area\/projects","priority\/backlog"],"946":["enhancement","area\/tracking","priority\/important-longterm"],"947":["enhancement","area\/projects","priority\/backlog"],"948":["bug","area\/windows","Acknowledged","area\/projects","priority\/important-soon"],"949":["enhancement","area\/artifacts","priority\/important-longterm"],"950":["enhancement","area\/scoring","priority\/backlog"],"951":["enhancement","priority\/important-longterm","area\/build"],"952":["enhancement","area\/uiux","priority\/important-soon"],"953":[],"954":["enhancement","Acknowledged","area\/projects","priority\/important-longterm"],"955":[],"956":["enhancement","area\/artifacts","priority\/important-longterm"],"957":["enhancement","area\/artifacts","area\/tracking","priority\/important-longterm"],"958":["enhancement","rn\/breaking-change","area\/tracking","priority\/backlog","needs design"],"959":["priority\/backlog","area\/build"],"960":["enhancement","area\/sqlalchemy","priority\/awaiting-more-evidence"],"961":["enhancement","help wanted","area\/scoring","priority\/important-longterm","needs design"],"962":["enhancement","Acknowledged","area\/tracking","priority\/important-longterm"],"963":["enhancement","area\/tracking","priority\/awaiting-more-evidence"],"964":["enhancement","area\/uiux","area\/tracking","priority\/important-longterm"],"965":["enhancement","area\/uiux","Acknowledged","area\/tracking","priority\/important-longterm"],"966":[],"967":[],"968":["LGTM"],"969":["area\/docs","priority\/important-soon"],"970":["enhancement","area\/uiux","Acknowledged","priority\/important-longterm"],"971":[],"972":["enhancement","area\/tracking","priority\/awaiting-more-evidence"],"973":["enhancement","language\/java","area\/tracking","priority\/awaiting-more-evidence"],"974":[],"975":["area\/uiux","area\/tracking","priority\/important-longterm"],"976":["bug","language\/r","Acknowledged"],"977":[],"978":["area\/uiux","priority\/important-soon"],"979":[],"980":["enhancement","Acknowledged","area\/tracking"],"981":["enhancement","area\/scoring","priority\/important-longterm"],"982":["enhancement","area\/uiux","area\/tracking","priority\/important-longterm"],"983":["enhancement","area\/uiux","Acknowledged","priority\/important-longterm"],"984":["enhancement","area\/uiux","Acknowledged","priority\/important-longterm"],"985":["enhancement","priority\/important-longterm","area\/build"],"986":["enhancement","area\/uiux","area\/tracking","priority\/important-longterm"],"987":["enhancement","area\/tracking","priority\/important-longterm"],"988":["enhancement","area\/tracking","priority\/awaiting-more-evidence"],"989":["enhancement","area\/uiux","Acknowledged","priority\/backlog"],"990":["enhancement","needs author feedback","integrations\/sagemaker"],"991":[],"992":["enhancement","area\/uiux","Acknowledged","priority\/important-longterm"],"993":["enhancement","language\/r","area\/models","priority\/backlog"],"994":["enhancement","good first issue","Acknowledged","area\/projects","priority\/backlog","integrations\/databricks"],"995":["enhancement","priority\/backlog","area\/build"],"996":["enhancement","area\/tracking","priority\/backlog"],"997":["enhancement","area\/tracking","priority\/backlog"],"998":["enhancement","area\/uiux","Acknowledged","help wanted","area\/tracking","priority\/awaiting-more-evidence"],"999":["enhancement","area\/uiux","Acknowledged","area\/tracking","priority\/backlog"]},"labels_description":{"0":["List under Small Changes in Changelogs.","Tracking service, tracking client APIs, autologging"],"1":[],"2":["Mention under Bug Fixes in Changelogs."],"3":["Something isn't working"],"4":["Mention under Bug Fixes in Changelogs.","Artifact stores and artifact logging"],"5":[],"6":[],"7":["List under Small Changes in Changelogs.","MLmodel format, model serialization\/deserialization, flavors"],"8":["New feature or request"],"9":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors"],"10":["Mention under Features in Changelogs.","Tracking service, tracking client APIs, autologging"],"11":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging"],"12":[],"13":[],"14":[],"15":["New feature or request","Tracking service, tracking client APIs, autologging"],"16":["New feature or request","Documentation issues","MLflow Model server, model deployment tools, Spark UDFs"],"17":["List under Small Changes in Changelogs."],"18":[],"19":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","Tracking service, tracking client APIs, autologging"],"20":["Something isn't working","Example code","Tracking service, tracking client APIs, autologging"],"21":["Mention under Bug Fixes in Changelogs.","Docker use anywhere, such as MLprojects and MLmodels"],"22":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"23":["Something isn't working","Tracking service, tracking client APIs, autologging"],"24":["Something isn't working"],"25":["Something isn't working"],"26":["Something isn't working"],"27":["Mention under Bug Fixes in Changelogs.","Tracking service, tracking client APIs, autologging"],"28":["New feature or request","Tracking service, tracking client APIs, autologging","Use of SQL alchemy in tracking service or model registry"],"29":["Tracking service, tracking client APIs, autologging","Use of SQL alchemy in tracking service or model registry"],"30":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","MLflow Model server, model deployment tools, Spark UDFs","Azure and Azure ML integrations"],"31":["Something isn't working","Tracking service, tracking client APIs, autologging"],"32":["New feature or request","Good for newcomers","This issue has been read and acknowledged by the MLflow admins.","Model registry, model registry APIs, and the fluent client calls for model registry","MLmodel format, model serialization\/deserialization, flavors","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"33":["New feature or request","MLflow Model server, model deployment tools, Spark UDFs"],"34":["Something isn't working","MLflow Model server, model deployment tools, Spark UDFs","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"35":["Something isn't working"],"36":["Something isn't working"],"37":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"38":["Something isn't working","Artifact stores and artifact logging","MLmodel format, model serialization\/deserialization, flavors","Tracking service, tracking client APIs, autologging"],"39":["New feature or request","Model registry, model registry APIs, and the fluent client calls for model registry"],"40":["List under Small Changes in Changelogs.","Tracking service, tracking client APIs, autologging"],"41":["Something isn't working","MLproject format, project running backends"],"42":["Something isn't working","Artifact stores and artifact logging","Example code","Tracking service, tracking client APIs, autologging"],"43":["Mention under Features in Changelogs.","Artifact stores and artifact logging","Model registry, model registry APIs, and the fluent client calls for model registry","MLmodel format, model serialization\/deserialization, flavors","Tracking service, tracking client APIs, autologging","Use of SQL alchemy in tracking service or model registry"],"44":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Model registry, model registry APIs, and the fluent client calls for model registry"],"45":["Mention under Breaking Changes in Changelogs."],"46":["List under Small Changes in Changelogs."],"47":[],"48":["Something isn't working","Model registry, model registry APIs, and the fluent client calls for model registry"],"49":["New feature or request","Tracking service, tracking client APIs, autologging"],"50":["Something isn't working","Model registry, model registry APIs, and the fluent client calls for model registry"],"51":["Something isn't working"],"52":["Something isn't working","Tracking service, tracking client APIs, autologging"],"53":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors"],"54":["New feature or request","MLmodel format, model serialization\/deserialization, flavors"],"55":["Something isn't working","Model registry, model registry APIs, and the fluent client calls for model registry"],"56":["List under Small Changes in Changelogs.","Tracking service, tracking client APIs, autologging"],"57":[],"58":["New feature or request","Artifact stores and artifact logging"],"59":["Pull requests that update a dependency file","Pull requests that update Java code"],"60":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Artifact stores and artifact logging"],"61":["New feature or request","Artifact stores and artifact logging","Model registry, model registry APIs, and the fluent client calls for model registry","MLmodel format, model serialization\/deserialization, flavors"],"62":["Something isn't working"],"63":["Something isn't working","Model registry, model registry APIs, and the fluent client calls for model registry"],"64":["New feature or request"],"65":["New feature or request","MLproject format, project running backends"],"66":["New feature or request","MLmodel format, model serialization\/deserialization, flavors"],"67":[],"68":["Something isn't working"],"69":["New feature or request","Documentation issues","Use of SQL alchemy in tracking service or model registry"],"70":["New feature or request","MLflow Tracking server backend"],"71":["New feature or request","Model registry, model registry APIs, and the fluent client calls for model registry","MLmodel format, model serialization\/deserialization, flavors"],"72":["Something isn't working","R APIs and clients","Artifact stores and artifact logging","Azure and Azure ML integrations"],"73":["New feature or request"],"74":["List under Small Changes in Changelogs.","Example code"],"75":["Something isn't working","R APIs and clients","Model registry, model registry APIs, and the fluent client calls for model registry"],"76":["Something isn't working"],"77":["Something isn't working","Documentation issues"],"78":["Something isn't working"],"79":["Mention under Bug Fixes in Changelogs.","MLproject format, project running backends"],"80":["Something isn't working","Azure and Azure ML integrations"],"81":["New feature or request","Documentation issues","R APIs and clients","Artifact stores and artifact logging","Example code","MLmodel format, model serialization\/deserialization, flavors"],"82":[],"83":["Something isn't working","Issue is unique to windows.","We would like help from the community to add this support","Artifact stores and artifact logging","MLmodel format, model serialization\/deserialization, flavors","Tracking service, tracking client APIs, autologging","Docker use anywhere, such as MLprojects and MLmodels"],"84":["New feature or request","Documentation issues","Example code","Tracking service, tracking client APIs, autologging"],"85":["Something isn't working","This issue has been read and acknowledged by the MLflow admins.","Model registry, model registry APIs, and the fluent client calls for model registry"],"86":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","Docker use anywhere, such as MLprojects and MLmodels"],"87":["Something isn't working","Artifact stores and artifact logging","Example code","Tracking service, tracking client APIs, autologging"],"88":[],"89":[],"90":["Mention under Bug Fixes in Changelogs."],"91":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors"],"92":["Something isn't working","Tracking service, tracking client APIs, autologging"],"93":["Something isn't working"],"94":["Something isn't working"],"95":[],"96":["New feature or request","MLmodel format, model serialization\/deserialization, flavors"],"97":[],"98":["Something isn't working"],"99":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors"],"100":["Something isn't working","Tracking service, tracking client APIs, autologging","Use of SQL alchemy in tracking service or model registry","MLflow Tracking server backend"],"101":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"102":["New feature or request","MLflow Tracking server backend"],"103":["Something isn't working","Artifact stores and artifact logging","Databricks integrations"],"104":["New feature or request"],"105":["Something isn't working","Issue is unique to windows.","Artifact stores and artifact logging","Model registry, model registry APIs, and the fluent client calls for model registry","Tracking service, tracking client APIs, autologging","Use of SQL alchemy in tracking service or model registry"],"106":["New feature or request","Artifact stores and artifact logging"],"107":[],"108":[],"109":["Something isn't working","Model registry, model registry APIs, and the fluent client calls for model registry","Docker use anywhere, such as MLprojects and MLmodels","Azure and Azure ML integrations"],"110":["Something isn't working","Tracking service, tracking client APIs, autologging","Use of SQL alchemy in tracking service or model registry"],"111":["List under Small Changes in Changelogs."],"112":["Something isn't working"],"113":["New feature or request","We would like help from the community to add this support","MLflow Model server, model deployment tools, Spark UDFs"],"114":["Something isn't working","We would like help from the community to add this support","Model registry, model registry APIs, and the fluent client calls for model registry","Tracking service, tracking client APIs, autologging"],"115":["Something isn't working"],"116":["New feature or request","Tracking service, tracking client APIs, autologging"],"117":["Something isn't working"],"118":["List under Small Changes in Changelogs.","Artifact stores and artifact logging","Use of SQL alchemy in tracking service or model registry"],"119":["New feature or request","Artifact stores and artifact logging","Use of SQL alchemy in tracking service or model registry"],"120":["New feature or request","Tracking service, tracking client APIs, autologging"],"121":[],"122":["Something isn't working"],"123":["Something isn't working","R APIs and clients","Tracking service, tracking client APIs, autologging"],"124":["List under Small Changes in Changelogs.","Tracking service, tracking client APIs, autologging"],"125":[],"126":["New feature or request","MLmodel format, model serialization\/deserialization, flavors"],"127":["Something isn't working"],"128":["New feature or request"],"129":["Mention under Features in Changelogs.","Tracking service, tracking client APIs, autologging"],"130":["Mention under Features in Changelogs.","MLmodel format, model serialization\/deserialization, flavors"],"131":["Something isn't working"],"132":["Something isn't working","Example code"],"133":[],"134":["Documentation issues"],"135":["Something isn't working"],"136":["Something isn't working","R APIs and clients","Model registry, model registry APIs, and the fluent client calls for model registry"],"137":["New feature or request","Tracking service, tracking client APIs, autologging"],"138":["Something isn't working"],"139":["Something isn't working","Artifact stores and artifact logging","MLmodel format, model serialization\/deserialization, flavors","Docker use anywhere, such as MLprojects and MLmodels"],"140":["Something isn't working","Tracking service, tracking client APIs, autologging"],"141":["List under Small Changes in Changelogs."],"142":["List under Small Changes in Changelogs.","MLproject format, project running backends"],"143":["Something isn't working"],"144":["Something isn't working"],"145":["Documentation issues"],"146":["New feature or request","Issue is unique to windows.","R APIs and clients","Java APIs and clients","Artifact stores and artifact logging","Tracking service, tracking client APIs, autologging","Proposals for new client languages"],"147":["New feature or request","MLflow Model server, model deployment tools, Spark UDFs"],"148":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Model registry, model registry APIs, and the fluent client calls for model registry"],"149":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Artifact stores and artifact logging","MLmodel format, model serialization\/deserialization, flavors","Azure and Azure ML integrations"],"150":["Something isn't working"],"151":["List under Small Changes in Changelogs.","Tracking service, tracking client APIs, autologging"],"152":["New feature or request","MLmodel format, model serialization\/deserialization, flavors"],"153":["Something isn't working"],"154":["Something isn't working","We would like help from the community to add this support","Artifact stores and artifact logging"],"155":["Documentation issues"],"156":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"157":["Something isn't working","MLflow Model server, model deployment tools, Spark UDFs"],"158":["MLflow Model server, model deployment tools, Spark UDFs"],"159":[],"160":["Something isn't working","This issue has been read and acknowledged by the MLflow admins.","MLmodel format, model serialization\/deserialization, flavors","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"161":["MLflow Model server, model deployment tools, Spark UDFs","Docker use anywhere, such as MLprojects and MLmodels"],"162":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server","We would like help from the community to add this support","MLproject format, project running backends","Databricks integrations"],"163":["Something isn't working","Artifact stores and artifact logging","Tracking service, tracking client APIs, autologging"],"164":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"165":["New feature or request","MLproject format, project running backends","Lowest priority. Possibly useful, but not yet enough support to actually get it done.","Databricks integrations"],"166":["Something isn't working","Use of SQL alchemy in tracking service or model registry","Build and test infrastructure for MLflow"],"167":["Something isn't working"],"168":["Something isn't working"],"169":[],"170":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Build and test infrastructure for MLflow"],"171":[],"172":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"173":["Something isn't working"],"174":["Something isn't working","Issue is unique to windows.","Artifact stores and artifact logging","Docker use anywhere, such as MLprojects and MLmodels"],"175":["New feature or request","MLmodel format, model serialization\/deserialization, flavors"],"176":["New feature or request"],"177":["Something isn't working","Example code","Docker use anywhere, such as MLprojects and MLmodels"],"178":["Something isn't working"],"179":["Mention under Bug Fixes in Changelogs.","Artifact stores and artifact logging","MLflow Model server, model deployment tools, Spark UDFs"],"180":["Something isn't working","Example code","MLproject format, project running backends","Tracking service, tracking client APIs, autologging"],"181":["New feature or request","Good for newcomers","Tracking service, tracking client APIs, autologging"],"182":["Something isn't working","Documentation issues","Build and test infrastructure for MLflow"],"183":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","We would like help from the community to add this support"],"184":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","This feature requires design and design review before starting coding"],"185":["Something isn't working","R APIs and clients","Tracking service, tracking client APIs, autologging"],"186":["Something isn't working"],"187":["Something isn't working","Tracking service, tracking client APIs, autologging"],"188":["New feature or request"],"189":["Something isn't working","Model registry, model registry APIs, and the fluent client calls for model registry","Tracking service, tracking client APIs, autologging"],"190":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Model registry, model registry APIs, and the fluent client calls for model registry"],"191":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Model registry, model registry APIs, and the fluent client calls for model registry"],"192":["New feature or request"],"193":["New feature or request","Tracking service, tracking client APIs, autologging"],"194":["New feature or request"],"195":["Something isn't working"],"196":["New feature or request","Sagemaker integrations"],"197":["Documentation issues","Mention under Features in Changelogs.","Artifact stores and artifact logging","MLmodel format, model serialization\/deserialization, flavors"],"198":["Documentation issues"],"199":["New feature or request"],"200":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors"],"201":["Something isn't working","MLproject format, project running backends","Important over the long term, but may not be staffed or may need multiple releases to complete."],"202":["Something isn't working"],"203":["New feature or request"],"204":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging"],"205":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging"],"206":["New feature or request"],"207":[],"208":["Something isn't working"],"209":["New feature or request"],"210":["New feature or request"],"211":["New feature or request","MLproject format, project running backends"],"212":["List under Small Changes in Changelogs.","Build and test infrastructure for MLflow"],"213":["New feature or request","MLflow Tracking server backend"],"214":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"215":["New feature or request"],"216":["Something isn't working","Tracking service, tracking client APIs, autologging"],"217":["Something isn't working"],"218":[],"219":["Something isn't working"],"220":["New feature or request","Artifact stores and artifact logging","MLmodel format, model serialization\/deserialization, flavors"],"221":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server","This issue has been read and acknowledged by the MLflow admins.","Artifact stores and artifact logging","Tracking service, tracking client APIs, autologging"],"222":["New feature or request","Artifact stores and artifact logging"],"223":["Something isn't working","This issue has been read and acknowledged by the MLflow admins.","We would like help from the community to add this support","Artifact stores and artifact logging","Model registry, model registry APIs, and the fluent client calls for model registry","MLmodel format, model serialization\/deserialization, flavors"],"224":[],"225":["Something isn't working","Issue is unique to windows.","MLmodel format, model serialization\/deserialization, flavors","MLflow Model server, model deployment tools, Spark UDFs"],"226":["Something isn't working","Artifact stores and artifact logging","Tracking service, tracking client APIs, autologging"],"227":["New feature or request","Artifact stores and artifact logging"],"228":["MLflow Tracking server backend"],"229":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors"],"230":["Something isn't working","Artifact stores and artifact logging"],"231":["Documentation issues"],"232":["New feature or request","Tracking service, tracking client APIs, autologging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"233":["New feature or request"],"234":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"235":[],"236":["Something isn't working","Model registry, model registry APIs, and the fluent client calls for model registry"],"237":[],"238":["Documentation issues"],"239":["Something isn't working"],"240":[],"241":["Something isn't working","Build and test infrastructure for MLflow"],"242":["New feature or request","Issue is unique to windows.","MLproject format, project running backends","Docker use anywhere, such as MLprojects and MLmodels"],"243":["Something isn't working","Artifact stores and artifact logging","MLmodel format, model serialization\/deserialization, flavors","MLflow Model server, model deployment tools, Spark UDFs","Tracking service, tracking client APIs, autologging","Sagemaker integrations"],"244":["MLproject format, project running backends","Docker use anywhere, such as MLprojects and MLmodels"],"245":["New feature or request"],"246":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"247":["New feature or request","Documentation issues","Tracking service, tracking client APIs, autologging","MLflow Tracking server backend"],"248":["New feature or request"],"249":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"250":["Something isn't working"],"251":["Documentation issues"],"252":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Model registry, model registry APIs, and the fluent client calls for model registry","MLmodel format, model serialization\/deserialization, flavors"],"253":["New feature or request","Tracking service, tracking client APIs, autologging"],"254":[],"255":["New feature or request"],"256":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging"],"257":["Something isn't working","We would like help from the community to add this support","Docker use anywhere, such as MLprojects and MLmodels","Sagemaker integrations"],"258":["List under Small Changes in Changelogs.","Artifact stores and artifact logging"],"259":["New feature or request"],"260":["New feature or request","MLmodel format, model serialization\/deserialization, flavors"],"261":["List under Small Changes in Changelogs.","Docker use anywhere, such as MLprojects and MLmodels"],"262":["Something isn't working","MLflow Tracking server backend"],"263":["Documentation issues"],"264":["Something isn't working","Sagemaker integrations"],"265":["Issue is unique to windows.","R APIs and clients","List under Small Changes in Changelogs."],"266":["Mention under Features in Changelogs.","Artifact stores and artifact logging","Tracking service, tracking client APIs, autologging","Azure and Azure ML integrations"],"267":["New feature or request"],"268":["Documentation issues"],"269":["Something isn't working"],"270":["Documentation issues"],"271":["Documentation issues"],"272":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors"],"273":["Something isn't working"],"274":[],"275":["Something isn't working"],"276":["New feature or request","MLflow Tracking server backend"],"277":["Mention under Features in Changelogs.","MLmodel format, model serialization\/deserialization, flavors","Docker use anywhere, such as MLprojects and MLmodels"],"278":["New feature or request"],"279":["Something isn't working"],"280":["New feature or request","R APIs and clients"],"281":["Documentation issues"],"282":["New feature or request","Java APIs and clients","Artifact stores and artifact logging","Databricks integrations"],"283":["Something isn't working","Tracking service, tracking client APIs, autologging"],"284":["Something isn't working","Artifact stores and artifact logging","Tracking service, tracking client APIs, autologging","Azure and Azure ML integrations","Databricks integrations"],"285":[],"286":[],"287":["Artifact stores and artifact logging","MLmodel format, model serialization\/deserialization, flavors"],"288":["New feature or request","Artifact stores and artifact logging","MLmodel format, model serialization\/deserialization, flavors"],"289":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"290":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Model registry, model registry APIs, and the fluent client calls for model registry","MLflow Model server, model deployment tools, Spark UDFs"],"291":["New feature or request"],"292":["Mention under Bug Fixes in Changelogs.","Artifact stores and artifact logging"],"293":["Something isn't working"],"294":["Something isn't working"],"295":[],"296":[],"297":["Something isn't working","Build and test infrastructure for MLflow"],"298":["New feature or request","Tracking service, tracking client APIs, autologging"],"299":[],"300":["Documentation issues","Mention under Features in Changelogs.","Mention under Documentation Changes in Changelogs.","MLproject format, project running backends","Docker use anywhere, such as MLprojects and MLmodels"],"301":["Something isn't working"],"302":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Model registry, model registry APIs, and the fluent client calls for model registry"],"303":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging"],"304":["New feature or request"],"305":[],"306":[],"307":[],"308":[],"309":["New feature or request","MLflow Model server, model deployment tools, Spark UDFs"],"310":["Something isn't working","Build and test infrastructure for MLflow"],"311":["Something isn't working","Tracking service, tracking client APIs, autologging","Use of SQL alchemy in tracking service or model registry"],"312":[],"313":["Something isn't working","Artifact stores and artifact logging","Tracking service, tracking client APIs, autologging"],"314":["Something isn't working","Example code","MLmodel format, model serialization\/deserialization, flavors","MLflow Model server, model deployment tools, Spark UDFs"],"315":["Something isn't working","Issue is unique to windows."],"316":["New feature or request","MLproject format, project running backends","Docker use anywhere, such as MLprojects and MLmodels"],"317":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Artifact stores and artifact logging"],"318":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Model registry, model registry APIs, and the fluent client calls for model registry"],"319":["Something isn't working"],"320":["Something isn't working","MLflow Model server, model deployment tools, Spark UDFs","Docker use anywhere, such as MLprojects and MLmodels","Sagemaker integrations"],"321":["Mention under Features in Changelogs.","Example code","MLproject format, project running backends","Docker use anywhere, such as MLprojects and MLmodels"],"322":[],"323":["Mention under Features in Changelogs.","We would like help from the community to add this support","MLmodel format, model serialization\/deserialization, flavors"],"324":["New feature or request","Artifact stores and artifact logging","Example code"],"325":["Something isn't working","Issue is waiting for the author to respond"],"326":["Mention under Features in Changelogs.","Tracking service, tracking client APIs, autologging"],"327":["New feature or request","We would like help from the community to add this support","Tracking service, tracking client APIs, autologging","Use of SQL alchemy in tracking service or model registry"],"328":["Mention under Features in Changelogs.","MLmodel format, model serialization\/deserialization, flavors","Docker use anywhere, such as MLprojects and MLmodels"],"329":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging"],"330":["New feature or request","Tracking service, tracking client APIs, autologging"],"331":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging"],"332":["New feature or request","Docker use anywhere, such as MLprojects and MLmodels"],"333":["New feature or request","Model registry, model registry APIs, and the fluent client calls for model registry"],"334":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging"],"335":["New feature or request","Build and test infrastructure for MLflow"],"336":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server","This issue has been read and acknowledged by the MLflow admins."],"337":["New feature or request"],"338":["New feature or request","MLproject format, project running backends"],"339":["New feature or request","MLmodel format, model serialization\/deserialization, flavors"],"340":["Something isn't working","Tracking service, tracking client APIs, autologging"],"341":["Something isn't working","Artifact stores and artifact logging"],"342":["New feature or request","Artifact stores and artifact logging","Azure and Azure ML integrations"],"343":["List under Small Changes in Changelogs."],"344":["New feature or request","Documentation issues","Front-end, user experience, plotting, JavaScript, JavaScript dev server","We would like help from the community to add this support"],"345":["Something isn't working","Use of SQL alchemy in tracking service or model registry","Build and test infrastructure for MLflow"],"346":["Issue is waiting for the author to respond"],"347":["New feature or request","Issue is waiting for the author to respond"],"348":["New feature or request","Tracking service, tracking client APIs, autologging"],"349":["Something isn't working","Issue is waiting for the author to respond","MLmodel format, model serialization\/deserialization, flavors","Tracking service, tracking client APIs, autologging"],"350":["Good for newcomers","Documentation issues"],"351":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Model registry, model registry APIs, and the fluent client calls for model registry"],"352":["Good for newcomers","Documentation issues"],"353":["Something isn't working","Tracking service, tracking client APIs, autologging","MLflow Tracking server backend"],"354":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Artifact stores and artifact logging"],"355":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","MLflow Model server, model deployment tools, Spark UDFs"],"356":[],"357":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"358":["New feature or request","Artifact stores and artifact logging"],"359":[],"360":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging"],"361":["MLproject format, project running backends"],"362":[],"363":["Something isn't working","Issue is waiting for the author to respond","MLproject format, project running backends"],"364":["New feature or request"],"365":["Documentation issues"],"366":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","MLflow Model server, model deployment tools, Spark UDFs"],"367":["New feature or request","Good for newcomers","Artifact stores and artifact logging","MLmodel format, model serialization\/deserialization, flavors"],"368":["List under Small Changes in Changelogs."],"369":["Something isn't working","Example code","MLmodel format, model serialization\/deserialization, flavors","Docker use anywhere, such as MLprojects and MLmodels"],"370":["Issue is waiting for the author to respond","Artifact stores and artifact logging"],"371":["New feature or request","MLproject format, project running backends","Docker use anywhere, such as MLprojects and MLmodels"],"372":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging"],"373":["Something isn't working","Example code","MLflow Model server, model deployment tools, Spark UDFs","Docker use anywhere, such as MLprojects and MLmodels"],"374":["Something isn't working"],"375":["Something isn't working","Issue is waiting for the author to respond"],"376":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"377":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"378":["Something isn't working","Tracking service, tracking client APIs, autologging"],"379":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"380":["Documentation issues"],"381":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","MLflow Tracking server backend"],"382":["Documentation issues"],"383":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","MLproject format, project running backends","MLflow Model server, model deployment tools, Spark UDFs","Docker use anywhere, such as MLprojects and MLmodels"],"384":["New feature or request","Artifact stores and artifact logging","MLmodel format, model serialization\/deserialization, flavors"],"385":["Something isn't working","Model registry, model registry APIs, and the fluent client calls for model registry","MLmodel format, model serialization\/deserialization, flavors"],"386":["List under Small Changes in Changelogs."],"387":["New feature or request","Documentation issues","MLproject format, project running backends","Docker use anywhere, such as MLprojects and MLmodels"],"388":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors"],"389":["Something isn't working","Tracking service, tracking client APIs, autologging"],"390":["Something isn't working","MLflow Model server, model deployment tools, Spark UDFs","Azure and Azure ML integrations"],"391":["New feature or request","Model registry, model registry APIs, and the fluent client calls for model registry","Tracking service, tracking client APIs, autologging","Databricks integrations"],"392":["New feature or request","Good for newcomers"],"393":["New feature or request","Tracking service, tracking client APIs, autologging"],"394":["Something isn't working","Artifact stores and artifact logging","Model registry, model registry APIs, and the fluent client calls for model registry","Use of SQL alchemy in tracking service or model registry","Build and test infrastructure for MLflow"],"395":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"396":["Mention under Features in Changelogs.","MLproject format, project running backends"],"397":["New feature or request","Artifact stores and artifact logging"],"398":["Something isn't working"],"399":["Documentation issues","Mention under Features in Changelogs.","Tracking service, tracking client APIs, autologging"],"400":["Something isn't working"],"401":["Mention under Features in Changelogs.","Model registry, model registry APIs, and the fluent client calls for model registry","Use of SQL alchemy in tracking service or model registry"],"402":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"403":["Something isn't working","Good for newcomers","MLmodel format, model serialization\/deserialization, flavors","Tracking service, tracking client APIs, autologging","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"404":["Something isn't working","Example code","MLmodel format, model serialization\/deserialization, flavors","Tracking service, tracking client APIs, autologging"],"405":["Something isn't working","Tracking service, tracking client APIs, autologging","Build and test infrastructure for MLflow"],"406":["List under Small Changes in Changelogs."],"407":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","MLflow Model server, model deployment tools, Spark UDFs"],"408":["Something isn't working","Documentation issues","This issue has been read and acknowledged by the MLflow admins.","Model registry, model registry APIs, and the fluent client calls for model registry","Azure and Azure ML integrations"],"409":["Something isn't working","R APIs and clients","Model registry, model registry APIs, and the fluent client calls for model registry","MLmodel format, model serialization\/deserialization, flavors","Docker use anywhere, such as MLprojects and MLmodels","Sagemaker integrations","Build and test infrastructure for MLflow"],"410":[],"411":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors","Tracking service, tracking client APIs, autologging"],"412":["Something isn't working","Artifact stores and artifact logging","Tracking service, tracking client APIs, autologging"],"413":["Something isn't working"],"414":["New feature or request","Artifact stores and artifact logging","Tracking service, tracking client APIs, autologging"],"415":[],"416":["Something isn't working","Artifact stores and artifact logging","Model registry, model registry APIs, and the fluent client calls for model registry"],"417":[],"418":["Something isn't working","Issue is unique to windows.","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Model registry, model registry APIs, and the fluent client calls for model registry","Docker use anywhere, such as MLprojects and MLmodels","Use of SQL alchemy in tracking service or model registry"],"419":["New feature or request","MLmodel format, model serialization\/deserialization, flavors"],"420":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors","Tracking service, tracking client APIs, autologging"],"421":["Something isn't working","Model registry, model registry APIs, and the fluent client calls for model registry"],"422":["Java APIs and clients","Tracking service, tracking client APIs, autologging"],"423":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors","MLflow Model server, model deployment tools, Spark UDFs"],"424":["Documentation issues"],"425":["Mention under Features in Changelogs.","Artifact stores and artifact logging"],"426":["MLproject format, project running backends"],"427":["Something isn't working","MLproject format, project running backends"],"428":["Mention under Features in Changelogs.","Mention under Bug Fixes in Changelogs.","Build and test infrastructure for MLflow"],"429":["Something isn't working","Example code","Build and test infrastructure for MLflow"],"430":["List under Small Changes in Changelogs."],"431":["New feature or request","Tracking service, tracking client APIs, autologging"],"432":["New feature or request","MLflow Model server, model deployment tools, Spark UDFs"],"433":["Something isn't working","MLproject format, project running backends","Docker use anywhere, such as MLprojects and MLmodels"],"434":["Something isn't working","MLproject format, project running backends"],"435":["New feature or request","Documentation issues","MLproject format, project running backends","Docker use anywhere, such as MLprojects and MLmodels"],"436":["List under Small Changes in Changelogs.","Java APIs and clients","Model registry, model registry APIs, and the fluent client calls for model registry"],"437":["New feature or request"],"438":["New feature or request","Artifact stores and artifact logging","Tracking service, tracking client APIs, autologging"],"439":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Artifact stores and artifact logging","Model registry, model registry APIs, and the fluent client calls for model registry"],"440":[],"441":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Example code","MLflow Model server, model deployment tools, Spark UDFs"],"442":["New feature or request","Example code","Tracking service, tracking client APIs, autologging"],"443":["Mention under Features in Changelogs.","Tracking service, tracking client APIs, autologging","Use of SQL alchemy in tracking service or model registry"],"444":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"445":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Model registry, model registry APIs, and the fluent client calls for model registry","Tracking service, tracking client APIs, autologging"],"446":["Something isn't working","Tracking service, tracking client APIs, autologging"],"447":["New feature or request","Tracking service, tracking client APIs, autologging","Use of SQL alchemy in tracking service or model registry"],"448":["Something isn't working","R APIs and clients","MLmodel format, model serialization\/deserialization, flavors"],"449":["Something isn't working"],"450":["Something isn't working","Tracking service, tracking client APIs, autologging","Docker use anywhere, such as MLprojects and MLmodels"],"451":["New feature or request"],"452":["Mention under Bug Fixes in Changelogs.","MLmodel format, model serialization\/deserialization, flavors"],"453":["Something isn't working"],"454":[],"455":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors"],"456":["New feature or request","MLflow Model server, model deployment tools, Spark UDFs"],"457":["MLflow Model server, model deployment tools, Spark UDFs"],"458":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"459":["MLmodel format, model serialization\/deserialization, flavors","Tracking service, tracking client APIs, autologging"],"460":["MLproject format, project running backends"],"461":["New feature or request","Model registry, model registry APIs, and the fluent client calls for model registry","MLmodel format, model serialization\/deserialization, flavors"],"462":["New feature or request","MLproject format, project running backends","Docker use anywhere, such as MLprojects and MLmodels"],"463":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging"],"464":["New feature or request","Tracking service, tracking client APIs, autologging","Use of SQL alchemy in tracking service or model registry"],"465":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Java APIs and clients","Model registry, model registry APIs, and the fluent client calls for model registry","Tracking service, tracking client APIs, autologging"],"466":["Something isn't working","Sagemaker integrations"],"467":["New feature or request"],"468":["Something isn't working","Model registry, model registry APIs, and the fluent client calls for model registry","MLmodel format, model serialization\/deserialization, flavors"],"469":["New feature or request","R APIs and clients"],"470":["New feature or request","R APIs and clients","MLmodel format, model serialization\/deserialization, flavors","Docker use anywhere, such as MLprojects and MLmodels"],"471":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors","MLflow Model server, model deployment tools, Spark UDFs"],"472":["New feature or request","Tracking service, tracking client APIs, autologging"],"473":[],"474":["Documentation issues"],"475":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"476":["Something isn't working","Issue is unique to windows."],"477":["R APIs and clients","Mention under Features in Changelogs.","Artifact stores and artifact logging"],"478":["Something isn't working","We would like help from the community to add this support","Tracking service, tracking client APIs, autologging","Use of SQL alchemy in tracking service or model registry"],"479":["New feature or request","Docker use anywhere, such as MLprojects and MLmodels","Build and test infrastructure for MLflow"],"480":["New feature or request","MLproject format, project running backends","Databricks integrations"],"481":["Documentation issues","Issue is waiting for the author to respond","Model registry, model registry APIs, and the fluent client calls for model registry"],"482":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Model registry, model registry APIs, and the fluent client calls for model registry"],"483":["Issue is unique to windows.","R APIs and clients","Mention under Bug Fixes in Changelogs.","MLmodel format, model serialization\/deserialization, flavors","Tracking service, tracking client APIs, autologging","MLflow Tracking server backend"],"484":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"485":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging"],"486":["Something isn't working"],"487":["Something isn't working"],"488":[],"489":["Something isn't working","Artifact stores and artifact logging","Azure and Azure ML integrations"],"490":["New feature or request","Tracking service, tracking client APIs, autologging"],"491":["New feature or request","MLproject format, project running backends"],"492":[],"493":["New feature or request"],"494":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Model registry, model registry APIs, and the fluent client calls for model registry"],"495":["New feature or request","Tracking service, tracking client APIs, autologging"],"496":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Docker use anywhere, such as MLprojects and MLmodels"],"497":["Something isn't working"],"498":["Tracking service, tracking client APIs, autologging"],"499":["List under Small Changes in Changelogs.","Example code"],"500":["Something isn't working","Artifact stores and artifact logging"],"501":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging"],"502":["Issue is waiting for the author to respond"],"503":["Something isn't working","Issue is unique to windows.","Tracking service, tracking client APIs, autologging"],"504":["New feature or request","Tracking service, tracking client APIs, autologging"],"505":["New feature or request"],"506":["New feature or request"],"507":["New feature or request"],"508":["New feature or request"],"509":["Something isn't working","Tracking service, tracking client APIs, autologging"],"510":["New feature or request"],"511":["New feature or request"],"512":["New feature or request","Documentation issues","Model registry, model registry APIs, and the fluent client calls for model registry"],"513":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors","MLflow Model server, model deployment tools, Spark UDFs"],"514":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors","MLflow Model server, model deployment tools, Spark UDFs"],"515":["Something isn't working"],"516":["Something isn't working","Tracking service, tracking client APIs, autologging"],"517":["New feature or request","MLproject format, project running backends"],"518":["Mention under Bug Fixes in Changelogs.","Artifact stores and artifact logging"],"519":["List under Small Changes in Changelogs.","Tracking service, tracking client APIs, autologging"],"520":["New feature or request","Tracking service, tracking client APIs, autologging"],"521":["Issue is unique to windows."],"522":["Something isn't working","Tracking service, tracking client APIs, autologging"],"523":[],"524":[],"525":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"526":["New feature or request","R APIs and clients"],"527":["New feature or request","Tracking service, tracking client APIs, autologging"],"528":["New feature or request","Documentation issues","Artifact stores and artifact logging","Model registry, model registry APIs, and the fluent client calls for model registry","Azure and Azure ML integrations"],"529":["New feature or request"],"530":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"531":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Model registry, model registry APIs, and the fluent client calls for model registry","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"532":["Something isn't working","Artifact stores and artifact logging","Use of SQL alchemy in tracking service or model registry"],"533":[],"534":["Something isn't working","Docker use anywhere, such as MLprojects and MLmodels","Azure and Azure ML integrations","Build and test infrastructure for MLflow"],"535":["Something isn't working"],"536":["Mention under Features in Changelogs.","Example code","MLproject format, project running backends"],"537":["New feature or request","Model registry, model registry APIs, and the fluent client calls for model registry","MLmodel format, model serialization\/deserialization, flavors"],"538":["New feature or request","Build and test infrastructure for MLflow"],"539":["New feature or request","MLmodel format, model serialization\/deserialization, flavors"],"540":["New feature or request","Tracking service, tracking client APIs, autologging"],"541":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Artifact stores and artifact logging","Model registry, model registry APIs, and the fluent client calls for model registry","MLmodel format, model serialization\/deserialization, flavors","Tracking service, tracking client APIs, autologging","Docker use anywhere, such as MLprojects and MLmodels"],"542":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors"],"543":["List under Small Changes in Changelogs.","Artifact stores and artifact logging","Sagemaker integrations"],"544":["New feature or request"],"545":["New feature or request","Artifact stores and artifact logging"],"546":["Tracking service, tracking client APIs, autologging"],"547":["New feature or request","Documentation issues","MLflow Model server, model deployment tools, Spark UDFs"],"548":["Something isn't working","Artifact stores and artifact logging","Model registry, model registry APIs, and the fluent client calls for model registry","MLmodel format, model serialization\/deserialization, flavors","Databricks integrations"],"549":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors"],"550":["Documentation issues","Tracking service, tracking client APIs, autologging"],"551":["Something isn't working","MLproject format, project running backends","Tracking service, tracking client APIs, autologging"],"552":["Documentation issues"],"553":["Documentation issues"],"554":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Databricks integrations"],"555":["Something isn't working"],"556":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","Tracking service, tracking client APIs, autologging"],"557":["Something isn't working","Tracking service, tracking client APIs, autologging"],"558":["Something isn't working"],"559":["Something isn't working","Tracking service, tracking client APIs, autologging"],"560":[],"561":["Model registry, model registry APIs, and the fluent client calls for model registry","MLmodel format, model serialization\/deserialization, flavors"],"562":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"563":["New feature or request","Documentation issues","Artifact stores and artifact logging","Example code","Model registry, model registry APIs, and the fluent client calls for model registry","MLmodel format, model serialization\/deserialization, flavors","Tracking service, tracking client APIs, autologging","MLflow Tracking server backend","Proposals for new client languages"],"564":["Documentation issues","Mention under Features in Changelogs.","Artifact stores and artifact logging","Model registry, model registry APIs, and the fluent client calls for model registry","Azure and Azure ML integrations"],"565":["New feature or request","Documentation issues","Artifact stores and artifact logging","Azure and Azure ML integrations"],"566":["Something isn't working","Build and test infrastructure for MLflow"],"567":["Something isn't working","Build and test infrastructure for MLflow"],"568":["Something isn't working","Build and test infrastructure for MLflow"],"569":["Something isn't working","R APIs and clients","Artifact stores and artifact logging","MLflow Tracking server backend"],"570":["Issue is unique to windows.","Tracking service, tracking client APIs, autologging"],"571":["Something isn't working","Tracking service, tracking client APIs, autologging"],"572":["Mention under Features in Changelogs.","Artifact stores and artifact logging","Model registry, model registry APIs, and the fluent client calls for model registry","Tracking service, tracking client APIs, autologging","MLflow Tracking server backend"],"573":["New feature or request","Documentation issues","Artifact stores and artifact logging","Example code"],"574":["Something isn't working","Documentation issues","Tracking service, tracking client APIs, autologging"],"575":["Documentation issues","List under Small Changes in Changelogs."],"576":["Documentation issues"],"577":[],"578":["Something isn't working","Azure and Azure ML integrations"],"579":["Something isn't working","Tracking service, tracking client APIs, autologging"],"580":["Something isn't working","Documentation issues","Example code","MLproject format, project running backends"],"581":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors","Tracking service, tracking client APIs, autologging"],"582":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Artifact stores and artifact logging"],"583":["New feature or request","Tracking service, tracking client APIs, autologging"],"584":["Something isn't working","Issue is unique to windows.","MLproject format, project running backends"],"585":["Something isn't working","Tracking service, tracking client APIs, autologging","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"586":["New feature or request","Artifact stores and artifact logging","Model registry, model registry APIs, and the fluent client calls for model registry","MLmodel format, model serialization\/deserialization, flavors","Important over the long term, but may not be staffed or may need multiple releases to complete."],"587":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"588":["New feature or request","MLmodel format, model serialization\/deserialization, flavors"],"589":["New feature or request","Documentation issues","R APIs and clients","Example code","MLmodel format, model serialization\/deserialization, flavors","Tracking service, tracking client APIs, autologging"],"590":["New feature or request","Tracking service, tracking client APIs, autologging"],"591":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors"],"592":["Something isn't working","MLflow Model server, model deployment tools, Spark UDFs","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"593":["Something isn't working","MLproject format, project running backends","Docker use anywhere, such as MLprojects and MLmodels"],"594":["Something isn't working","Tracking service, tracking client APIs, autologging"],"595":["Documentation issues"],"596":["Something isn't working","Issue is unique to windows.","R APIs and clients","Example code"],"597":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","Tracking service, tracking client APIs, autologging"],"598":["New feature or request","Tracking service, tracking client APIs, autologging"],"599":[],"600":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"601":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server","MLproject format, project running backends"],"602":["Something isn't working","MLproject format, project running backends","Docker use anywhere, such as MLprojects and MLmodels"],"603":["Mention under Bug Fixes in Changelogs.","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"604":["Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"605":["Mention under Features in Changelogs.","MLproject format, project running backends"],"606":["Something isn't working","Tracking service, tracking client APIs, autologging","Use of SQL alchemy in tracking service or model registry"],"607":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors","Tracking service, tracking client APIs, autologging"],"608":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors"],"609":["Something isn't working","Use of SQL alchemy in tracking service or model registry"],"610":["Something isn't working","MLflow Model server, model deployment tools, Spark UDFs"],"611":["Mention under Features in Changelogs.","Sagemaker integrations"],"612":["New feature or request","Sagemaker integrations"],"613":["Something isn't working","Tracking service, tracking client APIs, autologging"],"614":["Something isn't working","Issue is unique to windows.","MLmodel format, model serialization\/deserialization, flavors"],"615":["Mention under Features in Changelogs.","Model registry, model registry APIs, and the fluent client calls for model registry","Use of SQL alchemy in tracking service or model registry"],"616":["Something isn't working","Issue is unique to windows.","R APIs and clients"],"617":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors","MLflow Model server, model deployment tools, Spark UDFs"],"618":["New feature or request","Tracking service, tracking client APIs, autologging"],"619":["New feature or request"],"620":["New feature or request","Tracking service, tracking client APIs, autologging","Use of SQL alchemy in tracking service or model registry"],"621":["Mention under Bug Fixes in Changelogs.","MLmodel format, model serialization\/deserialization, flavors"],"622":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","MLflow Model server, model deployment tools, Spark UDFs"],"623":["New feature or request","Model registry, model registry APIs, and the fluent client calls for model registry"],"624":["New feature or request","MLproject format, project running backends"],"625":["New feature or request","Documentation issues","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging"],"626":["Mention under Features in Changelogs.","Model registry, model registry APIs, and the fluent client calls for model registry","Use of SQL alchemy in tracking service or model registry"],"627":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"628":["List under Small Changes in Changelogs.","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"629":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","We would like help from the community to add this support","Tracking service, tracking client APIs, autologging"],"630":["Something isn't working"],"631":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","Docker use anywhere, such as MLprojects and MLmodels"],"632":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","Docker use anywhere, such as MLprojects and MLmodels"],"633":["Documentation issues"],"634":[],"635":["Something isn't working","Use of SQL alchemy in tracking service or model registry"],"636":["Mention under Features in Changelogs.","Tracking service, tracking client APIs, autologging"],"637":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors","MLflow Model server, model deployment tools, Spark UDFs","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"638":["New feature or request","MLmodel format, model serialization\/deserialization, flavors"],"639":["Documentation issues","Artifact stores and artifact logging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"640":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"641":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","MLflow x Pytorch integrations"],"642":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors"],"643":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors"],"644":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Issue is waiting for the author to respond","Tracking service, tracking client APIs, autologging"],"645":["Mention under Features in Changelogs.","MLproject format, project running backends"],"646":["New feature or request","Docker use anywhere, such as MLprojects and MLmodels"],"647":["Something isn't working","R APIs and clients","Build and test infrastructure for MLflow"],"648":["New feature or request","Tracking service, tracking client APIs, autologging"],"649":["Mention under Features in Changelogs.","Tracking service, tracking client APIs, autologging"],"650":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"651":["Documentation issues","Tracking service, tracking client APIs, autologging","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"652":["New feature or request","Issue is unique to windows.","MLmodel format, model serialization\/deserialization, flavors","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"653":["Mention under Bug Fixes in Changelogs."],"654":["New feature or request","We would like help from the community to add this support","Model registry, model registry APIs, and the fluent client calls for model registry","Tracking service, tracking client APIs, autologging","This feature requires design and design review before starting coding"],"655":["New feature or request","Model registry, model registry APIs, and the fluent client calls for model registry","Tracking service, tracking client APIs, autologging"],"656":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","MLflow Model server, model deployment tools, Spark UDFs","The issue is worked on by the community currently or will be very soon, ideally in time for the","MLflow x Pytorch integrations"],"657":["Something isn't working","Artifact stores and artifact logging","MLmodel format, model serialization\/deserialization, flavors"],"658":["Something isn't working","Docker use anywhere, such as MLprojects and MLmodels"],"659":["Mention under Features in Changelogs.","Model registry, model registry APIs, and the fluent client calls for model registry"],"660":["New feature or request","Tracking service, tracking client APIs, autologging"],"661":["Mention under Bug Fixes in Changelogs.","Model registry, model registry APIs, and the fluent client calls for model registry"],"662":["New feature or request","We would like help from the community to add this support","Important over the long term, but may not be staffed or may need multiple releases to complete.","Build and test infrastructure for MLflow"],"663":["Something isn't working","Documentation issues","Example code","MLmodel format, model serialization\/deserialization, flavors","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"664":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"665":["New feature or request","Tracking service, tracking client APIs, autologging"],"666":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"667":["Something isn't working","Tracking service, tracking client APIs, autologging"],"668":["New feature or request","R APIs and clients","MLmodel format, model serialization\/deserialization, flavors","Important over the long term, but may not be staffed or may need multiple releases to complete."],"669":["New feature or request","MLproject format, project running backends","Important over the long term, but may not be staffed or may need multiple releases to complete."],"670":["Documentation issues","Issue is waiting for the author to respond"],"671":["Something isn't working","R APIs and clients","Tracking service, tracking client APIs, autologging","The issue needs feedback from a committer"],"672":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","Docker use anywhere, such as MLprojects and MLmodels","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"673":["Something isn't working","R APIs and clients","Artifact stores and artifact logging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"674":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","MLflow Model server, model deployment tools, Spark UDFs","The issue is worked on by the community currently or will be very soon, ideally in time for the","MLflow x Pytorch integrations"],"675":["Something isn't working","Example code","MLproject format, project running backends","Docker use anywhere, such as MLprojects and MLmodels","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"676":["List under Small Changes in Changelogs.","Tracking service, tracking client APIs, autologging"],"677":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"678":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"679":["New feature or request","MLproject format, project running backends","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"680":["Something isn't working","Tracking service, tracking client APIs, autologging","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"681":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"682":["Use of SQL alchemy in tracking service or model registry"],"683":["New feature or request","MLproject format, project running backends"],"684":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","We would like help from the community to add this support","Important over the long term, but may not be staffed or may need multiple releases to complete."],"685":["New feature or request","We would like help from the community to add this support","Model registry, model registry APIs, and the fluent client calls for model registry","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"686":["Something isn't working","Sagemaker integrations"],"687":["New feature or request","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"688":["New feature or request","Use of SQL alchemy in tracking service or model registry","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"689":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"690":["Documentation issues","Mention under Features in Changelogs.","MLproject format, project running backends","Docker use anywhere, such as MLprojects and MLmodels"],"691":["Something isn't working","R APIs and clients","Example code","MLproject format, project running backends","Tracking service, tracking client APIs, autologging","Use of SQL alchemy in tracking service or model registry","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"692":[],"693":["Something isn't working","Issue is unique to windows.","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"694":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","MLproject format, project running backends","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"695":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors","Important over the long term, but may not be staffed or may need multiple releases to complete."],"696":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"697":["New feature or request","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"698":["New feature or request","Tracking service, tracking client APIs, autologging"],"699":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","MLproject format, project running backends","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"700":[],"701":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"702":["New feature or request","Documentation issues","We would like help from the community to add this support","Model registry, model registry APIs, and the fluent client calls for model registry","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"703":["Something isn't working","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"704":["New feature or request","Artifact stores and artifact logging","Tracking service, tracking client APIs, autologging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"705":["List under Small Changes in Changelogs.","MLproject format, project running backends","Pull request is ready for code review"],"706":["Something isn't working","MLflow Model server, model deployment tools, Spark UDFs","Docker use anywhere, such as MLprojects and MLmodels","Sagemaker integrations","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"707":["New feature or request","Good for newcomers","We would like help from the community to add this support","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"708":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","MLflow Model server, model deployment tools, Spark UDFs","Important over the long term, but may not be staffed or may need multiple releases to complete.","MLflow x Pytorch integrations"],"709":["New feature or request","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"710":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","Important over the long term, but may not be staffed or may need multiple releases to complete."],"711":["New feature or request","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"712":["Tracking service, tracking client APIs, autologging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"713":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Artifact stores and artifact logging","Tracking service, tracking client APIs, autologging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"714":["New feature or request","Tracking service, tracking client APIs, autologging","Use of SQL alchemy in tracking service or model registry","Lowest priority. Possibly useful, but not yet enough support to actually get it done.","This feature requires design and design review before starting coding"],"715":["Issue is unique to windows.","Documentation issues","We would like help from the community to add this support"],"716":["Something isn't working","Documentation issues","Artifact stores and artifact logging","Example code","Docker use anywhere, such as MLprojects and MLmodels","Important over the long term, but may not be staffed or may need multiple releases to complete."],"717":["Mention under Features in Changelogs.","MLmodel format, model serialization\/deserialization, flavors"],"718":["New feature or request","Documentation issues","We would like help from the community to add this support","MLproject format, project running backends","The issue is worked on by the community currently or will be very soon, ideally in time for the","This feature requires design and design review before starting coding"],"719":["New feature or request","We would like help from the community to add this support","MLmodel format, model serialization\/deserialization, flavors","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"720":["New feature or request","We would like help from the community to add this support","MLproject format, project running backends","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"721":["Something isn't working","We would like help from the community to add this support","Example code","MLproject format, project running backends","Docker use anywhere, such as MLprojects and MLmodels","Important over the long term, but may not be staffed or may need multiple releases to complete."],"722":["New feature or request","We would like help from the community to add this support","Example code","MLproject format, project running backends","Docker use anywhere, such as MLprojects and MLmodels","Important over the long term, but may not be staffed or may need multiple releases to complete.","This feature requires design and design review before starting coding"],"723":["Mention under Features in Changelogs.","MLflow Model server, model deployment tools, Spark UDFs"],"724":["Model registry, model registry APIs, and the fluent client calls for model registry","MLflow Model server, model deployment tools, Spark UDFs"],"725":["Something isn't working","Artifact stores and artifact logging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"726":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"727":["Documentation issues","Artifact stores and artifact logging","MLmodel format, model serialization\/deserialization, flavors","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"728":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"729":["Documentation issues","Artifact stores and artifact logging","Tracking service, tracking client APIs, autologging","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"730":["Something isn't working","Documentation issues","MLmodel format, model serialization\/deserialization, flavors","MLflow Model server, model deployment tools, Spark UDFs","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"731":["New feature or request","MLflow Model server, model deployment tools, Spark UDFs","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"732":["MLproject format, project running backends","Pull request is ready for code review"],"733":["MLproject format, project running backends"],"734":["Something isn't working","MLproject format, project running backends","Important over the long term, but may not be staffed or may need multiple releases to complete."],"735":["New feature or request","Documentation issues","We would like help from the community to add this support","Model registry, model registry APIs, and the fluent client calls for model registry","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete.","This feature requires design and design review before starting coding"],"736":["Issue is waiting for the author to respond","MLproject format, project running backends"],"737":["Something isn't working","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"738":["Something isn't working","This issue has been read and acknowledged by the MLflow admins.","Artifact stores and artifact logging","Tracking service, tracking client APIs, autologging","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"739":["New feature or request","Issue is waiting for the author to respond","Artifact stores and artifact logging","MLmodel format, model serialization\/deserialization, flavors","MLflow Model server, model deployment tools, Spark UDFs","Tracking service, tracking client APIs, autologging","Sagemaker integrations","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"740":["Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"741":["Something isn't working","Good for newcomers","Documentation issues","This issue has been read and acknowledged by the MLflow admins.","We would like help from the community to add this support","MLproject format, project running backends","Tracking service, tracking client APIs, autologging","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"742":["Issue is waiting for the author to respond","Tracking service, tracking client APIs, autologging"],"743":["Documentation issues","Issue is waiting for the author to respond","Tracking service, tracking client APIs, autologging"],"744":["Something isn't working","This issue has been read and acknowledged by the MLflow admins.","Artifact stores and artifact logging","Docker use anywhere, such as MLprojects and MLmodels","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"745":["Artifact stores and artifact logging","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"746":["Something isn't working","Issue is unique to windows.","We would like help from the community to add this support","MLmodel format, model serialization\/deserialization, flavors","Important over the long term, but may not be staffed or may need multiple releases to complete."],"747":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors","MLflow Model server, model deployment tools, Spark UDFs","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"748":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"749":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","We would like help from the community to add this support","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"750":["Front-end, user experience, plotting, JavaScript, JavaScript dev server","Pull requests that update a dependency file","Pull request is ready for code review"],"751":["Artifact stores and artifact logging"],"752":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","This issue has been read and acknowledged by the MLflow admins.","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"753":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","This issue has been read and acknowledged by the MLflow admins.","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"754":["New feature or request","This issue has been read and acknowledged by the MLflow admins.","We would like help from the community to add this support","MLflow Model server, model deployment tools, Spark UDFs","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"755":["New feature or request","This issue has been read and acknowledged by the MLflow admins.","Sagemaker integrations"],"756":["Something isn't working","MLproject format, project running backends","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"757":["New feature or request","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"758":["Something isn't working","Tracking service, tracking client APIs, autologging"],"759":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","This issue has been read and acknowledged by the MLflow admins.","We would like help from the community to add this support","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"760":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","We would like help from the community to add this support","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"761":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Important over the long term, but may not be staffed or may need multiple releases to complete."],"762":["New feature or request","Documentation issues","We would like help from the community to add this support"],"763":["New feature or request","Artifact stores and artifact logging","Important over the long term, but may not be staffed or may need multiple releases to complete.","The issue needs feedback from a committer"],"764":["Documentation issues","Issue is waiting for the author to respond","Important over the long term, but may not be staffed or may need multiple releases to complete."],"765":["Something isn't working","Issue is unique to windows.","We believe it is useful, but don\u2019t see it being prioritized in the next few months.","Build and test infrastructure for MLflow"],"766":["Something isn't working","MLproject format, project running backends","Tracking service, tracking client APIs, autologging","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"767":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","This issue has been read and acknowledged by the MLflow admins.","We would like help from the community to add this support","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete.","This feature requires design and design review before starting coding"],"768":["Something isn't working","This issue has been read and acknowledged by the MLflow admins.","We would like help from the community to add this support","Tracking service, tracking client APIs, autologging","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"769":[],"770":["New feature or request","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"771":["Something isn't working","Good for newcomers","Artifact stores and artifact logging","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"772":["New feature or request","Artifact stores and artifact logging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"773":["Something isn't working","Artifact stores and artifact logging","Tracking service, tracking client APIs, autologging","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"774":["Something isn't working","This issue has been read and acknowledged by the MLflow admins.","Example code","MLproject format, project running backends","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"775":["New feature or request","This issue has been read and acknowledged by the MLflow admins.","MLmodel format, model serialization\/deserialization, flavors","Tracking service, tracking client APIs, autologging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"776":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","We would like help from the community to add this support","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"777":["New feature or request","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete.","Pull request is ready for code review"],"778":["New feature or request","We would like help from the community to add this support","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"779":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","This issue has been read and acknowledged by the MLflow admins.","Model registry, model registry APIs, and the fluent client calls for model registry","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"780":["Java APIs and clients","This issue has been read and acknowledged by the MLflow admins.","We would like help from the community to add this support","Tracking service, tracking client APIs, autologging"],"781":["Something isn't working","This issue has been read and acknowledged by the MLflow admins.","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"782":["New feature or request","Pull requests that update a dependency file","This issue has been read and acknowledged by the MLflow admins.","We would like help from the community to add this support","MLmodel format, model serialization\/deserialization, flavors","MLflow Model server, model deployment tools, Spark UDFs","Docker use anywhere, such as MLprojects and MLmodels","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"783":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors","Docker use anywhere, such as MLprojects and MLmodels","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"784":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","We would like help from the community to add this support","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"785":["New feature or request","This issue has been read and acknowledged by the MLflow admins.","MLproject format, project running backends","Docker use anywhere, such as MLprojects and MLmodels","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"786":["Mention under Bug Fixes in Changelogs.","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging"],"787":["Artifact stores and artifact logging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"788":["Something isn't working","We would like help from the community to add this support","Sagemaker integrations"],"789":["New feature or request","We would like help from the community to add this support","Important over the long term, but may not be staffed or may need multiple releases to complete.","Build and test infrastructure for MLflow"],"790":["Mention under Bug Fixes in Changelogs."],"791":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"792":["Something isn't working","This issue has been read and acknowledged by the MLflow admins.","MLmodel format, model serialization\/deserialization, flavors","Important over the long term, but may not be staffed or may need multiple releases to complete."],"793":["Something isn't working","Tracking service, tracking client APIs, autologging","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"794":["Something isn't working","Documentation issues","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"795":[],"796":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"797":["New feature or request","Good for newcomers","We would like help from the community to add this support","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"798":["New feature or request","Artifact stores and artifact logging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"799":["Something isn't working","Issue is unique to windows.","Docker use anywhere, such as MLprojects and MLmodels","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"800":["Something isn't working","Sagemaker integrations"],"801":["Mention under Features in Changelogs."],"802":["Something isn't working","Sagemaker integrations"],"803":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"804":["New feature or request","This issue has been read and acknowledged by the MLflow admins.","MLmodel format, model serialization\/deserialization, flavors","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"805":["New feature or request","Tracking service, tracking client APIs, autologging","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"806":["New feature or request","Artifact stores and artifact logging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"807":["Something isn't working","MLproject format, project running backends","Important over the long term, but may not be staffed or may need multiple releases to complete."],"808":[],"809":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","This issue has been read and acknowledged by the MLflow admins.","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"810":["Mention under Features in Changelogs."],"811":["Something isn't working","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"812":["New feature or request","Tracking service, tracking client APIs, autologging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"813":["Something isn't working","Use of SQL alchemy in tracking service or model registry","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"814":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"815":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Important over the long term, but may not be staffed or may need multiple releases to complete."],"816":["New feature or request","Tracking service, tracking client APIs, autologging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"817":[],"818":["New feature or request","This issue has been read and acknowledged by the MLflow admins.","MLflow Model server, model deployment tools, Spark UDFs","Docker use anywhere, such as MLprojects and MLmodels","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"819":["New feature or request","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"820":["New feature or request","MLproject format, project running backends","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"821":["New feature or request","Tracking service, tracking client APIs, autologging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"822":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"823":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"824":["Mention under Bug Fixes in Changelogs."],"825":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"826":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors","Sagemaker integrations","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"827":["New feature or request","Java APIs and clients","MLmodel format, model serialization\/deserialization, flavors","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"828":["New feature or request","We would like help from the community to add this support","Model registry, model registry APIs, and the fluent client calls for model registry","Tracking service, tracking client APIs, autologging","Use of SQL alchemy in tracking service or model registry","Important over the long term, but may not be staffed or may need multiple releases to complete.","This feature requires design and design review before starting coding"],"829":["Something isn't working","Tracking service, tracking client APIs, autologging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"830":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"831":["New feature or request","MLflow Model server, model deployment tools, Spark UDFs","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"832":[],"833":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"834":["Something isn't working","We would like help from the community to add this support","Use of SQL alchemy in tracking service or model registry","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"835":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"836":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors","Important over the long term, but may not be staffed or may need multiple releases to complete."],"837":["Something isn't working","Artifact stores and artifact logging","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"838":["New feature or request","Good for newcomers","Issue is unique to windows."],"839":["Mention under Features in Changelogs.","Front-end, user experience, plotting, JavaScript, JavaScript dev server"],"840":["New feature or request","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"841":["New feature or request","We would like help from the community to add this support","We believe it is useful, but don\u2019t see it being prioritized in the next few months.","This feature requires design and design review before starting coding","Build and test infrastructure for MLflow"],"842":["Something isn't working","Issue is unique to windows.","MLproject format, project running backends","Important over the long term, but may not be staffed or may need multiple releases to complete."],"843":["New feature or request","MLproject format, project running backends","MLflow Model server, model deployment tools, Spark UDFs","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"844":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"845":[],"846":["New feature or request","MLproject format, project running backends","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"847":["New feature or request","This issue has been read and acknowledged by the MLflow admins.","MLmodel format, model serialization\/deserialization, flavors","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"848":["New feature or request","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"849":["Something isn't working","MLflow Model server, model deployment tools, Spark UDFs","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"850":["Documentation issues","Important over the long term, but may not be staffed or may need multiple releases to complete."],"851":["Something isn't working","Tracking service, tracking client APIs, autologging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"852":[],"853":["Something isn't working","Issue is waiting for the author to respond","Tracking service, tracking client APIs, autologging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"854":[],"855":["New feature or request","MLproject format, project running backends","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"856":[],"857":[],"858":["Something isn't working","We would like help from the community to add this support","Model registry, model registry APIs, and the fluent client calls for model registry","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"859":["New feature or request","Docker use anywhere, such as MLprojects and MLmodels","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"860":["Docker use anywhere, such as MLprojects and MLmodels","The issue needs feedback from a committer"],"861":[],"862":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"863":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"864":["Something isn't working","","MLflow Model server, model deployment tools, Spark UDFs","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"865":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Artifact stores and artifact logging","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"866":[],"867":["New feature or request","Model registry, model registry APIs, and the fluent client calls for model registry","Important over the long term, but may not be staffed or may need multiple releases to complete."],"868":[],"869":["Documentation issues","Mention under Features in Changelogs.","MLproject format, project running backends","Docker use anywhere, such as MLprojects and MLmodels"],"870":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"871":["Something isn't working","We would like help from the community to add this support","MLproject format, project running backends","Docker use anywhere, such as MLprojects and MLmodels","Important over the long term, but may not be staffed or may need multiple releases to complete."],"872":["New feature or request","Artifact stores and artifact logging","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"873":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"874":["Something isn't working","Artifact stores and artifact logging","Tracking service, tracking client APIs, autologging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"875":["Something isn't working","","MLmodel format, model serialization\/deserialization, flavors","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"876":["New feature or request","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"877":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server","","Important over the long term, but may not be staffed or may need multiple releases to complete."],"878":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Issue is waiting for the author to respond"],"879":[],"880":["Something isn't working","","Tracking service, tracking client APIs, autologging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"881":["Documentation issues","","We would like help from the community to add this support","Tracking service, tracking client APIs, autologging"],"882":["New feature or request","Tracking service, tracking client APIs, autologging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"883":["Something isn't working","We would like help from the community to add this support","Tracking service, tracking client APIs, autologging"],"884":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months.","This feature requires design and design review before starting coding"],"885":["Something isn't working","Docker use anywhere, such as MLprojects and MLmodels","Important over the long term, but may not be staffed or may need multiple releases to complete."],"886":["New feature or request","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"887":["New feature or request","Artifact stores and artifact logging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"888":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Important over the long term, but may not be staffed or may need multiple releases to complete."],"889":["New feature or request","Artifact stores and artifact logging","Tracking service, tracking client APIs, autologging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"890":["","Artifact stores and artifact logging","Tracking service, tracking client APIs, autologging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"891":["Something isn't working","","Tracking service, tracking client APIs, autologging"],"892":["New feature or request","Good for newcomers","Front-end, user experience, plotting, JavaScript, JavaScript dev server","We would like help from the community to add this support","Important over the long term, but may not be staffed or may need multiple releases to complete."],"893":["New feature or request","We would like help from the community to add this support","Tracking service, tracking client APIs, autologging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"894":["Something isn't working","We would like help from the community to add this support","MLproject format, project running backends","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"895":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors"],"896":["New feature or request","Tracking service, tracking client APIs, autologging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"897":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"898":["Something isn't working","Front-end, user experience, plotting, JavaScript, JavaScript dev server","","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"899":["New feature or request","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"900":["Something isn't working","MLmodel format, model serialization\/deserialization, flavors","Tracking service, tracking client APIs, autologging","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"901":["New feature or request","Docker use anywhere, such as MLprojects and MLmodels","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"902":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"903":["Something isn't working","Issue is unique to windows."],"904":["New feature or request","Good for newcomers","MLproject format, project running backends","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"905":["New feature or request","This issue has been read and acknowledged by the MLflow admins.","We would like help from the community to add this support","MLproject format, project running backends","Important over the long term, but may not be staffed or may need multiple releases to complete."],"906":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","Important over the long term, but may not be staffed or may need multiple releases to complete."],"907":["Good for newcomers","MLmodel format, model serialization\/deserialization, flavors","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"908":["New feature or request","MLflow Model server, model deployment tools, Spark UDFs","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"909":["New feature or request","Tracking service, tracking client APIs, autologging"],"910":["Something isn't working","Docker use anywhere, such as MLprojects and MLmodels","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"911":["New feature or request","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"912":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"913":[],"914":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"915":[],"916":["Something isn't working","Good for newcomers","We would like help from the community to add this support","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"917":["New feature or request","Tracking service, tracking client APIs, autologging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"918":["New feature or request","This issue has been read and acknowledged by the MLflow admins.","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"919":[],"920":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","This issue has been read and acknowledged by the MLflow admins.","Important over the long term, but may not be staffed or may need multiple releases to complete."],"921":["Something isn't working","","Example code","MLproject format, project running backends","Important over the long term, but may not be staffed or may need multiple releases to complete."],"922":["New feature or request","Artifact stores and artifact logging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"923":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Important over the long term, but may not be staffed or may need multiple releases to complete."],"924":[],"925":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","We would like help from the community to add this support","Important over the long term, but may not be staffed or may need multiple releases to complete."],"926":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"927":["Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"928":["Something isn't working","","Artifact stores and artifact logging","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"929":[],"930":["New feature or request","","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"931":["New feature or request","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"932":[],"933":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","This issue has been read and acknowledged by the MLflow admins.","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"934":["New feature or request","We would like help from the community to add this support","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"935":["New feature or request","MLmodel format, model serialization\/deserialization, flavors","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"936":["New feature or request","Model registry, model registry APIs, and the fluent client calls for model registry","MLflow Model server, model deployment tools, Spark UDFs","Important over the long term, but may not be staffed or may need multiple releases to complete."],"937":["Something isn't working","","MLproject format, project running backends","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"938":["New feature or request","We would like help from the community to add this support","The issue is worked on by the community currently or will be very soon, ideally in time for the","Build and test infrastructure for MLflow"],"939":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"940":[],"941":["New feature or request","Tracking service, tracking client APIs, autologging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"942":["New feature or request","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"943":["New feature or request","Artifact stores and artifact logging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"944":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","We would like help from the community to add this support","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"945":["New feature or request","MLproject format, project running backends","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"946":["New feature or request","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"947":["New feature or request","MLproject format, project running backends","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"948":["Something isn't working","Issue is unique to windows.","This issue has been read and acknowledged by the MLflow admins.","MLproject format, project running backends","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"949":["New feature or request","Artifact stores and artifact logging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"950":["New feature or request","MLflow Model server, model deployment tools, Spark UDFs","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"951":["New feature or request","Important over the long term, but may not be staffed or may need multiple releases to complete.","Build and test infrastructure for MLflow"],"952":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"953":[],"954":["New feature or request","This issue has been read and acknowledged by the MLflow admins.","MLproject format, project running backends","Important over the long term, but may not be staffed or may need multiple releases to complete."],"955":[],"956":["New feature or request","Artifact stores and artifact logging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"957":["New feature or request","Artifact stores and artifact logging","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"958":["New feature or request","Mention under Breaking Changes in Changelogs.","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months.","This feature requires design and design review before starting coding"],"959":["We believe it is useful, but don\u2019t see it being prioritized in the next few months.","Build and test infrastructure for MLflow"],"960":["New feature or request","Use of SQL alchemy in tracking service or model registry","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"961":["New feature or request","We would like help from the community to add this support","MLflow Model server, model deployment tools, Spark UDFs","Important over the long term, but may not be staffed or may need multiple releases to complete.","This feature requires design and design review before starting coding"],"962":["New feature or request","This issue has been read and acknowledged by the MLflow admins.","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"963":["New feature or request","Tracking service, tracking client APIs, autologging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"964":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"965":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","This issue has been read and acknowledged by the MLflow admins.","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"966":[],"967":[],"968":[""],"969":["Documentation issues","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"970":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","This issue has been read and acknowledged by the MLflow admins.","Important over the long term, but may not be staffed or may need multiple releases to complete."],"971":[],"972":["New feature or request","Tracking service, tracking client APIs, autologging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"973":["New feature or request","Java APIs and clients","Tracking service, tracking client APIs, autologging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"974":[],"975":["Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"976":["Something isn't working","R APIs and clients","This issue has been read and acknowledged by the MLflow admins."],"977":[],"978":["Front-end, user experience, plotting, JavaScript, JavaScript dev server","The issue is worked on by the community currently or will be very soon, ideally in time for the"],"979":[],"980":["New feature or request","This issue has been read and acknowledged by the MLflow admins.","Tracking service, tracking client APIs, autologging"],"981":["New feature or request","MLflow Model server, model deployment tools, Spark UDFs","Important over the long term, but may not be staffed or may need multiple releases to complete."],"982":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"983":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","This issue has been read and acknowledged by the MLflow admins.","Important over the long term, but may not be staffed or may need multiple releases to complete."],"984":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","This issue has been read and acknowledged by the MLflow admins.","Important over the long term, but may not be staffed or may need multiple releases to complete."],"985":["New feature or request","Important over the long term, but may not be staffed or may need multiple releases to complete.","Build and test infrastructure for MLflow"],"986":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"987":["New feature or request","Tracking service, tracking client APIs, autologging","Important over the long term, but may not be staffed or may need multiple releases to complete."],"988":["New feature or request","Tracking service, tracking client APIs, autologging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"989":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","This issue has been read and acknowledged by the MLflow admins.","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"990":["New feature or request","Issue is waiting for the author to respond","Sagemaker integrations"],"991":[],"992":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","This issue has been read and acknowledged by the MLflow admins.","Important over the long term, but may not be staffed or may need multiple releases to complete."],"993":["New feature or request","R APIs and clients","MLmodel format, model serialization\/deserialization, flavors","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"994":["New feature or request","Good for newcomers","This issue has been read and acknowledged by the MLflow admins.","MLproject format, project running backends","We believe it is useful, but don\u2019t see it being prioritized in the next few months.","Databricks integrations"],"995":["New feature or request","We believe it is useful, but don\u2019t see it being prioritized in the next few months.","Build and test infrastructure for MLflow"],"996":["New feature or request","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"997":["New feature or request","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."],"998":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","This issue has been read and acknowledged by the MLflow admins.","We would like help from the community to add this support","Tracking service, tracking client APIs, autologging","Lowest priority. Possibly useful, but not yet enough support to actually get it done."],"999":["New feature or request","Front-end, user experience, plotting, JavaScript, JavaScript dev server","This issue has been read and acknowledged by the MLflow admins.","Tracking service, tracking client APIs, autologging","We believe it is useful, but don\u2019t see it being prioritized in the next few months."]}}